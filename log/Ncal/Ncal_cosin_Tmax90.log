nohup: ignoring input
main.py:110: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
n_per_node: 8
gpu 6
Use GPU: 6 for training
create model mf294
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 16, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 24, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 48, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 48, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 96, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 96, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 192, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 192, token: 192
L2G: 2 heads, inp: 192, token: 192
MobileFormer(
  (tokens): Embedding(6, 192)
  (stem): Sequential(
    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (features): Sequential(
    (0): DnaBlock3(
      (conv): Sequential(
        (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=16, bias=False)
        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Sequential()
        (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (5): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(16, 96, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=16, bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(24, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=16, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=16, bias=True)
        (proj): Linear(in_features=16, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (2): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=192, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=192, out_features=24, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (3): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(24, 144, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=288, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(144, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(48, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=48, bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (4): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=192, bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=384, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=192, out_features=48, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (5): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(48, 288, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=48, bias=False)
        (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=576, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(288, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(96, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(384, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=48, bias=True)
        (proj): Linear(in_features=48, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (6): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(96, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=384, bias=False)
        (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=768, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(384, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=192, out_features=96, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (7): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(96, 576, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(576, 576, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=576, bias=False)
        (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1152, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(576, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=96, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=96, bias=True)
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (8): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(128, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768, bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(768, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (9): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(128, 768, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(768, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(192, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=192, bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(768, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (10): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1152, 1152, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1152, bias=False)
        (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
    (11): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1152, 1152, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1152, bias=False)
        (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2304, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=192, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=192, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
    )
  )
  (local_global): Local2Global(
    (alpha): Sequential(
      (0): Linear(in_features=192, out_features=192, bias=True)
      (1): h_sigmoid(
        (relu): ReLU6(inplace=True)
      )
    )
    (q): Linear(in_features=192, out_features=192, bias=True)
    (proj): Linear(in_features=192, out_features=192, bias=True)
    (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (drop_path): DropPath(drop_prob=0.000)
  )
  (classifier): MergeClassifier(
    (conv): Sequential(
      (0): Sequential()
      (1): Conv3d(192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (2): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (act): DyReLU(
      (act): ReLU6(inplace=True)
    )
    (hyper): Sequential()
    (avgpool): Sequential(
      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=1344, out_features=1920, bias=True)
      (1): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.0, inplace=False)
      (1): Linear(in_features=1920, out_features=101, bias=True)
    )
  )
)
############################### Dataset loading ###############################
/home/amax/anaconda3/envs/yuan/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
###############################  Dataset loaded  ##############################
Epoch: [0][  0/109]	Time 11.145 (11.145)	Data  3.210 ( 3.210)	Loss 4.6424951553344727 (4.6424951553344727)	Acc@1   1.56 (  1.56)	Acc@5   3.12 (  3.12)
Epoch: [0][ 10/109]	Time  0.435 ( 1.405)	Data  0.000 ( 0.292)	Loss 4.2607488632202148 (4.3852987289428711)	Acc@1  12.50 ( 14.91)	Acc@5  25.00 ( 25.00)
Epoch: [0][ 20/109]	Time  0.481 ( 0.940)	Data  0.000 ( 0.153)	Loss 3.9828560352325439 (4.2112222626095726)	Acc@1  20.31 ( 16.44)	Acc@5  32.81 ( 28.27)
Epoch: [0][ 30/109]	Time  0.410 ( 0.767)	Data  0.000 ( 0.104)	Loss 3.1311604976654053 (4.0230293197016564)	Acc@1  32.81 ( 19.56)	Acc@5  51.56 ( 31.80)
Epoch: [0][ 40/109]	Time  0.380 ( 0.678)	Data  0.000 ( 0.079)	Loss 3.3563055992126465 (3.9839928440931365)	Acc@1  29.69 ( 19.70)	Acc@5  40.62 ( 32.16)
Epoch: [0][ 50/109]	Time  0.394 ( 0.624)	Data  0.000 ( 0.063)	Loss 3.5871884822845459 (3.9257433835197899)	Acc@1  28.12 ( 20.37)	Acc@5  40.62 ( 32.87)
Epoch: [0][ 60/109]	Time  0.435 ( 0.590)	Data  0.000 ( 0.053)	Loss 3.8395516872406006 (3.8932991379597146)	Acc@1  20.31 ( 20.54)	Acc@5  37.50 ( 33.40)
Epoch: [0][ 70/109]	Time  0.383 ( 0.569)	Data  0.000 ( 0.045)	Loss 3.5465002059936523 (3.8589900983891017)	Acc@1  25.00 ( 20.84)	Acc@5  37.50 ( 34.18)
Epoch: [0][ 80/109]	Time  0.380 ( 0.549)	Data  0.000 ( 0.040)	Loss 3.8350694179534912 (3.8199707107779419)	Acc@1  20.31 ( 21.20)	Acc@5  39.06 ( 34.84)
Epoch: [0][ 90/109]	Time  0.391 ( 0.532)	Data  0.000 ( 0.036)	Loss 3.1768054962158203 (3.7786753203842665)	Acc@1  26.56 ( 21.41)	Acc@5  48.44 ( 35.46)
Epoch: [0][100/109]	Time  0.369 ( 0.518)	Data  0.000 ( 0.032)	Loss 4.4724550247192383 (3.7480209463893779)	Acc@1  14.06 ( 21.80)	Acc@5  26.56 ( 36.12)
epoch: 0, Avg_Loss 3.7318042943237026
Test: [ 0/28]	Time  4.870 ( 4.870)	Loss 2.8793e+00 (2.8793e+00)	Acc@1  29.69 ( 29.69)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  1.178 ( 0.832)	Loss 4.4422e+00 (2.3828e+00)	Acc@1   1.56 ( 49.72)	Acc@5  10.94 ( 69.03)
Test: [20/28]	Time  0.091 ( 0.625)	Loss 5.5450e+00 (3.8649e+00)	Acc@1   0.00 ( 26.93)	Acc@5   7.81 ( 42.56)
 * Acc@1 20.540 Acc@5 37.423
Epoch: [1][  0/109]	Time  4.069 ( 4.069)	Data  3.510 ( 3.510)	Loss 3.5968403816223145 (3.5968403816223145)	Acc@1  23.44 ( 23.44)	Acc@5  32.81 ( 32.81)
Epoch: [1][ 10/109]	Time  0.454 ( 0.769)	Data  0.000 ( 0.319)	Loss 3.8566763401031494 (3.4366932348771528)	Acc@1  17.19 ( 23.86)	Acc@5  32.81 ( 42.90)
Epoch: [1][ 20/109]	Time  0.451 ( 0.647)	Data  0.000 ( 0.167)	Loss 3.5124478340148926 (3.4159142743973505)	Acc@1  25.00 ( 25.30)	Acc@5  37.50 ( 41.89)
Epoch: [1][ 30/109]	Time  0.464 ( 0.565)	Data  0.000 ( 0.113)	Loss 3.1423027515411377 (3.4020192469319990)	Acc@1  35.94 ( 26.41)	Acc@5  50.00 ( 42.79)
Epoch: [1][ 40/109]	Time  0.420 ( 0.526)	Data  0.000 ( 0.086)	Loss 3.4800760746002197 (3.3976557371093006)	Acc@1  25.00 ( 26.64)	Acc@5  40.62 ( 43.45)
Epoch: [1][ 50/109]	Time  0.383 ( 0.506)	Data  0.000 ( 0.069)	Loss 3.3081398010253906 (3.3655024182562734)	Acc@1  25.00 ( 26.87)	Acc@5  42.19 ( 43.60)
Epoch: [1][ 60/109]	Time  0.365 ( 0.493)	Data  0.000 ( 0.058)	Loss 3.5955927371978760 (3.3697897293528571)	Acc@1  21.88 ( 26.36)	Acc@5  37.50 ( 43.16)
Epoch: [1][ 70/109]	Time  0.442 ( 0.482)	Data  0.000 ( 0.050)	Loss 2.9292824268341064 (3.3577522727805125)	Acc@1  32.81 ( 26.43)	Acc@5  48.44 ( 43.68)
Epoch: [1][ 80/109]	Time  0.383 ( 0.473)	Data  0.000 ( 0.044)	Loss 3.2586073875427246 (3.3281456658869613)	Acc@1  28.12 ( 26.72)	Acc@5  37.50 ( 43.90)
Epoch: [1][ 90/109]	Time  0.454 ( 0.464)	Data  0.000 ( 0.039)	Loss 3.1615960597991943 (3.3129814588106594)	Acc@1  25.00 ( 26.68)	Acc@5  46.88 ( 44.20)
Epoch: [1][100/109]	Time  0.401 ( 0.455)	Data  0.000 ( 0.035)	Loss 3.2935538291931152 (3.2979646059546139)	Acc@1  26.56 ( 26.89)	Acc@5  51.56 ( 44.51)
epoch: 1, Avg_Loss 3.275608058369488
Test: [ 0/28]	Time  3.421 ( 3.421)	Loss 2.3825e+00 (2.3825e+00)	Acc@1  48.44 ( 48.44)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.128 ( 0.523)	Loss 3.7295e+00 (2.3249e+00)	Acc@1  12.50 ( 49.86)	Acc@5  37.50 ( 69.89)
Test: [20/28]	Time  0.088 ( 0.385)	Loss 4.6385e+00 (3.3162e+00)	Acc@1   1.56 ( 27.01)	Acc@5  10.94 ( 43.53)
 * Acc@1 22.454 Acc@5 39.336
Epoch: [2][  0/109]	Time  3.995 ( 3.995)	Data  3.551 ( 3.551)	Loss 2.6319992542266846 (2.6319992542266846)	Acc@1  43.75 ( 43.75)	Acc@5  59.38 ( 59.38)
Epoch: [2][ 10/109]	Time  0.370 ( 0.744)	Data  0.000 ( 0.323)	Loss 2.9946684837341309 (3.0729542428796943)	Acc@1  28.12 ( 29.40)	Acc@5  51.56 ( 50.99)
Epoch: [2][ 20/109]	Time  0.485 ( 0.597)	Data  0.000 ( 0.173)	Loss 2.8114361763000488 (3.1157728944505965)	Acc@1  34.38 ( 29.02)	Acc@5  56.25 ( 49.18)
Epoch: [2][ 30/109]	Time  0.465 ( 0.541)	Data  0.000 ( 0.117)	Loss 2.6994926929473877 (3.0798610102745796)	Acc@1  42.19 ( 30.24)	Acc@5  59.38 ( 49.75)
Epoch: [2][ 40/109]	Time  0.503 ( 0.513)	Data  0.000 ( 0.089)	Loss 2.8452689647674561 (3.0753870824488199)	Acc@1  40.62 ( 30.41)	Acc@5  60.94 ( 49.09)
Epoch: [2][ 50/109]	Time  0.418 ( 0.495)	Data  0.000 ( 0.071)	Loss 2.8088202476501465 (3.0537051967546049)	Acc@1  37.50 ( 30.91)	Acc@5  59.38 ( 49.69)
Epoch: [2][ 60/109]	Time  0.536 ( 0.497)	Data  0.000 ( 0.060)	Loss 2.5669317245483398 (3.0337887865598083)	Acc@1  37.50 ( 31.28)	Acc@5  62.50 ( 49.97)
Epoch: [2][ 70/109]	Time  0.416 ( 0.489)	Data  0.000 ( 0.051)	Loss 3.5965566635131836 (3.0328673745544865)	Acc@1  17.19 ( 31.43)	Acc@5  42.19 ( 50.02)
Epoch: [2][ 80/109]	Time  0.444 ( 0.479)	Data  0.000 ( 0.045)	Loss 2.8790516853332520 (3.0257356991002591)	Acc@1  37.50 ( 31.44)	Acc@5  53.12 ( 50.12)
Epoch: [2][ 90/109]	Time  0.390 ( 0.472)	Data  0.000 ( 0.040)	Loss 3.4358644485473633 (3.0403287436935926)	Acc@1  21.88 ( 31.18)	Acc@5  40.62 ( 50.03)
Epoch: [2][100/109]	Time  0.373 ( 0.464)	Data  0.000 ( 0.036)	Loss 3.0063107013702393 (3.0288168180106889)	Acc@1  29.69 ( 31.28)	Acc@5  53.12 ( 50.34)
epoch: 2, Avg_Loss 3.0172137732899516
Test: [ 0/28]	Time  3.590 ( 3.590)	Loss 2.9605e+00 (2.9605e+00)	Acc@1  15.62 ( 15.62)	Acc@5  68.75 ( 68.75)
Test: [10/28]	Time  0.093 ( 0.515)	Loss 4.1066e+00 (2.3595e+00)	Acc@1   7.81 ( 46.31)	Acc@5  21.88 ( 73.15)
Test: [20/28]	Time  0.088 ( 0.373)	Loss 3.9464e+00 (3.1336e+00)	Acc@1   3.12 ( 28.50)	Acc@5  32.81 ( 52.53)
 * Acc@1 25.324 Acc@5 47.440
Epoch: [3][  0/109]	Time  4.080 ( 4.080)	Data  3.601 ( 3.601)	Loss 2.5092945098876953 (2.5092945098876953)	Acc@1  45.31 ( 45.31)	Acc@5  57.81 ( 57.81)
Epoch: [3][ 10/109]	Time  0.572 ( 0.811)	Data  0.000 ( 0.328)	Loss 2.6871170997619629 (2.9330310821533203)	Acc@1  40.62 ( 33.81)	Acc@5  57.81 ( 51.70)
Epoch: [3][ 20/109]	Time  0.417 ( 0.662)	Data  0.000 ( 0.172)	Loss 3.1108038425445557 (2.9349667344774519)	Acc@1  31.25 ( 33.48)	Acc@5  46.88 ( 51.79)
Epoch: [3][ 30/109]	Time  0.428 ( 0.580)	Data  0.000 ( 0.116)	Loss 2.9974246025085449 (2.8922404243100073)	Acc@1  37.50 ( 34.22)	Acc@5  57.81 ( 52.67)
Epoch: [3][ 40/109]	Time  0.459 ( 0.541)	Data  0.000 ( 0.088)	Loss 3.2865774631500244 (2.8758152461633451)	Acc@1  26.56 ( 34.57)	Acc@5  39.06 ( 52.90)
Epoch: [3][ 50/109]	Time  0.382 ( 0.514)	Data  0.000 ( 0.071)	Loss 2.6996421813964844 (2.8688360289031385)	Acc@1  34.38 ( 34.07)	Acc@5  60.94 ( 53.52)
Epoch: [3][ 60/109]	Time  0.442 ( 0.500)	Data  0.000 ( 0.059)	Loss 3.1084110736846924 (2.8527223790278202)	Acc@1  28.12 ( 33.99)	Acc@5  50.00 ( 53.79)
Epoch: [3][ 70/109]	Time  0.369 ( 0.485)	Data  0.000 ( 0.051)	Loss 2.9448535442352295 (2.8338778690553048)	Acc@1  28.12 ( 34.29)	Acc@5  48.44 ( 54.09)
Epoch: [3][ 80/109]	Time  0.450 ( 0.479)	Data  0.000 ( 0.045)	Loss 3.1785700321197510 (2.8281257476335688)	Acc@1  25.00 ( 34.28)	Acc@5  48.44 ( 54.44)
Epoch: [3][ 90/109]	Time  0.381 ( 0.474)	Data  0.000 ( 0.040)	Loss 2.4673471450805664 (2.8305291762718787)	Acc@1  39.06 ( 34.27)	Acc@5  62.50 ( 54.62)
Epoch: [3][100/109]	Time  0.814 ( 0.475)	Data  0.000 ( 0.036)	Loss 2.5255327224731445 (2.8100598779055153)	Acc@1  35.94 ( 34.61)	Acc@5  64.06 ( 55.03)
epoch: 3, Avg_Loss 2.7980689324370216
Test: [ 0/28]	Time  3.005 ( 3.005)	Loss 3.0370e+00 (3.0370e+00)	Acc@1  21.88 ( 21.88)	Acc@5  54.69 ( 54.69)
Test: [10/28]	Time  0.230 ( 0.562)	Loss 4.1569e+00 (1.8985e+00)	Acc@1   3.12 ( 57.24)	Acc@5  32.81 ( 73.44)
Test: [20/28]	Time  0.096 ( 0.402)	Loss 3.4334e+00 (2.6932e+00)	Acc@1  20.31 ( 38.17)	Acc@5  48.44 ( 58.56)
 * Acc@1 33.202 Acc@5 53.292
Epoch: [4][  0/109]	Time  2.930 ( 2.930)	Data  2.471 ( 2.471)	Loss 2.2161114215850830 (2.2161114215850830)	Acc@1  48.44 ( 48.44)	Acc@5  67.19 ( 67.19)
Epoch: [4][ 10/109]	Time  0.417 ( 0.643)	Data  0.000 ( 0.225)	Loss 3.1766817569732666 (2.6794995394620029)	Acc@1  31.25 ( 35.51)	Acc@5  48.44 ( 59.94)
Epoch: [4][ 20/109]	Time  0.553 ( 0.537)	Data  0.000 ( 0.118)	Loss 2.8195002079010010 (2.7116341023218062)	Acc@1  37.50 ( 35.27)	Acc@5  62.50 ( 58.85)
Epoch: [4][ 30/109]	Time  0.468 ( 0.488)	Data  0.000 ( 0.080)	Loss 2.5225064754486084 (2.6889956382013138)	Acc@1  35.94 ( 35.03)	Acc@5  53.12 ( 58.67)
Epoch: [4][ 40/109]	Time  0.375 ( 0.471)	Data  0.000 ( 0.061)	Loss 2.8887479305267334 (2.6957214460140322)	Acc@1  31.25 ( 35.59)	Acc@5  48.44 ( 58.12)
Epoch: [4][ 50/109]	Time  0.507 ( 0.466)	Data  0.000 ( 0.049)	Loss 3.0044691562652588 (2.7379715349159990)	Acc@1  35.94 ( 35.17)	Acc@5  50.00 ( 56.95)
Epoch: [4][ 60/109]	Time  0.401 ( 0.459)	Data  0.000 ( 0.041)	Loss 2.3277578353881836 (2.7069712584135961)	Acc@1  45.31 ( 35.99)	Acc@5  65.62 ( 57.38)
Epoch: [4][ 70/109]	Time  0.364 ( 0.447)	Data  0.000 ( 0.035)	Loss 2.5559787750244141 (2.6907137078298651)	Acc@1  40.62 ( 36.40)	Acc@5  64.06 ( 57.55)
Epoch: [4][ 80/109]	Time  0.371 ( 0.441)	Data  0.000 ( 0.031)	Loss 2.5394971370697021 (2.6769848311388933)	Acc@1  35.94 ( 36.61)	Acc@5  60.94 ( 57.87)
Epoch: [4][ 90/109]	Time  0.421 ( 0.437)	Data  0.000 ( 0.027)	Loss 2.8292121887207031 (2.6687434400830949)	Acc@1  31.25 ( 36.74)	Acc@5  53.12 ( 58.19)
Epoch: [4][100/109]	Time  0.366 ( 0.432)	Data  0.000 ( 0.025)	Loss 2.6862130165100098 (2.6633333404465476)	Acc@1  40.62 ( 36.90)	Acc@5  56.25 ( 58.34)
epoch: 4, Avg_Loss 2.6443370460370264
Test: [ 0/28]	Time  3.061 ( 3.061)	Loss 2.2906e+00 (2.2906e+00)	Acc@1  34.38 ( 34.38)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.093 ( 0.535)	Loss 3.6107e+00 (1.4174e+00)	Acc@1  12.50 ( 67.19)	Acc@5  43.75 ( 83.24)
Test: [20/28]	Time  0.087 ( 0.390)	Loss 3.6209e+00 (2.3738e+00)	Acc@1  18.75 ( 42.86)	Acc@5  34.38 ( 64.58)
 * Acc@1 36.353 Acc@5 58.301
Epoch: [5][  0/109]	Time  3.516 ( 3.516)	Data  3.052 ( 3.052)	Loss 2.7472832202911377 (2.7472832202911377)	Acc@1  31.25 ( 31.25)	Acc@5  56.25 ( 56.25)
Epoch: [5][ 10/109]	Time  0.416 ( 0.775)	Data  0.000 ( 0.278)	Loss 2.2386991977691650 (2.6403699137947778)	Acc@1  43.75 ( 36.79)	Acc@5  67.19 ( 59.38)
Epoch: [5][ 20/109]	Time  0.362 ( 0.602)	Data  0.000 ( 0.146)	Loss 2.8530237674713135 (2.5343107552755448)	Acc@1  31.25 ( 39.58)	Acc@5  56.25 ( 62.72)
Epoch: [5][ 30/109]	Time  0.392 ( 0.538)	Data  0.000 ( 0.099)	Loss 2.8055493831634521 (2.5327033958127423)	Acc@1  34.38 ( 39.72)	Acc@5  65.62 ( 63.16)
Epoch: [5][ 40/109]	Time  0.467 ( 0.507)	Data  0.000 ( 0.075)	Loss 2.7297017574310303 (2.5238761058667811)	Acc@1  37.50 ( 40.17)	Acc@5  64.06 ( 62.77)
Epoch: [5][ 50/109]	Time  0.490 ( 0.490)	Data  0.000 ( 0.060)	Loss 2.7748203277587891 (2.5170349022921394)	Acc@1  32.81 ( 40.07)	Acc@5  57.81 ( 62.47)
Epoch: [5][ 60/109]	Time  0.377 ( 0.474)	Data  0.000 ( 0.050)	Loss 2.2420437335968018 (2.5071678376588666)	Acc@1  39.06 ( 40.04)	Acc@5  68.75 ( 62.45)
Epoch: [5][ 70/109]	Time  0.418 ( 0.464)	Data  0.000 ( 0.043)	Loss 2.1245951652526855 (2.4876086325712605)	Acc@1  51.56 ( 40.21)	Acc@5  65.62 ( 62.70)
Epoch: [5][ 80/109]	Time  0.429 ( 0.455)	Data  0.000 ( 0.038)	Loss 2.5062181949615479 (2.4709831564514726)	Acc@1  35.94 ( 40.41)	Acc@5  62.50 ( 62.98)
Epoch: [5][ 90/109]	Time  0.425 ( 0.448)	Data  0.000 ( 0.034)	Loss 2.3795490264892578 (2.4843942529552585)	Acc@1  39.06 ( 40.18)	Acc@5  73.44 ( 62.84)
Epoch: [5][100/109]	Time  0.401 ( 0.446)	Data  0.000 ( 0.030)	Loss 2.1838936805725098 (2.4971927923731285)	Acc@1  45.31 ( 40.07)	Acc@5  68.75 ( 62.55)
epoch: 5, Avg_Loss 2.4999899481414656
Test: [ 0/28]	Time  3.602 ( 3.602)	Loss 4.1481e+00 (4.1481e+00)	Acc@1   6.25 (  6.25)	Acc@5  26.56 ( 26.56)
Test: [10/28]	Time  0.129 ( 0.511)	Loss 4.4828e+00 (2.4103e+00)	Acc@1   3.12 ( 44.89)	Acc@5  26.56 ( 66.05)
Test: [20/28]	Time  0.087 ( 0.370)	Loss 4.0417e+00 (3.2087e+00)	Acc@1   9.38 ( 29.76)	Acc@5  34.38 ( 51.56)
 * Acc@1 26.618 Acc@5 47.721
Epoch: [6][  0/109]	Time  3.301 ( 3.301)	Data  2.840 ( 2.840)	Loss 2.2567803859710693 (2.2567803859710693)	Acc@1  53.12 ( 53.12)	Acc@5  67.19 ( 67.19)
Epoch: [6][ 10/109]	Time  0.373 ( 0.665)	Data  0.000 ( 0.258)	Loss 2.4611120223999023 (2.4722193154421719)	Acc@1  40.62 ( 40.20)	Acc@5  60.94 ( 62.64)
Epoch: [6][ 20/109]	Time  0.369 ( 0.536)	Data  0.001 ( 0.135)	Loss 2.7219591140747070 (2.4214297362736295)	Acc@1  34.38 ( 41.89)	Acc@5  56.25 ( 62.72)
Epoch: [6][ 30/109]	Time  0.369 ( 0.488)	Data  0.000 ( 0.092)	Loss 2.5975587368011475 (2.4323147650687926)	Acc@1  35.94 ( 41.23)	Acc@5  54.69 ( 61.95)
Epoch: [6][ 40/109]	Time  0.369 ( 0.467)	Data  0.000 ( 0.070)	Loss 2.1167974472045898 (2.3936296090847109)	Acc@1  48.44 ( 42.23)	Acc@5  73.44 ( 63.80)
Epoch: [6][ 50/109]	Time  0.355 ( 0.452)	Data  0.000 ( 0.056)	Loss 2.5725469589233398 (2.3914799550000359)	Acc@1  37.50 ( 42.13)	Acc@5  59.38 ( 63.91)
Epoch: [6][ 60/109]	Time  0.393 ( 0.445)	Data  0.000 ( 0.047)	Loss 2.3151662349700928 (2.3770322428374993)	Acc@1  46.88 ( 42.47)	Acc@5  64.06 ( 64.32)
Epoch: [6][ 70/109]	Time  0.364 ( 0.439)	Data  0.000 ( 0.040)	Loss 2.2295472621917725 (2.3460073370329093)	Acc@1  43.75 ( 43.00)	Acc@5  68.75 ( 65.10)
Epoch: [6][ 80/109]	Time  0.370 ( 0.433)	Data  0.000 ( 0.035)	Loss 1.5387208461761475 (2.3259608259907476)	Acc@1  64.06 ( 43.56)	Acc@5  82.81 ( 65.70)
Epoch: [6][ 90/109]	Time  0.429 ( 0.431)	Data  0.000 ( 0.031)	Loss 2.5068683624267578 (2.3371537766613804)	Acc@1  37.50 ( 43.01)	Acc@5  65.62 ( 65.33)
Epoch: [6][100/109]	Time  0.376 ( 0.428)	Data  0.000 ( 0.028)	Loss 2.5466256141662598 (2.3318157148833323)	Acc@1  35.94 ( 43.25)	Acc@5  68.75 ( 65.72)
epoch: 6, Avg_Loss 2.3279039684785614
Test: [ 0/28]	Time  3.543 ( 3.543)	Loss 2.3729e+00 (2.3729e+00)	Acc@1  37.50 ( 37.50)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.090 ( 0.563)	Loss 3.8513e+00 (1.7285e+00)	Acc@1  14.06 ( 61.36)	Acc@5  40.62 ( 75.00)
Test: [20/28]	Time  0.089 ( 0.399)	Loss 3.1573e+00 (2.5129e+00)	Acc@1  29.69 ( 41.82)	Acc@5  48.44 ( 61.61)
 * Acc@1 36.466 Acc@5 58.694
Epoch: [7][  0/109]	Time  4.114 ( 4.114)	Data  3.725 ( 3.725)	Loss 2.5104389190673828 (2.5104389190673828)	Acc@1  39.06 ( 39.06)	Acc@5  67.19 ( 67.19)
Epoch: [7][ 10/109]	Time  0.494 ( 0.755)	Data  0.000 ( 0.339)	Loss 2.3702926635742188 (2.3504865819757637)	Acc@1  40.62 ( 41.48)	Acc@5  64.06 ( 64.63)
Epoch: [7][ 20/109]	Time  0.563 ( 0.609)	Data  0.000 ( 0.178)	Loss 2.0661845207214355 (2.2978460448128835)	Acc@1  51.56 ( 43.30)	Acc@5  65.62 ( 66.44)
Epoch: [7][ 30/109]	Time  0.603 ( 0.606)	Data  0.000 ( 0.120)	Loss 2.5374553203582764 (2.2675571326286561)	Acc@1  37.50 ( 43.95)	Acc@5  57.81 ( 66.73)
Epoch: [7][ 40/109]	Time  0.579 ( 0.576)	Data  0.000 ( 0.091)	Loss 2.0276710987091064 (2.2710263729095459)	Acc@1  48.44 ( 43.29)	Acc@5  73.44 ( 67.11)
Epoch: [7][ 50/109]	Time  0.431 ( 0.549)	Data  0.000 ( 0.073)	Loss 2.1593008041381836 (2.2746512305502797)	Acc@1  51.56 ( 43.47)	Acc@5  70.31 ( 67.10)
Epoch: [7][ 60/109]	Time  0.412 ( 0.526)	Data  0.000 ( 0.061)	Loss 2.3898732662200928 (2.2873762201090329)	Acc@1  46.88 ( 43.34)	Acc@5  60.94 ( 66.85)
Epoch: [7][ 70/109]	Time  0.562 ( 0.517)	Data  0.000 ( 0.053)	Loss 2.2554013729095459 (2.2859971053163770)	Acc@1  43.75 ( 43.68)	Acc@5  68.75 ( 67.08)
Epoch: [7][ 80/109]	Time  0.372 ( 0.517)	Data  0.000 ( 0.046)	Loss 1.8605188131332397 (2.2687075653193909)	Acc@1  54.69 ( 44.16)	Acc@5  71.88 ( 67.44)
Epoch: [7][ 90/109]	Time  0.371 ( 0.504)	Data  0.000 ( 0.041)	Loss 2.4891359806060791 (2.2668907812663486)	Acc@1  35.94 ( 44.16)	Acc@5  62.50 ( 67.58)
Epoch: [7][100/109]	Time  0.369 ( 0.493)	Data  0.000 ( 0.037)	Loss 2.1456179618835449 (2.2497357944450758)	Acc@1  51.56 ( 44.79)	Acc@5  65.62 ( 67.78)
epoch: 7, Avg_Loss 2.2449047040501866
Test: [ 0/28]	Time  3.288 ( 3.288)	Loss 9.5639e-01 (9.5639e-01)	Acc@1  68.75 ( 68.75)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.099 ( 0.552)	Loss 5.2742e+00 (2.5454e+00)	Acc@1   6.25 ( 48.01)	Acc@5  17.19 ( 69.74)
Test: [20/28]	Time  0.098 ( 0.407)	Loss 4.0123e+00 (3.5337e+00)	Acc@1  21.88 ( 29.84)	Acc@5  45.31 ( 55.65)
 * Acc@1 27.068 Acc@5 51.548
Epoch: [8][  0/109]	Time  4.416 ( 4.416)	Data  4.028 ( 4.028)	Loss 1.7402923107147217 (1.7402923107147217)	Acc@1  51.56 ( 51.56)	Acc@5  78.12 ( 78.12)
Epoch: [8][ 10/109]	Time  0.418 ( 0.790)	Data  0.000 ( 0.366)	Loss 2.4871454238891602 (2.0468751950697466)	Acc@1  39.06 ( 48.58)	Acc@5  60.94 ( 72.30)
Epoch: [8][ 20/109]	Time  0.488 ( 0.616)	Data  0.000 ( 0.192)	Loss 2.1540780067443848 (2.1605164664132253)	Acc@1  53.12 ( 47.77)	Acc@5  70.31 ( 69.79)
Epoch: [8][ 30/109]	Time  0.469 ( 0.551)	Data  0.000 ( 0.130)	Loss 2.2327592372894287 (2.1540145028022026)	Acc@1  45.31 ( 47.33)	Acc@5  68.75 ( 69.76)
Epoch: [8][ 40/109]	Time  0.380 ( 0.512)	Data  0.000 ( 0.098)	Loss 1.7852547168731689 (2.1640025115594632)	Acc@1  50.00 ( 47.41)	Acc@5  78.12 ( 69.55)
Epoch: [8][ 50/109]	Time  0.377 ( 0.489)	Data  0.000 ( 0.079)	Loss 2.2463216781616211 (2.1233575507706286)	Acc@1  40.62 ( 48.07)	Acc@5  67.19 ( 70.22)
Epoch: [8][ 60/109]	Time  0.375 ( 0.474)	Data  0.000 ( 0.066)	Loss 2.0004632472991943 (2.1361136885940053)	Acc@1  59.38 ( 47.93)	Acc@5  73.44 ( 69.88)
Epoch: [8][ 70/109]	Time  0.423 ( 0.466)	Data  0.000 ( 0.057)	Loss 2.2110698223114014 (2.1513631528532002)	Acc@1  45.31 ( 47.89)	Acc@5  71.88 ( 69.50)
Epoch: [8][ 80/109]	Time  0.532 ( 0.471)	Data  0.000 ( 0.050)	Loss 2.3580217361450195 (2.1468479191815413)	Acc@1  48.44 ( 48.21)	Acc@5  59.38 ( 69.43)
Epoch: [8][ 90/109]	Time  0.395 ( 0.470)	Data  0.000 ( 0.045)	Loss 2.0974283218383789 (2.1464816816560517)	Acc@1  45.31 ( 47.96)	Acc@5  75.00 ( 69.47)
Epoch: [8][100/109]	Time  0.390 ( 0.463)	Data  0.000 ( 0.040)	Loss 1.8596699237823486 (2.1267821895013941)	Acc@1  54.69 ( 48.33)	Acc@5  76.56 ( 70.06)
epoch: 8, Avg_Loss 2.122674209262253
Test: [ 0/28]	Time  4.094 ( 4.094)	Loss 2.0944e+00 (2.0944e+00)	Acc@1  50.00 ( 50.00)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.088 ( 0.573)	Loss 3.4374e+00 (1.3756e+00)	Acc@1  18.75 ( 67.76)	Acc@5  37.50 ( 81.82)
Test: [20/28]	Time  0.087 ( 0.403)	Loss 2.8555e+00 (2.1647e+00)	Acc@1  35.94 ( 47.02)	Acc@5  54.69 ( 69.87)
 * Acc@1 43.725 Acc@5 67.304
Epoch: [9][  0/109]	Time  3.117 ( 3.117)	Data  2.607 ( 2.607)	Loss 1.8943052291870117 (1.8943052291870117)	Acc@1  46.88 ( 46.88)	Acc@5  76.56 ( 76.56)
Epoch: [9][ 10/109]	Time  0.412 ( 0.690)	Data  0.000 ( 0.260)	Loss 1.8160905838012695 (2.0443287871100684)	Acc@1  57.81 ( 48.30)	Acc@5  70.31 ( 72.87)
Epoch: [9][ 20/109]	Time  0.466 ( 0.566)	Data  0.000 ( 0.136)	Loss 1.9974019527435303 (2.0528911408923922)	Acc@1  51.56 ( 48.59)	Acc@5  71.88 ( 71.95)
Epoch: [9][ 30/109]	Time  0.457 ( 0.544)	Data  0.000 ( 0.092)	Loss 2.3262200355529785 (2.1208884716033936)	Acc@1  40.62 ( 46.52)	Acc@5  64.06 ( 70.61)
Epoch: [9][ 40/109]	Time  0.443 ( 0.526)	Data  0.000 ( 0.070)	Loss 1.9946756362915039 (2.0968988552326109)	Acc@1  46.88 ( 47.52)	Acc@5  71.88 ( 71.04)
Epoch: [9][ 50/109]	Time  0.442 ( 0.510)	Data  0.000 ( 0.056)	Loss 2.3951449394226074 (2.0883750003926895)	Acc@1  48.44 ( 47.70)	Acc@5  67.19 ( 71.38)
Epoch: [9][ 60/109]	Time  0.377 ( 0.493)	Data  0.000 ( 0.047)	Loss 2.1972358226776123 (2.1011890524723489)	Acc@1  48.44 ( 47.31)	Acc@5  70.31 ( 71.18)
Epoch: [9][ 70/109]	Time  0.387 ( 0.479)	Data  0.000 ( 0.040)	Loss 1.8232775926589966 (2.0743484597810555)	Acc@1  54.69 ( 48.11)	Acc@5  75.00 ( 71.65)
Epoch: [9][ 80/109]	Time  0.468 ( 0.472)	Data  0.000 ( 0.036)	Loss 2.0442719459533691 (2.0701636826550520)	Acc@1  51.56 ( 47.99)	Acc@5  76.56 ( 71.88)
Epoch: [9][ 90/109]	Time  0.478 ( 0.465)	Data  0.000 ( 0.032)	Loss 2.1256403923034668 (2.0636706876230764)	Acc@1  51.56 ( 48.27)	Acc@5  70.31 ( 71.89)
Epoch: [9][100/109]	Time  0.353 ( 0.457)	Data  0.000 ( 0.029)	Loss 1.8464983701705933 (2.0541479127241833)	Acc@1  56.25 ( 48.36)	Acc@5  75.00 ( 72.01)
epoch: 9, Avg_Loss 2.0433536341430942
Test: [ 0/28]	Time  3.181 ( 3.181)	Loss 2.2843e+00 (2.2843e+00)	Acc@1  37.50 ( 37.50)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.177 ( 0.517)	Loss 3.0770e+00 (1.3580e+00)	Acc@1  32.81 ( 68.18)	Acc@5  54.69 ( 83.24)
Test: [20/28]	Time  0.099 ( 0.407)	Loss 3.1508e+00 (2.0968e+00)	Acc@1  29.69 ( 49.70)	Acc@5  59.38 ( 70.46)
 * Acc@1 44.457 Acc@5 67.642
Epoch: [10][  0/109]	Time  4.113 ( 4.113)	Data  3.745 ( 3.745)	Loss 1.9825470447540283 (1.9825470447540283)	Acc@1  51.56 ( 51.56)	Acc@5  76.56 ( 76.56)
Epoch: [10][ 10/109]	Time  0.448 ( 0.762)	Data  0.000 ( 0.341)	Loss 2.0976202487945557 (1.8534950884905728)	Acc@1  50.00 ( 51.99)	Acc@5  70.31 ( 76.14)
Epoch: [10][ 20/109]	Time  0.506 ( 0.603)	Data  0.000 ( 0.179)	Loss 2.1785175800323486 (1.8874536582401820)	Acc@1  45.31 ( 52.23)	Acc@5  73.44 ( 75.82)
Epoch: [10][ 30/109]	Time  0.426 ( 0.543)	Data  0.000 ( 0.121)	Loss 1.8623756170272827 (1.8979413432459677)	Acc@1  54.69 ( 52.32)	Acc@5  73.44 ( 74.80)
Epoch: [10][ 40/109]	Time  0.425 ( 0.508)	Data  0.000 ( 0.092)	Loss 1.6685973405838013 (1.9227536800431042)	Acc@1  59.38 ( 51.37)	Acc@5  76.56 ( 74.54)
Epoch: [10][ 50/109]	Time  0.371 ( 0.490)	Data  0.000 ( 0.074)	Loss 2.1485714912414551 (1.9255720470465867)	Acc@1  48.44 ( 51.50)	Acc@5  67.19 ( 74.26)
Epoch: [10][ 60/109]	Time  0.372 ( 0.478)	Data  0.000 ( 0.062)	Loss 1.9399698972702026 (1.9197108804202470)	Acc@1  59.38 ( 51.90)	Acc@5  82.81 ( 74.49)
Epoch: [10][ 70/109]	Time  0.462 ( 0.476)	Data  0.000 ( 0.053)	Loss 1.8326067924499512 (1.9156018495559692)	Acc@1  56.25 ( 51.98)	Acc@5  79.69 ( 74.98)
Epoch: [10][ 80/109]	Time  0.396 ( 0.472)	Data  0.000 ( 0.046)	Loss 1.9203138351440430 (1.9121271960529280)	Acc@1  42.19 ( 51.91)	Acc@5  71.88 ( 74.83)
Epoch: [10][ 90/109]	Time  0.475 ( 0.465)	Data  0.000 ( 0.041)	Loss 2.2220623493194580 (1.9298229807025784)	Acc@1  43.75 ( 51.60)	Acc@5  64.06 ( 74.64)
Epoch: [10][100/109]	Time  0.379 ( 0.457)	Data  0.000 ( 0.037)	Loss 1.9147032499313354 (1.9278408761071686)	Acc@1  45.31 ( 51.45)	Acc@5  75.00 ( 74.77)
epoch: 10, Avg_Loss 1.9329643107335501
Test: [ 0/28]	Time  2.737 ( 2.737)	Loss 1.6833e+00 (1.6833e+00)	Acc@1  54.69 ( 54.69)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.184 ( 0.521)	Loss 3.8905e+00 (1.3995e+00)	Acc@1  25.00 ( 67.61)	Acc@5  35.94 ( 83.10)
Test: [20/28]	Time  0.155 ( 0.396)	Loss 2.5415e+00 (2.1401e+00)	Acc@1  46.88 ( 49.03)	Acc@5  64.06 ( 72.32)
 * Acc@1 43.444 Acc@5 66.348
Epoch: [11][  0/109]	Time  2.894 ( 2.894)	Data  2.445 ( 2.445)	Loss 2.0861139297485352 (2.0861139297485352)	Acc@1  56.25 ( 56.25)	Acc@5  71.88 ( 71.88)
Epoch: [11][ 10/109]	Time  0.403 ( 0.661)	Data  0.000 ( 0.223)	Loss 1.9352804422378540 (1.8539888750423084)	Acc@1  50.00 ( 53.84)	Acc@5  73.44 ( 76.70)
Epoch: [11][ 20/109]	Time  0.355 ( 0.534)	Data  0.000 ( 0.117)	Loss 1.8027052879333496 (1.8320910703568232)	Acc@1  46.88 ( 53.65)	Acc@5  78.12 ( 77.23)
Epoch: [11][ 30/109]	Time  0.447 ( 0.512)	Data  0.000 ( 0.079)	Loss 1.5373582839965820 (1.8414617853779947)	Acc@1  59.38 ( 53.68)	Acc@5  84.38 ( 76.97)
Epoch: [11][ 40/109]	Time  0.417 ( 0.486)	Data  0.000 ( 0.060)	Loss 1.8466546535491943 (1.8439766401197852)	Acc@1  57.81 ( 53.62)	Acc@5  76.56 ( 76.22)
Epoch: [11][ 50/109]	Time  0.416 ( 0.470)	Data  0.000 ( 0.048)	Loss 1.4166465997695923 (1.8525664011637371)	Acc@1  62.50 ( 53.89)	Acc@5  81.25 ( 76.07)
Epoch: [11][ 60/109]	Time  0.502 ( 0.461)	Data  0.000 ( 0.040)	Loss 1.6014218330383301 (1.8413779012492446)	Acc@1  65.62 ( 54.12)	Acc@5  79.69 ( 76.15)
Epoch: [11][ 70/109]	Time  0.407 ( 0.454)	Data  0.000 ( 0.035)	Loss 2.1214294433593750 (1.8571773515620702)	Acc@1  48.44 ( 53.76)	Acc@5  67.19 ( 75.84)
Epoch: [11][ 80/109]	Time  0.440 ( 0.448)	Data  0.000 ( 0.030)	Loss 1.6991904973983765 (1.8549401465757394)	Acc@1  62.50 ( 53.88)	Acc@5  76.56 ( 75.85)
Epoch: [11][ 90/109]	Time  0.374 ( 0.444)	Data  0.000 ( 0.027)	Loss 1.6615937948226929 (1.8612055437905448)	Acc@1  56.25 ( 53.74)	Acc@5  81.25 ( 75.81)
Epoch: [11][100/109]	Time  0.369 ( 0.440)	Data  0.000 ( 0.024)	Loss 1.8345957994461060 (1.8463881629528385)	Acc@1  53.12 ( 53.98)	Acc@5  75.00 ( 76.11)
epoch: 11, Avg_Loss 1.8475974415420393
Test: [ 0/28]	Time  3.635 ( 3.635)	Loss 1.4950e+00 (1.4950e+00)	Acc@1  62.50 ( 62.50)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.101 ( 0.531)	Loss 3.7223e+00 (1.5117e+00)	Acc@1  14.06 ( 65.48)	Acc@5  42.19 ( 81.96)
Test: [20/28]	Time  0.087 ( 0.404)	Loss 2.8732e+00 (2.3713e+00)	Acc@1  31.25 ( 43.75)	Acc@5  60.94 ( 66.89)
 * Acc@1 40.574 Acc@5 65.222
Epoch: [12][  0/109]	Time  3.191 ( 3.191)	Data  2.648 ( 2.648)	Loss 1.8017628192901611 (1.8017628192901611)	Acc@1  53.12 ( 53.12)	Acc@5  75.00 ( 75.00)
Epoch: [12][ 10/109]	Time  0.424 ( 0.719)	Data  0.000 ( 0.280)	Loss 1.8640968799591064 (1.8104217811064287)	Acc@1  51.56 ( 52.70)	Acc@5  79.69 ( 76.70)
Epoch: [12][ 20/109]	Time  0.412 ( 0.575)	Data  0.000 ( 0.147)	Loss 1.7745791673660278 (1.7590819710776919)	Acc@1  50.00 ( 52.83)	Acc@5  79.69 ( 77.83)
Epoch: [12][ 30/109]	Time  0.354 ( 0.524)	Data  0.000 ( 0.099)	Loss 1.3144577741622925 (1.7045856483521000)	Acc@1  65.62 ( 55.09)	Acc@5  85.94 ( 78.98)
Epoch: [12][ 40/109]	Time  0.371 ( 0.490)	Data  0.000 ( 0.075)	Loss 1.3977247476577759 (1.6986952932869517)	Acc@1  60.94 ( 55.75)	Acc@5  87.50 ( 78.89)
Epoch: [12][ 50/109]	Time  0.369 ( 0.475)	Data  0.000 ( 0.061)	Loss 1.8400775194168091 (1.7214137432621974)	Acc@1  53.12 ( 55.09)	Acc@5  70.31 ( 78.16)
Epoch: [12][ 60/109]	Time  0.564 ( 0.474)	Data  0.000 ( 0.051)	Loss 1.8425635099411011 (1.7117932135941551)	Acc@1  51.56 ( 55.25)	Acc@5  76.56 ( 78.41)
Epoch: [12][ 70/109]	Time  0.503 ( 0.472)	Data  0.000 ( 0.044)	Loss 2.4059553146362305 (1.7215308236404203)	Acc@1  45.31 ( 55.11)	Acc@5  57.81 ( 78.37)
Epoch: [12][ 80/109]	Time  0.445 ( 0.465)	Data  0.000 ( 0.038)	Loss 1.7605893611907959 (1.7303696311550376)	Acc@1  60.94 ( 54.82)	Acc@5  76.56 ( 78.18)
Epoch: [12][ 90/109]	Time  0.447 ( 0.459)	Data  0.000 ( 0.034)	Loss 1.7575079202651978 (1.7544813182327774)	Acc@1  51.56 ( 54.53)	Acc@5  81.25 ( 77.68)
Epoch: [12][100/109]	Time  0.370 ( 0.453)	Data  0.000 ( 0.031)	Loss 1.6535499095916748 (1.7576862620835256)	Acc@1  60.94 ( 54.53)	Acc@5  85.94 ( 77.71)
epoch: 12, Avg_Loss 1.7613930560033255
Test: [ 0/28]	Time  3.642 ( 3.642)	Loss 2.8789e+00 (2.8789e+00)	Acc@1  31.25 ( 31.25)	Acc@5  56.25 ( 56.25)
Test: [10/28]	Time  0.126 ( 0.523)	Loss 3.1161e+00 (1.3351e+00)	Acc@1  25.00 ( 68.75)	Acc@5  48.44 ( 81.11)
Test: [20/28]	Time  0.088 ( 0.399)	Loss 1.8017e+00 (1.8037e+00)	Acc@1  57.81 ( 55.21)	Acc@5  76.56 ( 75.30)
 * Acc@1 51.491 Acc@5 72.707
Epoch: [13][  0/109]	Time  3.493 ( 3.493)	Data  3.050 ( 3.050)	Loss 1.7649208307266235 (1.7649208307266235)	Acc@1  50.00 ( 50.00)	Acc@5  81.25 ( 81.25)
Epoch: [13][ 10/109]	Time  0.425 ( 0.720)	Data  0.000 ( 0.285)	Loss 1.8437891006469727 (1.7954365448518232)	Acc@1  60.94 ( 53.69)	Acc@5  75.00 ( 77.70)
Epoch: [13][ 20/109]	Time  0.430 ( 0.566)	Data  0.000 ( 0.149)	Loss 1.3186029195785522 (1.7627077670324416)	Acc@1  65.62 ( 54.76)	Acc@5  84.38 ( 77.75)
Epoch: [13][ 30/109]	Time  0.438 ( 0.514)	Data  0.000 ( 0.101)	Loss 1.7114720344543457 (1.7459456536077684)	Acc@1  56.25 ( 55.14)	Acc@5  78.12 ( 77.67)
Epoch: [13][ 40/109]	Time  0.357 ( 0.483)	Data  0.000 ( 0.078)	Loss 1.4436285495758057 (1.7402141937395421)	Acc@1  65.62 ( 55.37)	Acc@5  76.56 ( 77.78)
Epoch: [13][ 50/109]	Time  0.446 ( 0.469)	Data  0.000 ( 0.063)	Loss 1.4539866447448730 (1.7240573004180311)	Acc@1  62.50 ( 55.88)	Acc@5  85.94 ( 78.46)
Epoch: [13][ 60/109]	Time  0.355 ( 0.460)	Data  0.000 ( 0.053)	Loss 1.3281090259552002 (1.7121613475142932)	Acc@1  65.62 ( 56.05)	Acc@5  87.50 ( 78.51)
Epoch: [13][ 70/109]	Time  0.464 ( 0.454)	Data  0.000 ( 0.045)	Loss 1.4554085731506348 (1.7067978667541288)	Acc@1  59.38 ( 56.18)	Acc@5  84.38 ( 78.50)
Epoch: [13][ 80/109]	Time  0.414 ( 0.448)	Data  0.000 ( 0.040)	Loss 1.7327322959899902 (1.6978666488035226)	Acc@1  56.25 ( 56.44)	Acc@5  76.56 ( 78.80)
Epoch: [13][ 90/109]	Time  0.512 ( 0.444)	Data  0.000 ( 0.035)	Loss 1.8353680372238159 (1.6991857997663729)	Acc@1  46.88 ( 55.92)	Acc@5  75.00 ( 78.78)
Epoch: [13][100/109]	Time  0.463 ( 0.446)	Data  0.000 ( 0.032)	Loss 2.0604722499847412 (1.7073120504322619)	Acc@1  46.88 ( 55.96)	Acc@5  76.56 ( 78.85)
epoch: 13, Avg_Loss 1.7114543761682073
Test: [ 0/28]	Time  3.739 ( 3.739)	Loss 1.6970e+00 (1.6970e+00)	Acc@1  54.69 ( 54.69)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.099 ( 0.552)	Loss 2.9545e+00 (1.1673e+00)	Acc@1  29.69 ( 73.58)	Acc@5  54.69 ( 85.65)
Test: [20/28]	Time  0.087 ( 0.405)	Loss 2.4194e+00 (1.9583e+00)	Acc@1  42.19 ( 53.57)	Acc@5  67.19 ( 73.74)
 * Acc@1 49.015 Acc@5 71.863
Epoch: [14][  0/109]	Time  3.767 ( 3.767)	Data  3.335 ( 3.335)	Loss 1.6523277759552002 (1.6523277759552002)	Acc@1  59.38 ( 59.38)	Acc@5  78.12 ( 78.12)
Epoch: [14][ 10/109]	Time  0.425 ( 0.717)	Data  0.000 ( 0.303)	Loss 1.6746044158935547 (1.6562276970256458)	Acc@1  56.25 ( 58.38)	Acc@5  75.00 ( 79.69)
Epoch: [14][ 20/109]	Time  0.396 ( 0.567)	Data  0.000 ( 0.159)	Loss 1.5849735736846924 (1.6360028073901223)	Acc@1  59.38 ( 57.81)	Acc@5  82.81 ( 80.43)
Epoch: [14][ 30/109]	Time  0.367 ( 0.510)	Data  0.000 ( 0.108)	Loss 1.8173319101333618 (1.6099037201173845)	Acc@1  45.31 ( 58.17)	Acc@5  79.69 ( 80.90)
Epoch: [14][ 40/109]	Time  0.413 ( 0.490)	Data  0.000 ( 0.082)	Loss 1.3574254512786865 (1.5952346993655693)	Acc@1  62.50 ( 58.50)	Acc@5  89.06 ( 81.14)
Epoch: [14][ 50/109]	Time  0.739 ( 0.527)	Data  0.000 ( 0.066)	Loss 1.9410206079483032 (1.6166355609893799)	Acc@1  50.00 ( 57.87)	Acc@5  70.31 ( 80.51)
Epoch: [14][ 60/109]	Time  0.382 ( 0.511)	Data  0.000 ( 0.055)	Loss 1.6836081743240356 (1.6161888212454123)	Acc@1  60.94 ( 58.22)	Acc@5  81.25 ( 80.43)
Epoch: [14][ 70/109]	Time  0.672 ( 0.523)	Data  0.000 ( 0.047)	Loss 1.5580869913101196 (1.6250237528706941)	Acc@1  59.38 ( 57.92)	Acc@5  81.25 ( 80.37)
Epoch: [14][ 80/109]	Time  0.528 ( 0.525)	Data  0.000 ( 0.041)	Loss 1.5956087112426758 (1.6228814566576923)	Acc@1  60.94 ( 57.95)	Acc@5  81.25 ( 80.29)
Epoch: [14][ 90/109]	Time  0.426 ( 0.513)	Data  0.000 ( 0.037)	Loss 1.6422888040542603 (1.6258613120068561)	Acc@1  60.94 ( 57.86)	Acc@5  81.25 ( 80.29)
Epoch: [14][100/109]	Time  0.366 ( 0.499)	Data  0.000 ( 0.033)	Loss 1.5202423334121704 (1.6293329472589020)	Acc@1  56.25 ( 57.86)	Acc@5  79.69 ( 80.37)
epoch: 14, Avg_Loss 1.6444969078816405
Test: [ 0/28]	Time  3.276 ( 3.276)	Loss 2.1684e+00 (2.1684e+00)	Acc@1  34.38 ( 34.38)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.090 ( 0.521)	Loss 2.9330e+00 (1.1685e+00)	Acc@1  31.25 ( 71.73)	Acc@5  54.69 ( 85.09)
Test: [20/28]	Time  0.087 ( 0.385)	Loss 2.2991e+00 (1.7342e+00)	Acc@1  51.56 ( 56.18)	Acc@5  65.62 ( 77.31)
 * Acc@1 53.348 Acc@5 75.127
Epoch: [15][  0/109]	Time  3.119 ( 3.119)	Data  2.664 ( 2.664)	Loss 1.6293632984161377 (1.6293632984161377)	Acc@1  60.94 ( 60.94)	Acc@5  79.69 ( 79.69)
Epoch: [15][ 10/109]	Time  0.403 ( 0.667)	Data  0.000 ( 0.249)	Loss 1.3260463476181030 (1.4570170857689597)	Acc@1  65.62 ( 62.07)	Acc@5  84.38 ( 83.24)
Epoch: [15][ 20/109]	Time  0.380 ( 0.544)	Data  0.000 ( 0.131)	Loss 1.4054600000381470 (1.5232619444529216)	Acc@1  68.75 ( 60.57)	Acc@5  78.12 ( 82.07)
Epoch: [15][ 30/109]	Time  0.626 ( 0.541)	Data  0.000 ( 0.089)	Loss 1.4996924400329590 (1.4902329291066816)	Acc@1  56.25 ( 61.49)	Acc@5  78.12 ( 82.36)
Epoch: [15][ 40/109]	Time  0.374 ( 0.536)	Data  0.000 ( 0.067)	Loss 1.4635890722274780 (1.5022058516013912)	Acc@1  62.50 ( 60.75)	Acc@5  82.81 ( 82.47)
Epoch: [15][ 50/109]	Time  0.355 ( 0.512)	Data  0.000 ( 0.054)	Loss 1.5002876520156860 (1.5373882218903185)	Acc@1  57.81 ( 60.32)	Acc@5  81.25 ( 81.86)
Epoch: [15][ 60/109]	Time  0.408 ( 0.496)	Data  0.000 ( 0.045)	Loss 1.6055418252944946 (1.5566147448586636)	Acc@1  57.81 ( 59.91)	Acc@5  79.69 ( 81.48)
Epoch: [15][ 70/109]	Time  0.430 ( 0.485)	Data  0.000 ( 0.039)	Loss 1.4614053964614868 (1.5429704424361108)	Acc@1  65.62 ( 60.45)	Acc@5  82.81 ( 81.60)
Epoch: [15][ 80/109]	Time  0.369 ( 0.475)	Data  0.000 ( 0.034)	Loss 1.7958221435546875 (1.5551773530465585)	Acc@1  56.25 ( 59.78)	Acc@5  81.25 ( 81.52)
Epoch: [15][ 90/109]	Time  0.368 ( 0.467)	Data  0.000 ( 0.030)	Loss 1.5004334449768066 (1.5588404228399089)	Acc@1  60.94 ( 59.70)	Acc@5  81.25 ( 81.52)
Epoch: [15][100/109]	Time  0.383 ( 0.460)	Data  0.000 ( 0.027)	Loss 1.6904736757278442 (1.5640795573149577)	Acc@1  59.38 ( 59.44)	Acc@5  81.25 ( 81.48)
epoch: 15, Avg_Loss 1.5575438420706933
Test: [ 0/28]	Time  3.745 ( 3.745)	Loss 1.4161e+00 (1.4161e+00)	Acc@1  60.94 ( 60.94)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.175 ( 0.548)	Loss 2.1375e+00 (9.4014e-01)	Acc@1  42.19 ( 76.85)	Acc@5  73.44 ( 90.06)
Test: [20/28]	Time  0.125 ( 0.419)	Loss 2.4778e+00 (1.6936e+00)	Acc@1  40.62 ( 56.40)	Acc@5  68.75 ( 78.72)
 * Acc@1 52.448 Acc@5 75.352
Epoch: [16][  0/109]	Time  5.203 ( 5.203)	Data  4.773 ( 4.773)	Loss 1.0491276979446411 (1.0491276979446411)	Acc@1  76.56 ( 76.56)	Acc@5  89.06 ( 89.06)
Epoch: [16][ 10/109]	Time  0.369 ( 0.869)	Data  0.000 ( 0.434)	Loss 1.0290135145187378 (1.2559804591265591)	Acc@1  71.88 ( 67.47)	Acc@5  90.62 ( 86.65)
Epoch: [16][ 20/109]	Time  0.355 ( 0.646)	Data  0.000 ( 0.227)	Loss 1.1949642896652222 (1.3946262938635690)	Acc@1  64.06 ( 62.95)	Acc@5  84.38 ( 83.48)
Epoch: [16][ 30/109]	Time  0.389 ( 0.563)	Data  0.000 ( 0.154)	Loss 1.6903508901596069 (1.4262332108712965)	Acc@1  64.06 ( 62.10)	Acc@5  81.25 ( 83.11)
Epoch: [16][ 40/109]	Time  0.486 ( 0.523)	Data  0.000 ( 0.117)	Loss 1.3561409711837769 (1.4156535049764121)	Acc@1  64.06 ( 62.42)	Acc@5  87.50 ( 83.65)
Epoch: [16][ 50/109]	Time  0.375 ( 0.501)	Data  0.000 ( 0.094)	Loss 2.0087141990661621 (1.4342088792838303)	Acc@1  46.88 ( 62.25)	Acc@5  75.00 ( 83.58)
Epoch: [16][ 60/109]	Time  0.371 ( 0.485)	Data  0.000 ( 0.078)	Loss 1.8027957677841187 (1.4457266408889020)	Acc@1  57.81 ( 62.22)	Acc@5  73.44 ( 83.43)
Epoch: [16][ 70/109]	Time  0.438 ( 0.472)	Data  0.000 ( 0.067)	Loss 1.7280834913253784 (1.4492314012957290)	Acc@1  59.38 ( 62.04)	Acc@5  78.12 ( 83.25)
Epoch: [16][ 80/109]	Time  0.561 ( 0.469)	Data  0.001 ( 0.059)	Loss 1.5062260627746582 (1.4782917543693825)	Acc@1  57.81 ( 61.32)	Acc@5  81.25 ( 82.68)
Epoch: [16][ 90/109]	Time  0.506 ( 0.477)	Data  0.000 ( 0.053)	Loss 1.7695503234863281 (1.4995962656461275)	Acc@1  54.69 ( 61.01)	Acc@5  79.69 ( 82.45)
Epoch: [16][100/109]	Time  0.382 ( 0.475)	Data  0.000 ( 0.048)	Loss 1.2835930585861206 (1.4948765865646967)	Acc@1  64.06 ( 61.11)	Acc@5  89.06 ( 82.50)
epoch: 16, Avg_Loss 1.4940239355104779
Test: [ 0/28]	Time  3.227 ( 3.227)	Loss 3.3021e+00 (3.3021e+00)	Acc@1  17.19 ( 17.19)	Acc@5  48.44 ( 48.44)
Test: [10/28]	Time  0.094 ( 0.517)	Loss 3.1323e+00 (1.5356e+00)	Acc@1  25.00 ( 62.22)	Acc@5  50.00 ( 79.55)
Test: [20/28]	Time  0.088 ( 0.401)	Loss 2.1727e+00 (1.9027e+00)	Acc@1  51.56 ( 50.82)	Acc@5  75.00 ( 75.67)
 * Acc@1 49.859 Acc@5 74.226
Epoch: [17][  0/109]	Time  3.731 ( 3.731)	Data  3.279 ( 3.279)	Loss 1.3096141815185547 (1.3096141815185547)	Acc@1  65.62 ( 65.62)	Acc@5  85.94 ( 85.94)
Epoch: [17][ 10/109]	Time  0.434 ( 0.708)	Data  0.000 ( 0.298)	Loss 1.2889695167541504 (1.3659422072497280)	Acc@1  57.81 ( 62.50)	Acc@5  82.81 ( 85.94)
Epoch: [17][ 20/109]	Time  0.422 ( 0.566)	Data  0.000 ( 0.156)	Loss 1.9057040214538574 (1.4177700508208502)	Acc@1  50.00 ( 61.83)	Acc@5  75.00 ( 84.60)
Epoch: [17][ 30/109]	Time  0.457 ( 0.518)	Data  0.000 ( 0.106)	Loss 1.3573753833770752 (1.4032028375133392)	Acc@1  62.50 ( 62.45)	Acc@5  92.19 ( 85.43)
Epoch: [17][ 40/109]	Time  0.429 ( 0.501)	Data  0.000 ( 0.080)	Loss 1.5933609008789062 (1.4234968830899495)	Acc@1  54.69 ( 61.81)	Acc@5  84.38 ( 84.76)
Epoch: [17][ 50/109]	Time  0.493 ( 0.511)	Data  0.000 ( 0.065)	Loss 1.5566496849060059 (1.4327709207347794)	Acc@1  60.94 ( 62.07)	Acc@5  79.69 ( 84.07)
Epoch: [17][ 60/109]	Time  0.413 ( 0.502)	Data  0.000 ( 0.054)	Loss 1.4270849227905273 (1.4179348496140027)	Acc@1  62.50 ( 62.35)	Acc@5  81.25 ( 84.14)
Epoch: [17][ 70/109]	Time  0.417 ( 0.492)	Data  0.000 ( 0.046)	Loss 1.2760945558547974 (1.4289225474209852)	Acc@1  62.50 ( 62.21)	Acc@5  89.06 ( 83.89)
Epoch: [17][ 80/109]	Time  0.494 ( 0.483)	Data  0.000 ( 0.041)	Loss 1.3997920751571655 (1.4200327190352076)	Acc@1  65.62 ( 62.67)	Acc@5  84.38 ( 84.03)
Epoch: [17][ 90/109]	Time  0.389 ( 0.476)	Data  0.000 ( 0.036)	Loss 1.7296477556228638 (1.4182170721200795)	Acc@1  53.12 ( 62.72)	Acc@5  85.94 ( 84.12)
Epoch: [17][100/109]	Time  0.386 ( 0.466)	Data  0.000 ( 0.033)	Loss 1.4843721389770508 (1.4223195621282747)	Acc@1  62.50 ( 62.53)	Acc@5  82.81 ( 84.10)
epoch: 17, Avg_Loss 1.4293664912565038
Test: [ 0/28]	Time  2.939 ( 2.939)	Loss 2.3556e+00 (2.3556e+00)	Acc@1  37.50 ( 37.50)	Acc@5  73.44 ( 73.44)
Test: [10/28]	Time  0.315 ( 0.505)	Loss 2.4318e+00 (1.7751e+00)	Acc@1  45.31 ( 54.26)	Acc@5  70.31 ( 81.11)
Test: [20/28]	Time  0.089 ( 0.369)	Loss 1.8839e+00 (2.1607e+00)	Acc@1  59.38 ( 46.28)	Acc@5  76.56 ( 74.40)
 * Acc@1 46.258 Acc@5 74.620
Epoch: [18][  0/109]	Time  3.881 ( 3.881)	Data  3.298 ( 3.298)	Loss 1.6309043169021606 (1.6309043169021606)	Acc@1  50.00 ( 50.00)	Acc@5  81.25 ( 81.25)
Epoch: [18][ 10/109]	Time  0.487 ( 0.755)	Data  0.000 ( 0.300)	Loss 1.3233890533447266 (1.3645251772620461)	Acc@1  70.31 ( 64.06)	Acc@5  84.38 ( 85.51)
Epoch: [18][ 20/109]	Time  0.442 ( 0.606)	Data  0.000 ( 0.157)	Loss 1.5687624216079712 (1.3681414354415167)	Acc@1  59.38 ( 64.58)	Acc@5  82.81 ( 84.97)
Epoch: [18][ 30/109]	Time  0.379 ( 0.547)	Data  0.000 ( 0.107)	Loss 1.2491000890731812 (1.3265969695583466)	Acc@1  67.19 ( 65.57)	Acc@5  85.94 ( 85.64)
Epoch: [18][ 40/109]	Time  0.421 ( 0.508)	Data  0.000 ( 0.081)	Loss 1.3531104326248169 (1.3492013550386197)	Acc@1  62.50 ( 64.63)	Acc@5  84.38 ( 85.56)
Epoch: [18][ 50/109]	Time  0.400 ( 0.487)	Data  0.000 ( 0.065)	Loss 1.5779176950454712 (1.3449818024448319)	Acc@1  59.38 ( 64.83)	Acc@5  79.69 ( 85.42)
Epoch: [18][ 60/109]	Time  0.383 ( 0.475)	Data  0.000 ( 0.054)	Loss 1.8685625791549683 (1.3516640242983082)	Acc@1  54.69 ( 64.37)	Acc@5  70.31 ( 85.32)
Epoch: [18][ 70/109]	Time  0.385 ( 0.465)	Data  0.000 ( 0.047)	Loss 1.2299343347549438 (1.3558635417844209)	Acc@1  65.62 ( 64.22)	Acc@5  82.81 ( 85.26)
Epoch: [18][ 80/109]	Time  0.428 ( 0.459)	Data  0.000 ( 0.041)	Loss 1.6913732290267944 (1.3633978138735265)	Acc@1  51.56 ( 63.87)	Acc@5  78.12 ( 85.05)
Epoch: [18][ 90/109]	Time  0.502 ( 0.460)	Data  0.000 ( 0.037)	Loss 1.3403277397155762 (1.3564374597517999)	Acc@1  57.81 ( 63.98)	Acc@5  90.62 ( 85.13)
Epoch: [18][100/109]	Time  0.384 ( 0.460)	Data  0.000 ( 0.033)	Loss 1.6044694185256958 (1.3680363769578461)	Acc@1  53.12 ( 63.74)	Acc@5  81.25 ( 84.96)
epoch: 18, Avg_Loss 1.3764342162587226
Test: [ 0/28]	Time  3.152 ( 3.152)	Loss 1.2266e+00 (1.2266e+00)	Acc@1  67.19 ( 67.19)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.152 ( 0.557)	Loss 3.7212e+00 (1.2662e+00)	Acc@1  23.44 ( 69.32)	Acc@5  34.38 ( 84.52)
Test: [20/28]	Time  0.089 ( 0.389)	Loss 3.1614e+00 (1.8708e+00)	Acc@1  35.94 ( 52.46)	Acc@5  53.12 ( 76.64)
 * Acc@1 49.409 Acc@5 73.945
Epoch: [19][  0/109]	Time  3.344 ( 3.344)	Data  2.753 ( 2.753)	Loss 1.0618822574615479 (1.0618822574615479)	Acc@1  71.88 ( 71.88)	Acc@5  90.62 ( 90.62)
Epoch: [19][ 10/109]	Time  0.371 ( 0.703)	Data  0.000 ( 0.251)	Loss 1.4515664577484131 (1.2546592083844272)	Acc@1  60.94 ( 67.19)	Acc@5  87.50 ( 87.93)
Epoch: [19][ 20/109]	Time  0.387 ( 0.568)	Data  0.000 ( 0.131)	Loss 1.4687445163726807 (1.2693322272527785)	Acc@1  56.25 ( 66.29)	Acc@5  87.50 ( 87.50)
Epoch: [19][ 30/109]	Time  0.415 ( 0.519)	Data  0.000 ( 0.089)	Loss 1.8545110225677490 (1.3529251698524720)	Acc@1  50.00 ( 64.06)	Acc@5  79.69 ( 86.29)
Epoch: [19][ 40/109]	Time  0.528 ( 0.494)	Data  0.000 ( 0.067)	Loss 1.2214862108230591 (1.3636345020154628)	Acc@1  70.31 ( 64.10)	Acc@5  85.94 ( 85.98)
Epoch: [19][ 50/109]	Time  0.462 ( 0.493)	Data  0.001 ( 0.054)	Loss 1.2962927818298340 (1.3445878800223856)	Acc@1  64.06 ( 64.58)	Acc@5  82.81 ( 86.18)
Epoch: [19][ 60/109]	Time  0.450 ( 0.489)	Data  0.000 ( 0.045)	Loss 1.4527455568313599 (1.3459716820326009)	Acc@1  67.19 ( 64.75)	Acc@5  84.38 ( 85.89)
Epoch: [19][ 70/109]	Time  0.419 ( 0.481)	Data  0.000 ( 0.039)	Loss 1.1870064735412598 (1.3473275715196635)	Acc@1  75.00 ( 64.68)	Acc@5  85.94 ( 85.70)
Epoch: [19][ 80/109]	Time  0.455 ( 0.471)	Data  0.001 ( 0.034)	Loss 0.7498943805694580 (1.3432837754120062)	Acc@1  81.25 ( 64.89)	Acc@5  93.75 ( 85.71)
Epoch: [19][ 90/109]	Time  0.396 ( 0.466)	Data  0.000 ( 0.031)	Loss 1.0350495576858521 (1.3225387426523061)	Acc@1  71.88 ( 65.50)	Acc@5  89.06 ( 86.01)
Epoch: [19][100/109]	Time  0.397 ( 0.462)	Data  0.000 ( 0.028)	Loss 1.1983357667922974 (1.3198840535513245)	Acc@1  65.62 ( 65.41)	Acc@5  89.06 ( 85.86)
epoch: 19, Avg_Loss 1.3308050205948156
Test: [ 0/28]	Time  2.709 ( 2.709)	Loss 2.5266e+00 (2.5266e+00)	Acc@1  35.94 ( 35.94)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.187 ( 0.497)	Loss 3.2681e+00 (1.4085e+00)	Acc@1  35.94 ( 69.32)	Acc@5  59.38 ( 83.38)
Test: [20/28]	Time  0.088 ( 0.366)	Loss 2.4395e+00 (1.9410e+00)	Acc@1  50.00 ( 55.58)	Acc@5  70.31 ( 77.68)
 * Acc@1 50.197 Acc@5 73.720
Epoch: [20][  0/109]	Time  2.937 ( 2.937)	Data  2.501 ( 2.501)	Loss 1.2132225036621094 (1.2132225036621094)	Acc@1  73.44 ( 73.44)	Acc@5  87.50 ( 87.50)
Epoch: [20][ 10/109]	Time  0.528 ( 0.803)	Data  0.000 ( 0.260)	Loss 0.9184854626655579 (1.2604587782513013)	Acc@1  70.31 ( 64.91)	Acc@5  93.75 ( 85.94)
Epoch: [20][ 20/109]	Time  0.520 ( 0.637)	Data  0.000 ( 0.136)	Loss 1.0750097036361694 (1.2632832583926974)	Acc@1  70.31 ( 65.55)	Acc@5  89.06 ( 86.61)
Epoch: [20][ 30/109]	Time  0.377 ( 0.559)	Data  0.000 ( 0.092)	Loss 1.3070567846298218 (1.2301087244864433)	Acc@1  62.50 ( 66.58)	Acc@5  87.50 ( 87.15)
Epoch: [20][ 40/109]	Time  0.399 ( 0.520)	Data  0.000 ( 0.070)	Loss 1.5138262510299683 (1.2551625283753001)	Acc@1  62.50 ( 66.08)	Acc@5  82.81 ( 86.70)
Epoch: [20][ 50/109]	Time  0.388 ( 0.500)	Data  0.000 ( 0.056)	Loss 1.4888910055160522 (1.2591020535020268)	Acc@1  62.50 ( 66.12)	Acc@5  85.94 ( 86.89)
Epoch: [20][ 60/109]	Time  0.398 ( 0.483)	Data  0.000 ( 0.047)	Loss 1.3479317426681519 (1.2572036844785097)	Acc@1  64.06 ( 66.47)	Acc@5  85.94 ( 86.73)
Epoch: [20][ 70/109]	Time  0.372 ( 0.473)	Data  0.000 ( 0.040)	Loss 1.2186880111694336 (1.2707488553624757)	Acc@1  70.31 ( 66.24)	Acc@5  84.38 ( 86.49)
Epoch: [20][ 80/109]	Time  0.403 ( 0.465)	Data  0.000 ( 0.035)	Loss 1.6208336353302002 (1.2553969893926455)	Acc@1  59.38 ( 66.65)	Acc@5  79.69 ( 86.75)
Epoch: [20][ 90/109]	Time  0.411 ( 0.458)	Data  0.000 ( 0.032)	Loss 1.3368172645568848 (1.2511383262309399)	Acc@1  64.06 ( 66.98)	Acc@5  90.62 ( 86.88)
Epoch: [20][100/109]	Time  0.369 ( 0.452)	Data  0.000 ( 0.029)	Loss 1.7157843112945557 (1.2662765135859499)	Acc@1  54.69 ( 66.58)	Acc@5  81.25 ( 86.74)
epoch: 20, Avg_Loss 1.2696733305213648
Test: [ 0/28]	Time  3.914 ( 3.914)	Loss 1.9469e+00 (1.9469e+00)	Acc@1  43.75 ( 43.75)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.088 ( 0.588)	Loss 3.3252e+00 (1.6254e+00)	Acc@1  25.00 ( 62.50)	Acc@5  56.25 ( 82.24)
Test: [20/28]	Time  0.088 ( 0.398)	Loss 3.1567e+00 (2.1949e+00)	Acc@1  32.81 ( 47.99)	Acc@5  56.25 ( 73.51)
 * Acc@1 44.682 Acc@5 70.062
Epoch: [21][  0/109]	Time  4.082 ( 4.082)	Data  3.607 ( 3.607)	Loss 0.8884747028350830 (0.8884747028350830)	Acc@1  71.88 ( 71.88)	Acc@5  95.31 ( 95.31)
Epoch: [21][ 10/109]	Time  0.497 ( 0.748)	Data  0.000 ( 0.328)	Loss 1.3361115455627441 (1.2420262152498418)	Acc@1  65.62 ( 66.90)	Acc@5  84.38 ( 88.07)
Epoch: [21][ 20/109]	Time  0.483 ( 0.587)	Data  0.000 ( 0.172)	Loss 1.2262445688247681 (1.2217758411452884)	Acc@1  71.88 ( 67.41)	Acc@5  85.94 ( 88.47)
Epoch: [21][ 30/109]	Time  0.368 ( 0.526)	Data  0.000 ( 0.117)	Loss 1.0985264778137207 (1.2168369043257929)	Acc@1  67.19 ( 66.99)	Acc@5  90.62 ( 88.10)
Epoch: [21][ 40/109]	Time  0.391 ( 0.495)	Data  0.000 ( 0.088)	Loss 0.9357183575630188 (1.2004866774489240)	Acc@1  70.31 ( 67.26)	Acc@5  90.62 ( 88.57)
Epoch: [21][ 50/109]	Time  0.376 ( 0.478)	Data  0.000 ( 0.071)	Loss 1.3849241733551025 (1.2205349826345258)	Acc@1  64.06 ( 66.85)	Acc@5  84.38 ( 88.27)
Epoch: [21][ 60/109]	Time  0.514 ( 0.465)	Data  0.000 ( 0.059)	Loss 1.3353577852249146 (1.2345835117043042)	Acc@1  67.19 ( 66.91)	Acc@5  82.81 ( 87.86)
Epoch: [21][ 70/109]	Time  0.478 ( 0.473)	Data  0.000 ( 0.051)	Loss 1.1255033016204834 (1.2396281193679488)	Acc@1  68.75 ( 66.81)	Acc@5  87.50 ( 87.79)
Epoch: [21][ 80/109]	Time  0.371 ( 0.468)	Data  0.000 ( 0.045)	Loss 1.3567913770675659 (1.2326324854368045)	Acc@1  62.50 ( 66.96)	Acc@5  84.38 ( 87.77)
Epoch: [21][ 90/109]	Time  0.404 ( 0.462)	Data  0.000 ( 0.040)	Loss 1.0068949460983276 (1.2363462932817229)	Acc@1  70.31 ( 66.95)	Acc@5  89.06 ( 87.67)
Epoch: [21][100/109]	Time  0.371 ( 0.455)	Data  0.000 ( 0.036)	Loss 1.1737903356552124 (1.2355423115267612)	Acc@1  67.19 ( 67.05)	Acc@5  85.94 ( 87.65)
epoch: 21, Avg_Loss 1.2380400310962572
Test: [ 0/28]	Time  2.899 ( 2.899)	Loss 1.8552e+00 (1.8552e+00)	Acc@1  53.12 ( 53.12)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.096 ( 0.520)	Loss 3.0164e+00 (1.3521e+00)	Acc@1  39.06 ( 67.90)	Acc@5  54.69 ( 84.66)
Test: [20/28]	Time  0.093 ( 0.378)	Loss 2.1799e+00 (1.9048e+00)	Acc@1  57.81 ( 54.39)	Acc@5  73.44 ( 76.12)
 * Acc@1 51.154 Acc@5 75.408
Epoch: [22][  0/109]	Time  3.606 ( 3.606)	Data  3.103 ( 3.103)	Loss 0.8406781554222107 (0.8406781554222107)	Acc@1  75.00 ( 75.00)	Acc@5  96.88 ( 96.88)
Epoch: [22][ 10/109]	Time  0.427 ( 0.716)	Data  0.000 ( 0.293)	Loss 0.8668560981750488 (0.9992788759144869)	Acc@1  75.00 ( 71.59)	Acc@5  93.75 ( 92.05)
Epoch: [22][ 20/109]	Time  0.625 ( 0.602)	Data  0.000 ( 0.154)	Loss 1.4554582834243774 (1.0532093558992659)	Acc@1  53.12 ( 70.76)	Acc@5  85.94 ( 91.15)
Epoch: [22][ 30/109]	Time  0.462 ( 0.594)	Data  0.001 ( 0.104)	Loss 1.2840547561645508 (1.1051478732016780)	Acc@1  67.19 ( 69.91)	Acc@5  87.50 ( 90.68)
Epoch: [22][ 40/109]	Time  0.384 ( 0.550)	Data  0.000 ( 0.079)	Loss 0.8188604712486267 (1.1066030103985856)	Acc@1  75.00 ( 69.97)	Acc@5  93.75 ( 90.21)
Epoch: [22][ 50/109]	Time  0.396 ( 0.526)	Data  0.000 ( 0.063)	Loss 1.1295310258865356 (1.1296123558399724)	Acc@1  71.88 ( 69.30)	Acc@5  90.62 ( 89.61)
Epoch: [22][ 60/109]	Time  0.365 ( 0.503)	Data  0.000 ( 0.053)	Loss 1.5007426738739014 (1.1832307000629236)	Acc@1  57.81 ( 68.24)	Acc@5  82.81 ( 88.88)
Epoch: [22][ 70/109]	Time  0.387 ( 0.489)	Data  0.000 ( 0.046)	Loss 1.3643870353698730 (1.1952438220171862)	Acc@1  68.75 ( 68.33)	Acc@5  87.50 ( 88.53)
Epoch: [22][ 80/109]	Time  0.436 ( 0.481)	Data  0.000 ( 0.040)	Loss 1.3193032741546631 (1.1947672676157068)	Acc@1  62.50 ( 68.36)	Acc@5  89.06 ( 88.45)
Epoch: [22][ 90/109]	Time  0.407 ( 0.472)	Data  0.000 ( 0.036)	Loss 1.0730887651443481 (1.1964069893071940)	Acc@1  70.31 ( 68.29)	Acc@5  85.94 ( 88.46)
Epoch: [22][100/109]	Time  0.368 ( 0.464)	Data  0.000 ( 0.032)	Loss 1.0803073644638062 (1.1899432528136979)	Acc@1  70.31 ( 68.22)	Acc@5  89.06 ( 88.47)
epoch: 22, Avg_Loss 1.1903070550446118
Test: [ 0/28]	Time  3.477 ( 3.477)	Loss 1.6875e+00 (1.6875e+00)	Acc@1  54.69 ( 54.69)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.097 ( 0.537)	Loss 2.8961e+00 (1.1190e+00)	Acc@1  35.94 ( 74.43)	Acc@5  64.06 ( 87.50)
Test: [20/28]	Time  0.131 ( 0.419)	Loss 2.4861e+00 (1.7485e+00)	Acc@1  50.00 ( 57.81)	Acc@5  67.19 ( 78.57)
 * Acc@1 55.093 Acc@5 76.421
Epoch: [23][  0/109]	Time  3.897 ( 3.897)	Data  3.447 ( 3.447)	Loss 1.3176048994064331 (1.3176048994064331)	Acc@1  65.62 ( 65.62)	Acc@5  87.50 ( 87.50)
Epoch: [23][ 10/109]	Time  0.400 ( 0.726)	Data  0.000 ( 0.314)	Loss 1.2403637170791626 (1.1541828513145447)	Acc@1  67.19 ( 69.03)	Acc@5  89.06 ( 87.78)
Epoch: [23][ 20/109]	Time  0.379 ( 0.576)	Data  0.000 ( 0.164)	Loss 0.7040289640426636 (1.1007187820616222)	Acc@1  81.25 ( 70.09)	Acc@5  95.31 ( 88.84)
Epoch: [23][ 30/109]	Time  0.384 ( 0.513)	Data  0.000 ( 0.111)	Loss 1.2701650857925415 (1.1257516664843406)	Acc@1  60.94 ( 69.00)	Acc@5  90.62 ( 89.06)
Epoch: [23][ 40/109]	Time  0.389 ( 0.483)	Data  0.000 ( 0.084)	Loss 1.1196690797805786 (1.1201326076577349)	Acc@1  67.19 ( 69.21)	Acc@5  89.06 ( 89.33)
Epoch: [23][ 50/109]	Time  0.379 ( 0.468)	Data  0.000 ( 0.068)	Loss 1.0813633203506470 (1.1301639956586502)	Acc@1  73.44 ( 69.18)	Acc@5  92.19 ( 89.28)
Epoch: [23][ 60/109]	Time  0.359 ( 0.455)	Data  0.000 ( 0.057)	Loss 0.6111599206924438 (1.1083455994480946)	Acc@1  82.81 ( 69.80)	Acc@5  96.88 ( 89.55)
Epoch: [23][ 70/109]	Time  0.365 ( 0.446)	Data  0.000 ( 0.049)	Loss 1.1256207227706909 (1.1097066049844446)	Acc@1  70.31 ( 69.94)	Acc@5  87.50 ( 89.28)
Epoch: [23][ 80/109]	Time  0.417 ( 0.445)	Data  0.000 ( 0.043)	Loss 1.3461800813674927 (1.1158355253714103)	Acc@1  67.19 ( 69.58)	Acc@5  90.62 ( 89.27)
Epoch: [23][ 90/109]	Time  0.633 ( 0.450)	Data  0.000 ( 0.038)	Loss 0.9718575477600098 (1.1121263621927617)	Acc@1  79.69 ( 69.73)	Acc@5  89.06 ( 89.18)
Epoch: [23][100/109]	Time  0.367 ( 0.449)	Data  0.000 ( 0.034)	Loss 0.7846565246582031 (1.1148161734684858)	Acc@1  78.12 ( 69.62)	Acc@5  96.88 ( 89.11)
epoch: 23, Avg_Loss 1.1188028000910348
Test: [ 0/28]	Time  3.519 ( 3.519)	Loss 1.7765e+00 (1.7765e+00)	Acc@1  43.75 ( 43.75)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.088 ( 0.534)	Loss 2.4330e+00 (1.2281e+00)	Acc@1  40.62 ( 68.61)	Acc@5  76.56 ( 87.78)
Test: [20/28]	Time  0.089 ( 0.372)	Loss 1.8205e+00 (1.9158e+00)	Acc@1  53.12 ( 54.84)	Acc@5  81.25 ( 77.60)
 * Acc@1 52.617 Acc@5 75.858
Epoch: [24][  0/109]	Time  3.241 ( 3.241)	Data  2.799 ( 2.799)	Loss 0.8109365105628967 (0.8109365105628967)	Acc@1  75.00 ( 75.00)	Acc@5  90.62 ( 90.62)
Epoch: [24][ 10/109]	Time  0.403 ( 0.699)	Data  0.000 ( 0.285)	Loss 1.3552433252334595 (1.0465108427134426)	Acc@1  67.19 ( 70.88)	Acc@5  84.38 ( 90.91)
Epoch: [24][ 20/109]	Time  0.383 ( 0.559)	Data  0.000 ( 0.149)	Loss 0.9397392868995667 (1.0689419564746676)	Acc@1  76.56 ( 71.06)	Acc@5  92.19 ( 89.81)
Epoch: [24][ 30/109]	Time  0.387 ( 0.501)	Data  0.000 ( 0.101)	Loss 1.0037539005279541 (1.0945267177397204)	Acc@1  73.44 ( 70.31)	Acc@5  92.19 ( 89.01)
Epoch: [24][ 40/109]	Time  0.408 ( 0.480)	Data  0.000 ( 0.077)	Loss 1.1684076786041260 (1.0721136215256482)	Acc@1  67.19 ( 70.92)	Acc@5  87.50 ( 89.41)
Epoch: [24][ 50/109]	Time  0.537 ( 0.486)	Data  0.000 ( 0.062)	Loss 1.1272828578948975 (1.0667272128310858)	Acc@1  67.19 ( 71.02)	Acc@5  90.62 ( 89.58)
Epoch: [24][ 60/109]	Time  0.368 ( 0.483)	Data  0.000 ( 0.052)	Loss 0.9497867822647095 (1.0616796036235621)	Acc@1  73.44 ( 71.26)	Acc@5  92.19 ( 89.63)
Epoch: [24][ 70/109]	Time  0.386 ( 0.473)	Data  0.000 ( 0.044)	Loss 1.0203826427459717 (1.0660947796324609)	Acc@1  73.44 ( 71.30)	Acc@5  85.94 ( 89.28)
Epoch: [24][ 80/109]	Time  0.426 ( 0.465)	Data  0.000 ( 0.039)	Loss 0.9393730759620667 (1.0722310403246937)	Acc@1  75.00 ( 71.06)	Acc@5  93.75 ( 89.14)
Epoch: [24][ 90/109]	Time  0.447 ( 0.459)	Data  0.000 ( 0.035)	Loss 1.3629367351531982 (1.0754915233496780)	Acc@1  71.88 ( 71.05)	Acc@5  84.38 ( 89.11)
Epoch: [24][100/109]	Time  0.367 ( 0.452)	Data  0.000 ( 0.031)	Loss 1.3358074426651001 (1.0849954851783148)	Acc@1  67.19 ( 71.01)	Acc@5  84.38 ( 89.02)
epoch: 24, Avg_Loss 1.100699153515177
Test: [ 0/28]	Time  2.597 ( 2.597)	Loss 1.9447e+00 (1.9447e+00)	Acc@1  42.19 ( 42.19)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.089 ( 0.506)	Loss 2.9432e+00 (1.4945e+00)	Acc@1  34.38 ( 63.64)	Acc@5  65.62 ( 84.23)
Test: [20/28]	Time  0.087 ( 0.374)	Loss 2.6045e+00 (2.1715e+00)	Acc@1  42.19 ( 49.93)	Acc@5  70.31 ( 72.62)
 * Acc@1 48.227 Acc@5 71.187
Epoch: [25][  0/109]	Time  4.205 ( 4.205)	Data  3.613 ( 3.613)	Loss 0.9618749618530273 (0.9618749618530273)	Acc@1  75.00 ( 75.00)	Acc@5  89.06 ( 89.06)
Epoch: [25][ 10/109]	Time  0.509 ( 0.775)	Data  0.000 ( 0.329)	Loss 1.1847534179687500 (0.9877500750801780)	Acc@1  67.19 ( 72.44)	Acc@5  87.50 ( 91.05)
Epoch: [25][ 20/109]	Time  0.462 ( 0.604)	Data  0.000 ( 0.172)	Loss 1.2023071050643921 (1.0461969375610352)	Acc@1  73.44 ( 71.43)	Acc@5  87.50 ( 90.40)
Epoch: [25][ 30/109]	Time  0.378 ( 0.546)	Data  0.000 ( 0.117)	Loss 1.1504551172256470 (1.0582232494508066)	Acc@1  71.88 ( 70.92)	Acc@5  89.06 ( 90.12)
Epoch: [25][ 40/109]	Time  0.378 ( 0.510)	Data  0.000 ( 0.088)	Loss 1.3002336025238037 (1.0427809808312394)	Acc@1  62.50 ( 71.46)	Acc@5  87.50 ( 90.13)
Epoch: [25][ 50/109]	Time  0.479 ( 0.494)	Data  0.000 ( 0.071)	Loss 0.8545340299606323 (1.0444638062925899)	Acc@1  75.00 ( 71.60)	Acc@5  90.62 ( 90.13)
Epoch: [25][ 60/109]	Time  0.369 ( 0.479)	Data  0.000 ( 0.060)	Loss 1.0691533088684082 (1.0470492556446889)	Acc@1  70.31 ( 71.67)	Acc@5  90.62 ( 90.22)
Epoch: [25][ 70/109]	Time  0.389 ( 0.469)	Data  0.000 ( 0.051)	Loss 0.8253503441810608 (1.0483869700364663)	Acc@1  76.56 ( 71.76)	Acc@5  92.19 ( 90.21)
Epoch: [25][ 80/109]	Time  0.371 ( 0.461)	Data  0.000 ( 0.045)	Loss 1.1688137054443359 (1.0444018340405123)	Acc@1  67.19 ( 71.84)	Acc@5  84.38 ( 90.14)
Epoch: [25][ 90/109]	Time  0.514 ( 0.461)	Data  0.002 ( 0.040)	Loss 1.1116983890533447 (1.0607610744434399)	Acc@1  76.56 ( 71.57)	Acc@5  87.50 ( 89.87)
Epoch: [25][100/109]	Time  0.371 ( 0.462)	Data  0.000 ( 0.036)	Loss 1.0048117637634277 (1.0584468151083086)	Acc@1  73.44 ( 71.43)	Acc@5  90.62 ( 89.90)
epoch: 25, Avg_Loss 1.0596090194282182
Test: [ 0/28]	Time  3.228 ( 3.228)	Loss 3.1480e+00 (3.1480e+00)	Acc@1  28.12 ( 28.12)	Acc@5  56.25 ( 56.25)
Test: [10/28]	Time  0.096 ( 0.539)	Loss 1.9352e+00 (1.1152e+00)	Acc@1  50.00 ( 73.72)	Acc@5  78.12 ( 87.36)
Test: [20/28]	Time  0.088 ( 0.380)	Loss 1.3765e+00 (1.6508e+00)	Acc@1  64.06 ( 59.00)	Acc@5  85.94 ( 81.25)
 * Acc@1 57.794 Acc@5 80.810
Epoch: [26][  0/109]	Time  3.828 ( 3.828)	Data  3.330 ( 3.330)	Loss 0.7825518250465393 (0.7825518250465393)	Acc@1  78.12 ( 78.12)	Acc@5  93.75 ( 93.75)
Epoch: [26][ 10/109]	Time  0.390 ( 0.726)	Data  0.000 ( 0.303)	Loss 1.0234285593032837 (0.9602102095430548)	Acc@1  67.19 ( 73.86)	Acc@5  93.75 ( 91.62)
Epoch: [26][ 20/109]	Time  0.370 ( 0.570)	Data  0.000 ( 0.159)	Loss 1.1741443872451782 (0.9666737346422105)	Acc@1  71.88 ( 73.74)	Acc@5  87.50 ( 91.44)
Epoch: [26][ 30/109]	Time  0.380 ( 0.519)	Data  0.000 ( 0.108)	Loss 1.0595629215240479 (0.9677615780984202)	Acc@1  68.75 ( 73.08)	Acc@5  87.50 ( 91.03)
Epoch: [26][ 40/109]	Time  0.478 ( 0.498)	Data  0.000 ( 0.081)	Loss 0.8653362393379211 (0.9700843401071502)	Acc@1  73.44 ( 72.79)	Acc@5  95.31 ( 91.16)
Epoch: [26][ 50/109]	Time  0.412 ( 0.500)	Data  0.000 ( 0.066)	Loss 0.7516049742698669 (0.9837731952760734)	Acc@1  81.25 ( 72.76)	Acc@5  93.75 ( 90.69)
Epoch: [26][ 60/109]	Time  0.385 ( 0.484)	Data  0.000 ( 0.055)	Loss 1.3797924518585205 (0.9847399660798369)	Acc@1  67.19 ( 72.93)	Acc@5  85.94 ( 90.60)
Epoch: [26][ 70/109]	Time  0.422 ( 0.473)	Data  0.000 ( 0.047)	Loss 0.9445393681526184 (0.9980474215158275)	Acc@1  75.00 ( 72.67)	Acc@5  90.62 ( 90.45)
Epoch: [26][ 80/109]	Time  0.378 ( 0.465)	Data  0.000 ( 0.041)	Loss 0.9628727436065674 (1.0114568170206046)	Acc@1  73.44 ( 72.45)	Acc@5  90.62 ( 90.28)
Epoch: [26][ 90/109]	Time  0.372 ( 0.456)	Data  0.000 ( 0.037)	Loss 1.0130335092544556 (1.0214671990373632)	Acc@1  73.44 ( 72.20)	Acc@5  89.06 ( 90.04)
Epoch: [26][100/109]	Time  0.377 ( 0.449)	Data  0.000 ( 0.033)	Loss 0.6689617037773132 (1.0251316074097510)	Acc@1  79.69 ( 72.06)	Acc@5  96.88 ( 90.08)
epoch: 26, Avg_Loss 1.0306525547570045
Test: [ 0/28]	Time  3.518 ( 3.518)	Loss 2.2495e+00 (2.2495e+00)	Acc@1  29.69 ( 29.69)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.088 ( 0.538)	Loss 2.3156e+00 (9.9256e-01)	Acc@1  56.25 ( 76.56)	Acc@5  79.69 ( 89.77)
Test: [20/28]	Time  0.088 ( 0.384)	Loss 1.2974e+00 (1.4369e+00)	Acc@1  65.62 ( 64.81)	Acc@5  87.50 ( 83.78)
 * Acc@1 61.902 Acc@5 82.273
Epoch: [27][  0/109]	Time  3.219 ( 3.219)	Data  2.524 ( 2.524)	Loss 0.7736889123916626 (0.7736889123916626)	Acc@1  76.56 ( 76.56)	Acc@5  93.75 ( 93.75)
Epoch: [27][ 10/109]	Time  0.367 ( 0.779)	Data  0.000 ( 0.283)	Loss 1.2369699478149414 (0.8636391921476885)	Acc@1  64.06 ( 76.99)	Acc@5  89.06 ( 92.61)
Epoch: [27][ 20/109]	Time  0.448 ( 0.603)	Data  0.000 ( 0.148)	Loss 0.8029842376708984 (0.9292576681999933)	Acc@1  76.56 ( 75.22)	Acc@5  93.75 ( 92.11)
Epoch: [27][ 30/109]	Time  0.376 ( 0.540)	Data  0.000 ( 0.101)	Loss 0.8131964802742004 (0.9387057481273529)	Acc@1  73.44 ( 75.40)	Acc@5  93.75 ( 91.68)
Epoch: [27][ 40/109]	Time  0.435 ( 0.509)	Data  0.000 ( 0.076)	Loss 0.9156659841537476 (0.9660110720774022)	Acc@1  75.00 ( 74.35)	Acc@5  87.50 ( 91.04)
Epoch: [27][ 50/109]	Time  0.405 ( 0.492)	Data  0.000 ( 0.061)	Loss 1.0499491691589355 (0.9811930936925551)	Acc@1  70.31 ( 74.05)	Acc@5  87.50 ( 90.81)
Epoch: [27][ 60/109]	Time  0.412 ( 0.478)	Data  0.000 ( 0.051)	Loss 0.8192234635353088 (0.9695056911374702)	Acc@1  81.25 ( 74.15)	Acc@5  93.75 ( 91.11)
Epoch: [27][ 70/109]	Time  0.434 ( 0.466)	Data  0.000 ( 0.044)	Loss 1.2161594629287720 (0.9743020383405013)	Acc@1  67.19 ( 73.99)	Acc@5  89.06 ( 90.85)
Epoch: [27][ 80/109]	Time  0.415 ( 0.459)	Data  0.000 ( 0.039)	Loss 0.9786519408226013 (0.9666090438395371)	Acc@1  75.00 ( 74.29)	Acc@5  89.06 ( 91.05)
Epoch: [27][ 90/109]	Time  0.427 ( 0.453)	Data  0.000 ( 0.034)	Loss 0.9636052846908569 (0.9695644588260860)	Acc@1  71.88 ( 74.30)	Acc@5  89.06 ( 90.88)
Epoch: [27][100/109]	Time  0.475 ( 0.456)	Data  0.000 ( 0.031)	Loss 1.0851835012435913 (0.9736302317959247)	Acc@1  65.62 ( 74.18)	Acc@5  93.75 ( 90.72)
epoch: 27, Avg_Loss 0.9736575916272785
Test: [ 0/28]	Time  3.097 ( 3.097)	Loss 2.3574e+00 (2.3574e+00)	Acc@1  37.50 ( 37.50)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.344 ( 0.511)	Loss 2.3086e+00 (9.6336e-01)	Acc@1  48.44 ( 76.56)	Acc@5  73.44 ( 89.20)
Test: [20/28]	Time  0.087 ( 0.368)	Loss 1.9695e+00 (1.5245e+00)	Acc@1  59.38 ( 62.50)	Acc@5  76.56 ( 82.29)
 * Acc@1 60.495 Acc@5 81.598
Epoch: [28][  0/109]	Time  3.639 ( 3.639)	Data  3.189 ( 3.189)	Loss 1.0187209844589233 (1.0187209844589233)	Acc@1  70.31 ( 70.31)	Acc@5  90.62 ( 90.62)
Epoch: [28][ 10/109]	Time  0.381 ( 0.700)	Data  0.000 ( 0.290)	Loss 0.7815488576889038 (0.9507435397668318)	Acc@1  78.12 ( 73.72)	Acc@5  93.75 ( 92.47)
Epoch: [28][ 20/109]	Time  0.434 ( 0.563)	Data  0.000 ( 0.152)	Loss 0.6879419088363647 (0.9273404053279332)	Acc@1  81.25 ( 75.15)	Acc@5  95.31 ( 91.82)
Epoch: [28][ 30/109]	Time  0.380 ( 0.517)	Data  0.000 ( 0.103)	Loss 0.6432427763938904 (0.9253301889665665)	Acc@1  81.25 ( 75.00)	Acc@5  98.44 ( 92.04)
Epoch: [28][ 40/109]	Time  0.374 ( 0.492)	Data  0.000 ( 0.078)	Loss 0.8785198330879211 (0.9134187073242374)	Acc@1  73.44 ( 75.15)	Acc@5  87.50 ( 91.88)
Epoch: [28][ 50/109]	Time  0.533 ( 0.483)	Data  0.000 ( 0.063)	Loss 1.0294438600540161 (0.9460587022351283)	Acc@1  73.44 ( 74.30)	Acc@5  87.50 ( 91.57)
Epoch: [28][ 60/109]	Time  0.465 ( 0.486)	Data  0.000 ( 0.053)	Loss 0.9956037402153015 (0.9383448606631795)	Acc@1  68.75 ( 74.49)	Acc@5  87.50 ( 91.60)
Epoch: [28][ 70/109]	Time  0.394 ( 0.477)	Data  0.000 ( 0.045)	Loss 0.7367894053459167 (0.9430023750788729)	Acc@1  76.56 ( 74.23)	Acc@5  93.75 ( 91.70)
Epoch: [28][ 80/109]	Time  0.394 ( 0.467)	Data  0.000 ( 0.040)	Loss 0.7811385989189148 (0.9625650644302368)	Acc@1  78.12 ( 73.63)	Acc@5  93.75 ( 91.28)
Epoch: [28][ 90/109]	Time  0.372 ( 0.460)	Data  0.000 ( 0.035)	Loss 0.8563221693038940 (0.9586485198565892)	Acc@1  76.56 ( 73.88)	Acc@5  92.19 ( 91.29)
Epoch: [28][100/109]	Time  0.368 ( 0.454)	Data  0.000 ( 0.032)	Loss 1.1899882555007935 (0.9590952284265273)	Acc@1  65.62 ( 73.81)	Acc@5  87.50 ( 91.17)
epoch: 28, Avg_Loss 0.9605913074738389
Test: [ 0/28]	Time  3.131 ( 3.131)	Loss 2.9311e+00 (2.9311e+00)	Acc@1  25.00 ( 25.00)	Acc@5  67.19 ( 67.19)
Test: [10/28]	Time  0.128 ( 0.505)	Loss 2.3653e+00 (1.3316e+00)	Acc@1  39.06 ( 66.19)	Acc@5  65.62 ( 85.51)
Test: [20/28]	Time  0.140 ( 0.376)	Loss 2.2166e+00 (1.8520e+00)	Acc@1  46.88 ( 55.36)	Acc@5  73.44 ( 77.53)
 * Acc@1 54.249 Acc@5 76.927
Epoch: [29][  0/109]	Time  3.846 ( 3.846)	Data  3.474 ( 3.474)	Loss 1.2246192693710327 (1.2246192693710327)	Acc@1  62.50 ( 62.50)	Acc@5  87.50 ( 87.50)
Epoch: [29][ 10/109]	Time  0.598 ( 0.795)	Data  0.000 ( 0.316)	Loss 0.8523622155189514 (0.9011353850364685)	Acc@1  75.00 ( 76.14)	Acc@5  93.75 ( 90.77)
Epoch: [29][ 20/109]	Time  0.368 ( 0.643)	Data  0.000 ( 0.166)	Loss 0.6967532634735107 (0.8870915344783238)	Acc@1  84.38 ( 76.79)	Acc@5  95.31 ( 91.07)
Epoch: [29][ 30/109]	Time  0.374 ( 0.566)	Data  0.000 ( 0.112)	Loss 1.0166388750076294 (0.8959330627995152)	Acc@1  76.56 ( 76.16)	Acc@5  90.62 ( 91.18)
Epoch: [29][ 40/109]	Time  0.367 ( 0.527)	Data  0.000 ( 0.085)	Loss 0.5701712965965271 (0.8574673693354536)	Acc@1  85.94 ( 77.21)	Acc@5  93.75 ( 91.92)
Epoch: [29][ 50/109]	Time  0.458 ( 0.503)	Data  0.000 ( 0.069)	Loss 1.0997886657714844 (0.8689486512950823)	Acc@1  70.31 ( 76.72)	Acc@5  87.50 ( 92.10)
Epoch: [29][ 60/109]	Time  0.477 ( 0.487)	Data  0.000 ( 0.057)	Loss 0.6166354417800903 (0.8516960339468034)	Acc@1  87.50 ( 77.33)	Acc@5  95.31 ( 92.24)
Epoch: [29][ 70/109]	Time  0.447 ( 0.476)	Data  0.000 ( 0.049)	Loss 0.6961833238601685 (0.8562327698922493)	Acc@1  82.81 ( 77.29)	Acc@5  93.75 ( 92.14)
Epoch: [29][ 80/109]	Time  0.377 ( 0.465)	Data  0.000 ( 0.043)	Loss 0.9332146048545837 (0.8554494557557283)	Acc@1  73.44 ( 77.14)	Acc@5  92.19 ( 92.26)
Epoch: [29][ 90/109]	Time  0.480 ( 0.461)	Data  0.000 ( 0.039)	Loss 0.5616635084152222 (0.8623811982490204)	Acc@1  81.25 ( 76.96)	Acc@5 100.00 ( 92.10)
Epoch: [29][100/109]	Time  0.367 ( 0.452)	Data  0.000 ( 0.035)	Loss 0.5074250698089600 (0.8634912283113687)	Acc@1  87.50 ( 76.87)	Acc@5  95.31 ( 92.09)
epoch: 29, Avg_Loss 0.8660140737481073
Test: [ 0/28]	Time  3.424 ( 3.424)	Loss 1.7122e+00 (1.7122e+00)	Acc@1  50.00 ( 50.00)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.098 ( 0.522)	Loss 2.3318e+00 (9.4670e-01)	Acc@1  50.00 ( 78.12)	Acc@5  68.75 ( 89.49)
Test: [20/28]	Time  0.266 ( 0.381)	Loss 1.3810e+00 (1.4309e+00)	Acc@1  64.06 ( 64.06)	Acc@5  84.38 ( 84.08)
 * Acc@1 60.889 Acc@5 82.217
Epoch: [30][  0/109]	Time  3.120 ( 3.120)	Data  2.559 ( 2.559)	Loss 0.6310997605323792 (0.6310997605323792)	Acc@1  81.25 ( 81.25)	Acc@5  96.88 ( 96.88)
Epoch: [30][ 10/109]	Time  0.618 ( 0.686)	Data  0.000 ( 0.254)	Loss 1.0370556116104126 (0.8388533483852040)	Acc@1  70.31 ( 76.56)	Acc@5  90.62 ( 92.33)
Epoch: [30][ 20/109]	Time  0.367 ( 0.555)	Data  0.000 ( 0.133)	Loss 0.9766848087310791 (0.8596140401703971)	Acc@1  75.00 ( 75.97)	Acc@5  92.19 ( 92.41)
Epoch: [30][ 30/109]	Time  0.451 ( 0.509)	Data  0.000 ( 0.090)	Loss 0.9661205410957336 (0.8646074398871391)	Acc@1  75.00 ( 75.76)	Acc@5  90.62 ( 92.79)
Epoch: [30][ 40/109]	Time  0.356 ( 0.484)	Data  0.000 ( 0.069)	Loss 0.7073826789855957 (0.8453902762110640)	Acc@1  79.69 ( 76.49)	Acc@5  93.75 ( 92.91)
Epoch: [30][ 50/109]	Time  0.443 ( 0.472)	Data  0.000 ( 0.055)	Loss 0.7681875228881836 (0.8406714247722252)	Acc@1  79.69 ( 76.84)	Acc@5  93.75 ( 92.77)
Epoch: [30][ 60/109]	Time  0.508 ( 0.471)	Data  0.000 ( 0.046)	Loss 1.0401092767715454 (0.8475609001566152)	Acc@1  71.88 ( 76.77)	Acc@5  89.06 ( 92.65)
Epoch: [30][ 70/109]	Time  0.431 ( 0.473)	Data  0.000 ( 0.040)	Loss 0.7208421230316162 (0.8517007550723116)	Acc@1  78.12 ( 76.74)	Acc@5  93.75 ( 92.72)
Epoch: [30][ 80/109]	Time  0.390 ( 0.466)	Data  0.000 ( 0.035)	Loss 0.6148104071617126 (0.8623848851816154)	Acc@1  84.38 ( 76.56)	Acc@5  95.31 ( 92.53)
Epoch: [30][ 90/109]	Time  0.393 ( 0.461)	Data  0.000 ( 0.031)	Loss 1.0058274269104004 (0.8606796110724355)	Acc@1  73.44 ( 76.60)	Acc@5  89.06 ( 92.55)
Epoch: [30][100/109]	Time  0.364 ( 0.455)	Data  0.000 ( 0.028)	Loss 0.9011249542236328 (0.8588037971812900)	Acc@1  76.56 ( 76.59)	Acc@5  93.75 ( 92.56)
epoch: 30, Avg_Loss 0.8599187100152357
Test: [ 0/28]	Time  2.582 ( 2.582)	Loss 1.5293e+00 (1.5293e+00)	Acc@1  60.94 ( 60.94)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.141 ( 0.495)	Loss 2.3704e+00 (1.0646e+00)	Acc@1  48.44 ( 74.01)	Acc@5  70.31 ( 88.78)
Test: [20/28]	Time  0.152 ( 0.363)	Loss 2.1441e+00 (1.4923e+00)	Acc@1  45.31 ( 62.65)	Acc@5  75.00 ( 83.18)
 * Acc@1 60.383 Acc@5 81.542
Epoch: [31][  0/109]	Time  3.260 ( 3.260)	Data  2.750 ( 2.750)	Loss 1.0585113763809204 (1.0585113763809204)	Acc@1  73.44 ( 73.44)	Acc@5  85.94 ( 85.94)
Epoch: [31][ 10/109]	Time  0.453 ( 0.678)	Data  0.000 ( 0.250)	Loss 0.6773400902748108 (0.8642865311015736)	Acc@1  78.12 ( 75.99)	Acc@5  96.88 ( 93.61)
Epoch: [31][ 20/109]	Time  0.597 ( 0.580)	Data  0.000 ( 0.131)	Loss 0.8088243603706360 (0.8375607416743324)	Acc@1  73.44 ( 77.23)	Acc@5  96.88 ( 93.08)
Epoch: [31][ 30/109]	Time  0.395 ( 0.535)	Data  0.000 ( 0.089)	Loss 1.0924175977706909 (0.8340545738897016)	Acc@1  75.00 ( 77.32)	Acc@5  89.06 ( 92.59)
Epoch: [31][ 40/109]	Time  0.384 ( 0.506)	Data  0.000 ( 0.067)	Loss 0.7375171184539795 (0.8346637618250963)	Acc@1  79.69 ( 77.17)	Acc@5  93.75 ( 92.53)
Epoch: [31][ 50/109]	Time  0.405 ( 0.488)	Data  0.000 ( 0.054)	Loss 0.9628054499626160 (0.8281825722432604)	Acc@1  78.12 ( 77.85)	Acc@5  90.62 ( 92.59)
Epoch: [31][ 60/109]	Time  0.458 ( 0.475)	Data  0.000 ( 0.045)	Loss 0.9015054106712341 (0.8256447588811155)	Acc@1  75.00 ( 77.74)	Acc@5  90.62 ( 92.65)
Epoch: [31][ 70/109]	Time  0.381 ( 0.466)	Data  0.000 ( 0.039)	Loss 0.6454849839210510 (0.8240902717684356)	Acc@1  84.38 ( 77.84)	Acc@5  96.88 ( 92.69)
Epoch: [31][ 80/109]	Time  0.372 ( 0.455)	Data  0.000 ( 0.034)	Loss 0.4403755366802216 (0.8221625821825899)	Acc@1  85.94 ( 78.03)	Acc@5  96.88 ( 92.71)
Epoch: [31][ 90/109]	Time  0.378 ( 0.449)	Data  0.000 ( 0.030)	Loss 0.8718401193618774 (0.8182019457057282)	Acc@1  84.38 ( 78.12)	Acc@5  89.06 ( 92.82)
Epoch: [31][100/109]	Time  0.367 ( 0.443)	Data  0.000 ( 0.027)	Loss 0.9925935864448547 (0.8167054667921350)	Acc@1  70.31 ( 77.97)	Acc@5  90.62 ( 92.96)
epoch: 31, Avg_Loss 0.8194786077792492
Test: [ 0/28]	Time  3.309 ( 3.309)	Loss 2.6778e+00 (2.6778e+00)	Acc@1  34.38 ( 34.38)	Acc@5  70.31 ( 70.31)
Test: [10/28]	Time  0.104 ( 0.513)	Loss 2.9846e+00 (1.1903e+00)	Acc@1  37.50 ( 72.73)	Acc@5  59.38 ( 86.65)
Test: [20/28]	Time  0.088 ( 0.387)	Loss 1.4663e+00 (1.7194e+00)	Acc@1  64.06 ( 60.94)	Acc@5  85.94 ( 81.32)
 * Acc@1 57.907 Acc@5 79.572
Epoch: [32][  0/109]	Time  3.555 ( 3.555)	Data  3.096 ( 3.096)	Loss 0.7308704257011414 (0.7308704257011414)	Acc@1  75.00 ( 75.00)	Acc@5  93.75 ( 93.75)
Epoch: [32][ 10/109]	Time  0.376 ( 0.696)	Data  0.000 ( 0.282)	Loss 0.6918723583221436 (0.7620544487779791)	Acc@1  75.00 ( 77.27)	Acc@5  93.75 ( 94.03)
Epoch: [32][ 20/109]	Time  0.402 ( 0.547)	Data  0.000 ( 0.148)	Loss 0.6737125515937805 (0.8001011326199486)	Acc@1  76.56 ( 77.01)	Acc@5  96.88 ( 93.53)
Epoch: [32][ 30/109]	Time  0.370 ( 0.494)	Data  0.000 ( 0.100)	Loss 0.6129816770553589 (0.7868580548994003)	Acc@1  85.94 ( 77.57)	Acc@5  96.88 ( 93.60)
Epoch: [32][ 40/109]	Time  0.374 ( 0.471)	Data  0.000 ( 0.076)	Loss 0.6562002897262573 (0.8044817665728127)	Acc@1  81.25 ( 77.32)	Acc@5  98.44 ( 93.52)
Epoch: [32][ 50/109]	Time  0.352 ( 0.458)	Data  0.000 ( 0.061)	Loss 0.8192710876464844 (0.8118012185190239)	Acc@1  82.81 ( 77.21)	Acc@5  95.31 ( 93.60)
Epoch: [32][ 60/109]	Time  0.758 ( 0.460)	Data  0.000 ( 0.051)	Loss 0.6344887018203735 (0.8124601626005329)	Acc@1  82.81 ( 77.20)	Acc@5  96.88 ( 93.62)
Epoch: [32][ 70/109]	Time  0.387 ( 0.458)	Data  0.000 ( 0.044)	Loss 0.5790104269981384 (0.7998679154355761)	Acc@1  81.25 ( 77.44)	Acc@5  96.88 ( 93.75)
Epoch: [32][ 80/109]	Time  0.369 ( 0.453)	Data  0.000 ( 0.038)	Loss 0.5789767503738403 (0.8061973437850858)	Acc@1  85.94 ( 77.28)	Acc@5  98.44 ( 93.60)
Epoch: [32][ 90/109]	Time  0.355 ( 0.448)	Data  0.000 ( 0.034)	Loss 0.8842713236808777 (0.8101250771637801)	Acc@1  75.00 ( 77.20)	Acc@5  92.19 ( 93.54)
Epoch: [32][100/109]	Time  0.355 ( 0.441)	Data  0.000 ( 0.031)	Loss 0.9740089774131775 (0.8181558168760621)	Acc@1  70.31 ( 76.95)	Acc@5  90.62 ( 93.36)
epoch: 32, Avg_Loss 0.8196002583984935
Test: [ 0/28]	Time  3.518 ( 3.518)	Loss 1.7726e+00 (1.7726e+00)	Acc@1  56.25 ( 56.25)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.088 ( 0.507)	Loss 2.5016e+00 (9.5977e-01)	Acc@1  42.19 ( 78.98)	Acc@5  70.31 ( 89.91)
Test: [20/28]	Time  0.178 ( 0.377)	Loss 1.9671e+00 (1.3808e+00)	Acc@1  54.69 ( 66.07)	Acc@5  78.12 ( 85.27)
 * Acc@1 64.266 Acc@5 83.962
Epoch: [33][  0/109]	Time  3.550 ( 3.550)	Data  3.079 ( 3.079)	Loss 0.7598260045051575 (0.7598260045051575)	Acc@1  78.12 ( 78.12)	Acc@5  90.62 ( 90.62)
Epoch: [33][ 10/109]	Time  0.402 ( 0.685)	Data  0.000 ( 0.280)	Loss 0.8208217024803162 (0.7937503077767112)	Acc@1  76.56 ( 77.70)	Acc@5  95.31 ( 93.32)
Epoch: [33][ 20/109]	Time  0.365 ( 0.566)	Data  0.000 ( 0.147)	Loss 0.5965791940689087 (0.7820135723976862)	Acc@1  85.94 ( 77.68)	Acc@5  98.44 ( 93.45)
Epoch: [33][ 30/109]	Time  0.403 ( 0.515)	Data  0.000 ( 0.100)	Loss 0.8355840444564819 (0.7846892629900286)	Acc@1  70.31 ( 77.47)	Acc@5  95.31 ( 93.55)
Epoch: [33][ 40/109]	Time  0.368 ( 0.489)	Data  0.000 ( 0.076)	Loss 1.1514298915863037 (0.8015495378796648)	Acc@1  65.62 ( 76.98)	Acc@5  84.38 ( 93.33)
Epoch: [33][ 50/109]	Time  0.432 ( 0.476)	Data  0.000 ( 0.061)	Loss 0.6939235329627991 (0.7799229358925539)	Acc@1  81.25 ( 77.73)	Acc@5  93.75 ( 93.66)
Epoch: [33][ 60/109]	Time  0.359 ( 0.465)	Data  0.000 ( 0.051)	Loss 0.7775276303291321 (0.7633375755099000)	Acc@1  82.81 ( 78.38)	Acc@5  95.31 ( 93.85)
Epoch: [33][ 70/109]	Time  0.364 ( 0.458)	Data  0.000 ( 0.044)	Loss 0.9325302243232727 (0.7705392094565110)	Acc@1  75.00 ( 78.26)	Acc@5  89.06 ( 93.88)
Epoch: [33][ 80/109]	Time  0.454 ( 0.453)	Data  0.000 ( 0.038)	Loss 0.6996584534645081 (0.7722954245997063)	Acc@1  79.69 ( 78.18)	Acc@5  95.31 ( 93.92)
Epoch: [33][ 90/109]	Time  0.373 ( 0.446)	Data  0.000 ( 0.034)	Loss 0.9157332181930542 (0.7776553660303682)	Acc@1  75.00 ( 78.18)	Acc@5  95.31 ( 93.96)
Epoch: [33][100/109]	Time  0.373 ( 0.443)	Data  0.000 ( 0.031)	Loss 0.7371066808700562 (0.7778911221735548)	Acc@1  78.12 ( 78.23)	Acc@5  92.19 ( 93.78)
epoch: 33, Avg_Loss 0.7848823149816706
Test: [ 0/28]	Time  2.793 ( 2.793)	Loss 1.6968e+00 (1.6968e+00)	Acc@1  56.25 ( 56.25)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.131 ( 0.499)	Loss 2.4450e+00 (8.7717e-01)	Acc@1  53.12 ( 79.55)	Acc@5  76.56 ( 91.62)
Test: [20/28]	Time  0.088 ( 0.372)	Loss 2.2849e+00 (1.5002e+00)	Acc@1  53.12 ( 64.29)	Acc@5  75.00 ( 83.63)
 * Acc@1 60.945 Acc@5 82.105
Epoch: [34][  0/109]	Time  3.558 ( 3.558)	Data  3.105 ( 3.105)	Loss 0.8834183216094971 (0.8834183216094971)	Acc@1  78.12 ( 78.12)	Acc@5  89.06 ( 89.06)
Epoch: [34][ 10/109]	Time  0.435 ( 0.697)	Data  0.000 ( 0.282)	Loss 0.7135868072509766 (0.7999756011095914)	Acc@1  84.38 ( 77.70)	Acc@5  93.75 ( 93.04)
Epoch: [34][ 20/109]	Time  0.398 ( 0.549)	Data  0.000 ( 0.148)	Loss 0.6106442213058472 (0.7637106393064771)	Acc@1  87.50 ( 79.02)	Acc@5  93.75 ( 93.45)
Epoch: [34][ 30/109]	Time  0.385 ( 0.505)	Data  0.000 ( 0.100)	Loss 0.7832357883453369 (0.7279166473496345)	Acc@1  73.44 ( 79.33)	Acc@5  95.31 ( 94.35)
Epoch: [34][ 40/109]	Time  0.362 ( 0.479)	Data  0.000 ( 0.076)	Loss 0.6157144904136658 (0.7300868623140382)	Acc@1  84.38 ( 79.46)	Acc@5  95.31 ( 94.32)
Epoch: [34][ 50/109]	Time  0.477 ( 0.470)	Data  0.000 ( 0.061)	Loss 0.3951742649078369 (0.7120584734514648)	Acc@1  89.06 ( 79.87)	Acc@5  98.44 ( 94.45)
Epoch: [34][ 60/109]	Time  0.540 ( 0.478)	Data  0.000 ( 0.051)	Loss 0.5485258698463440 (0.7256714833564446)	Acc@1  85.94 ( 79.41)	Acc@5  95.31 ( 94.19)
Epoch: [34][ 70/109]	Time  0.372 ( 0.470)	Data  0.000 ( 0.044)	Loss 0.5933697819709778 (0.7144307330460615)	Acc@1  82.81 ( 79.67)	Acc@5  90.62 ( 94.32)
Epoch: [34][ 80/109]	Time  0.482 ( 0.463)	Data  0.000 ( 0.039)	Loss 0.6040645837783813 (0.7171625785621596)	Acc@1  87.50 ( 79.90)	Acc@5  93.75 ( 94.16)
Epoch: [34][ 90/109]	Time  0.433 ( 0.458)	Data  0.000 ( 0.034)	Loss 0.4754713177680969 (0.7196276119122138)	Acc@1  84.38 ( 79.96)	Acc@5  96.88 ( 94.09)
Epoch: [34][100/109]	Time  0.363 ( 0.451)	Data  0.000 ( 0.031)	Loss 0.7382788062095642 (0.7326291448409015)	Acc@1  81.25 ( 79.58)	Acc@5  90.62 ( 93.94)
epoch: 34, Avg_Loss 0.7352459050646616
Test: [ 0/28]	Time  3.377 ( 3.377)	Loss 1.9466e+00 (1.9466e+00)	Acc@1  40.62 ( 40.62)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.089 ( 0.506)	Loss 2.4676e+00 (1.0902e+00)	Acc@1  48.44 ( 74.72)	Acc@5  67.19 ( 87.93)
Test: [20/28]	Time  0.098 ( 0.372)	Loss 1.2389e+00 (1.4528e+00)	Acc@1  70.31 ( 64.43)	Acc@5  87.50 ( 84.08)
 * Acc@1 61.339 Acc@5 82.499
Epoch: [35][  0/109]	Time  3.307 ( 3.307)	Data  2.810 ( 2.810)	Loss 0.5949113965034485 (0.5949113965034485)	Acc@1  79.69 ( 79.69)	Acc@5  93.75 ( 93.75)
Epoch: [35][ 10/109]	Time  0.575 ( 0.762)	Data  0.000 ( 0.256)	Loss 0.8747242093086243 (0.7020802389491688)	Acc@1  73.44 ( 79.40)	Acc@5  92.19 ( 95.60)
Epoch: [35][ 20/109]	Time  0.523 ( 0.636)	Data  0.000 ( 0.134)	Loss 0.4450176954269409 (0.6766550796372550)	Acc@1  85.94 ( 80.36)	Acc@5  98.44 ( 95.83)
Epoch: [35][ 30/109]	Time  0.371 ( 0.563)	Data  0.000 ( 0.091)	Loss 0.5763857960700989 (0.6648029463906442)	Acc@1  82.81 ( 80.29)	Acc@5  95.31 ( 95.56)
Epoch: [35][ 40/109]	Time  0.375 ( 0.526)	Data  0.000 ( 0.069)	Loss 0.5380726456642151 (0.6902815488780417)	Acc@1  82.81 ( 79.99)	Acc@5  98.44 ( 94.89)
Epoch: [35][ 50/109]	Time  0.387 ( 0.498)	Data  0.000 ( 0.055)	Loss 0.8084014654159546 (0.6940772001649819)	Acc@1  73.44 ( 80.12)	Acc@5  96.88 ( 94.88)
Epoch: [35][ 60/109]	Time  0.381 ( 0.481)	Data  0.000 ( 0.046)	Loss 0.5166120529174805 (0.6981979144401238)	Acc@1  85.94 ( 79.99)	Acc@5  96.88 ( 94.72)
Epoch: [35][ 70/109]	Time  0.375 ( 0.471)	Data  0.000 ( 0.040)	Loss 0.7610248327255249 (0.6946266969324837)	Acc@1  76.56 ( 80.26)	Acc@5  93.75 ( 94.76)
Epoch: [35][ 80/109]	Time  0.370 ( 0.462)	Data  0.000 ( 0.035)	Loss 0.6001911163330078 (0.7013924890830193)	Acc@1  81.25 ( 80.13)	Acc@5  96.88 ( 94.56)
Epoch: [35][ 90/109]	Time  0.411 ( 0.458)	Data  0.000 ( 0.031)	Loss 1.0893537998199463 (0.7103322200722747)	Acc@1  68.75 ( 80.07)	Acc@5  92.19 ( 94.57)
Epoch: [35][100/109]	Time  0.382 ( 0.453)	Data  0.000 ( 0.028)	Loss 0.8160479068756104 (0.7061733246439754)	Acc@1  81.25 ( 80.28)	Acc@5  93.75 ( 94.65)
epoch: 35, Avg_Loss 0.7126116164780538
Test: [ 0/28]	Time  3.747 ( 3.747)	Loss 1.6962e+00 (1.6962e+00)	Acc@1  51.56 ( 51.56)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.206 ( 0.548)	Loss 2.6742e+00 (1.0417e+00)	Acc@1  35.94 ( 74.57)	Acc@5  73.44 ( 90.77)
Test: [20/28]	Time  0.093 ( 0.371)	Loss 2.0439e+00 (1.5889e+00)	Acc@1  62.50 ( 63.69)	Acc@5  76.56 ( 83.11)
 * Acc@1 61.002 Acc@5 81.992
Epoch: [36][  0/109]	Time  3.000 ( 3.000)	Data  2.556 ( 2.556)	Loss 0.5814868807792664 (0.5814868807792664)	Acc@1  85.94 ( 85.94)	Acc@5  95.31 ( 95.31)
Epoch: [36][ 10/109]	Time  0.402 ( 0.672)	Data  0.000 ( 0.248)	Loss 0.6718385815620422 (0.7466723593798551)	Acc@1  79.69 ( 79.55)	Acc@5  93.75 ( 93.61)
Epoch: [36][ 20/109]	Time  0.371 ( 0.545)	Data  0.000 ( 0.130)	Loss 0.7884347438812256 (0.6694028377532959)	Acc@1  75.00 ( 81.77)	Acc@5  90.62 ( 94.57)
Epoch: [36][ 30/109]	Time  0.433 ( 0.501)	Data  0.000 ( 0.088)	Loss 0.9570589065551758 (0.6829943791512521)	Acc@1  75.00 ( 81.45)	Acc@5  89.06 ( 94.30)
Epoch: [36][ 40/109]	Time  0.403 ( 0.474)	Data  0.000 ( 0.067)	Loss 0.6917000412940979 (0.6995871590404976)	Acc@1  81.25 ( 81.14)	Acc@5  93.75 ( 94.02)
Epoch: [36][ 50/109]	Time  0.377 ( 0.460)	Data  0.000 ( 0.054)	Loss 0.7509371042251587 (0.6979406861697927)	Acc@1  76.56 ( 81.22)	Acc@5  92.19 ( 93.96)
Epoch: [36][ 60/109]	Time  0.479 ( 0.457)	Data  0.000 ( 0.045)	Loss 0.3535810708999634 (0.6949148627578235)	Acc@1  90.62 ( 81.28)	Acc@5  98.44 ( 94.08)
Epoch: [36][ 70/109]	Time  0.425 ( 0.461)	Data  0.000 ( 0.039)	Loss 0.5603665113449097 (0.6908087180533879)	Acc@1  89.06 ( 81.12)	Acc@5  95.31 ( 94.15)
Epoch: [36][ 80/109]	Time  0.544 ( 0.470)	Data  0.000 ( 0.034)	Loss 0.7477820515632629 (0.7030643375567448)	Acc@1  82.81 ( 80.71)	Acc@5  92.19 ( 93.85)
Epoch: [36][ 90/109]	Time  0.477 ( 0.461)	Data  0.000 ( 0.030)	Loss 0.8637815713882446 (0.7023986735186734)	Acc@1  78.12 ( 80.77)	Acc@5  89.06 ( 93.82)
Epoch: [36][100/109]	Time  0.370 ( 0.454)	Data  0.000 ( 0.027)	Loss 0.9095603227615356 (0.7043619486364988)	Acc@1  79.69 ( 80.75)	Acc@5  92.19 ( 93.90)
epoch: 36, Avg_Loss 0.7035592340548104
Test: [ 0/28]	Time  3.461 ( 3.461)	Loss 1.9762e+00 (1.9762e+00)	Acc@1  56.25 ( 56.25)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.088 ( 0.519)	Loss 2.2315e+00 (1.0589e+00)	Acc@1  56.25 ( 76.99)	Acc@5  75.00 ( 88.92)
Test: [20/28]	Time  0.088 ( 0.385)	Loss 1.5395e+00 (1.4563e+00)	Acc@1  65.62 ( 66.89)	Acc@5  84.38 ( 84.23)
 * Acc@1 66.010 Acc@5 83.568
Epoch: [37][  0/109]	Time  3.174 ( 3.174)	Data  2.725 ( 2.725)	Loss 0.6610440611839294 (0.6610440611839294)	Acc@1  81.25 ( 81.25)	Acc@5  96.88 ( 96.88)
Epoch: [37][ 10/109]	Time  0.467 ( 0.680)	Data  0.000 ( 0.248)	Loss 0.3700020909309387 (0.5831223048947074)	Acc@1  93.75 ( 84.52)	Acc@5  98.44 ( 96.02)
Epoch: [37][ 20/109]	Time  0.411 ( 0.555)	Data  0.000 ( 0.130)	Loss 0.5972080826759338 (0.5858910850116185)	Acc@1  84.38 ( 83.71)	Acc@5  95.31 ( 96.21)
Epoch: [37][ 30/109]	Time  0.460 ( 0.518)	Data  0.000 ( 0.088)	Loss 0.4964701235294342 (0.6059815681749775)	Acc@1  84.38 ( 83.32)	Acc@5  98.44 ( 95.72)
Epoch: [37][ 40/109]	Time  0.379 ( 0.511)	Data  0.000 ( 0.067)	Loss 0.7536955475807190 (0.6193529258414012)	Acc@1  82.81 ( 82.96)	Acc@5  93.75 ( 95.27)
Epoch: [37][ 50/109]	Time  0.525 ( 0.491)	Data  0.000 ( 0.054)	Loss 0.8775975704193115 (0.6269693053236195)	Acc@1  81.25 ( 82.97)	Acc@5  92.19 ( 95.16)
Epoch: [37][ 60/109]	Time  0.433 ( 0.477)	Data  0.000 ( 0.045)	Loss 0.5440355539321899 (0.6241845214953188)	Acc@1  87.50 ( 83.09)	Acc@5  92.19 ( 95.06)
Epoch: [37][ 70/109]	Time  0.384 ( 0.467)	Data  0.000 ( 0.039)	Loss 0.8202393651008606 (0.6314320178099082)	Acc@1  79.69 ( 82.68)	Acc@5  90.62 ( 95.03)
Epoch: [37][ 80/109]	Time  0.406 ( 0.459)	Data  0.000 ( 0.034)	Loss 0.5575585961341858 (0.6424426532086031)	Acc@1  89.06 ( 82.48)	Acc@5  96.88 ( 94.91)
Epoch: [37][ 90/109]	Time  0.369 ( 0.452)	Data  0.000 ( 0.030)	Loss 0.5713644027709961 (0.6490279370611840)	Acc@1  87.50 ( 82.30)	Acc@5  95.31 ( 94.90)
Epoch: [37][100/109]	Time  0.370 ( 0.446)	Data  0.000 ( 0.027)	Loss 0.7907857298851013 (0.6472620648322719)	Acc@1  78.12 ( 82.33)	Acc@5  93.75 ( 94.97)
epoch: 37, Avg_Loss 0.6535473769411034
Test: [ 0/28]	Time  3.191 ( 3.191)	Loss 1.6151e+00 (1.6151e+00)	Acc@1  53.12 ( 53.12)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.132 ( 0.506)	Loss 1.9644e+00 (9.9193e-01)	Acc@1  59.38 ( 76.56)	Acc@5  71.88 ( 88.92)
Test: [20/28]	Time  0.104 ( 0.380)	Loss 1.4323e+00 (1.4551e+00)	Acc@1  71.88 ( 65.77)	Acc@5  84.38 ( 83.48)
 * Acc@1 63.703 Acc@5 82.667
Epoch: [38][  0/109]	Time  3.100 ( 3.100)	Data  2.537 ( 2.537)	Loss 0.7037058472633362 (0.7037058472633362)	Acc@1  79.69 ( 79.69)	Acc@5  96.88 ( 96.88)
Epoch: [38][ 10/109]	Time  0.405 ( 0.660)	Data  0.000 ( 0.231)	Loss 0.3003512024879456 (0.5926451005718925)	Acc@1  90.62 ( 83.24)	Acc@5 100.00 ( 96.02)
Epoch: [38][ 20/109]	Time  0.458 ( 0.546)	Data  0.000 ( 0.121)	Loss 0.6129027009010315 (0.5994519534565154)	Acc@1  84.38 ( 83.26)	Acc@5  92.19 ( 95.76)
Epoch: [38][ 30/109]	Time  0.447 ( 0.504)	Data  0.000 ( 0.082)	Loss 0.5848258733749390 (0.6117859915379555)	Acc@1  82.81 ( 82.86)	Acc@5  95.31 ( 95.46)
Epoch: [38][ 40/109]	Time  0.496 ( 0.483)	Data  0.000 ( 0.062)	Loss 0.7857360839843750 (0.6153262933579887)	Acc@1  82.81 ( 82.81)	Acc@5  93.75 ( 95.27)
Epoch: [38][ 50/109]	Time  0.380 ( 0.466)	Data  0.000 ( 0.050)	Loss 0.6424598097801208 (0.6157330362235799)	Acc@1  82.81 ( 82.97)	Acc@5  93.75 ( 95.25)
Epoch: [38][ 60/109]	Time  0.377 ( 0.452)	Data  0.000 ( 0.042)	Loss 0.7233920097351074 (0.6239955278693653)	Acc@1  75.00 ( 82.68)	Acc@5  98.44 ( 95.34)
Epoch: [38][ 70/109]	Time  0.564 ( 0.452)	Data  0.000 ( 0.036)	Loss 0.9008947610855103 (0.6294832876030828)	Acc@1  81.25 ( 82.66)	Acc@5  90.62 ( 95.18)
Epoch: [38][ 80/109]	Time  0.540 ( 0.464)	Data  0.000 ( 0.032)	Loss 0.5965054035186768 (0.6416196403680025)	Acc@1  78.12 ( 82.25)	Acc@5  98.44 ( 94.97)
Epoch: [38][ 90/109]	Time  0.376 ( 0.462)	Data  0.000 ( 0.028)	Loss 0.5218228697776794 (0.6363588574823442)	Acc@1  87.50 ( 82.50)	Acc@5  96.88 ( 95.02)
Epoch: [38][100/109]	Time  0.367 ( 0.454)	Data  0.000 ( 0.025)	Loss 0.5293787121772766 (0.6327178770362740)	Acc@1  82.81 ( 82.50)	Acc@5  96.88 ( 95.05)
epoch: 38, Avg_Loss 0.6381219901622982
Test: [ 0/28]	Time  3.334 ( 3.334)	Loss 1.8458e+00 (1.8458e+00)	Acc@1  57.81 ( 57.81)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.088 ( 0.579)	Loss 2.2410e+00 (9.4676e-01)	Acc@1  51.56 ( 78.84)	Acc@5  71.88 ( 89.35)
Test: [20/28]	Time  0.088 ( 0.404)	Loss 1.3662e+00 (1.3698e+00)	Acc@1  65.62 ( 67.86)	Acc@5  84.38 ( 84.97)
 * Acc@1 64.660 Acc@5 83.455
Epoch: [39][  0/109]	Time  2.913 ( 2.913)	Data  2.435 ( 2.435)	Loss 0.7072323560714722 (0.7072323560714722)	Acc@1  79.69 ( 79.69)	Acc@5  93.75 ( 93.75)
Epoch: [39][ 10/109]	Time  0.450 ( 0.640)	Data  0.000 ( 0.222)	Loss 0.6553843617439270 (0.6315785565159537)	Acc@1  81.25 ( 83.52)	Acc@5  96.88 ( 94.32)
Epoch: [39][ 20/109]	Time  0.438 ( 0.545)	Data  0.000 ( 0.116)	Loss 0.6993487477302551 (0.6310115030833653)	Acc@1  79.69 ( 82.81)	Acc@5  92.19 ( 94.05)
Epoch: [39][ 30/109]	Time  0.561 ( 0.511)	Data  0.000 ( 0.079)	Loss 0.5368348360061646 (0.6055765017386405)	Acc@1  85.94 ( 83.72)	Acc@5  96.88 ( 94.61)
Epoch: [39][ 40/109]	Time  0.441 ( 0.516)	Data  0.000 ( 0.060)	Loss 0.5031873583793640 (0.6134063841366186)	Acc@1  85.94 ( 83.61)	Acc@5  96.88 ( 94.70)
Epoch: [39][ 50/109]	Time  0.370 ( 0.492)	Data  0.000 ( 0.048)	Loss 0.6238623261451721 (0.6061648036919388)	Acc@1  85.94 ( 83.73)	Acc@5  92.19 ( 94.85)
Epoch: [39][ 60/109]	Time  0.415 ( 0.480)	Data  0.000 ( 0.040)	Loss 0.8578458428382874 (0.6127326688805564)	Acc@1  71.88 ( 83.22)	Acc@5  92.19 ( 94.83)
Epoch: [39][ 70/109]	Time  0.375 ( 0.469)	Data  0.000 ( 0.035)	Loss 0.8092311620712280 (0.6184424019195665)	Acc@1  76.56 ( 82.94)	Acc@5  92.19 ( 94.74)
Epoch: [39][ 80/109]	Time  0.424 ( 0.462)	Data  0.000 ( 0.030)	Loss 0.5770913362503052 (0.6060310105482737)	Acc@1  81.25 ( 83.16)	Acc@5  90.62 ( 94.83)
Epoch: [39][ 90/109]	Time  0.410 ( 0.455)	Data  0.000 ( 0.027)	Loss 0.6252767443656921 (0.6052384769523537)	Acc@1  84.38 ( 83.14)	Acc@5  95.31 ( 94.90)
Epoch: [39][100/109]	Time  0.368 ( 0.449)	Data  0.000 ( 0.024)	Loss 0.6529933810234070 (0.6071478913326075)	Acc@1  81.25 ( 83.04)	Acc@5  96.88 ( 94.94)
epoch: 39, Avg_Loss 0.6042169906677456
Test: [ 0/28]	Time  2.857 ( 2.857)	Loss 1.3491e+00 (1.3491e+00)	Acc@1  60.94 ( 60.94)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.119 ( 0.491)	Loss 2.1410e+00 (8.8250e-01)	Acc@1  50.00 ( 79.83)	Acc@5  70.31 ( 90.62)
Test: [20/28]	Time  0.088 ( 0.375)	Loss 1.4220e+00 (1.3669e+00)	Acc@1  65.62 ( 67.34)	Acc@5  84.38 ( 84.90)
 * Acc@1 64.885 Acc@5 84.131
Epoch: [40][  0/109]	Time  3.232 ( 3.232)	Data  2.736 ( 2.736)	Loss 0.5392870306968689 (0.5392870306968689)	Acc@1  87.50 ( 87.50)	Acc@5  95.31 ( 95.31)
Epoch: [40][ 10/109]	Time  0.487 ( 0.690)	Data  0.000 ( 0.258)	Loss 0.8509840965270996 (0.6573798141696237)	Acc@1  75.00 ( 82.53)	Acc@5  95.31 ( 94.89)
Epoch: [40][ 20/109]	Time  0.462 ( 0.563)	Data  0.000 ( 0.135)	Loss 0.4096696674823761 (0.5968405121848697)	Acc@1  87.50 ( 83.78)	Acc@5  98.44 ( 95.46)
Epoch: [40][ 30/109]	Time  0.374 ( 0.512)	Data  0.000 ( 0.092)	Loss 0.4910663962364197 (0.5717929130600344)	Acc@1  84.38 ( 84.27)	Acc@5  96.88 ( 95.72)
Epoch: [40][ 40/109]	Time  0.376 ( 0.488)	Data  0.000 ( 0.069)	Loss 0.7310981154441833 (0.5948275589361424)	Acc@1  79.69 ( 83.84)	Acc@5  95.31 ( 95.62)
Epoch: [40][ 50/109]	Time  0.403 ( 0.473)	Data  0.000 ( 0.056)	Loss 0.5778074860572815 (0.5957439775560417)	Acc@1  82.81 ( 83.64)	Acc@5  95.31 ( 95.68)
Epoch: [40][ 60/109]	Time  0.386 ( 0.465)	Data  0.000 ( 0.047)	Loss 0.6723859310150146 (0.5943158459467967)	Acc@1  81.25 ( 83.68)	Acc@5  93.75 ( 95.59)
Epoch: [40][ 70/109]	Time  0.448 ( 0.462)	Data  0.000 ( 0.040)	Loss 0.6653191447257996 (0.6072093202194697)	Acc@1  79.69 ( 83.47)	Acc@5  92.19 ( 95.36)
Epoch: [40][ 80/109]	Time  0.477 ( 0.456)	Data  0.000 ( 0.035)	Loss 0.7913718223571777 (0.6128203585559939)	Acc@1  81.25 ( 83.43)	Acc@5  90.62 ( 95.22)
Epoch: [40][ 90/109]	Time  0.476 ( 0.453)	Data  0.000 ( 0.031)	Loss 0.5381726622581482 (0.6104703604520022)	Acc@1  85.94 ( 83.60)	Acc@5  98.44 ( 95.16)
Epoch: [40][100/109]	Time  0.356 ( 0.447)	Data  0.000 ( 0.028)	Loss 0.7835690379142761 (0.6084981979710040)	Acc@1  76.56 ( 83.65)	Acc@5  93.75 ( 95.17)
epoch: 40, Avg_Loss 0.6078004008586254
Test: [ 0/28]	Time  3.685 ( 3.685)	Loss 1.8152e+00 (1.8152e+00)	Acc@1  59.38 ( 59.38)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.154 ( 0.507)	Loss 2.7087e+00 (9.4676e-01)	Acc@1  50.00 ( 79.55)	Acc@5  75.00 ( 90.91)
Test: [20/28]	Time  0.255 ( 0.382)	Loss 1.1346e+00 (1.3660e+00)	Acc@1  64.06 ( 66.67)	Acc@5  96.88 ( 86.53)
 * Acc@1 65.053 Acc@5 85.031
Epoch: [41][  0/109]	Time  4.147 ( 4.147)	Data  3.781 ( 3.781)	Loss 0.3960294127464294 (0.3960294127464294)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [41][ 10/109]	Time  0.443 ( 0.739)	Data  0.000 ( 0.344)	Loss 0.4943274855613708 (0.4879116632721641)	Acc@1  84.38 ( 86.79)	Acc@5  96.88 ( 96.73)
Epoch: [41][ 20/109]	Time  0.464 ( 0.594)	Data  0.000 ( 0.180)	Loss 0.3850508034229279 (0.4993736417520614)	Acc@1  87.50 ( 86.38)	Acc@5  96.88 ( 96.50)
Epoch: [41][ 30/109]	Time  0.387 ( 0.530)	Data  0.000 ( 0.122)	Loss 0.5703029632568359 (0.5228021933186439)	Acc@1  78.12 ( 85.89)	Acc@5  93.75 ( 96.12)
Epoch: [41][ 40/109]	Time  0.455 ( 0.504)	Data  0.008 ( 0.093)	Loss 0.4813362658023834 (0.5325639058903950)	Acc@1  85.94 ( 85.56)	Acc@5  98.44 ( 95.92)
Epoch: [41][ 50/109]	Time  0.397 ( 0.482)	Data  0.000 ( 0.075)	Loss 0.5798762440681458 (0.5355197080210143)	Acc@1  84.38 ( 85.11)	Acc@5  96.88 ( 96.02)
Epoch: [41][ 60/109]	Time  0.412 ( 0.467)	Data  0.000 ( 0.062)	Loss 0.8262004852294922 (0.5419878290324914)	Acc@1  76.56 ( 84.91)	Acc@5  89.06 ( 96.00)
Epoch: [41][ 70/109]	Time  0.475 ( 0.462)	Data  0.000 ( 0.054)	Loss 0.5805489420890808 (0.5503815366348750)	Acc@1  82.81 ( 84.84)	Acc@5  93.75 ( 95.75)
Epoch: [41][ 80/109]	Time  0.455 ( 0.455)	Data  0.000 ( 0.047)	Loss 0.5431036353111267 (0.5539582198784675)	Acc@1  84.38 ( 84.78)	Acc@5  93.75 ( 95.54)
Epoch: [41][ 90/109]	Time  0.454 ( 0.450)	Data  0.000 ( 0.042)	Loss 0.4586914479732513 (0.5528083139068478)	Acc@1  84.38 ( 84.79)	Acc@5  98.44 ( 95.62)
Epoch: [41][100/109]	Time  0.370 ( 0.445)	Data  0.000 ( 0.038)	Loss 0.5587529540061951 (0.5644733690389312)	Acc@1  82.81 ( 84.50)	Acc@5  92.19 ( 95.54)
epoch: 41, Avg_Loss 0.5609260395579382
Test: [ 0/28]	Time  3.715 ( 3.715)	Loss 2.6649e+00 (2.6649e+00)	Acc@1  35.94 ( 35.94)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.091 ( 0.564)	Loss 2.4821e+00 (1.0825e+00)	Acc@1  46.88 ( 74.72)	Acc@5  70.31 ( 88.35)
Test: [20/28]	Time  0.088 ( 0.419)	Loss 1.3802e+00 (1.4656e+00)	Acc@1  59.38 ( 65.77)	Acc@5  89.06 ( 84.15)
 * Acc@1 63.421 Acc@5 82.780
Epoch: [42][  0/109]	Time  3.414 ( 3.414)	Data  2.967 ( 2.967)	Loss 0.7281188368797302 (0.7281188368797302)	Acc@1  81.25 ( 81.25)	Acc@5  92.19 ( 92.19)
Epoch: [42][ 10/109]	Time  0.417 ( 0.694)	Data  0.000 ( 0.270)	Loss 0.4922192096710205 (0.4957353404977105)	Acc@1  89.06 ( 86.36)	Acc@5  92.19 ( 95.88)
Epoch: [42][ 20/109]	Time  0.377 ( 0.556)	Data  0.000 ( 0.142)	Loss 0.4938610494136810 (0.5391059453998294)	Acc@1  89.06 ( 85.27)	Acc@5  96.88 ( 95.83)
Epoch: [42][ 30/109]	Time  0.391 ( 0.504)	Data  0.000 ( 0.096)	Loss 0.3797808587551117 (0.5197070591872738)	Acc@1  90.62 ( 85.89)	Acc@5  98.44 ( 95.97)
Epoch: [42][ 40/109]	Time  0.381 ( 0.481)	Data  0.000 ( 0.073)	Loss 0.6561425924301147 (0.5239723168495225)	Acc@1  81.25 ( 85.75)	Acc@5  93.75 ( 96.15)
Epoch: [42][ 50/109]	Time  0.612 ( 0.489)	Data  0.000 ( 0.058)	Loss 0.8170150518417358 (0.5206571732665978)	Acc@1  78.12 ( 85.69)	Acc@5  92.19 ( 96.11)
Epoch: [42][ 60/109]	Time  0.458 ( 0.487)	Data  0.000 ( 0.049)	Loss 0.8640583753585815 (0.5302601625196269)	Acc@1  70.31 ( 85.30)	Acc@5  95.31 ( 96.03)
Epoch: [42][ 70/109]	Time  0.398 ( 0.475)	Data  0.000 ( 0.042)	Loss 0.6258298158645630 (0.5316587312960289)	Acc@1  82.81 ( 85.32)	Acc@5  95.31 ( 95.91)
Epoch: [42][ 80/109]	Time  0.369 ( 0.466)	Data  0.000 ( 0.037)	Loss 0.7733479142189026 (0.5363364723729499)	Acc@1  75.00 ( 85.22)	Acc@5  93.75 ( 95.87)
Epoch: [42][ 90/109]	Time  0.513 ( 0.461)	Data  0.000 ( 0.033)	Loss 0.4094445109367371 (0.5393212267330715)	Acc@1  89.06 ( 85.13)	Acc@5  98.44 ( 95.84)
Epoch: [42][100/109]	Time  0.365 ( 0.453)	Data  0.000 ( 0.030)	Loss 0.5657737851142883 (0.5459706927880202)	Acc@1  84.38 ( 84.96)	Acc@5  95.31 ( 95.73)
epoch: 42, Avg_Loss 0.5456904044391913
Test: [ 0/28]	Time  3.508 ( 3.508)	Loss 1.5856e+00 (1.5856e+00)	Acc@1  57.81 ( 57.81)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.094 ( 0.554)	Loss 1.5171e+00 (8.2576e-01)	Acc@1  64.06 ( 80.68)	Acc@5  84.38 ( 93.47)
Test: [20/28]	Time  0.092 ( 0.404)	Loss 1.9218e+00 (1.4324e+00)	Acc@1  54.69 ( 66.07)	Acc@5  75.00 ( 85.12)
 * Acc@1 63.815 Acc@5 83.849
Epoch: [43][  0/109]	Time  3.787 ( 3.787)	Data  3.339 ( 3.339)	Loss 0.3817844390869141 (0.3817844390869141)	Acc@1  87.50 ( 87.50)	Acc@5  96.88 ( 96.88)
Epoch: [43][ 10/109]	Time  0.461 ( 0.732)	Data  0.000 ( 0.304)	Loss 0.4958815872669220 (0.5215037397362969)	Acc@1  85.94 ( 86.93)	Acc@5 100.00 ( 95.74)
Epoch: [43][ 20/109]	Time  0.439 ( 0.579)	Data  0.000 ( 0.159)	Loss 0.3003950715065002 (0.4820846603030250)	Acc@1  90.62 ( 86.83)	Acc@5  98.44 ( 96.35)
Epoch: [43][ 30/109]	Time  0.434 ( 0.523)	Data  0.000 ( 0.108)	Loss 0.5008669495582581 (0.4890916241753486)	Acc@1  85.94 ( 86.64)	Acc@5  95.31 ( 96.17)
Epoch: [43][ 40/109]	Time  0.449 ( 0.498)	Data  0.000 ( 0.082)	Loss 0.6780264973640442 (0.4773707037291876)	Acc@1  79.69 ( 87.16)	Acc@5  95.31 ( 96.30)
Epoch: [43][ 50/109]	Time  0.415 ( 0.480)	Data  0.000 ( 0.066)	Loss 0.2805733680725098 (0.4706174307594113)	Acc@1  92.19 ( 86.98)	Acc@5  98.44 ( 96.35)
Epoch: [43][ 60/109]	Time  0.387 ( 0.466)	Data  0.000 ( 0.055)	Loss 0.3864255845546722 (0.4725185664462261)	Acc@1  92.19 ( 87.06)	Acc@5  96.88 ( 96.44)
Epoch: [43][ 70/109]	Time  0.408 ( 0.460)	Data  0.000 ( 0.047)	Loss 0.4436776340007782 (0.4803295544755291)	Acc@1  90.62 ( 87.06)	Acc@5  98.44 ( 96.26)
Epoch: [43][ 80/109]	Time  0.645 ( 0.464)	Data  0.000 ( 0.042)	Loss 0.4934317767620087 (0.4923192602984699)	Acc@1  84.38 ( 86.63)	Acc@5  98.44 ( 96.16)
Epoch: [43][ 90/109]	Time  0.383 ( 0.468)	Data  0.000 ( 0.037)	Loss 0.6017897129058838 (0.4987967389298009)	Acc@1  85.94 ( 86.59)	Acc@5  93.75 ( 96.17)
Epoch: [43][100/109]	Time  0.366 ( 0.462)	Data  0.000 ( 0.033)	Loss 0.6517120599746704 (0.5060490589625765)	Acc@1  78.12 ( 86.32)	Acc@5  95.31 ( 96.16)
epoch: 43, Avg_Loss 0.515399133256816
Test: [ 0/28]	Time  3.450 ( 3.450)	Loss 8.8439e-01 (8.8439e-01)	Acc@1  76.56 ( 76.56)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.160 ( 0.520)	Loss 2.9766e+00 (9.6472e-01)	Acc@1  40.62 ( 78.55)	Acc@5  65.62 ( 91.05)
Test: [20/28]	Time  0.088 ( 0.395)	Loss 2.2457e+00 (1.5087e+00)	Acc@1  59.38 ( 66.89)	Acc@5  81.25 ( 85.19)
 * Acc@1 64.153 Acc@5 83.793
Epoch: [44][  0/109]	Time  3.241 ( 3.241)	Data  2.765 ( 2.765)	Loss 0.4546594023704529 (0.4546594023704529)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
Epoch: [44][ 10/109]	Time  0.548 ( 0.733)	Data  0.000 ( 0.281)	Loss 0.5142280459403992 (0.5293071730570360)	Acc@1  85.94 ( 83.81)	Acc@5  95.31 ( 96.73)
Epoch: [44][ 20/109]	Time  0.436 ( 0.580)	Data  0.000 ( 0.147)	Loss 0.5440275073051453 (0.5079259787287030)	Acc@1  79.69 ( 84.52)	Acc@5  98.44 ( 97.02)
Epoch: [44][ 30/109]	Time  0.488 ( 0.537)	Data  0.000 ( 0.100)	Loss 0.4360471069812775 (0.5115837954705761)	Acc@1  85.94 ( 84.73)	Acc@5  98.44 ( 97.08)
Epoch: [44][ 40/109]	Time  0.386 ( 0.500)	Data  0.000 ( 0.076)	Loss 0.4690996408462524 (0.5206371596673640)	Acc@1  87.50 ( 84.79)	Acc@5  95.31 ( 96.76)
Epoch: [44][ 50/109]	Time  0.454 ( 0.487)	Data  0.000 ( 0.061)	Loss 0.3698270022869110 (0.5032195530685724)	Acc@1  87.50 ( 85.42)	Acc@5 100.00 ( 96.88)
Epoch: [44][ 60/109]	Time  0.403 ( 0.473)	Data  0.000 ( 0.051)	Loss 0.7558308243751526 (0.5029828262622239)	Acc@1  81.25 ( 85.63)	Acc@5  93.75 ( 96.82)
Epoch: [44][ 70/109]	Time  0.445 ( 0.464)	Data  0.000 ( 0.044)	Loss 0.3727209568023682 (0.4951519802422591)	Acc@1  89.06 ( 85.92)	Acc@5  95.31 ( 96.83)
Epoch: [44][ 80/109]	Time  0.419 ( 0.457)	Data  0.000 ( 0.038)	Loss 0.4592026770114899 (0.4943105250964930)	Acc@1  87.50 ( 86.01)	Acc@5  98.44 ( 96.76)
Epoch: [44][ 90/109]	Time  0.375 ( 0.452)	Data  0.000 ( 0.034)	Loss 0.4968261420726776 (0.4940004597653400)	Acc@1  85.94 ( 86.11)	Acc@5  93.75 ( 96.63)
Epoch: [44][100/109]	Time  0.370 ( 0.444)	Data  0.000 ( 0.031)	Loss 0.3915532231330872 (0.4962642971831973)	Acc@1  90.62 ( 86.05)	Acc@5  95.31 ( 96.58)
epoch: 44, Avg_Loss 0.4996392576519502
Test: [ 0/28]	Time  3.604 ( 3.604)	Loss 1.7070e+00 (1.7070e+00)	Acc@1  53.12 ( 53.12)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.095 ( 0.564)	Loss 2.4955e+00 (9.4024e-01)	Acc@1  39.06 ( 77.98)	Acc@5  65.62 ( 90.48)
Test: [20/28]	Time  0.092 ( 0.397)	Loss 1.2140e+00 (1.4104e+00)	Acc@1  70.31 ( 65.70)	Acc@5  87.50 ( 84.38)
 * Acc@1 64.153 Acc@5 83.568
Epoch: [45][  0/109]	Time  3.930 ( 3.930)	Data  3.538 ( 3.538)	Loss 0.6945465803146362 (0.6945465803146362)	Acc@1  82.81 ( 82.81)	Acc@5  93.75 ( 93.75)
Epoch: [45][ 10/109]	Time  0.404 ( 0.726)	Data  0.000 ( 0.322)	Loss 0.2750381529331207 (0.4481085457585074)	Acc@1  95.31 ( 87.36)	Acc@5  98.44 ( 96.88)
Epoch: [45][ 20/109]	Time  0.418 ( 0.579)	Data  0.000 ( 0.169)	Loss 0.2565532922744751 (0.4405997154258546)	Acc@1  92.19 ( 87.35)	Acc@5  98.44 ( 96.88)
Epoch: [45][ 30/109]	Time  0.378 ( 0.517)	Data  0.000 ( 0.114)	Loss 0.3654536604881287 (0.4601234072639096)	Acc@1  87.50 ( 87.10)	Acc@5  98.44 ( 96.72)
Epoch: [45][ 40/109]	Time  0.362 ( 0.492)	Data  0.000 ( 0.087)	Loss 0.3931670188903809 (0.4601752212861689)	Acc@1  85.94 ( 87.00)	Acc@5  98.44 ( 96.68)
Epoch: [45][ 50/109]	Time  0.394 ( 0.475)	Data  0.000 ( 0.070)	Loss 0.2448090165853500 (0.4526258233715506)	Acc@1  93.75 ( 87.13)	Acc@5  98.44 ( 96.94)
Epoch: [45][ 60/109]	Time  0.380 ( 0.462)	Data  0.000 ( 0.058)	Loss 0.4070104062557220 (0.4496221967407915)	Acc@1  89.06 ( 87.17)	Acc@5  98.44 ( 97.08)
Epoch: [45][ 70/109]	Time  0.549 ( 0.458)	Data  0.000 ( 0.050)	Loss 0.5085732936859131 (0.4483424689568264)	Acc@1  85.94 ( 87.24)	Acc@5  98.44 ( 97.10)
Epoch: [45][ 80/109]	Time  0.447 ( 0.456)	Data  0.000 ( 0.044)	Loss 0.3993566632270813 (0.4529261073948425)	Acc@1  84.38 ( 87.04)	Acc@5 100.00 ( 97.13)
Epoch: [45][ 90/109]	Time  0.370 ( 0.450)	Data  0.000 ( 0.039)	Loss 0.5888429284095764 (0.4611959185574081)	Acc@1  85.94 ( 86.88)	Acc@5  93.75 ( 97.00)
Epoch: [45][100/109]	Time  0.377 ( 0.445)	Data  0.000 ( 0.035)	Loss 0.7976722717285156 (0.4666178335647772)	Acc@1  79.69 ( 86.80)	Acc@5  89.06 ( 96.84)
epoch: 45, Avg_Loss 0.46836705656226624
Test: [ 0/28]	Time  3.493 ( 3.493)	Loss 2.3791e+00 (2.3791e+00)	Acc@1  48.44 ( 48.44)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.090 ( 0.559)	Loss 3.4841e+00 (1.6959e+00)	Acc@1  37.50 ( 60.23)	Acc@5  59.38 ( 83.38)
Test: [20/28]	Time  0.088 ( 0.410)	Loss 2.0444e+00 (1.8756e+00)	Acc@1  54.69 ( 55.65)	Acc@5  79.69 ( 80.65)
 * Acc@1 56.050 Acc@5 80.360
Epoch: [46][  0/109]	Time  3.925 ( 3.925)	Data  3.384 ( 3.384)	Loss 0.6408839821815491 (0.6408839821815491)	Acc@1  79.69 ( 79.69)	Acc@5  98.44 ( 98.44)
Epoch: [46][ 10/109]	Time  0.437 ( 0.747)	Data  0.000 ( 0.308)	Loss 0.5081718564033508 (0.4171867018396204)	Acc@1  87.50 ( 88.64)	Acc@5  95.31 ( 97.73)
Epoch: [46][ 20/109]	Time  0.541 ( 0.598)	Data  0.000 ( 0.161)	Loss 0.7203338742256165 (0.4544620556490762)	Acc@1  78.12 ( 87.87)	Acc@5  93.75 ( 97.02)
Epoch: [46][ 30/109]	Time  0.428 ( 0.536)	Data  0.000 ( 0.110)	Loss 0.5496129989624023 (0.4388857911671362)	Acc@1  87.50 ( 88.26)	Acc@5  95.31 ( 96.98)
Epoch: [46][ 40/109]	Time  0.425 ( 0.506)	Data  0.000 ( 0.083)	Loss 0.4865295290946960 (0.4457834566511759)	Acc@1  87.50 ( 88.26)	Acc@5  95.31 ( 96.84)
Epoch: [46][ 50/109]	Time  0.429 ( 0.488)	Data  0.000 ( 0.067)	Loss 0.6479710340499878 (0.4538511879303876)	Acc@1  81.25 ( 87.87)	Acc@5  92.19 ( 96.81)
Epoch: [46][ 60/109]	Time  0.410 ( 0.471)	Data  0.000 ( 0.056)	Loss 0.8297448754310608 (0.4545051939174777)	Acc@1  75.00 ( 87.78)	Acc@5  93.75 ( 96.75)
Epoch: [46][ 70/109]	Time  0.373 ( 0.463)	Data  0.000 ( 0.048)	Loss 0.4171981215476990 (0.4525785328636707)	Acc@1  87.50 ( 87.81)	Acc@5  96.88 ( 96.83)
Epoch: [46][ 80/109]	Time  0.535 ( 0.458)	Data  0.000 ( 0.042)	Loss 0.5149294734001160 (0.4519909517264660)	Acc@1  79.69 ( 87.58)	Acc@5  98.44 ( 96.88)
Epoch: [46][ 90/109]	Time  0.504 ( 0.456)	Data  0.000 ( 0.038)	Loss 0.3390343189239502 (0.4566060078668071)	Acc@1  89.06 ( 87.45)	Acc@5 100.00 ( 96.75)
Epoch: [46][100/109]	Time  0.381 ( 0.449)	Data  0.000 ( 0.034)	Loss 0.3506442308425903 (0.4603134951379039)	Acc@1  90.62 ( 87.21)	Acc@5  96.88 ( 96.77)
epoch: 46, Avg_Loss 0.4633603422740184
Test: [ 0/28]	Time  4.074 ( 4.074)	Loss 8.5326e-01 (8.5326e-01)	Acc@1  75.00 ( 75.00)	Acc@5  96.88 ( 96.88)
Test: [10/28]	Time  0.179 ( 0.571)	Loss 2.3931e+00 (1.0594e+00)	Acc@1  53.12 ( 76.14)	Acc@5  79.69 ( 92.47)
Test: [20/28]	Time  0.099 ( 0.424)	Loss 2.1705e+00 (1.5567e+00)	Acc@1  57.81 ( 65.62)	Acc@5  81.25 ( 87.13)
 * Acc@1 63.759 Acc@5 85.087
Epoch: [47][  0/109]	Time  3.620 ( 3.620)	Data  3.134 ( 3.134)	Loss 0.2977891266345978 (0.2977891266345978)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [47][ 10/109]	Time  0.440 ( 0.697)	Data  0.000 ( 0.285)	Loss 0.2834475338459015 (0.4860266338695179)	Acc@1  90.62 ( 85.94)	Acc@5 100.00 ( 96.16)
Epoch: [47][ 20/109]	Time  0.433 ( 0.569)	Data  0.000 ( 0.149)	Loss 0.4055145978927612 (0.4724297480923789)	Acc@1  89.06 ( 87.13)	Acc@5  96.88 ( 96.13)
Epoch: [47][ 30/109]	Time  0.391 ( 0.518)	Data  0.000 ( 0.101)	Loss 0.2298080325126648 (0.4627455982469743)	Acc@1  95.31 ( 87.55)	Acc@5 100.00 ( 96.17)
Epoch: [47][ 40/109]	Time  0.441 ( 0.493)	Data  0.000 ( 0.077)	Loss 0.2402843683958054 (0.4328910250489305)	Acc@1  98.44 ( 88.53)	Acc@5  98.44 ( 96.46)
Epoch: [47][ 50/109]	Time  0.400 ( 0.477)	Data  0.000 ( 0.062)	Loss 0.4589392840862274 (0.4461232575715757)	Acc@1  90.62 ( 88.20)	Acc@5  96.88 ( 96.45)
Epoch: [47][ 60/109]	Time  0.399 ( 0.473)	Data  0.000 ( 0.053)	Loss 0.2878976464271545 (0.4430838965001653)	Acc@1  93.75 ( 88.27)	Acc@5  96.88 ( 96.39)
Epoch: [47][ 70/109]	Time  0.402 ( 0.466)	Data  0.000 ( 0.046)	Loss 0.5486263632774353 (0.4485205882032153)	Acc@1  87.50 ( 88.12)	Acc@5  98.44 ( 96.35)
Epoch: [47][ 80/109]	Time  0.403 ( 0.459)	Data  0.000 ( 0.040)	Loss 0.3671897947788239 (0.4441379124735608)	Acc@1  87.50 ( 88.12)	Acc@5  98.44 ( 96.47)
Epoch: [47][ 90/109]	Time  0.384 ( 0.456)	Data  0.004 ( 0.036)	Loss 0.3568196892738342 (0.4512142303225758)	Acc@1  89.06 ( 87.79)	Acc@5  96.88 ( 96.38)
Epoch: [47][100/109]	Time  0.401 ( 0.449)	Data  0.000 ( 0.032)	Loss 0.5057721734046936 (0.4481796271140032)	Acc@1  87.50 ( 87.79)	Acc@5  96.88 ( 96.49)
epoch: 47, Avg_Loss 0.45367918293410486
Test: [ 0/28]	Time  3.555 ( 3.555)	Loss 2.3730e+00 (2.3730e+00)	Acc@1  48.44 ( 48.44)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.144 ( 0.553)	Loss 2.0471e+00 (1.0099e+00)	Acc@1  56.25 ( 78.55)	Acc@5  81.25 ( 89.20)
Test: [20/28]	Time  0.088 ( 0.416)	Loss 1.2395e+00 (1.4251e+00)	Acc@1  71.88 ( 67.93)	Acc@5  89.06 ( 85.27)
 * Acc@1 65.898 Acc@5 84.018
Epoch: [48][  0/109]	Time  3.566 ( 3.566)	Data  3.087 ( 3.087)	Loss 0.2404388785362244 (0.2404388785362244)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [48][ 10/109]	Time  0.475 ( 0.720)	Data  0.000 ( 0.283)	Loss 0.5220971107482910 (0.3629144403067502)	Acc@1  85.94 ( 90.77)	Acc@5  95.31 ( 98.01)
Epoch: [48][ 20/109]	Time  0.403 ( 0.580)	Data  0.000 ( 0.148)	Loss 0.2906199395656586 (0.3929808735847473)	Acc@1  92.19 ( 89.73)	Acc@5  98.44 ( 97.69)
Epoch: [48][ 30/109]	Time  0.361 ( 0.525)	Data  0.000 ( 0.100)	Loss 0.7259154319763184 (0.4277359141457465)	Acc@1  81.25 ( 88.56)	Acc@5  90.62 ( 97.18)
Epoch: [48][ 40/109]	Time  0.372 ( 0.492)	Data  0.000 ( 0.076)	Loss 0.3881644904613495 (0.4194768914362280)	Acc@1  89.06 ( 88.83)	Acc@5  98.44 ( 97.33)
Epoch: [48][ 50/109]	Time  0.382 ( 0.485)	Data  0.000 ( 0.061)	Loss 0.4078497886657715 (0.4308070815077015)	Acc@1  87.50 ( 88.51)	Acc@5  96.88 ( 96.97)
Epoch: [48][ 60/109]	Time  0.437 ( 0.471)	Data  0.000 ( 0.051)	Loss 0.4007692039012909 (0.4266873133964226)	Acc@1  92.19 ( 88.47)	Acc@5  98.44 ( 97.03)
Epoch: [48][ 70/109]	Time  0.384 ( 0.462)	Data  0.000 ( 0.044)	Loss 0.5173659324645996 (0.4345353615116065)	Acc@1  85.94 ( 88.25)	Acc@5  93.75 ( 96.92)
Epoch: [48][ 80/109]	Time  0.444 ( 0.457)	Data  0.000 ( 0.039)	Loss 0.4816642701625824 (0.4417646578800531)	Acc@1  85.94 ( 88.06)	Acc@5  96.88 ( 96.78)
Epoch: [48][ 90/109]	Time  0.380 ( 0.451)	Data  0.000 ( 0.034)	Loss 0.1972652673721313 (0.4356000924503410)	Acc@1  93.75 ( 88.34)	Acc@5 100.00 ( 96.81)
Epoch: [48][100/109]	Time  0.379 ( 0.447)	Data  0.000 ( 0.031)	Loss 0.5271800756454468 (0.4426159950176088)	Acc@1  89.06 ( 88.26)	Acc@5  96.88 ( 96.69)
epoch: 48, Avg_Loss 0.4406022455440749
Test: [ 0/28]	Time  3.555 ( 3.555)	Loss 1.3697e+00 (1.3697e+00)	Acc@1  65.62 ( 65.62)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.356 ( 0.619)	Loss 1.7915e+00 (7.9583e-01)	Acc@1  59.38 ( 82.10)	Acc@5  79.69 ( 92.47)
Test: [20/28]	Time  0.089 ( 0.432)	Loss 1.1293e+00 (1.1845e+00)	Acc@1  76.56 ( 72.02)	Acc@5  87.50 ( 88.02)
 * Acc@1 68.542 Acc@5 85.988
Epoch: [49][  0/109]	Time  3.593 ( 3.593)	Data  3.127 ( 3.127)	Loss 0.2369359731674194 (0.2369359731674194)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [49][ 10/109]	Time  0.441 ( 0.716)	Data  0.000 ( 0.285)	Loss 0.3283256590366364 (0.3847812617366964)	Acc@1  89.06 ( 89.77)	Acc@5  98.44 ( 97.44)
Epoch: [49][ 20/109]	Time  0.374 ( 0.576)	Data  0.000 ( 0.149)	Loss 0.1898100972175598 (0.3601056656667164)	Acc@1  93.75 ( 89.88)	Acc@5 100.00 ( 97.54)
Epoch: [49][ 30/109]	Time  0.482 ( 0.526)	Data  0.000 ( 0.101)	Loss 0.6176078915596008 (0.3624117970466614)	Acc@1  85.94 ( 89.77)	Acc@5  93.75 ( 97.58)
Epoch: [49][ 40/109]	Time  0.475 ( 0.501)	Data  0.000 ( 0.077)	Loss 0.5459100008010864 (0.3737130753877687)	Acc@1  85.94 ( 89.52)	Acc@5  96.88 ( 97.56)
Epoch: [49][ 50/109]	Time  0.434 ( 0.485)	Data  0.000 ( 0.062)	Loss 0.4307642579078674 (0.3810390067451140)	Acc@1  90.62 ( 89.61)	Acc@5  98.44 ( 97.52)
Epoch: [49][ 60/109]	Time  0.399 ( 0.475)	Data  0.001 ( 0.052)	Loss 0.5894522666931152 (0.3975253916177593)	Acc@1  85.94 ( 89.04)	Acc@5  96.88 ( 97.41)
Epoch: [49][ 70/109]	Time  0.393 ( 0.464)	Data  0.001 ( 0.044)	Loss 0.3656826317310333 (0.3964224277247845)	Acc@1  89.06 ( 89.02)	Acc@5  98.44 ( 97.47)
Epoch: [49][ 80/109]	Time  0.467 ( 0.463)	Data  0.000 ( 0.039)	Loss 0.3863999843597412 (0.4056401109253919)	Acc@1  84.38 ( 88.77)	Acc@5 100.00 ( 97.40)
Epoch: [49][ 90/109]	Time  0.371 ( 0.462)	Data  0.000 ( 0.035)	Loss 0.4290252923965454 (0.4095011743215414)	Acc@1  89.06 ( 88.67)	Acc@5  96.88 ( 97.41)
Epoch: [49][100/109]	Time  0.377 ( 0.456)	Data  0.000 ( 0.031)	Loss 0.5343438982963562 (0.4104349002389625)	Acc@1  89.06 ( 88.60)	Acc@5  95.31 ( 97.40)
epoch: 49, Avg_Loss 0.4163835543558138
Test: [ 0/28]	Time  3.836 ( 3.836)	Loss 1.7651e+00 (1.7651e+00)	Acc@1  51.56 ( 51.56)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.149 ( 0.558)	Loss 1.9859e+00 (8.4825e-01)	Acc@1  59.38 ( 80.68)	Acc@5  75.00 ( 92.05)
Test: [20/28]	Time  0.087 ( 0.418)	Loss 1.4683e+00 (1.3013e+00)	Acc@1  68.75 ( 70.83)	Acc@5  79.69 ( 86.01)
 * Acc@1 69.555 Acc@5 86.044
Epoch: [50][  0/109]	Time  3.541 ( 3.541)	Data  3.063 ( 3.063)	Loss 0.6496287584304810 (0.6496287584304810)	Acc@1  87.50 ( 87.50)	Acc@5  92.19 ( 92.19)
Epoch: [50][ 10/109]	Time  0.479 ( 0.735)	Data  0.001 ( 0.317)	Loss 0.4870084822177887 (0.4213275611400604)	Acc@1  85.94 ( 87.93)	Acc@5  98.44 ( 97.73)
Epoch: [50][ 20/109]	Time  0.363 ( 0.590)	Data  0.000 ( 0.166)	Loss 0.3207314908504486 (0.3851772199074427)	Acc@1  90.62 ( 89.29)	Acc@5  98.44 ( 97.77)
Epoch: [50][ 30/109]	Time  0.372 ( 0.542)	Data  0.000 ( 0.113)	Loss 0.3773459196090698 (0.4005567902518857)	Acc@1  87.50 ( 89.21)	Acc@5  98.44 ( 97.48)
Epoch: [50][ 40/109]	Time  0.351 ( 0.505)	Data  0.000 ( 0.085)	Loss 0.4520825147628784 (0.4051820875667944)	Acc@1  87.50 ( 88.68)	Acc@5  96.88 ( 97.26)
Epoch: [50][ 50/109]	Time  0.502 ( 0.486)	Data  0.000 ( 0.069)	Loss 0.5459049344062805 (0.3926227157022439)	Acc@1  85.94 ( 89.06)	Acc@5  96.88 ( 97.46)
Epoch: [50][ 60/109]	Time  0.482 ( 0.475)	Data  0.000 ( 0.058)	Loss 0.4395097494125366 (0.4013176448032504)	Acc@1  87.50 ( 88.81)	Acc@5  95.31 ( 97.26)
Epoch: [50][ 70/109]	Time  0.407 ( 0.472)	Data  0.000 ( 0.049)	Loss 0.3945669233798981 (0.3958402101842450)	Acc@1  87.50 ( 89.02)	Acc@5  96.88 ( 97.23)
Epoch: [50][ 80/109]	Time  0.489 ( 0.466)	Data  0.000 ( 0.043)	Loss 0.3910362422466278 (0.3876059011176781)	Acc@1  89.06 ( 89.29)	Acc@5  98.44 ( 97.28)
Epoch: [50][ 90/109]	Time  0.480 ( 0.461)	Data  0.000 ( 0.039)	Loss 0.4081381559371948 (0.3862168237075701)	Acc@1  89.06 ( 89.44)	Acc@5  95.31 ( 97.29)
Epoch: [50][100/109]	Time  0.368 ( 0.455)	Data  0.000 ( 0.035)	Loss 0.3834494054317474 (0.3817474350775822)	Acc@1  85.94 ( 89.60)	Acc@5 100.00 ( 97.29)
epoch: 50, Avg_Loss 0.3846050015556703
Test: [ 0/28]	Time  3.666 ( 3.666)	Loss 2.1395e+00 (2.1395e+00)	Acc@1  45.31 ( 45.31)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.088 ( 0.575)	Loss 1.3995e+00 (8.4813e-01)	Acc@1  68.75 ( 80.40)	Acc@5  87.50 ( 91.90)
Test: [20/28]	Time  0.092 ( 0.408)	Loss 1.1066e+00 (1.2537e+00)	Acc@1  81.25 ( 71.95)	Acc@5  90.62 ( 87.35)
 * Acc@1 70.062 Acc@5 86.438
Epoch: [51][  0/109]	Time  4.060 ( 4.060)	Data  3.588 ( 3.588)	Loss 0.5096261501312256 (0.5096261501312256)	Acc@1  84.38 ( 84.38)	Acc@5  98.44 ( 98.44)
Epoch: [51][ 10/109]	Time  0.449 ( 0.752)	Data  0.000 ( 0.326)	Loss 0.4298468828201294 (0.3519875204021281)	Acc@1  89.06 ( 90.48)	Acc@5  96.88 ( 98.15)
Epoch: [51][ 20/109]	Time  0.409 ( 0.589)	Data  0.000 ( 0.171)	Loss 0.2674440145492554 (0.3836471048139390)	Acc@1  93.75 ( 89.73)	Acc@5  98.44 ( 97.32)
Epoch: [51][ 30/109]	Time  0.448 ( 0.537)	Data  0.000 ( 0.116)	Loss 0.3517656326293945 (0.3777990514232266)	Acc@1  90.62 ( 89.97)	Acc@5  96.88 ( 97.33)
Epoch: [51][ 40/109]	Time  0.505 ( 0.512)	Data  0.000 ( 0.088)	Loss 0.2720352113246918 (0.3672729109118624)	Acc@1  95.31 ( 90.09)	Acc@5  98.44 ( 97.48)
Epoch: [51][ 50/109]	Time  0.370 ( 0.496)	Data  0.000 ( 0.071)	Loss 0.3429126739501953 (0.3583521626743616)	Acc@1  92.19 ( 90.23)	Acc@5  98.44 ( 97.67)
Epoch: [51][ 60/109]	Time  0.372 ( 0.478)	Data  0.000 ( 0.059)	Loss 0.2374214231967926 (0.3616365321346971)	Acc@1  93.75 ( 90.06)	Acc@5 100.00 ( 97.59)
Epoch: [51][ 70/109]	Time  0.417 ( 0.469)	Data  0.000 ( 0.051)	Loss 0.3916714191436768 (0.3671469375701018)	Acc@1  87.50 ( 89.77)	Acc@5  98.44 ( 97.51)
Epoch: [51][ 80/109]	Time  0.374 ( 0.460)	Data  0.000 ( 0.045)	Loss 0.6387922763824463 (0.3687315700966635)	Acc@1  84.38 ( 89.78)	Acc@5  96.88 ( 97.55)
Epoch: [51][ 90/109]	Time  0.421 ( 0.454)	Data  0.000 ( 0.040)	Loss 0.3702860772609711 (0.3733884603767605)	Acc@1  89.06 ( 89.66)	Acc@5  95.31 ( 97.51)
Epoch: [51][100/109]	Time  0.368 ( 0.448)	Data  0.000 ( 0.036)	Loss 0.3344028294086456 (0.3829216697428486)	Acc@1  92.19 ( 89.34)	Acc@5  96.88 ( 97.39)
epoch: 51, Avg_Loss 0.38319228138398687
Test: [ 0/28]	Time  3.614 ( 3.614)	Loss 1.1450e+00 (1.1450e+00)	Acc@1  62.50 ( 62.50)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.087 ( 0.546)	Loss 1.8478e+00 (8.1315e-01)	Acc@1  60.94 ( 80.82)	Acc@5  81.25 ( 93.18)
Test: [20/28]	Time  0.087 ( 0.403)	Loss 1.5591e+00 (1.3156e+00)	Acc@1  71.88 ( 69.42)	Acc@5  84.38 ( 87.65)
 * Acc@1 67.923 Acc@5 86.100
Epoch: [52][  0/109]	Time  3.949 ( 3.949)	Data  3.491 ( 3.491)	Loss 0.3442208170890808 (0.3442208170890808)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [52][ 10/109]	Time  0.426 ( 0.754)	Data  0.000 ( 0.318)	Loss 0.6006242632865906 (0.3535815843126990)	Acc@1  87.50 ( 90.77)	Acc@5  93.75 ( 97.87)
Epoch: [52][ 20/109]	Time  0.376 ( 0.587)	Data  0.000 ( 0.166)	Loss 0.1435127556324005 (0.3460068823326202)	Acc@1  95.31 ( 90.92)	Acc@5 100.00 ( 98.07)
Epoch: [52][ 30/109]	Time  0.372 ( 0.520)	Data  0.000 ( 0.113)	Loss 0.1143473833799362 (0.3507455505671040)	Acc@1  98.44 ( 90.83)	Acc@5 100.00 ( 97.98)
Epoch: [52][ 40/109]	Time  0.384 ( 0.491)	Data  0.000 ( 0.085)	Loss 0.2387128919363022 (0.3324237698461951)	Acc@1  96.88 ( 91.46)	Acc@5  98.44 ( 97.83)
Epoch: [52][ 50/109]	Time  0.372 ( 0.476)	Data  0.000 ( 0.069)	Loss 0.3588392734527588 (0.3387708047441408)	Acc@1  85.94 ( 91.18)	Acc@5  98.44 ( 97.79)
Epoch: [52][ 60/109]	Time  0.434 ( 0.467)	Data  0.000 ( 0.057)	Loss 0.4538123607635498 (0.3495759326414984)	Acc@1  84.38 ( 90.96)	Acc@5  96.88 ( 97.72)
Epoch: [52][ 70/109]	Time  0.432 ( 0.463)	Data  0.000 ( 0.049)	Loss 0.5104681253433228 (0.3531471744809352)	Acc@1  84.38 ( 90.71)	Acc@5  95.31 ( 97.67)
Epoch: [52][ 80/109]	Time  0.419 ( 0.455)	Data  0.000 ( 0.043)	Loss 0.3021821081638336 (0.3535577518704497)	Acc@1  89.06 ( 90.61)	Acc@5  96.88 ( 97.61)
Epoch: [52][ 90/109]	Time  0.446 ( 0.451)	Data  0.000 ( 0.039)	Loss 0.2970138192176819 (0.3501055403561382)	Acc@1  89.06 ( 90.69)	Acc@5 100.00 ( 97.65)
Epoch: [52][100/109]	Time  0.370 ( 0.444)	Data  0.000 ( 0.035)	Loss 0.4108703732490540 (0.3484812686496442)	Acc@1  89.06 ( 90.69)	Acc@5  95.31 ( 97.66)
epoch: 52, Avg_Loss 0.350219806604976
Test: [ 0/28]	Time  3.014 ( 3.014)	Loss 1.9328e+00 (1.9328e+00)	Acc@1  51.56 ( 51.56)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.329 ( 0.528)	Loss 1.6439e+00 (8.3795e-01)	Acc@1  60.94 ( 80.82)	Acc@5  78.12 ( 91.34)
Test: [20/28]	Time  0.088 ( 0.400)	Loss 1.1834e+00 (1.2020e+00)	Acc@1  73.44 ( 72.32)	Acc@5  87.50 ( 88.17)
 * Acc@1 70.062 Acc@5 86.325
Epoch: [53][  0/109]	Time  3.872 ( 3.872)	Data  3.423 ( 3.423)	Loss 0.1954987496137619 (0.1954987496137619)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [53][ 10/109]	Time  0.433 ( 0.716)	Data  0.000 ( 0.311)	Loss 0.1324250251054764 (0.2776430560783906)	Acc@1  95.31 ( 92.47)	Acc@5  98.44 ( 98.15)
Epoch: [53][ 20/109]	Time  0.354 ( 0.591)	Data  0.000 ( 0.163)	Loss 0.3129929602146149 (0.3243492841720581)	Acc@1  89.06 ( 91.29)	Acc@5  98.44 ( 97.62)
Epoch: [53][ 30/109]	Time  0.435 ( 0.534)	Data  0.000 ( 0.111)	Loss 0.3969222903251648 (0.3394528829282330)	Acc@1  92.19 ( 90.68)	Acc@5  95.31 ( 97.53)
Epoch: [53][ 40/109]	Time  0.424 ( 0.503)	Data  0.000 ( 0.084)	Loss 0.3395802974700928 (0.3546880338250137)	Acc@1  89.06 ( 90.51)	Acc@5 100.00 ( 97.33)
Epoch: [53][ 50/109]	Time  0.467 ( 0.490)	Data  0.000 ( 0.067)	Loss 0.3453196585178375 (0.3572520175400902)	Acc@1  93.75 ( 90.59)	Acc@5  98.44 ( 97.15)
Epoch: [53][ 60/109]	Time  0.369 ( 0.474)	Data  0.000 ( 0.056)	Loss 0.4079935550689697 (0.3664572273121505)	Acc@1  89.06 ( 90.37)	Acc@5  95.31 ( 97.00)
Epoch: [53][ 70/109]	Time  0.364 ( 0.462)	Data  0.000 ( 0.048)	Loss 0.1502084583044052 (0.3566477877992979)	Acc@1  96.88 ( 90.58)	Acc@5 100.00 ( 97.14)
Epoch: [53][ 80/109]	Time  0.431 ( 0.457)	Data  0.000 ( 0.042)	Loss 0.3510441780090332 (0.3615162045131495)	Acc@1  84.38 ( 90.30)	Acc@5  98.44 ( 97.15)
Epoch: [53][ 90/109]	Time  0.393 ( 0.449)	Data  0.000 ( 0.038)	Loss 0.3281791508197784 (0.3598400891482175)	Acc@1  89.06 ( 90.33)	Acc@5  98.44 ( 97.22)
Epoch: [53][100/109]	Time  0.379 ( 0.444)	Data  0.000 ( 0.034)	Loss 0.2778711616992950 (0.3612911684973405)	Acc@1  93.75 ( 90.30)	Acc@5  98.44 ( 97.23)
epoch: 53, Avg_Loss 0.35853344577988355
Test: [ 0/28]	Time  3.768 ( 3.768)	Loss 1.2966e+00 (1.2966e+00)	Acc@1  62.50 ( 62.50)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.093 ( 0.586)	Loss 1.7496e+00 (8.1548e-01)	Acc@1  60.94 ( 81.82)	Acc@5  78.12 ( 92.05)
Test: [20/28]	Time  0.087 ( 0.418)	Loss 1.4296e+00 (1.3119e+00)	Acc@1  67.19 ( 69.72)	Acc@5  85.94 ( 86.38)
 * Acc@1 67.304 Acc@5 85.031
Epoch: [54][  0/109]	Time  3.255 ( 3.255)	Data  2.766 ( 2.766)	Loss 0.4221534430980682 (0.4221534430980682)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [54][ 10/109]	Time  0.466 ( 0.676)	Data  0.000 ( 0.260)	Loss 0.4660077095031738 (0.3019962107593363)	Acc@1  87.50 ( 92.61)	Acc@5  96.88 ( 98.30)
Epoch: [54][ 20/109]	Time  0.377 ( 0.543)	Data  0.000 ( 0.136)	Loss 0.2304363399744034 (0.2936916699012120)	Acc@1  95.31 ( 92.71)	Acc@5 100.00 ( 98.21)
Epoch: [54][ 30/109]	Time  0.378 ( 0.494)	Data  0.000 ( 0.092)	Loss 0.4751807153224945 (0.3024063076703779)	Acc@1  87.50 ( 92.39)	Acc@5  95.31 ( 97.73)
Epoch: [54][ 40/109]	Time  0.435 ( 0.474)	Data  0.000 ( 0.070)	Loss 0.2849740982055664 (0.3025363491075795)	Acc@1  92.19 ( 92.30)	Acc@5 100.00 ( 97.75)
Epoch: [54][ 50/109]	Time  0.411 ( 0.460)	Data  0.000 ( 0.056)	Loss 0.4870740473270416 (0.3012475362595390)	Acc@1  87.50 ( 92.31)	Acc@5  93.75 ( 97.86)
Epoch: [54][ 60/109]	Time  0.417 ( 0.456)	Data  0.000 ( 0.047)	Loss 0.3208949863910675 (0.3074218413380326)	Acc@1  92.19 ( 92.14)	Acc@5  96.88 ( 97.69)
Epoch: [54][ 70/109]	Time  0.448 ( 0.449)	Data  0.000 ( 0.040)	Loss 0.1781719624996185 (0.3021997595337075)	Acc@1  95.31 ( 92.30)	Acc@5 100.00 ( 97.84)
Epoch: [54][ 80/109]	Time  0.377 ( 0.444)	Data  0.000 ( 0.035)	Loss 0.4008597135543823 (0.3108855162137820)	Acc@1  90.62 ( 91.94)	Acc@5  95.31 ( 97.74)
Epoch: [54][ 90/109]	Time  0.386 ( 0.437)	Data  0.000 ( 0.032)	Loss 0.2697564065456390 (0.3189932723621746)	Acc@1  89.06 ( 91.62)	Acc@5  98.44 ( 97.70)
Epoch: [54][100/109]	Time  0.369 ( 0.432)	Data  0.000 ( 0.028)	Loss 0.2226134985685349 (0.3202945379042390)	Acc@1  93.75 ( 91.54)	Acc@5  98.44 ( 97.74)
epoch: 54, Avg_Loss 0.32035690135912065
Test: [ 0/28]	Time  3.550 ( 3.550)	Loss 1.4911e+00 (1.4911e+00)	Acc@1  54.69 ( 54.69)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.087 ( 0.606)	Loss 2.2381e+00 (9.0817e-01)	Acc@1  51.56 ( 79.12)	Acc@5  68.75 ( 90.20)
Test: [20/28]	Time  0.089 ( 0.413)	Loss 1.0529e+00 (1.2908e+00)	Acc@1  79.69 ( 69.27)	Acc@5  90.62 ( 85.71)
 * Acc@1 66.854 Acc@5 85.200
Epoch: [55][  0/109]	Time  3.348 ( 3.348)	Data  2.956 ( 2.956)	Loss 0.1969898492097855 (0.1969898492097855)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [55][ 10/109]	Time  0.438 ( 0.702)	Data  0.000 ( 0.290)	Loss 0.4201290309429169 (0.2561582164330916)	Acc@1  89.06 ( 93.18)	Acc@5  96.88 ( 98.15)
Epoch: [55][ 20/109]	Time  0.435 ( 0.563)	Data  0.000 ( 0.152)	Loss 0.1089187264442444 (0.2690572837988536)	Acc@1  98.44 ( 92.86)	Acc@5 100.00 ( 98.29)
Epoch: [55][ 30/109]	Time  0.471 ( 0.508)	Data  0.000 ( 0.103)	Loss 0.2149329632520676 (0.2692095041275024)	Acc@1  95.31 ( 92.49)	Acc@5  98.44 ( 98.54)
Epoch: [55][ 40/109]	Time  0.410 ( 0.483)	Data  0.000 ( 0.078)	Loss 0.1388280689716339 (0.2865543616254155)	Acc@1  95.31 ( 92.11)	Acc@5 100.00 ( 98.36)
Epoch: [55][ 50/109]	Time  0.369 ( 0.468)	Data  0.000 ( 0.063)	Loss 0.5527834296226501 (0.2878414491812388)	Acc@1  84.38 ( 92.06)	Acc@5  96.88 ( 98.35)
Epoch: [55][ 60/109]	Time  0.479 ( 0.460)	Data  0.000 ( 0.052)	Loss 0.2367662936449051 (0.2866795908232204)	Acc@1  93.75 ( 92.11)	Acc@5 100.00 ( 98.44)
Epoch: [55][ 70/109]	Time  0.382 ( 0.452)	Data  0.000 ( 0.045)	Loss 0.3330258131027222 (0.2924431805879297)	Acc@1  90.62 ( 91.97)	Acc@5  98.44 ( 98.28)
Epoch: [55][ 80/109]	Time  0.401 ( 0.447)	Data  0.000 ( 0.040)	Loss 0.6169103384017944 (0.2967088790955367)	Acc@1  90.62 ( 91.86)	Acc@5  93.75 ( 98.21)
Epoch: [55][ 90/109]	Time  0.370 ( 0.442)	Data  0.000 ( 0.035)	Loss 0.2261660695075989 (0.2996806559654382)	Acc@1  95.31 ( 91.81)	Acc@5  98.44 ( 98.18)
Epoch: [55][100/109]	Time  0.371 ( 0.440)	Data  0.000 ( 0.032)	Loss 0.2933520376682281 (0.2984727576817616)	Acc@1  90.62 ( 91.83)	Acc@5  98.44 ( 98.19)
epoch: 55, Avg_Loss 0.29883318182525287
Test: [ 0/28]	Time  3.558 ( 3.558)	Loss 2.0626e+00 (2.0626e+00)	Acc@1  53.12 ( 53.12)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.097 ( 0.590)	Loss 1.8335e+00 (9.0385e-01)	Acc@1  57.81 ( 78.98)	Acc@5  81.25 ( 91.05)
Test: [20/28]	Time  0.087 ( 0.404)	Loss 1.1836e+00 (1.2131e+00)	Acc@1  70.31 ( 70.46)	Acc@5  87.50 ( 88.24)
 * Acc@1 68.768 Acc@5 87.394
Epoch: [56][  0/109]	Time  4.289 ( 4.289)	Data  3.899 ( 3.899)	Loss 0.1454429626464844 (0.1454429626464844)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [56][ 10/109]	Time  0.430 ( 0.749)	Data  0.000 ( 0.355)	Loss 0.3565693795681000 (0.3117600706490604)	Acc@1  85.94 ( 90.62)	Acc@5  98.44 ( 98.01)
Epoch: [56][ 20/109]	Time  0.425 ( 0.585)	Data  0.000 ( 0.186)	Loss 0.2862085700035095 (0.3054891583465394)	Acc@1  93.75 ( 91.82)	Acc@5  98.44 ( 98.14)
Epoch: [56][ 30/109]	Time  0.366 ( 0.527)	Data  0.000 ( 0.126)	Loss 0.2957404553890228 (0.3306703240640702)	Acc@1  93.75 ( 91.63)	Acc@5  96.88 ( 97.88)
Epoch: [56][ 40/109]	Time  0.376 ( 0.498)	Data  0.000 ( 0.095)	Loss 0.4823980927467346 (0.3401820605121008)	Acc@1  90.62 ( 91.39)	Acc@5  95.31 ( 97.68)
Epoch: [56][ 50/109]	Time  0.522 ( 0.485)	Data  0.000 ( 0.077)	Loss 0.3424310684204102 (0.3366423377803728)	Acc@1  96.88 ( 91.33)	Acc@5  98.44 ( 97.76)
Epoch: [56][ 60/109]	Time  0.508 ( 0.471)	Data  0.000 ( 0.064)	Loss 0.2639792263507843 (0.3275978254978774)	Acc@1  92.19 ( 91.50)	Acc@5  98.44 ( 97.82)
Epoch: [56][ 70/109]	Time  0.376 ( 0.460)	Data  0.000 ( 0.055)	Loss 0.2080889493227005 (0.3184763338993972)	Acc@1  92.19 ( 91.68)	Acc@5 100.00 ( 97.95)
Epoch: [56][ 80/109]	Time  0.375 ( 0.451)	Data  0.000 ( 0.048)	Loss 0.2812880277633667 (0.3151733066748690)	Acc@1  95.31 ( 91.63)	Acc@5  96.88 ( 98.03)
Epoch: [56][ 90/109]	Time  0.457 ( 0.447)	Data  0.000 ( 0.043)	Loss 0.1949300915002823 (0.3110988383273502)	Acc@1  93.75 ( 91.69)	Acc@5 100.00 ( 98.09)
Epoch: [56][100/109]	Time  0.369 ( 0.441)	Data  0.000 ( 0.039)	Loss 0.0837048813700676 (0.3056001465509434)	Acc@1  98.44 ( 91.80)	Acc@5 100.00 ( 98.10)
epoch: 56, Avg_Loss 0.311207607935328
Test: [ 0/28]	Time  3.276 ( 3.276)	Loss 1.2783e+00 (1.2783e+00)	Acc@1  70.31 ( 70.31)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.088 ( 0.554)	Loss 1.5900e+00 (7.5671e-01)	Acc@1  68.75 ( 85.23)	Acc@5  82.81 ( 92.05)
Test: [20/28]	Time  0.088 ( 0.406)	Loss 1.2262e+00 (1.2053e+00)	Acc@1  75.00 ( 73.59)	Acc@5  92.19 ( 87.95)
 * Acc@1 71.300 Acc@5 87.620
Epoch: [57][  0/109]	Time  4.010 ( 4.010)	Data  3.515 ( 3.515)	Loss 0.1750724017620087 (0.1750724017620087)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [57][ 10/109]	Time  0.369 ( 0.763)	Data  0.000 ( 0.320)	Loss 0.3055771589279175 (0.3345753794366663)	Acc@1  87.50 ( 91.34)	Acc@5 100.00 ( 97.44)
Epoch: [57][ 20/109]	Time  0.451 ( 0.583)	Data  0.000 ( 0.168)	Loss 0.4228177070617676 (0.3175864148707617)	Acc@1  87.50 ( 91.52)	Acc@5  96.88 ( 97.84)
Epoch: [57][ 30/109]	Time  0.397 ( 0.557)	Data  0.000 ( 0.114)	Loss 0.3684273064136505 (0.3032600211520349)	Acc@1  87.50 ( 91.68)	Acc@5  98.44 ( 98.14)
Epoch: [57][ 40/109]	Time  0.433 ( 0.519)	Data  0.000 ( 0.086)	Loss 0.2141075134277344 (0.2972361161941435)	Acc@1  92.19 ( 91.73)	Acc@5 100.00 ( 98.17)
Epoch: [57][ 50/109]	Time  0.364 ( 0.494)	Data  0.000 ( 0.069)	Loss 0.0957093536853790 (0.2934556717381758)	Acc@1  98.44 ( 92.19)	Acc@5 100.00 ( 98.10)
Epoch: [57][ 60/109]	Time  0.384 ( 0.478)	Data  0.000 ( 0.058)	Loss 0.2632389962673187 (0.2889186334414560)	Acc@1  95.31 ( 92.26)	Acc@5  98.44 ( 98.13)
Epoch: [57][ 70/109]	Time  0.385 ( 0.469)	Data  0.000 ( 0.050)	Loss 0.2760586142539978 (0.2876169271242451)	Acc@1  95.31 ( 92.39)	Acc@5  96.88 ( 98.11)
Epoch: [57][ 80/109]	Time  0.412 ( 0.461)	Data  0.000 ( 0.044)	Loss 0.4409756958484650 (0.2845168826572689)	Acc@1  89.06 ( 92.50)	Acc@5  93.75 ( 98.15)
Epoch: [57][ 90/109]	Time  0.367 ( 0.457)	Data  0.000 ( 0.039)	Loss 0.4496845901012421 (0.2815395638674170)	Acc@1  92.19 ( 92.69)	Acc@5  95.31 ( 98.09)
Epoch: [57][100/109]	Time  0.361 ( 0.450)	Data  0.000 ( 0.035)	Loss 0.0855848044157028 (0.2784548349457212)	Acc@1  96.88 ( 92.65)	Acc@5 100.00 ( 98.16)
epoch: 57, Avg_Loss 0.2801520740357014
Test: [ 0/28]	Time  3.765 ( 3.765)	Loss 1.7198e+00 (1.7198e+00)	Acc@1  54.69 ( 54.69)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.100 ( 0.576)	Loss 1.8780e+00 (7.8527e-01)	Acc@1  65.62 ( 83.38)	Acc@5  79.69 ( 92.76)
Test: [20/28]	Time  0.178 ( 0.400)	Loss 1.3294e+00 (1.1600e+00)	Acc@1  73.44 ( 73.66)	Acc@5  84.38 ( 88.54)
 * Acc@1 71.919 Acc@5 87.901
Epoch: [58][  0/109]	Time  3.173 ( 3.173)	Data  2.604 ( 2.604)	Loss 0.1798019260168076 (0.1798019260168076)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [58][ 10/109]	Time  0.416 ( 0.694)	Data  0.000 ( 0.266)	Loss 0.1912229657173157 (0.2356883890249512)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 ( 98.58)
Epoch: [58][ 20/109]	Time  0.446 ( 0.570)	Data  0.000 ( 0.139)	Loss 0.2439312636852264 (0.2615047945153146)	Acc@1  90.62 ( 93.01)	Acc@5  98.44 ( 98.36)
Epoch: [58][ 30/109]	Time  0.454 ( 0.519)	Data  0.000 ( 0.094)	Loss 0.3373687267303467 (0.2724200922154611)	Acc@1  90.62 ( 92.89)	Acc@5  98.44 ( 98.14)
Epoch: [58][ 40/109]	Time  0.377 ( 0.494)	Data  0.000 ( 0.072)	Loss 0.3596897721290588 (0.2712692269464819)	Acc@1  92.19 ( 93.06)	Acc@5  98.44 ( 98.09)
Epoch: [58][ 50/109]	Time  0.483 ( 0.483)	Data  0.000 ( 0.058)	Loss 0.2582857012748718 (0.2712515814631593)	Acc@1  92.19 ( 93.01)	Acc@5 100.00 ( 98.16)
Epoch: [58][ 60/109]	Time  0.401 ( 0.468)	Data  0.000 ( 0.048)	Loss 0.4309128820896149 (0.2661621938230562)	Acc@1  84.38 ( 93.06)	Acc@5  95.31 ( 98.21)
Epoch: [58][ 70/109]	Time  0.444 ( 0.463)	Data  0.000 ( 0.041)	Loss 0.3731693923473358 (0.2693889328921345)	Acc@1  92.19 ( 92.89)	Acc@5  96.88 ( 98.17)
Epoch: [58][ 80/109]	Time  0.364 ( 0.462)	Data  0.000 ( 0.036)	Loss 0.3425478041172028 (0.2704639143230003)	Acc@1  92.19 ( 92.73)	Acc@5  96.88 ( 98.19)
Epoch: [58][ 90/109]	Time  0.469 ( 0.455)	Data  0.000 ( 0.032)	Loss 0.1697008758783340 (0.2727214971577728)	Acc@1  93.75 ( 92.77)	Acc@5 100.00 ( 98.21)
Epoch: [58][100/109]	Time  0.367 ( 0.448)	Data  0.000 ( 0.029)	Loss 0.1696120798587799 (0.2716902425826186)	Acc@1  96.88 ( 92.78)	Acc@5 100.00 ( 98.22)
epoch: 58, Avg_Loss 0.2789017251188602
Test: [ 0/28]	Time  3.467 ( 3.467)	Loss 2.1931e+00 (2.1931e+00)	Acc@1  46.88 ( 46.88)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.168 ( 0.515)	Loss 1.7492e+00 (7.8167e-01)	Acc@1  59.38 ( 81.68)	Acc@5  78.12 ( 91.90)
Test: [20/28]	Time  0.088 ( 0.385)	Loss 1.4190e+00 (1.1335e+00)	Acc@1  64.06 ( 73.07)	Acc@5  85.94 ( 88.62)
 * Acc@1 71.356 Acc@5 87.507
Epoch: [59][  0/109]	Time  3.898 ( 3.898)	Data  3.460 ( 3.460)	Loss 0.1894686520099640 (0.1894686520099640)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [59][ 10/109]	Time  0.446 ( 0.741)	Data  0.000 ( 0.315)	Loss 0.4038969874382019 (0.2209872427311811)	Acc@1  87.50 ( 93.89)	Acc@5  98.44 ( 98.86)
Epoch: [59][ 20/109]	Time  0.441 ( 0.590)	Data  0.000 ( 0.165)	Loss 0.1832667887210846 (0.2389723427948497)	Acc@1  95.31 ( 93.30)	Acc@5 100.00 ( 98.74)
Epoch: [59][ 30/109]	Time  0.381 ( 0.531)	Data  0.000 ( 0.112)	Loss 0.3289328813552856 (0.2551013204839922)	Acc@1  87.50 ( 92.84)	Acc@5  98.44 ( 98.39)
Epoch: [59][ 40/109]	Time  0.448 ( 0.504)	Data  0.000 ( 0.085)	Loss 0.2864468097686768 (0.2706402705573454)	Acc@1  95.31 ( 92.64)	Acc@5  96.88 ( 98.25)
Epoch: [59][ 50/109]	Time  0.438 ( 0.486)	Data  0.000 ( 0.068)	Loss 0.3385761976242065 (0.2743348869330743)	Acc@1  92.19 ( 92.65)	Acc@5  98.44 ( 98.10)
Epoch: [59][ 60/109]	Time  0.373 ( 0.474)	Data  0.000 ( 0.057)	Loss 0.2609300315380096 (0.2747328313159161)	Acc@1  93.75 ( 92.78)	Acc@5  98.44 ( 98.05)
Epoch: [59][ 70/109]	Time  0.446 ( 0.466)	Data  0.000 ( 0.049)	Loss 0.3148822486400604 (0.2684578412855175)	Acc@1  93.75 ( 93.02)	Acc@5  96.88 ( 98.17)
Epoch: [59][ 80/109]	Time  0.391 ( 0.458)	Data  0.000 ( 0.043)	Loss 0.3976433575153351 (0.2682021379838755)	Acc@1  87.50 ( 93.06)	Acc@5  96.88 ( 98.23)
Epoch: [59][ 90/109]	Time  0.376 ( 0.451)	Data  0.000 ( 0.038)	Loss 0.1193999573588371 (0.2704685603033055)	Acc@1  95.31 ( 93.01)	Acc@5 100.00 ( 98.21)
Epoch: [59][100/109]	Time  0.366 ( 0.445)	Data  0.000 ( 0.034)	Loss 0.1210004389286041 (0.2716956024270247)	Acc@1  96.88 ( 92.95)	Acc@5  98.44 ( 98.19)
epoch: 59, Avg_Loss 0.2725499271662957
Test: [ 0/28]	Time  3.610 ( 3.610)	Loss 1.9691e+00 (1.9691e+00)	Acc@1  46.88 ( 46.88)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.088 ( 0.533)	Loss 1.7713e+00 (7.8063e-01)	Acc@1  60.94 ( 82.67)	Acc@5  79.69 ( 92.19)
Test: [20/28]	Time  0.088 ( 0.386)	Loss 1.4432e+00 (1.1963e+00)	Acc@1  67.19 ( 71.65)	Acc@5  87.50 ( 87.80)
 * Acc@1 71.469 Acc@5 87.001
Epoch: [60][  0/109]	Time  3.088 ( 3.088)	Data  2.624 ( 2.624)	Loss 0.3629240393638611 (0.3629240393638611)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [60][ 10/109]	Time  0.466 ( 0.693)	Data  0.000 ( 0.239)	Loss 0.2628553509712219 (0.2449366409670223)	Acc@1  92.19 ( 93.32)	Acc@5  98.44 ( 98.30)
Epoch: [60][ 20/109]	Time  0.477 ( 0.558)	Data  0.000 ( 0.125)	Loss 0.2200181186199188 (0.2403275491226287)	Acc@1  95.31 ( 93.97)	Acc@5  98.44 ( 98.29)
Epoch: [60][ 30/109]	Time  0.372 ( 0.508)	Data  0.000 ( 0.085)	Loss 0.2300250232219696 (0.2339248899971285)	Acc@1  92.19 ( 94.05)	Acc@5  98.44 ( 98.29)
Epoch: [60][ 40/109]	Time  0.363 ( 0.483)	Data  0.000 ( 0.064)	Loss 0.2156901061534882 (0.2376994636000657)	Acc@1  93.75 ( 93.94)	Acc@5  96.88 ( 98.32)
Epoch: [60][ 50/109]	Time  0.443 ( 0.472)	Data  0.000 ( 0.052)	Loss 0.3614633381366730 (0.2454833832441592)	Acc@1  93.75 ( 93.81)	Acc@5  95.31 ( 98.31)
Epoch: [60][ 60/109]	Time  0.428 ( 0.460)	Data  0.000 ( 0.043)	Loss 0.3005741834640503 (0.2591655039396442)	Acc@1  93.75 ( 93.37)	Acc@5  96.88 ( 98.13)
Epoch: [60][ 70/109]	Time  0.394 ( 0.454)	Data  0.006 ( 0.037)	Loss 0.1539534032344818 (0.2592650549092763)	Acc@1  96.88 ( 93.27)	Acc@5  98.44 ( 98.04)
Epoch: [60][ 80/109]	Time  0.392 ( 0.449)	Data  0.000 ( 0.033)	Loss 0.2219968438148499 (0.2598482589294881)	Acc@1  93.75 ( 93.25)	Acc@5  98.44 ( 98.03)
Epoch: [60][ 90/109]	Time  0.373 ( 0.443)	Data  0.002 ( 0.029)	Loss 0.2061832398176193 (0.2595997447004685)	Acc@1  93.75 ( 93.13)	Acc@5  98.44 ( 98.09)
Epoch: [60][100/109]	Time  0.365 ( 0.438)	Data  0.000 ( 0.026)	Loss 0.0817897915840149 (0.2564843893788828)	Acc@1 100.00 ( 93.19)	Acc@5 100.00 ( 98.11)
epoch: 60, Avg_Loss 0.2555988679101708
Test: [ 0/28]	Time  4.056 ( 4.056)	Loss 1.7456e+00 (1.7456e+00)	Acc@1  60.94 ( 60.94)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.146 ( 0.511)	Loss 1.5253e+00 (7.6524e-01)	Acc@1  71.88 ( 83.81)	Acc@5  85.94 ( 91.90)
Test: [20/28]	Time  0.123 ( 0.365)	Loss 1.0305e+00 (1.1254e+00)	Acc@1  76.56 ( 74.40)	Acc@5  92.19 ( 88.10)
 * Acc@1 72.819 Acc@5 86.888
Epoch: [61][  0/109]	Time  3.675 ( 3.675)	Data  3.206 ( 3.206)	Loss 0.3235422670841217 (0.3235422670841217)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [61][ 10/109]	Time  0.369 ( 0.743)	Data  0.000 ( 0.310)	Loss 0.1560179740190506 (0.2176239206032320)	Acc@1  95.31 ( 94.03)	Acc@5 100.00 ( 99.01)
Epoch: [61][ 20/109]	Time  0.407 ( 0.586)	Data  0.000 ( 0.162)	Loss 0.2761055529117584 (0.2261520389999662)	Acc@1  93.75 ( 94.12)	Acc@5 100.00 ( 99.03)
Epoch: [61][ 30/109]	Time  0.416 ( 0.527)	Data  0.000 ( 0.110)	Loss 0.3478864431381226 (0.2338717224136476)	Acc@1  92.19 ( 93.95)	Acc@5  95.31 ( 98.74)
Epoch: [61][ 40/109]	Time  0.459 ( 0.500)	Data  0.000 ( 0.083)	Loss 0.3649694025516510 (0.2462924170057948)	Acc@1  90.62 ( 93.37)	Acc@5  96.88 ( 98.51)
Epoch: [61][ 50/109]	Time  0.422 ( 0.483)	Data  0.000 ( 0.067)	Loss 0.1834101825952530 (0.2358637636198717)	Acc@1  93.75 ( 93.66)	Acc@5 100.00 ( 98.62)
Epoch: [61][ 60/109]	Time  0.367 ( 0.469)	Data  0.000 ( 0.056)	Loss 0.2616515159606934 (0.2287930461471198)	Acc@1  93.75 ( 93.88)	Acc@5  96.88 ( 98.62)
Epoch: [61][ 70/109]	Time  0.379 ( 0.461)	Data  0.000 ( 0.048)	Loss 0.1192479208111763 (0.2279252271417161)	Acc@1  96.88 ( 93.93)	Acc@5 100.00 ( 98.64)
Epoch: [61][ 80/109]	Time  0.381 ( 0.456)	Data  0.000 ( 0.042)	Loss 0.3211216926574707 (0.2277347441808677)	Acc@1  90.62 ( 93.98)	Acc@5  96.88 ( 98.59)
Epoch: [61][ 90/109]	Time  0.449 ( 0.450)	Data  0.000 ( 0.038)	Loss 0.4692524969577789 (0.2313178393703241)	Acc@1  84.38 ( 93.80)	Acc@5  96.88 ( 98.61)
Epoch: [61][100/109]	Time  0.369 ( 0.443)	Data  0.000 ( 0.034)	Loss 0.1836406290531158 (0.2345679032773074)	Acc@1  96.88 ( 93.67)	Acc@5  98.44 ( 98.59)
epoch: 61, Avg_Loss 0.23579680147247578
Test: [ 0/28]	Time  3.198 ( 3.198)	Loss 1.0394e+00 (1.0394e+00)	Acc@1  79.69 ( 79.69)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.337 ( 0.499)	Loss 2.0779e+00 (8.1718e-01)	Acc@1  60.94 ( 83.10)	Acc@5  79.69 ( 93.32)
Test: [20/28]	Time  0.095 ( 0.371)	Loss 1.0991e+00 (1.2327e+00)	Acc@1  71.88 ( 72.17)	Acc@5  90.62 ( 88.47)
 * Acc@1 70.456 Acc@5 87.338
Epoch: [62][  0/109]	Time  3.821 ( 3.821)	Data  3.377 ( 3.377)	Loss 0.2734013199806213 (0.2734013199806213)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [62][ 10/109]	Time  0.378 ( 0.731)	Data  0.000 ( 0.307)	Loss 0.4179927706718445 (0.2454943480816754)	Acc@1  87.50 ( 93.32)	Acc@5  96.88 ( 98.15)
Epoch: [62][ 20/109]	Time  0.380 ( 0.576)	Data  0.000 ( 0.161)	Loss 0.1605726629495621 (0.2486478225106285)	Acc@1  92.19 ( 93.15)	Acc@5 100.00 ( 98.07)
Epoch: [62][ 30/109]	Time  0.411 ( 0.521)	Data  0.000 ( 0.109)	Loss 0.3187276422977448 (0.2503816927632978)	Acc@1  93.75 ( 93.25)	Acc@5  96.88 ( 98.19)
Epoch: [62][ 40/109]	Time  0.391 ( 0.488)	Data  0.000 ( 0.083)	Loss 0.3433008193969727 (0.2494795831238351)	Acc@1  90.62 ( 93.22)	Acc@5  96.88 ( 98.32)
Epoch: [62][ 50/109]	Time  0.389 ( 0.473)	Data  0.000 ( 0.066)	Loss 0.5292925834655762 (0.2534541484771990)	Acc@1  85.94 ( 93.05)	Acc@5  93.75 ( 98.38)
Epoch: [62][ 60/109]	Time  0.453 ( 0.462)	Data  0.000 ( 0.056)	Loss 0.2012540251016617 (0.2467179457183744)	Acc@1  93.75 ( 93.31)	Acc@5 100.00 ( 98.46)
Epoch: [62][ 70/109]	Time  0.393 ( 0.452)	Data  0.000 ( 0.048)	Loss 0.2663355171680450 (0.2445715011005670)	Acc@1  92.19 ( 93.33)	Acc@5  98.44 ( 98.48)
Epoch: [62][ 80/109]	Time  0.474 ( 0.448)	Data  0.000 ( 0.042)	Loss 0.2641926407814026 (0.2449501029871128)	Acc@1  95.31 ( 93.36)	Acc@5  98.44 ( 98.44)
Epoch: [62][ 90/109]	Time  0.465 ( 0.445)	Data  0.000 ( 0.037)	Loss 0.1824948936700821 (0.2469399653293274)	Acc@1  93.75 ( 93.30)	Acc@5 100.00 ( 98.42)
Epoch: [62][100/109]	Time  0.360 ( 0.440)	Data  0.000 ( 0.034)	Loss 0.1251179426908493 (0.2466027045456490)	Acc@1  96.88 ( 93.36)	Acc@5 100.00 ( 98.39)
epoch: 62, Avg_Loss 0.24617432174059228
Test: [ 0/28]	Time  3.591 ( 3.591)	Loss 1.6878e+00 (1.6878e+00)	Acc@1  50.00 ( 50.00)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.088 ( 0.541)	Loss 1.6480e+00 (8.0588e-01)	Acc@1  70.31 ( 81.53)	Acc@5  79.69 ( 91.48)
Test: [20/28]	Time  0.146 ( 0.391)	Loss 1.2412e+00 (1.1208e+00)	Acc@1  73.44 ( 73.96)	Acc@5  85.94 ( 88.62)
 * Acc@1 72.088 Acc@5 87.620
Epoch: [63][  0/109]	Time  2.918 ( 2.918)	Data  2.444 ( 2.444)	Loss 0.3310946822166443 (0.3310946822166443)	Acc@1  90.62 ( 90.62)	Acc@5  96.88 ( 96.88)
Epoch: [63][ 10/109]	Time  0.417 ( 0.656)	Data  0.000 ( 0.242)	Loss 0.2541925609111786 (0.2318095409057357)	Acc@1  90.62 ( 93.47)	Acc@5 100.00 ( 98.58)
Epoch: [63][ 20/109]	Time  0.522 ( 0.548)	Data  0.000 ( 0.127)	Loss 0.5589718818664551 (0.2206468342670373)	Acc@1  84.38 ( 94.20)	Acc@5  95.31 ( 98.74)
Epoch: [63][ 30/109]	Time  0.364 ( 0.499)	Data  0.000 ( 0.086)	Loss 0.0820501223206520 (0.2126698074561934)	Acc@1  98.44 ( 94.35)	Acc@5 100.00 ( 98.89)
Epoch: [63][ 40/109]	Time  0.510 ( 0.483)	Data  0.000 ( 0.065)	Loss 0.2386381030082703 (0.2242504947977822)	Acc@1  93.75 ( 94.09)	Acc@5  98.44 ( 98.59)
Epoch: [63][ 50/109]	Time  0.405 ( 0.469)	Data  0.000 ( 0.052)	Loss 0.1458401829004288 (0.2283205899099509)	Acc@1  96.88 ( 94.09)	Acc@5  98.44 ( 98.31)
Epoch: [63][ 60/109]	Time  0.465 ( 0.459)	Data  0.000 ( 0.044)	Loss 0.2703893184661865 (0.2299544334289480)	Acc@1  92.19 ( 94.06)	Acc@5  98.44 ( 98.31)
Epoch: [63][ 70/109]	Time  0.371 ( 0.451)	Data  0.000 ( 0.038)	Loss 0.3070450127124786 (0.2260204122834642)	Acc@1  92.19 ( 94.23)	Acc@5  98.44 ( 98.35)
Epoch: [63][ 80/109]	Time  0.431 ( 0.447)	Data  0.000 ( 0.033)	Loss 0.1961775720119476 (0.2249244785879129)	Acc@1  95.31 ( 94.16)	Acc@5 100.00 ( 98.36)
Epoch: [63][ 90/109]	Time  0.405 ( 0.441)	Data  0.000 ( 0.030)	Loss 0.2336641103029251 (0.2249895567176761)	Acc@1  93.75 ( 94.14)	Acc@5 100.00 ( 98.40)
Epoch: [63][100/109]	Time  0.372 ( 0.437)	Data  0.000 ( 0.027)	Loss 0.1657744795084000 (0.2212494969884358)	Acc@1  93.75 ( 94.18)	Acc@5 100.00 ( 98.45)
epoch: 63, Avg_Loss 0.22870599427217736
Test: [ 0/28]	Time  3.244 ( 3.244)	Loss 1.9093e+00 (1.9093e+00)	Acc@1  51.56 ( 51.56)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.087 ( 0.504)	Loss 1.8340e+00 (8.1627e-01)	Acc@1  59.38 ( 82.10)	Acc@5  78.12 ( 91.05)
Test: [20/28]	Time  0.088 ( 0.368)	Loss 1.1771e+00 (1.1257e+00)	Acc@1  76.56 ( 74.40)	Acc@5  87.50 ( 88.24)
 * Acc@1 72.313 Acc@5 87.845
Epoch: [64][  0/109]	Time  3.840 ( 3.840)	Data  3.381 ( 3.381)	Loss 0.4518360197544098 (0.4518360197544098)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [64][ 10/109]	Time  0.375 ( 0.714)	Data  0.000 ( 0.308)	Loss 0.4082277417182922 (0.2817098403518850)	Acc@1  89.06 ( 92.76)	Acc@5  96.88 ( 97.73)
Epoch: [64][ 20/109]	Time  0.369 ( 0.566)	Data  0.000 ( 0.161)	Loss 0.1863340735435486 (0.2657267891225361)	Acc@1  95.31 ( 93.08)	Acc@5  98.44 ( 97.77)
Epoch: [64][ 30/109]	Time  0.461 ( 0.512)	Data  0.000 ( 0.109)	Loss 0.0808870270848274 (0.2447625588505499)	Acc@1  98.44 ( 93.30)	Acc@5 100.00 ( 98.19)
Epoch: [64][ 40/109]	Time  0.426 ( 0.483)	Data  0.000 ( 0.083)	Loss 0.1302901059389114 (0.2476221283034581)	Acc@1  95.31 ( 93.25)	Acc@5 100.00 ( 98.02)
Epoch: [64][ 50/109]	Time  0.454 ( 0.468)	Data  0.000 ( 0.067)	Loss 0.2953817546367645 (0.2435894620184805)	Acc@1  93.75 ( 93.35)	Acc@5  98.44 ( 98.16)
Epoch: [64][ 60/109]	Time  0.404 ( 0.455)	Data  0.000 ( 0.056)	Loss 0.2599063217639923 (0.2414372581683221)	Acc@1  92.19 ( 93.49)	Acc@5  98.44 ( 98.10)
Epoch: [64][ 70/109]	Time  0.384 ( 0.447)	Data  0.000 ( 0.048)	Loss 0.1621091812849045 (0.2414369781462239)	Acc@1  98.44 ( 93.60)	Acc@5 100.00 ( 98.11)
Epoch: [64][ 80/109]	Time  0.454 ( 0.441)	Data  0.000 ( 0.042)	Loss 0.2315603196620941 (0.2339856771775234)	Acc@1  93.75 ( 93.73)	Acc@5  96.88 ( 98.24)
Epoch: [64][ 90/109]	Time  0.371 ( 0.436)	Data  0.000 ( 0.037)	Loss 0.2236558645963669 (0.2349602670132459)	Acc@1  93.75 ( 93.80)	Acc@5  96.88 ( 98.21)
Epoch: [64][100/109]	Time  0.382 ( 0.431)	Data  0.000 ( 0.034)	Loss 0.0941334515810013 (0.2382330502023791)	Acc@1  96.88 ( 93.69)	Acc@5 100.00 ( 98.16)
epoch: 64, Avg_Loss 0.2361869210496955
Test: [ 0/28]	Time  3.729 ( 3.729)	Loss 1.2236e+00 (1.2236e+00)	Acc@1  68.75 ( 68.75)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.088 ( 0.544)	Loss 1.6240e+00 (6.6534e-01)	Acc@1  68.75 ( 85.09)	Acc@5  81.25 ( 93.61)
Test: [20/28]	Time  0.088 ( 0.385)	Loss 9.9597e-01 (1.0866e+00)	Acc@1  73.44 ( 75.37)	Acc@5  92.19 ( 89.81)
 * Acc@1 73.213 Acc@5 88.295
Epoch: [65][  0/109]	Time  3.410 ( 3.410)	Data  2.890 ( 2.890)	Loss 0.1067377850413322 (0.1067377850413322)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [65][ 10/109]	Time  0.500 ( 0.738)	Data  0.000 ( 0.277)	Loss 0.2146472632884979 (0.2133708223700523)	Acc@1  95.31 ( 94.03)	Acc@5  98.44 ( 98.58)
Epoch: [65][ 20/109]	Time  0.405 ( 0.582)	Data  0.000 ( 0.145)	Loss 0.0943115651607513 (0.1961821977581297)	Acc@1  95.31 ( 94.79)	Acc@5 100.00 ( 98.59)
Epoch: [65][ 30/109]	Time  0.378 ( 0.559)	Data  0.000 ( 0.098)	Loss 0.1791049689054489 (0.2079323879893749)	Acc@1  92.19 ( 94.41)	Acc@5 100.00 ( 98.59)
Epoch: [65][ 40/109]	Time  0.429 ( 0.524)	Data  0.000 ( 0.074)	Loss 0.1489500105381012 (0.2187508052987296)	Acc@1  98.44 ( 94.05)	Acc@5 100.00 ( 98.40)
Epoch: [65][ 50/109]	Time  0.404 ( 0.508)	Data  0.000 ( 0.060)	Loss 0.1433912664651871 (0.2210665357609590)	Acc@1  96.88 ( 94.09)	Acc@5 100.00 ( 98.31)
Epoch: [65][ 60/109]	Time  0.381 ( 0.495)	Data  0.000 ( 0.050)	Loss 0.2348012626171112 (0.2219688263950778)	Acc@1  93.75 ( 94.08)	Acc@5  96.88 ( 98.34)
Epoch: [65][ 70/109]	Time  0.402 ( 0.485)	Data  0.000 ( 0.043)	Loss 0.2223801612854004 (0.2211850381548136)	Acc@1  93.75 ( 94.06)	Acc@5  98.44 ( 98.35)
Epoch: [65][ 80/109]	Time  0.398 ( 0.475)	Data  0.000 ( 0.038)	Loss 0.1527063846588135 (0.2204010333451960)	Acc@1  96.88 ( 94.10)	Acc@5  98.44 ( 98.30)
Epoch: [65][ 90/109]	Time  0.379 ( 0.468)	Data  0.000 ( 0.034)	Loss 0.0873396545648575 (0.2189964073618035)	Acc@1  98.44 ( 94.13)	Acc@5 100.00 ( 98.35)
Epoch: [65][100/109]	Time  0.366 ( 0.461)	Data  0.000 ( 0.030)	Loss 0.2576433718204498 (0.2167117036141381)	Acc@1  92.19 ( 94.18)	Acc@5 100.00 ( 98.38)
epoch: 65, Avg_Loss 0.21490327169725654
Test: [ 0/28]	Time  3.435 ( 3.435)	Loss 1.0861e+00 (1.0861e+00)	Acc@1  71.88 ( 71.88)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.096 ( 0.524)	Loss 1.6294e+00 (6.8321e-01)	Acc@1  68.75 ( 85.23)	Acc@5  82.81 ( 93.18)
Test: [20/28]	Time  0.106 ( 0.382)	Loss 1.1073e+00 (1.1002e+00)	Acc@1  75.00 ( 74.18)	Acc@5  90.62 ( 89.51)
 * Acc@1 72.032 Acc@5 87.507
Epoch: [66][  0/109]	Time  4.238 ( 4.238)	Data  3.828 ( 3.828)	Loss 0.1510444432497025 (0.1510444432497025)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [66][ 10/109]	Time  0.520 ( 0.792)	Data  0.000 ( 0.348)	Loss 0.0847574248909950 (0.1708523509177295)	Acc@1 100.00 ( 95.88)	Acc@5 100.00 ( 99.01)
Epoch: [66][ 20/109]	Time  0.438 ( 0.605)	Data  0.000 ( 0.183)	Loss 0.2761715948581696 (0.1898485603077071)	Acc@1  93.75 ( 95.09)	Acc@5  98.44 ( 98.59)
Epoch: [66][ 30/109]	Time  0.363 ( 0.536)	Data  0.000 ( 0.124)	Loss 0.2779753208160400 (0.2022110596299171)	Acc@1  95.31 ( 94.91)	Acc@5  96.88 ( 98.44)
Epoch: [66][ 40/109]	Time  0.373 ( 0.504)	Data  0.000 ( 0.094)	Loss 0.3580924272537231 (0.2122661776658965)	Acc@1  92.19 ( 94.70)	Acc@5  98.44 ( 98.44)
Epoch: [66][ 50/109]	Time  0.401 ( 0.483)	Data  0.000 ( 0.075)	Loss 0.1470464468002319 (0.2095242871665487)	Acc@1  98.44 ( 94.82)	Acc@5  98.44 ( 98.44)
Epoch: [66][ 60/109]	Time  0.381 ( 0.477)	Data  0.000 ( 0.063)	Loss 0.1799890100955963 (0.2180847426662680)	Acc@1  95.31 ( 94.62)	Acc@5  98.44 ( 98.26)
Epoch: [66][ 70/109]	Time  0.419 ( 0.467)	Data  0.000 ( 0.054)	Loss 0.2668321132659912 (0.2184752827169190)	Acc@1  92.19 ( 94.61)	Acc@5 100.00 ( 98.24)
Epoch: [66][ 80/109]	Time  0.363 ( 0.456)	Data  0.000 ( 0.047)	Loss 0.1611550301313400 (0.2237379123215322)	Acc@1  98.44 ( 94.54)	Acc@5 100.00 ( 98.19)
Epoch: [66][ 90/109]	Time  0.432 ( 0.450)	Data  0.000 ( 0.042)	Loss 0.2708577513694763 (0.2193588135497911)	Acc@1  93.75 ( 94.61)	Acc@5 100.00 ( 98.32)
Epoch: [66][100/109]	Time  0.384 ( 0.445)	Data  0.000 ( 0.038)	Loss 0.4899229407310486 (0.2198470908005049)	Acc@1  87.50 ( 94.51)	Acc@5  93.75 ( 98.31)
epoch: 66, Avg_Loss 0.22437286394041614
Test: [ 0/28]	Time  4.064 ( 4.064)	Loss 1.3117e+00 (1.3117e+00)	Acc@1  75.00 ( 75.00)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.093 ( 0.574)	Loss 1.5782e+00 (7.1510e-01)	Acc@1  68.75 ( 85.65)	Acc@5  82.81 ( 92.90)
Test: [20/28]	Time  0.088 ( 0.428)	Loss 1.4068e+00 (1.0461e+00)	Acc@1  68.75 ( 76.12)	Acc@5  90.62 ( 89.88)
 * Acc@1 73.720 Acc@5 88.407
Epoch: [67][  0/109]	Time  3.368 ( 3.368)	Data  2.905 ( 2.905)	Loss 0.1483753621578217 (0.1483753621578217)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [67][ 10/109]	Time  0.416 ( 0.731)	Data  0.000 ( 0.288)	Loss 0.2165658324956894 (0.1473424786871130)	Acc@1  90.62 ( 96.59)	Acc@5 100.00 ( 99.29)
Epoch: [67][ 20/109]	Time  0.391 ( 0.575)	Data  0.000 ( 0.151)	Loss 0.1103408560156822 (0.1897167457001550)	Acc@1  98.44 ( 95.39)	Acc@5  98.44 ( 98.44)
Epoch: [67][ 30/109]	Time  0.387 ( 0.516)	Data  0.000 ( 0.102)	Loss 0.3155832886695862 (0.2000890258819826)	Acc@1  92.19 ( 95.06)	Acc@5  96.88 ( 98.44)
Epoch: [67][ 40/109]	Time  0.369 ( 0.486)	Data  0.000 ( 0.077)	Loss 0.0822480544447899 (0.1930148892286347)	Acc@1 100.00 ( 95.46)	Acc@5 100.00 ( 98.40)
Epoch: [67][ 50/109]	Time  0.406 ( 0.472)	Data  0.000 ( 0.062)	Loss 0.1451439261436462 (0.1897656233871684)	Acc@1  95.31 ( 95.37)	Acc@5  98.44 ( 98.53)
Epoch: [67][ 60/109]	Time  0.477 ( 0.462)	Data  0.000 ( 0.052)	Loss 0.5872368216514587 (0.1936614570803330)	Acc@1  85.94 ( 95.34)	Acc@5  92.19 ( 98.44)
Epoch: [67][ 70/109]	Time  0.384 ( 0.459)	Data  0.000 ( 0.045)	Loss 0.2396813929080963 (0.1971392972578465)	Acc@1  93.75 ( 95.18)	Acc@5  98.44 ( 98.44)
Epoch: [67][ 80/109]	Time  0.565 ( 0.460)	Data  0.000 ( 0.039)	Loss 0.1528460830450058 (0.2006234966310454)	Acc@1  95.31 ( 95.16)	Acc@5 100.00 ( 98.42)
Epoch: [67][ 90/109]	Time  0.367 ( 0.455)	Data  0.000 ( 0.035)	Loss 0.1861004531383514 (0.2011242631700013)	Acc@1  96.88 ( 95.19)	Acc@5  98.44 ( 98.47)
Epoch: [67][100/109]	Time  0.367 ( 0.448)	Data  0.000 ( 0.032)	Loss 0.2473095953464508 (0.2007473553023716)	Acc@1  92.19 ( 95.13)	Acc@5  98.44 ( 98.47)
epoch: 67, Avg_Loss 0.19747942105072355
Test: [ 0/28]	Time  2.843 ( 2.843)	Loss 1.6491e+00 (1.6491e+00)	Acc@1  60.94 ( 60.94)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.089 ( 0.521)	Loss 1.6447e+00 (7.9728e-01)	Acc@1  64.06 ( 83.24)	Acc@5  82.81 ( 92.47)
Test: [20/28]	Time  0.090 ( 0.372)	Loss 1.1508e+00 (1.0774e+00)	Acc@1  73.44 ( 76.56)	Acc@5  87.50 ( 89.73)
 * Acc@1 74.395 Acc@5 88.351
Epoch: [68][  0/109]	Time  4.089 ( 4.089)	Data  3.705 ( 3.705)	Loss 0.2867101728916168 (0.2867101728916168)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [68][ 10/109]	Time  0.382 ( 0.755)	Data  0.000 ( 0.337)	Loss 0.2582494914531708 (0.2273163700645620)	Acc@1  93.75 ( 94.32)	Acc@5  96.88 ( 98.30)
Epoch: [68][ 20/109]	Time  0.453 ( 0.591)	Data  0.000 ( 0.177)	Loss 0.0586357451975346 (0.2032606791527498)	Acc@1  98.44 ( 94.49)	Acc@5 100.00 ( 98.59)
Epoch: [68][ 30/109]	Time  0.589 ( 0.592)	Data  0.001 ( 0.120)	Loss 0.1770250946283340 (0.1947330355403885)	Acc@1  95.31 ( 94.76)	Acc@5  98.44 ( 98.54)
Epoch: [68][ 40/109]	Time  0.702 ( 0.583)	Data  0.001 ( 0.091)	Loss 0.2148958891630173 (0.1923629011867977)	Acc@1  96.88 ( 94.97)	Acc@5  96.88 ( 98.51)
Epoch: [68][ 50/109]	Time  0.372 ( 0.557)	Data  0.000 ( 0.073)	Loss 0.1826321482658386 (0.2085780751909695)	Acc@1  93.75 ( 94.61)	Acc@5 100.00 ( 98.31)
Epoch: [68][ 60/109]	Time  0.383 ( 0.534)	Data  0.000 ( 0.061)	Loss 0.1796224713325500 (0.2018941425275607)	Acc@1  95.31 ( 94.83)	Acc@5 100.00 ( 98.39)
Epoch: [68][ 70/109]	Time  0.373 ( 0.513)	Data  0.000 ( 0.053)	Loss 0.1925971955060959 (0.1976736194755830)	Acc@1  96.88 ( 95.00)	Acc@5  98.44 ( 98.44)
Epoch: [68][ 80/109]	Time  0.375 ( 0.498)	Data  0.000 ( 0.046)	Loss 0.2608211338520050 (0.1941331932666125)	Acc@1  93.75 ( 95.10)	Acc@5  93.75 ( 98.46)
Epoch: [68][ 90/109]	Time  0.422 ( 0.488)	Data  0.000 ( 0.041)	Loss 0.2481753826141357 (0.1981512194724528)	Acc@1  93.75 ( 95.04)	Acc@5  96.88 ( 98.35)
Epoch: [68][100/109]	Time  0.366 ( 0.478)	Data  0.000 ( 0.037)	Loss 0.6196752786636353 (0.2012999528410411)	Acc@1  82.81 ( 94.97)	Acc@5  92.19 ( 98.30)
epoch: 68, Avg_Loss 0.20080593857196494
Test: [ 0/28]	Time  3.424 ( 3.424)	Loss 1.3241e+00 (1.3241e+00)	Acc@1  67.19 ( 67.19)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.088 ( 0.550)	Loss 1.7175e+00 (6.9670e-01)	Acc@1  64.06 ( 83.66)	Acc@5  79.69 ( 92.90)
Test: [20/28]	Time  0.103 ( 0.400)	Loss 8.3117e-01 (1.0394e+00)	Acc@1  78.12 ( 74.85)	Acc@5  93.75 ( 89.36)
 * Acc@1 72.088 Acc@5 88.858
Epoch: [69][  0/109]	Time  4.349 ( 4.349)	Data  3.805 ( 3.805)	Loss 0.1118991300463676 (0.1118991300463676)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [69][ 10/109]	Time  0.391 ( 0.807)	Data  0.000 ( 0.346)	Loss 0.0756262987852097 (0.1592636359008876)	Acc@1  96.88 ( 95.88)	Acc@5 100.00 ( 98.86)
Epoch: [69][ 20/109]	Time  0.372 ( 0.622)	Data  0.000 ( 0.181)	Loss 0.0298349745571613 (0.1611391128528686)	Acc@1 100.00 ( 95.68)	Acc@5 100.00 ( 99.03)
Epoch: [69][ 30/109]	Time  0.462 ( 0.551)	Data  0.000 ( 0.123)	Loss 0.2129236459732056 (0.1861239885610919)	Acc@1  92.19 ( 95.06)	Acc@5  98.44 ( 98.79)
Epoch: [69][ 40/109]	Time  0.377 ( 0.513)	Data  0.000 ( 0.093)	Loss 0.1476894170045853 (0.1771630417646431)	Acc@1  96.88 ( 95.16)	Acc@5  98.44 ( 98.89)
Epoch: [69][ 50/109]	Time  0.389 ( 0.490)	Data  0.000 ( 0.075)	Loss 0.0976229757070541 (0.1805411675835357)	Acc@1  96.88 ( 95.16)	Acc@5 100.00 ( 98.81)
Epoch: [69][ 60/109]	Time  0.421 ( 0.477)	Data  0.000 ( 0.063)	Loss 0.2464901953935623 (0.1851731050820624)	Acc@1  93.75 ( 95.11)	Acc@5  96.88 ( 98.69)
Epoch: [69][ 70/109]	Time  0.368 ( 0.467)	Data  0.000 ( 0.054)	Loss 0.0576273985207081 (0.1823106642130395)	Acc@1  98.44 ( 95.14)	Acc@5 100.00 ( 98.72)
Epoch: [69][ 80/109]	Time  0.387 ( 0.461)	Data  0.000 ( 0.047)	Loss 0.1366087496280670 (0.1824175445017991)	Acc@1  95.31 ( 95.20)	Acc@5 100.00 ( 98.69)
Epoch: [69][ 90/109]	Time  0.369 ( 0.455)	Data  0.000 ( 0.042)	Loss 0.1570235788822174 (0.1805553375282785)	Acc@1  93.75 ( 95.28)	Acc@5 100.00 ( 98.76)
Epoch: [69][100/109]	Time  0.381 ( 0.447)	Data  0.000 ( 0.038)	Loss 0.1244718432426453 (0.1832334482950149)	Acc@1  95.31 ( 95.20)	Acc@5 100.00 ( 98.72)
epoch: 69, Avg_Loss 0.18553507639043923
Test: [ 0/28]	Time  4.000 ( 4.000)	Loss 1.6331e+00 (1.6331e+00)	Acc@1  60.94 ( 60.94)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.122 ( 0.543)	Loss 1.2773e+00 (7.3134e-01)	Acc@1  71.88 ( 84.23)	Acc@5  87.50 ( 93.32)
Test: [20/28]	Time  0.093 ( 0.389)	Loss 8.0881e-01 (1.0201e+00)	Acc@1  78.12 ( 76.86)	Acc@5  93.75 ( 90.10)
 * Acc@1 74.902 Acc@5 88.970
Epoch: [70][  0/109]	Time  3.646 ( 3.646)	Data  3.190 ( 3.190)	Loss 0.2520091235637665 (0.2520091235637665)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [70][ 10/109]	Time  0.411 ( 0.714)	Data  0.000 ( 0.290)	Loss 0.2181202769279480 (0.1798948422074318)	Acc@1  93.75 ( 94.74)	Acc@5  98.44 ( 98.44)
Epoch: [70][ 20/109]	Time  0.516 ( 0.597)	Data  0.000 ( 0.152)	Loss 0.0837050005793571 (0.1838315987870807)	Acc@1  98.44 ( 95.09)	Acc@5 100.00 ( 98.36)
Epoch: [70][ 30/109]	Time  0.441 ( 0.535)	Data  0.000 ( 0.103)	Loss 0.2221076786518097 (0.1938274632538519)	Acc@1  93.75 ( 94.76)	Acc@5  96.88 ( 98.24)
Epoch: [70][ 40/109]	Time  0.381 ( 0.503)	Data  0.000 ( 0.078)	Loss 0.1576479673385620 (0.1826474310421362)	Acc@1  96.88 ( 95.12)	Acc@5  98.44 ( 98.55)
Epoch: [70][ 50/109]	Time  0.400 ( 0.483)	Data  0.000 ( 0.063)	Loss 0.1842012256383896 (0.1832709851510385)	Acc@1  95.31 ( 95.22)	Acc@5 100.00 ( 98.59)
Epoch: [70][ 60/109]	Time  0.372 ( 0.473)	Data  0.000 ( 0.053)	Loss 0.0997102558612823 (0.1878102490159332)	Acc@1  96.88 ( 95.03)	Acc@5 100.00 ( 98.57)
Epoch: [70][ 70/109]	Time  0.454 ( 0.467)	Data  0.000 ( 0.045)	Loss 0.1805191785097122 (0.1816636839173210)	Acc@1  96.88 ( 95.20)	Acc@5  98.44 ( 98.66)
Epoch: [70][ 80/109]	Time  0.376 ( 0.461)	Data  0.000 ( 0.040)	Loss 0.1228429228067398 (0.1795595177897701)	Acc@1  95.31 ( 95.20)	Acc@5 100.00 ( 98.69)
Epoch: [70][ 90/109]	Time  0.361 ( 0.455)	Data  0.000 ( 0.035)	Loss 0.1802826374769211 (0.1800912101190169)	Acc@1  93.75 ( 95.23)	Acc@5  98.44 ( 98.63)
Epoch: [70][100/109]	Time  0.382 ( 0.449)	Data  0.000 ( 0.032)	Loss 0.3391431868076324 (0.1815033896577240)	Acc@1  92.19 ( 95.22)	Acc@5  98.44 ( 98.58)
epoch: 70, Avg_Loss 0.17939192453108796
Test: [ 0/28]	Time  3.517 ( 3.517)	Loss 1.6067e+00 (1.6067e+00)	Acc@1  54.69 ( 54.69)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.088 ( 0.564)	Loss 1.6991e+00 (7.5204e-01)	Acc@1  64.06 ( 82.95)	Acc@5  79.69 ( 93.32)
Test: [20/28]	Time  0.093 ( 0.404)	Loss 1.0311e+00 (1.1003e+00)	Acc@1  67.19 ( 73.51)	Acc@5  90.62 ( 89.66)
 * Acc@1 72.538 Acc@5 89.083
Epoch: [71][  0/109]	Time  3.643 ( 3.643)	Data  3.200 ( 3.200)	Loss 0.1719855815172195 (0.1719855815172195)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [71][ 10/109]	Time  0.434 ( 0.712)	Data  0.000 ( 0.291)	Loss 0.1737527102231979 (0.1680492447181181)	Acc@1  98.44 ( 95.60)	Acc@5 100.00 ( 99.01)
Epoch: [71][ 20/109]	Time  0.368 ( 0.557)	Data  0.000 ( 0.153)	Loss 0.2691749930381775 (0.1645118163100311)	Acc@1  93.75 ( 95.83)	Acc@5  98.44 ( 98.88)
Epoch: [71][ 30/109]	Time  0.421 ( 0.517)	Data  0.000 ( 0.103)	Loss 0.1418276578187943 (0.1740849384617421)	Acc@1  93.75 ( 95.51)	Acc@5 100.00 ( 98.69)
Epoch: [71][ 40/109]	Time  0.381 ( 0.495)	Data  0.000 ( 0.078)	Loss 0.4609634280204773 (0.1814171991697172)	Acc@1  89.06 ( 95.46)	Acc@5  92.19 ( 98.51)
Epoch: [71][ 50/109]	Time  0.522 ( 0.490)	Data  0.000 ( 0.063)	Loss 0.2899910211563110 (0.1954855222035857)	Acc@1  89.06 ( 95.22)	Acc@5  96.88 ( 98.31)
Epoch: [71][ 60/109]	Time  0.368 ( 0.476)	Data  0.000 ( 0.053)	Loss 0.1961259990930557 (0.1871281584999600)	Acc@1  93.75 ( 95.49)	Acc@5  98.44 ( 98.39)
Epoch: [71][ 70/109]	Time  0.462 ( 0.465)	Data  0.000 ( 0.045)	Loss 0.0944182425737381 (0.1803055206235026)	Acc@1  98.44 ( 95.69)	Acc@5  98.44 ( 98.46)
Epoch: [71][ 80/109]	Time  0.423 ( 0.459)	Data  0.000 ( 0.040)	Loss 0.0796144083142281 (0.1822648956267922)	Acc@1  96.88 ( 95.58)	Acc@5 100.00 ( 98.46)
Epoch: [71][ 90/109]	Time  0.371 ( 0.454)	Data  0.000 ( 0.035)	Loss 0.2311191707849503 (0.1803753502093829)	Acc@1  93.75 ( 95.62)	Acc@5  96.88 ( 98.52)
Epoch: [71][100/109]	Time  0.368 ( 0.447)	Data  0.000 ( 0.032)	Loss 0.2257599383592606 (0.1833208373720103)	Acc@1  95.31 ( 95.59)	Acc@5  98.44 ( 98.48)
epoch: 71, Avg_Loss 0.18043515752625028
Test: [ 0/28]	Time  3.050 ( 3.050)	Loss 1.4250e+00 (1.4250e+00)	Acc@1  65.62 ( 65.62)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.088 ( 0.567)	Loss 1.4820e+00 (7.7703e-01)	Acc@1  70.31 ( 84.09)	Acc@5  84.38 ( 91.90)
Test: [20/28]	Time  0.089 ( 0.417)	Loss 9.1816e-01 (1.0502e+00)	Acc@1  73.44 ( 75.60)	Acc@5  90.62 ( 89.73)
 * Acc@1 73.213 Acc@5 88.914
Epoch: [72][  0/109]	Time  3.534 ( 3.534)	Data  3.088 ( 3.088)	Loss 0.0975901633501053 (0.0975901633501053)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [72][ 10/109]	Time  0.354 ( 0.686)	Data  0.000 ( 0.290)	Loss 0.1547558009624481 (0.1066248342394829)	Acc@1  93.75 ( 98.01)	Acc@5 100.00 ( 99.72)
Epoch: [72][ 20/109]	Time  0.413 ( 0.551)	Data  0.000 ( 0.152)	Loss 0.1107785180211067 (0.1230621281124297)	Acc@1  95.31 ( 96.95)	Acc@5 100.00 ( 99.11)
Epoch: [72][ 30/109]	Time  0.448 ( 0.501)	Data  0.000 ( 0.103)	Loss 0.2235531359910965 (0.1292158300357480)	Acc@1  96.88 ( 96.93)	Acc@5  98.44 ( 99.09)
Epoch: [72][ 40/109]	Time  0.371 ( 0.480)	Data  0.000 ( 0.078)	Loss 0.1163800731301308 (0.1442654743427184)	Acc@1  96.88 ( 96.57)	Acc@5 100.00 ( 98.86)
Epoch: [72][ 50/109]	Time  0.376 ( 0.465)	Data  0.000 ( 0.063)	Loss 0.1202978566288948 (0.1417167992422394)	Acc@1  98.44 ( 96.60)	Acc@5  98.44 ( 98.93)
Epoch: [72][ 60/109]	Time  0.369 ( 0.453)	Data  0.000 ( 0.053)	Loss 0.0825422555208206 (0.1448124276443583)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 98.85)
Epoch: [72][ 70/109]	Time  0.380 ( 0.446)	Data  0.000 ( 0.045)	Loss 0.2403013408184052 (0.1491616259683186)	Acc@1  95.31 ( 96.41)	Acc@5  98.44 ( 98.86)
Epoch: [72][ 80/109]	Time  0.362 ( 0.442)	Data  0.000 ( 0.040)	Loss 0.2798902690410614 (0.1532678177787198)	Acc@1  95.31 ( 96.26)	Acc@5  95.31 ( 98.77)
Epoch: [72][ 90/109]	Time  0.447 ( 0.452)	Data  0.000 ( 0.035)	Loss 0.0720252320170403 (0.1566240516092096)	Acc@1 100.00 ( 96.21)	Acc@5 100.00 ( 98.78)
Epoch: [72][100/109]	Time  0.402 ( 0.448)	Data  0.000 ( 0.032)	Loss 0.1334271281957626 (0.1571040378865039)	Acc@1  96.88 ( 96.23)	Acc@5 100.00 ( 98.79)
epoch: 72, Avg_Loss 0.15938788549889119
Test: [ 0/28]	Time  3.558 ( 3.558)	Loss 1.3899e+00 (1.3899e+00)	Acc@1  65.62 ( 65.62)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.135 ( 0.482)	Loss 1.5140e+00 (7.0801e-01)	Acc@1  65.62 ( 84.23)	Acc@5  84.38 ( 94.03)
Test: [20/28]	Time  0.087 ( 0.374)	Loss 1.1708e+00 (1.0688e+00)	Acc@1  68.75 ( 74.55)	Acc@5  89.06 ( 90.25)
 * Acc@1 73.495 Acc@5 89.195
Epoch: [73][  0/109]	Time  4.028 ( 4.028)	Data  3.642 ( 3.642)	Loss 0.0638427436351776 (0.0638427436351776)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [73][ 10/109]	Time  0.454 ( 0.745)	Data  0.000 ( 0.331)	Loss 0.2712630033493042 (0.1794467155228961)	Acc@1  92.19 ( 95.31)	Acc@5  98.44 ( 98.58)
Epoch: [73][ 20/109]	Time  0.392 ( 0.591)	Data  0.000 ( 0.174)	Loss 0.2365379482507706 (0.1820055326180799)	Acc@1  96.88 ( 95.46)	Acc@5  96.88 ( 98.66)
Epoch: [73][ 30/109]	Time  0.504 ( 0.542)	Data  0.000 ( 0.118)	Loss 0.1260699033737183 (0.1761441031290639)	Acc@1  96.88 ( 95.77)	Acc@5 100.00 ( 98.64)
Epoch: [73][ 40/109]	Time  0.457 ( 0.521)	Data  0.000 ( 0.089)	Loss 0.2786917388439178 (0.1633264367445940)	Acc@1  92.19 ( 96.07)	Acc@5  96.88 ( 98.78)
Epoch: [73][ 50/109]	Time  0.376 ( 0.502)	Data  0.000 ( 0.072)	Loss 0.2724461555480957 (0.1683825436687353)	Acc@1  95.31 ( 95.93)	Acc@5  96.88 ( 98.71)
Epoch: [73][ 60/109]	Time  0.501 ( 0.491)	Data  0.000 ( 0.060)	Loss 0.3857760429382324 (0.1782953615498836)	Acc@1  90.62 ( 95.57)	Acc@5  95.31 ( 98.51)
Epoch: [73][ 70/109]	Time  0.384 ( 0.479)	Data  0.000 ( 0.052)	Loss 0.2210415303707123 (0.1759611561002446)	Acc@1  95.31 ( 95.60)	Acc@5  96.88 ( 98.57)
Epoch: [73][ 80/109]	Time  0.371 ( 0.471)	Data  0.000 ( 0.045)	Loss 0.1214824393391609 (0.1804559310599242)	Acc@1  98.44 ( 95.49)	Acc@5 100.00 ( 98.51)
Epoch: [73][ 90/109]	Time  0.438 ( 0.466)	Data  0.000 ( 0.040)	Loss 0.1007170379161835 (0.1758350134100560)	Acc@1  98.44 ( 95.60)	Acc@5  98.44 ( 98.56)
Epoch: [73][100/109]	Time  0.368 ( 0.458)	Data  0.000 ( 0.036)	Loss 0.2664615809917450 (0.1761404578159056)	Acc@1  90.62 ( 95.64)	Acc@5  96.88 ( 98.50)
epoch: 73, Avg_Loss 0.1749658794954009
Test: [ 0/28]	Time  3.034 ( 3.034)	Loss 1.4523e+00 (1.4523e+00)	Acc@1  64.06 ( 64.06)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.259 ( 0.604)	Loss 1.4144e+00 (7.0386e-01)	Acc@1  70.31 ( 85.80)	Acc@5  82.81 ( 92.90)
Test: [20/28]	Time  0.099 ( 0.418)	Loss 1.1449e+00 (1.0223e+00)	Acc@1  75.00 ( 76.93)	Acc@5  90.62 ( 89.96)
 * Acc@1 75.521 Acc@5 89.026
Epoch: [74][  0/109]	Time  4.071 ( 4.071)	Data  3.674 ( 3.674)	Loss 0.0630498826503754 (0.0630498826503754)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [74][ 10/109]	Time  0.365 ( 0.749)	Data  0.000 ( 0.334)	Loss 0.1162648871541023 (0.1513923257589340)	Acc@1  96.88 ( 96.02)	Acc@5  98.44 ( 98.86)
Epoch: [74][ 20/109]	Time  0.425 ( 0.609)	Data  0.000 ( 0.175)	Loss 0.0241972375661135 (0.1631523933971212)	Acc@1 100.00 ( 95.98)	Acc@5 100.00 ( 98.81)
Epoch: [74][ 30/109]	Time  0.425 ( 0.556)	Data  0.000 ( 0.119)	Loss 0.1121429353952408 (0.1735635161279671)	Acc@1  95.31 ( 95.46)	Acc@5 100.00 ( 98.74)
Epoch: [74][ 40/109]	Time  0.423 ( 0.518)	Data  0.000 ( 0.090)	Loss 0.2062937915325165 (0.1720127277530548)	Acc@1  93.75 ( 95.54)	Acc@5  98.44 ( 98.78)
Epoch: [74][ 50/109]	Time  0.372 ( 0.497)	Data  0.000 ( 0.072)	Loss 0.2215468436479568 (0.1819909905613053)	Acc@1  93.75 ( 95.31)	Acc@5  98.44 ( 98.62)
Epoch: [74][ 60/109]	Time  0.374 ( 0.481)	Data  0.000 ( 0.060)	Loss 0.3276150226593018 (0.1825511520575793)	Acc@1  92.19 ( 95.34)	Acc@5  96.88 ( 98.59)
Epoch: [74][ 70/109]	Time  0.434 ( 0.471)	Data  0.000 ( 0.052)	Loss 0.1145277097821236 (0.1857408671574274)	Acc@1  96.88 ( 95.18)	Acc@5 100.00 ( 98.64)
Epoch: [74][ 80/109]	Time  0.381 ( 0.466)	Data  0.000 ( 0.046)	Loss 0.1095037311315536 (0.1821309559185196)	Acc@1  98.44 ( 95.29)	Acc@5 100.00 ( 98.63)
Epoch: [74][ 90/109]	Time  0.428 ( 0.459)	Data  0.000 ( 0.041)	Loss 0.1825627535581589 (0.1809612487412089)	Acc@1  96.88 ( 95.38)	Acc@5  98.44 ( 98.59)
Epoch: [74][100/109]	Time  0.369 ( 0.452)	Data  0.000 ( 0.037)	Loss 0.1162838041782379 (0.1803059046258136)	Acc@1  98.44 ( 95.50)	Acc@5 100.00 ( 98.59)
epoch: 74, Avg_Loss 0.1882619013787683
Test: [ 0/28]	Time  3.557 ( 3.557)	Loss 1.5925e+00 (1.5925e+00)	Acc@1  59.38 ( 59.38)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.091 ( 0.536)	Loss 1.5450e+00 (7.6292e-01)	Acc@1  67.19 ( 83.81)	Acc@5  81.25 ( 92.90)
Test: [20/28]	Time  0.092 ( 0.401)	Loss 1.1162e+00 (1.0720e+00)	Acc@1  75.00 ( 75.22)	Acc@5  85.94 ( 89.66)
 * Acc@1 74.339 Acc@5 88.801
Epoch: [75][  0/109]	Time  4.146 ( 4.146)	Data  3.741 ( 3.741)	Loss 0.0461623817682266 (0.0461623817682266)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [75][ 10/109]	Time  0.391 ( 0.751)	Data  0.000 ( 0.340)	Loss 0.1011581569910049 (0.1399263360283592)	Acc@1 100.00 ( 96.88)	Acc@5 100.00 ( 99.01)
Epoch: [75][ 20/109]	Time  0.548 ( 0.611)	Data  0.000 ( 0.178)	Loss 0.2260959148406982 (0.1602153826859735)	Acc@1  92.19 ( 95.98)	Acc@5  98.44 ( 98.81)
Epoch: [75][ 30/109]	Time  0.458 ( 0.573)	Data  0.000 ( 0.121)	Loss 0.1445225924253464 (0.1541002333284386)	Acc@1  98.44 ( 96.12)	Acc@5 100.00 ( 98.99)
Epoch: [75][ 40/109]	Time  0.395 ( 0.532)	Data  0.000 ( 0.091)	Loss 0.1232170984148979 (0.1556068633842032)	Acc@1  95.31 ( 95.88)	Acc@5  98.44 ( 99.09)
Epoch: [75][ 50/109]	Time  0.367 ( 0.508)	Data  0.000 ( 0.074)	Loss 0.1544758379459381 (0.1585747450224909)	Acc@1  95.31 ( 95.77)	Acc@5 100.00 ( 98.93)
Epoch: [75][ 60/109]	Time  0.411 ( 0.493)	Data  0.000 ( 0.062)	Loss 0.1702794581651688 (0.1605940827886101)	Acc@1  95.31 ( 95.65)	Acc@5 100.00 ( 98.90)
Epoch: [75][ 70/109]	Time  0.451 ( 0.480)	Data  0.000 ( 0.053)	Loss 0.2575469017028809 (0.1614182363461021)	Acc@1  93.75 ( 95.64)	Acc@5  96.88 ( 98.83)
Epoch: [75][ 80/109]	Time  0.533 ( 0.473)	Data  0.000 ( 0.046)	Loss 0.0681522265076637 (0.1625450541161829)	Acc@1  98.44 ( 95.72)	Acc@5 100.00 ( 98.75)
Epoch: [75][ 90/109]	Time  0.398 ( 0.468)	Data  0.000 ( 0.041)	Loss 0.1127093806862831 (0.1602418382375777)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 98.78)
Epoch: [75][100/109]	Time  0.380 ( 0.462)	Data  0.000 ( 0.037)	Loss 0.0892201811075211 (0.1584694459112269)	Acc@1  98.44 ( 95.92)	Acc@5 100.00 ( 98.82)
epoch: 75, Avg_Loss 0.16099477147495528
Test: [ 0/28]	Time  3.184 ( 3.184)	Loss 1.6587e+00 (1.6587e+00)	Acc@1  59.38 ( 59.38)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.141 ( 0.525)	Loss 1.6517e+00 (7.3097e-01)	Acc@1  67.19 ( 84.80)	Acc@5  85.94 ( 93.04)
Test: [20/28]	Time  0.160 ( 0.391)	Loss 9.8618e-01 (1.0586e+00)	Acc@1  73.44 ( 76.19)	Acc@5  89.06 ( 90.18)
 * Acc@1 74.902 Acc@5 89.139
Epoch: [76][  0/109]	Time  3.193 ( 3.193)	Data  2.675 ( 2.675)	Loss 0.1876463890075684 (0.1876463890075684)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [76][ 10/109]	Time  0.457 ( 0.677)	Data  0.000 ( 0.243)	Loss 0.1143073067069054 (0.1626655025915666)	Acc@1 100.00 ( 96.02)	Acc@5 100.00 ( 99.15)
Epoch: [76][ 20/109]	Time  0.355 ( 0.546)	Data  0.000 ( 0.128)	Loss 0.1822098046541214 (0.1788944857461112)	Acc@1  95.31 ( 95.61)	Acc@5  96.88 ( 98.44)
Epoch: [76][ 30/109]	Time  0.452 ( 0.501)	Data  0.000 ( 0.087)	Loss 0.0993703678250313 (0.1770840373731428)	Acc@1  98.44 ( 95.61)	Acc@5 100.00 ( 98.44)
Epoch: [76][ 40/109]	Time  0.361 ( 0.476)	Data  0.000 ( 0.065)	Loss 0.3376971185207367 (0.1701286313373868)	Acc@1  89.06 ( 95.69)	Acc@5  98.44 ( 98.51)
Epoch: [76][ 50/109]	Time  0.375 ( 0.466)	Data  0.000 ( 0.053)	Loss 0.1578960418701172 (0.1719233095645905)	Acc@1  96.88 ( 95.62)	Acc@5  98.44 ( 98.50)
Epoch: [76][ 60/109]	Time  0.515 ( 0.464)	Data  0.000 ( 0.044)	Loss 0.1160922646522522 (0.1701953212623714)	Acc@1  98.44 ( 95.72)	Acc@5  98.44 ( 98.54)
Epoch: [76][ 70/109]	Time  0.432 ( 0.458)	Data  0.000 ( 0.038)	Loss 0.1769132912158966 (0.1656191822298816)	Acc@1  95.31 ( 95.82)	Acc@5  98.44 ( 98.61)
Epoch: [76][ 80/109]	Time  0.446 ( 0.452)	Data  0.000 ( 0.033)	Loss 0.1884399056434631 (0.1636688979687514)	Acc@1  96.88 ( 95.93)	Acc@5  98.44 ( 98.65)
Epoch: [76][ 90/109]	Time  0.424 ( 0.447)	Data  0.000 ( 0.030)	Loss 0.0770602598786354 (0.1607720502703399)	Acc@1  96.88 ( 96.00)	Acc@5 100.00 ( 98.68)
Epoch: [76][100/109]	Time  0.366 ( 0.443)	Data  0.000 ( 0.027)	Loss 0.0626660361886024 (0.1610121979645573)	Acc@1 100.00 ( 96.04)	Acc@5 100.00 ( 98.65)
epoch: 76, Avg_Loss 0.15974992178722258
Test: [ 0/28]	Time  3.111 ( 3.111)	Loss 1.5850e+00 (1.5850e+00)	Acc@1  62.50 ( 62.50)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.143 ( 0.519)	Loss 1.6337e+00 (7.3433e-01)	Acc@1  65.62 ( 84.23)	Acc@5  81.25 ( 92.05)
Test: [20/28]	Time  0.088 ( 0.390)	Loss 1.1952e+00 (1.0953e+00)	Acc@1  71.88 ( 75.15)	Acc@5  89.06 ( 89.21)
 * Acc@1 73.720 Acc@5 88.520
Epoch: [77][  0/109]	Time  3.119 ( 3.119)	Data  2.724 ( 2.724)	Loss 0.1174526959657669 (0.1174526959657669)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [77][ 10/109]	Time  0.437 ( 0.678)	Data  0.000 ( 0.270)	Loss 0.1431321352720261 (0.1212337867102840)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 99.15)
Epoch: [77][ 20/109]	Time  0.455 ( 0.553)	Data  0.000 ( 0.142)	Loss 0.1748072654008865 (0.1459670072155339)	Acc@1  93.75 ( 96.65)	Acc@5  98.44 ( 98.51)
Epoch: [77][ 30/109]	Time  0.387 ( 0.499)	Data  0.000 ( 0.096)	Loss 0.0940470695495605 (0.1442905347794294)	Acc@1  98.44 ( 96.77)	Acc@5 100.00 ( 98.74)
Epoch: [77][ 40/109]	Time  0.453 ( 0.479)	Data  0.000 ( 0.073)	Loss 0.0518529713153839 (0.1437946040546749)	Acc@1 100.00 ( 96.53)	Acc@5 100.00 ( 98.78)
Epoch: [77][ 50/109]	Time  0.374 ( 0.467)	Data  0.000 ( 0.059)	Loss 0.1114998310804367 (0.1382672703076227)	Acc@1  96.88 ( 96.57)	Acc@5  98.44 ( 98.96)
Epoch: [77][ 60/109]	Time  0.373 ( 0.455)	Data  0.000 ( 0.049)	Loss 0.2019789665937424 (0.1407823391319787)	Acc@1  95.31 ( 96.59)	Acc@5  96.88 ( 98.85)
Epoch: [77][ 70/109]	Time  0.370 ( 0.448)	Data  0.000 ( 0.042)	Loss 0.2128112912178040 (0.1426673545436540)	Acc@1  96.88 ( 96.50)	Acc@5  96.88 ( 98.81)
Epoch: [77][ 80/109]	Time  0.545 ( 0.446)	Data  0.000 ( 0.037)	Loss 0.0674352124333382 (0.1399026726269060)	Acc@1  98.44 ( 96.51)	Acc@5 100.00 ( 98.90)
Epoch: [77][ 90/109]	Time  0.365 ( 0.442)	Data  0.000 ( 0.033)	Loss 0.0897082164883614 (0.1363325294025324)	Acc@1  98.44 ( 96.62)	Acc@5 100.00 ( 98.94)
Epoch: [77][100/109]	Time  0.381 ( 0.438)	Data  0.000 ( 0.030)	Loss 0.3129268884658813 (0.1402886103617378)	Acc@1  92.19 ( 96.50)	Acc@5  98.44 ( 98.92)
epoch: 77, Avg_Loss 0.1410014790166682
Test: [ 0/28]	Time  3.445 ( 3.445)	Loss 1.4012e+00 (1.4012e+00)	Acc@1  60.94 ( 60.94)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.141 ( 0.556)	Loss 1.3356e+00 (6.4228e-01)	Acc@1  62.50 ( 84.38)	Acc@5  87.50 ( 94.32)
Test: [20/28]	Time  0.093 ( 0.396)	Loss 6.9683e-01 (1.0100e+00)	Acc@1  79.69 ( 75.37)	Acc@5  92.19 ( 90.55)
 * Acc@1 74.170 Acc@5 89.758
Epoch: [78][  0/109]	Time  3.623 ( 3.623)	Data  3.160 ( 3.160)	Loss 0.0433061495423317 (0.0433061495423317)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [78][ 10/109]	Time  0.423 ( 0.717)	Data  0.000 ( 0.288)	Loss 0.1322611719369888 (0.1443841586058790)	Acc@1  95.31 ( 96.02)	Acc@5 100.00 ( 98.86)
Epoch: [78][ 20/109]	Time  0.391 ( 0.562)	Data  0.000 ( 0.151)	Loss 0.0766105353832245 (0.1376135601174264)	Acc@1  98.44 ( 96.21)	Acc@5 100.00 ( 99.03)
Epoch: [78][ 30/109]	Time  0.542 ( 0.542)	Data  0.000 ( 0.102)	Loss 0.1276409626007080 (0.1396321435609172)	Acc@1  96.88 ( 96.47)	Acc@5 100.00 ( 98.94)
Epoch: [78][ 40/109]	Time  0.401 ( 0.521)	Data  0.000 ( 0.077)	Loss 0.1957650035619736 (0.1383369165222819)	Acc@1  95.31 ( 96.53)	Acc@5  96.88 ( 98.97)
Epoch: [78][ 50/109]	Time  0.394 ( 0.502)	Data  0.000 ( 0.062)	Loss 0.2542339861392975 (0.1371689203615282)	Acc@1  92.19 ( 96.60)	Acc@5 100.00 ( 98.96)
Epoch: [78][ 60/109]	Time  0.381 ( 0.492)	Data  0.000 ( 0.052)	Loss 0.1616088449954987 (0.1364068023738314)	Acc@1  98.44 ( 96.62)	Acc@5 100.00 ( 99.05)
Epoch: [78][ 70/109]	Time  0.406 ( 0.478)	Data  0.000 ( 0.045)	Loss 0.1741720885038376 (0.1426764446454988)	Acc@1  95.31 ( 96.48)	Acc@5 100.00 ( 99.03)
Epoch: [78][ 80/109]	Time  0.361 ( 0.467)	Data  0.000 ( 0.039)	Loss 0.2077430635690689 (0.1453049927030081)	Acc@1  92.19 ( 96.37)	Acc@5  96.88 ( 98.98)
Epoch: [78][ 90/109]	Time  0.380 ( 0.463)	Data  0.000 ( 0.035)	Loss 0.0644545257091522 (0.1449579427857975)	Acc@1  98.44 ( 96.36)	Acc@5 100.00 ( 98.94)
Epoch: [78][100/109]	Time  0.403 ( 0.456)	Data  0.000 ( 0.032)	Loss 0.2269332110881805 (0.1442353289832573)	Acc@1  92.19 ( 96.35)	Acc@5  96.88 ( 98.92)
epoch: 78, Avg_Loss 0.14553870359828713
Test: [ 0/28]	Time  3.375 ( 3.375)	Loss 1.9340e+00 (1.9340e+00)	Acc@1  59.38 ( 59.38)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.097 ( 0.496)	Loss 1.4061e+00 (6.8312e-01)	Acc@1  62.50 ( 84.94)	Acc@5  84.38 ( 92.90)
Test: [20/28]	Time  0.088 ( 0.380)	Loss 1.1826e+00 (1.0667e+00)	Acc@1  75.00 ( 74.85)	Acc@5  89.06 ( 89.14)
 * Acc@1 73.607 Acc@5 88.689
Epoch: [79][  0/109]	Time  4.027 ( 4.027)	Data  3.663 ( 3.663)	Loss 0.0592272281646729 (0.0592272281646729)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [79][ 10/109]	Time  0.492 ( 0.748)	Data  0.000 ( 0.333)	Loss 0.0416068360209465 (0.1522499973123724)	Acc@1 100.00 ( 95.88)	Acc@5 100.00 ( 98.86)
Epoch: [79][ 20/109]	Time  0.371 ( 0.590)	Data  0.000 ( 0.175)	Loss 0.2542229592800140 (0.1425015880238442)	Acc@1  93.75 ( 96.35)	Acc@5  96.88 ( 98.96)
Epoch: [79][ 30/109]	Time  0.383 ( 0.535)	Data  0.000 ( 0.118)	Loss 0.2156798690557480 (0.1403902712608537)	Acc@1  93.75 ( 96.42)	Acc@5  96.88 ( 98.89)
Epoch: [79][ 40/109]	Time  0.391 ( 0.510)	Data  0.000 ( 0.090)	Loss 0.1334821730852127 (0.1412570939921751)	Acc@1  96.88 ( 96.46)	Acc@5  98.44 ( 98.89)
Epoch: [79][ 50/109]	Time  0.375 ( 0.491)	Data  0.000 ( 0.072)	Loss 0.2757751047611237 (0.1439940786244822)	Acc@1  93.75 ( 96.26)	Acc@5  98.44 ( 98.93)
Epoch: [79][ 60/109]	Time  0.381 ( 0.478)	Data  0.000 ( 0.060)	Loss 0.0961860939860344 (0.1414385023908537)	Acc@1  96.88 ( 96.34)	Acc@5 100.00 ( 99.03)
Epoch: [79][ 70/109]	Time  0.449 ( 0.469)	Data  0.000 ( 0.052)	Loss 0.2632064521312714 (0.1398571151977694)	Acc@1  90.62 ( 96.30)	Acc@5  98.44 ( 99.01)
Epoch: [79][ 80/109]	Time  0.383 ( 0.464)	Data  0.000 ( 0.045)	Loss 0.1241355314850807 (0.1391980186978608)	Acc@1  96.88 ( 96.33)	Acc@5 100.00 ( 99.00)
Epoch: [79][ 90/109]	Time  0.361 ( 0.458)	Data  0.000 ( 0.040)	Loss 0.1423425674438477 (0.1357798391523269)	Acc@1  96.88 ( 96.48)	Acc@5  98.44 ( 98.99)
Epoch: [79][100/109]	Time  0.375 ( 0.452)	Data  0.000 ( 0.037)	Loss 0.0758471190929413 (0.1323454788526391)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 99.07)
epoch: 79, Avg_Loss 0.13446611143785334
Test: [ 0/28]	Time  3.440 ( 3.440)	Loss 1.9505e+00 (1.9505e+00)	Acc@1  56.25 ( 56.25)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.089 ( 0.527)	Loss 1.3993e+00 (7.2188e-01)	Acc@1  73.44 ( 83.95)	Acc@5  82.81 ( 92.76)
Test: [20/28]	Time  0.090 ( 0.384)	Loss 1.0280e+00 (1.0212e+00)	Acc@1  81.25 ( 76.34)	Acc@5  92.19 ( 90.18)
 * Acc@1 74.620 Acc@5 88.970
Epoch: [80][  0/109]	Time  3.622 ( 3.622)	Data  3.171 ( 3.171)	Loss 0.0642757341265678 (0.0642757341265678)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [80][ 10/109]	Time  0.369 ( 0.687)	Data  0.000 ( 0.288)	Loss 0.2279172539710999 (0.1226338581605391)	Acc@1  93.75 ( 97.02)	Acc@5  98.44 ( 99.29)
Epoch: [80][ 20/109]	Time  0.547 ( 0.585)	Data  0.000 ( 0.151)	Loss 0.0694389194250107 (0.1301111820198241)	Acc@1  98.44 ( 96.73)	Acc@5 100.00 ( 99.48)
Epoch: [80][ 30/109]	Time  0.508 ( 0.562)	Data  0.000 ( 0.103)	Loss 0.1387897133827209 (0.1283564285164879)	Acc@1  95.31 ( 96.82)	Acc@5  98.44 ( 99.34)
Epoch: [80][ 40/109]	Time  0.385 ( 0.530)	Data  0.000 ( 0.078)	Loss 0.1188732087612152 (0.1355343306573426)	Acc@1  96.88 ( 96.57)	Acc@5 100.00 ( 99.28)
Epoch: [80][ 50/109]	Time  0.621 ( 0.515)	Data  0.000 ( 0.062)	Loss 0.2871171534061432 (0.1285584594908298)	Acc@1  92.19 ( 96.66)	Acc@5  96.88 ( 99.33)
Epoch: [80][ 60/109]	Time  0.440 ( 0.516)	Data  0.000 ( 0.052)	Loss 0.0523810200393200 (0.1260793637789664)	Acc@1 100.00 ( 96.67)	Acc@5 100.00 ( 99.33)
Epoch: [80][ 70/109]	Time  0.513 ( 0.505)	Data  0.000 ( 0.045)	Loss 0.0795326158404350 (0.1232064379982545)	Acc@1  98.44 ( 96.88)	Acc@5 100.00 ( 99.34)
Epoch: [80][ 80/109]	Time  0.477 ( 0.497)	Data  0.000 ( 0.039)	Loss 0.2606806159019470 (0.1300375668538941)	Acc@1  90.62 ( 96.70)	Acc@5  98.44 ( 99.25)
Epoch: [80][ 90/109]	Time  0.442 ( 0.489)	Data  0.001 ( 0.035)	Loss 0.0556574724614620 (0.1278858439853558)	Acc@1  96.88 ( 96.74)	Acc@5 100.00 ( 99.23)
Epoch: [80][100/109]	Time  0.368 ( 0.480)	Data  0.000 ( 0.032)	Loss 0.3389853537082672 (0.1292510916395943)	Acc@1  90.62 ( 96.70)	Acc@5  98.44 ( 99.21)
epoch: 80, Avg_Loss 0.12647378410494656
Test: [ 0/28]	Time  4.033 ( 4.033)	Loss 1.5995e+00 (1.5995e+00)	Acc@1  60.94 ( 60.94)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.090 ( 0.578)	Loss 1.7336e+00 (7.6029e-01)	Acc@1  60.94 ( 82.81)	Acc@5  81.25 ( 92.33)
Test: [20/28]	Time  0.089 ( 0.425)	Loss 1.0112e+00 (1.0788e+00)	Acc@1  70.31 ( 74.70)	Acc@5  89.06 ( 89.36)
 * Acc@1 73.551 Acc@5 88.914
Epoch: [81][  0/109]	Time  3.848 ( 3.848)	Data  3.255 ( 3.255)	Loss 0.2646887898445129 (0.2646887898445129)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [81][ 10/109]	Time  0.437 ( 0.834)	Data  0.000 ( 0.307)	Loss 0.0941140204668045 (0.1218227029524066)	Acc@1  98.44 ( 96.88)	Acc@5 100.00 ( 99.29)
Epoch: [81][ 20/109]	Time  0.365 ( 0.639)	Data  0.000 ( 0.161)	Loss 0.2424775660037994 (0.1362822687342053)	Acc@1  93.75 ( 96.80)	Acc@5  98.44 ( 99.11)
Epoch: [81][ 30/109]	Time  0.366 ( 0.561)	Data  0.000 ( 0.109)	Loss 0.2075473666191101 (0.1293183768228177)	Acc@1  93.75 ( 96.88)	Acc@5  98.44 ( 99.09)
Epoch: [81][ 40/109]	Time  0.417 ( 0.522)	Data  0.000 ( 0.083)	Loss 0.2062609791755676 (0.1357995613319118)	Acc@1  96.88 ( 96.65)	Acc@5  98.44 ( 99.09)
Epoch: [81][ 50/109]	Time  0.524 ( 0.503)	Data  0.000 ( 0.066)	Loss 0.2890768647193909 (0.1414300212088753)	Acc@1  93.75 ( 96.45)	Acc@5  95.31 ( 98.99)
Epoch: [81][ 60/109]	Time  0.459 ( 0.486)	Data  0.000 ( 0.056)	Loss 0.0975188687443733 (0.1422195728318613)	Acc@1  98.44 ( 96.47)	Acc@5  98.44 ( 98.87)
Epoch: [81][ 70/109]	Time  0.485 ( 0.475)	Data  0.000 ( 0.048)	Loss 0.1590185910463333 (0.1397623170009801)	Acc@1  96.88 ( 96.57)	Acc@5 100.00 ( 98.92)
Epoch: [81][ 80/109]	Time  0.538 ( 0.471)	Data  0.000 ( 0.042)	Loss 0.0931104868650436 (0.1357247598561240)	Acc@1  98.44 ( 96.72)	Acc@5  98.44 ( 98.96)
Epoch: [81][ 90/109]	Time  0.401 ( 0.464)	Data  0.000 ( 0.037)	Loss 0.1676594614982605 (0.1355595341423056)	Acc@1  95.31 ( 96.69)	Acc@5 100.00 ( 98.95)
Epoch: [81][100/109]	Time  0.426 ( 0.461)	Data  0.000 ( 0.034)	Loss 0.1621140837669373 (0.1339785099619686)	Acc@1  96.88 ( 96.69)	Acc@5 100.00 ( 99.01)
epoch: 81, Avg_Loss 0.13578368162890092
Test: [ 0/28]	Time  3.120 ( 3.120)	Loss 1.5445e+00 (1.5445e+00)	Acc@1  59.38 ( 59.38)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.148 ( 0.534)	Loss 1.5821e+00 (7.0658e-01)	Acc@1  68.75 ( 83.81)	Acc@5  84.38 ( 93.32)
Test: [20/28]	Time  0.088 ( 0.380)	Loss 1.1345e+00 (1.1098e+00)	Acc@1  75.00 ( 74.33)	Acc@5  87.50 ( 89.66)
 * Acc@1 73.213 Acc@5 88.520
Epoch: [82][  0/109]	Time  3.157 ( 3.157)	Data  2.678 ( 2.678)	Loss 0.2042061686515808 (0.2042061686515808)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [82][ 10/109]	Time  0.371 ( 0.670)	Data  0.000 ( 0.266)	Loss 0.0737271904945374 (0.1202198212796992)	Acc@1  98.44 ( 96.31)	Acc@5 100.00 ( 99.86)
Epoch: [82][ 20/109]	Time  0.377 ( 0.545)	Data  0.000 ( 0.140)	Loss 0.0421191416680813 (0.1289523607563405)	Acc@1  98.44 ( 95.98)	Acc@5 100.00 ( 99.33)
Epoch: [82][ 30/109]	Time  0.482 ( 0.505)	Data  0.000 ( 0.095)	Loss 0.1190755814313889 (0.1249924638578969)	Acc@1  98.44 ( 96.57)	Acc@5  98.44 ( 99.29)
Epoch: [82][ 40/109]	Time  0.482 ( 0.488)	Data  0.000 ( 0.072)	Loss 0.0321138352155685 (0.1162784455752954)	Acc@1 100.00 ( 96.76)	Acc@5 100.00 ( 99.31)
Epoch: [82][ 50/109]	Time  0.525 ( 0.480)	Data  0.000 ( 0.058)	Loss 0.1080403774976730 (0.1224731666711616)	Acc@1  96.88 ( 96.60)	Acc@5  98.44 ( 99.23)
Epoch: [82][ 60/109]	Time  0.496 ( 0.479)	Data  0.000 ( 0.048)	Loss 0.1761116832494736 (0.1209158403646262)	Acc@1  95.31 ( 96.77)	Acc@5  98.44 ( 99.21)
Epoch: [82][ 70/109]	Time  0.374 ( 0.469)	Data  0.000 ( 0.041)	Loss 0.1124499216675758 (0.1225751268769234)	Acc@1  96.88 ( 96.74)	Acc@5  98.44 ( 99.19)
Epoch: [82][ 80/109]	Time  0.394 ( 0.461)	Data  0.000 ( 0.036)	Loss 0.1664558351039886 (0.1231585364604806)	Acc@1  96.88 ( 96.84)	Acc@5  98.44 ( 99.17)
Epoch: [82][ 90/109]	Time  0.396 ( 0.455)	Data  0.000 ( 0.032)	Loss 0.1214503124356270 (0.1284696082942761)	Acc@1  96.88 ( 96.79)	Acc@5  98.44 ( 99.04)
Epoch: [82][100/109]	Time  0.368 ( 0.449)	Data  0.000 ( 0.029)	Loss 0.0724648237228394 (0.1284862613803384)	Acc@1 100.00 ( 96.81)	Acc@5 100.00 ( 99.04)
epoch: 82, Avg_Loss 0.12816058777682826
Test: [ 0/28]	Time  3.588 ( 3.588)	Loss 1.7286e+00 (1.7286e+00)	Acc@1  59.38 ( 59.38)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.122 ( 0.550)	Loss 1.3961e+00 (6.9982e-01)	Acc@1  73.44 ( 84.52)	Acc@5  84.38 ( 92.90)
Test: [20/28]	Time  0.137 ( 0.391)	Loss 8.7711e-01 (9.8460e-01)	Acc@1  76.56 ( 77.01)	Acc@5  89.06 ( 89.88)
 * Acc@1 75.464 Acc@5 89.252
Epoch: [83][  0/109]	Time  3.452 ( 3.452)	Data  2.953 ( 2.953)	Loss 0.1262720078229904 (0.1262720078229904)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [83][ 10/109]	Time  0.483 ( 0.706)	Data  0.000 ( 0.269)	Loss 0.0501280166208744 (0.1265996609899131)	Acc@1  98.44 ( 96.88)	Acc@5 100.00 ( 99.15)
Epoch: [83][ 20/109]	Time  0.466 ( 0.575)	Data  0.000 ( 0.141)	Loss 0.1401399523019791 (0.1256678087548131)	Acc@1  96.88 ( 97.10)	Acc@5  98.44 ( 99.03)
Epoch: [83][ 30/109]	Time  0.485 ( 0.534)	Data  0.000 ( 0.096)	Loss 0.0223277863115072 (0.1370603720987997)	Acc@1 100.00 ( 96.72)	Acc@5 100.00 ( 98.94)
Epoch: [83][ 40/109]	Time  0.406 ( 0.504)	Data  0.000 ( 0.072)	Loss 0.1116328090429306 (0.1331342903033989)	Acc@1  98.44 ( 96.95)	Acc@5  98.44 ( 98.97)
Epoch: [83][ 50/109]	Time  0.366 ( 0.483)	Data  0.000 ( 0.058)	Loss 0.2374096363782883 (0.1334334099117447)	Acc@1  93.75 ( 96.91)	Acc@5  96.88 ( 98.90)
Epoch: [83][ 60/109]	Time  0.472 ( 0.470)	Data  0.000 ( 0.049)	Loss 0.1179530844092369 (0.1311333008476945)	Acc@1  96.88 ( 96.95)	Acc@5  98.44 ( 98.87)
Epoch: [83][ 70/109]	Time  0.401 ( 0.461)	Data  0.000 ( 0.042)	Loss 0.0897632315754890 (0.1312456523448648)	Acc@1  96.88 ( 96.94)	Acc@5  98.44 ( 98.92)
Epoch: [83][ 80/109]	Time  0.549 ( 0.458)	Data  0.000 ( 0.037)	Loss 0.0661766231060028 (0.1375713470725366)	Acc@1  98.44 ( 96.66)	Acc@5  98.44 ( 98.80)
Epoch: [83][ 90/109]	Time  0.380 ( 0.456)	Data  0.000 ( 0.033)	Loss 0.1592021435499191 (0.1361432871730118)	Acc@1  93.75 ( 96.65)	Acc@5 100.00 ( 98.85)
Epoch: [83][100/109]	Time  0.362 ( 0.449)	Data  0.000 ( 0.029)	Loss 0.1492453366518021 (0.1335806989359974)	Acc@1  98.44 ( 96.77)	Acc@5  98.44 ( 98.84)
epoch: 83, Avg_Loss 0.13710901971667186
Test: [ 0/28]	Time  3.317 ( 3.317)	Loss 1.6791e+00 (1.6791e+00)	Acc@1  57.81 ( 57.81)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.088 ( 0.550)	Loss 1.3195e+00 (7.6082e-01)	Acc@1  71.88 ( 83.66)	Acc@5  85.94 ( 92.90)
Test: [20/28]	Time  0.089 ( 0.396)	Loss 1.0390e+00 (1.0768e+00)	Acc@1  76.56 ( 74.78)	Acc@5  85.94 ( 89.81)
 * Acc@1 73.889 Acc@5 88.858
Epoch: [84][  0/109]	Time  3.380 ( 3.380)	Data  2.922 ( 2.922)	Loss 0.0299747847020626 (0.0299747847020626)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [84][ 10/109]	Time  0.417 ( 0.687)	Data  0.000 ( 0.266)	Loss 0.0910824984312057 (0.1177606511522423)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.29)
Epoch: [84][ 20/109]	Time  0.431 ( 0.555)	Data  0.000 ( 0.139)	Loss 0.2027697414159775 (0.1298663511517502)	Acc@1  93.75 ( 96.95)	Acc@5  98.44 ( 99.18)
Epoch: [84][ 30/109]	Time  0.381 ( 0.506)	Data  0.000 ( 0.094)	Loss 0.1931326389312744 (0.1365008661823888)	Acc@1  95.31 ( 96.88)	Acc@5  98.44 ( 99.14)
Epoch: [84][ 40/109]	Time  0.421 ( 0.502)	Data  0.000 ( 0.072)	Loss 0.1205880567431450 (0.1317748546418620)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 99.12)
Epoch: [84][ 50/109]	Time  0.429 ( 0.493)	Data  0.000 ( 0.058)	Loss 0.1286416947841644 (0.1252475125240345)	Acc@1  96.88 ( 97.00)	Acc@5  98.44 ( 99.20)
Epoch: [84][ 60/109]	Time  0.417 ( 0.478)	Data  0.000 ( 0.048)	Loss 0.1191359609365463 (0.1276605028475894)	Acc@1  95.31 ( 96.93)	Acc@5 100.00 ( 99.26)
Epoch: [84][ 70/109]	Time  0.385 ( 0.472)	Data  0.000 ( 0.041)	Loss 0.0619804151356220 (0.1254614023360568)	Acc@1 100.00 ( 96.99)	Acc@5 100.00 ( 99.27)
Epoch: [84][ 80/109]	Time  0.375 ( 0.463)	Data  0.000 ( 0.036)	Loss 0.1857002228498459 (0.1299236799923726)	Acc@1  95.31 ( 96.78)	Acc@5  98.44 ( 99.21)
Epoch: [84][ 90/109]	Time  0.432 ( 0.457)	Data  0.000 ( 0.032)	Loss 0.0317491181194782 (0.1242063780120768)	Acc@1 100.00 ( 96.93)	Acc@5 100.00 ( 99.26)
Epoch: [84][100/109]	Time  0.369 ( 0.451)	Data  0.000 ( 0.029)	Loss 0.2042434215545654 (0.1246403991106418)	Acc@1  93.75 ( 96.91)	Acc@5  98.44 ( 99.23)
epoch: 84, Avg_Loss 0.1313858636988139
Test: [ 0/28]	Time  3.584 ( 3.584)	Loss 1.8217e+00 (1.8217e+00)	Acc@1  59.38 ( 59.38)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.089 ( 0.513)	Loss 1.6483e+00 (7.0025e-01)	Acc@1  59.38 ( 83.95)	Acc@5  81.25 ( 92.90)
Test: [20/28]	Time  0.088 ( 0.381)	Loss 9.9488e-01 (1.0213e+00)	Acc@1  75.00 ( 76.41)	Acc@5  89.06 ( 89.51)
 * Acc@1 74.508 Acc@5 88.689
Epoch: [85][  0/109]	Time  3.303 ( 3.303)	Data  2.841 ( 2.841)	Loss 0.0271343179047108 (0.0271343179047108)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [85][ 10/109]	Time  0.470 ( 0.687)	Data  0.000 ( 0.268)	Loss 0.1066067442297935 (0.1486143896525556)	Acc@1  98.44 ( 96.45)	Acc@5  98.44 ( 98.86)
Epoch: [85][ 20/109]	Time  0.510 ( 0.569)	Data  0.000 ( 0.140)	Loss 0.1689276397228241 (0.1418331698292778)	Acc@1  95.31 ( 96.35)	Acc@5  98.44 ( 99.03)
Epoch: [85][ 30/109]	Time  0.423 ( 0.526)	Data  0.000 ( 0.095)	Loss 0.2248721718788147 (0.1351569315358516)	Acc@1  96.88 ( 96.57)	Acc@5  98.44 ( 99.19)
Epoch: [85][ 40/109]	Time  0.409 ( 0.500)	Data  0.000 ( 0.072)	Loss 0.2425717860460281 (0.1351399764236881)	Acc@1  93.75 ( 96.49)	Acc@5  98.44 ( 99.05)
Epoch: [85][ 50/109]	Time  0.393 ( 0.484)	Data  0.000 ( 0.058)	Loss 0.1284993290901184 (0.1319205275207174)	Acc@1  95.31 ( 96.35)	Acc@5  98.44 ( 99.11)
Epoch: [85][ 60/109]	Time  0.371 ( 0.474)	Data  0.000 ( 0.048)	Loss 0.1039280891418457 (0.1306037723895956)	Acc@1  98.44 ( 96.41)	Acc@5 100.00 ( 99.08)
Epoch: [85][ 70/109]	Time  0.780 ( 0.479)	Data  0.000 ( 0.042)	Loss 0.2373264878988266 (0.1320560481661642)	Acc@1  93.75 ( 96.37)	Acc@5  96.88 ( 99.05)
Epoch: [85][ 80/109]	Time  0.361 ( 0.472)	Data  0.000 ( 0.037)	Loss 0.1284950375556946 (0.1337556740108096)	Acc@1  96.88 ( 96.35)	Acc@5  98.44 ( 99.02)
Epoch: [85][ 90/109]	Time  0.375 ( 0.466)	Data  0.000 ( 0.033)	Loss 0.0596893802285194 (0.1320701508608821)	Acc@1 100.00 ( 96.38)	Acc@5 100.00 ( 99.07)
Epoch: [85][100/109]	Time  0.368 ( 0.459)	Data  0.000 ( 0.029)	Loss 0.0516155734658241 (0.1297835861655450)	Acc@1  98.44 ( 96.49)	Acc@5 100.00 ( 99.07)
epoch: 85, Avg_Loss 0.12824937104837064
Test: [ 0/28]	Time  3.286 ( 3.286)	Loss 1.7211e+00 (1.7211e+00)	Acc@1  59.38 ( 59.38)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.152 ( 0.501)	Loss 1.4340e+00 (7.3561e-01)	Acc@1  71.88 ( 85.09)	Acc@5  82.81 ( 92.33)
Test: [20/28]	Time  0.088 ( 0.376)	Loss 1.0168e+00 (1.0188e+00)	Acc@1  75.00 ( 76.56)	Acc@5  85.94 ( 90.25)
 * Acc@1 75.070 Acc@5 89.252
Epoch: [86][  0/109]	Time  3.832 ( 3.832)	Data  3.385 ( 3.385)	Loss 0.1202691569924355 (0.1202691569924355)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [86][ 10/109]	Time  0.544 ( 0.736)	Data  0.000 ( 0.308)	Loss 0.0790603384375572 (0.1245924051512371)	Acc@1  98.44 ( 96.88)	Acc@5  98.44 ( 98.86)
Epoch: [86][ 20/109]	Time  0.502 ( 0.592)	Data  0.000 ( 0.161)	Loss 0.0781545490026474 (0.1218918700303350)	Acc@1  98.44 ( 97.17)	Acc@5 100.00 ( 98.96)
Epoch: [86][ 30/109]	Time  0.525 ( 0.561)	Data  0.000 ( 0.109)	Loss 0.2075858712196350 (0.1264613085696774)	Acc@1  95.31 ( 97.13)	Acc@5  98.44 ( 98.94)
Epoch: [86][ 40/109]	Time  0.365 ( 0.524)	Data  0.000 ( 0.083)	Loss 0.2405068278312683 (0.1333549772275657)	Acc@1  96.88 ( 96.91)	Acc@5  98.44 ( 98.93)
Epoch: [86][ 50/109]	Time  0.407 ( 0.501)	Data  0.000 ( 0.067)	Loss 0.0861883312463760 (0.1364732211565270)	Acc@1  95.31 ( 96.84)	Acc@5 100.00 ( 98.96)
Epoch: [86][ 60/109]	Time  0.374 ( 0.488)	Data  0.000 ( 0.056)	Loss 0.0481465235352516 (0.1367539102669622)	Acc@1  98.44 ( 96.75)	Acc@5 100.00 ( 99.00)
Epoch: [86][ 70/109]	Time  0.512 ( 0.479)	Data  0.000 ( 0.048)	Loss 0.0333242081105709 (0.1350272396238337)	Acc@1 100.00 ( 96.85)	Acc@5 100.00 ( 98.97)
Epoch: [86][ 80/109]	Time  0.376 ( 0.469)	Data  0.000 ( 0.042)	Loss 0.2832425534725189 (0.1370662623717461)	Acc@1  92.19 ( 96.78)	Acc@5  96.88 ( 98.92)
Epoch: [86][ 90/109]	Time  0.501 ( 0.463)	Data  0.000 ( 0.037)	Loss 0.0463666841387749 (0.1318991399564586)	Acc@1  98.44 ( 96.82)	Acc@5 100.00 ( 99.00)
Epoch: [86][100/109]	Time  0.381 ( 0.455)	Data  0.000 ( 0.034)	Loss 0.1814672946929932 (0.1289140915332159)	Acc@1  96.88 ( 96.92)	Acc@5  98.44 ( 99.03)
epoch: 86, Avg_Loss 0.13002019948027002
Test: [ 0/28]	Time  3.665 ( 3.665)	Loss 1.5215e+00 (1.5215e+00)	Acc@1  62.50 ( 62.50)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.089 ( 0.575)	Loss 1.3533e+00 (6.4932e-01)	Acc@1  68.75 ( 85.80)	Acc@5  87.50 ( 93.89)
Test: [20/28]	Time  0.095 ( 0.398)	Loss 1.0446e+00 (9.8378e-01)	Acc@1  68.75 ( 77.38)	Acc@5  87.50 ( 90.18)
 * Acc@1 74.733 Acc@5 88.858
Epoch: [87][  0/109]	Time  3.756 ( 3.756)	Data  3.339 ( 3.339)	Loss 0.2576949894428253 (0.2576949894428253)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [87][ 10/109]	Time  0.372 ( 0.764)	Data  0.000 ( 0.304)	Loss 0.1098494157195091 (0.1798951185562394)	Acc@1  98.44 ( 95.88)	Acc@5  98.44 ( 98.30)
Epoch: [87][ 20/109]	Time  0.406 ( 0.585)	Data  0.000 ( 0.159)	Loss 0.1228688061237335 (0.1488074995577335)	Acc@1  96.88 ( 96.58)	Acc@5 100.00 ( 98.66)
Epoch: [87][ 30/109]	Time  0.434 ( 0.532)	Data  0.000 ( 0.108)	Loss 0.1777641475200653 (0.1432658758374953)	Acc@1  93.75 ( 96.52)	Acc@5  98.44 ( 98.79)
Epoch: [87][ 40/109]	Time  0.357 ( 0.501)	Data  0.000 ( 0.082)	Loss 0.1956185102462769 (0.1481305473461384)	Acc@1  95.31 ( 96.57)	Acc@5  96.88 ( 98.59)
Epoch: [87][ 50/109]	Time  0.529 ( 0.484)	Data  0.000 ( 0.066)	Loss 0.2354531437158585 (0.1507699191570282)	Acc@1  95.31 ( 96.48)	Acc@5  96.88 ( 98.53)
Epoch: [87][ 60/109]	Time  0.382 ( 0.478)	Data  0.000 ( 0.055)	Loss 0.1072069853544235 (0.1529027834901067)	Acc@1  96.88 ( 96.18)	Acc@5  98.44 ( 98.57)
Epoch: [87][ 70/109]	Time  0.424 ( 0.471)	Data  0.000 ( 0.047)	Loss 0.1935960352420807 (0.1482859965361340)	Acc@1  95.31 ( 96.32)	Acc@5  98.44 ( 98.68)
Epoch: [87][ 80/109]	Time  0.422 ( 0.465)	Data  0.000 ( 0.041)	Loss 0.0680367797613144 (0.1440072948182071)	Acc@1  98.44 ( 96.43)	Acc@5 100.00 ( 98.77)
Epoch: [87][ 90/109]	Time  0.491 ( 0.460)	Data  0.000 ( 0.037)	Loss 0.0563111081719398 (0.1412364038137289)	Acc@1  98.44 ( 96.45)	Acc@5 100.00 ( 98.76)
Epoch: [87][100/109]	Time  0.393 ( 0.457)	Data  0.000 ( 0.033)	Loss 0.1496844291687012 (0.1393281767642734)	Acc@1  95.31 ( 96.52)	Acc@5  98.44 ( 98.81)
epoch: 87, Avg_Loss 0.1364874736995462
Test: [ 0/28]	Time  3.643 ( 3.643)	Loss 2.0007e+00 (2.0007e+00)	Acc@1  53.12 ( 53.12)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.149 ( 0.574)	Loss 1.5544e+00 (7.4704e-01)	Acc@1  60.94 ( 81.82)	Acc@5  82.81 ( 92.05)
Test: [20/28]	Time  0.089 ( 0.437)	Loss 7.5619e-01 (1.0629e+00)	Acc@1  79.69 ( 74.85)	Acc@5  92.19 ( 89.36)
 * Acc@1 73.157 Acc@5 88.689
Epoch: [88][  0/109]	Time  3.999 ( 3.999)	Data  3.548 ( 3.548)	Loss 0.0948237776756287 (0.0948237776756287)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [88][ 10/109]	Time  0.371 ( 0.731)	Data  0.000 ( 0.323)	Loss 0.0446029715240002 (0.1045404994352297)	Acc@1 100.00 ( 97.02)	Acc@5 100.00 ( 99.57)
Epoch: [88][ 20/109]	Time  0.370 ( 0.573)	Data  0.000 ( 0.169)	Loss 0.2242949455976486 (0.1136034209103811)	Acc@1  93.75 ( 97.10)	Acc@5  98.44 ( 99.48)
Epoch: [88][ 30/109]	Time  0.406 ( 0.523)	Data  0.000 ( 0.115)	Loss 0.1166386976838112 (0.1236875295158355)	Acc@1  96.88 ( 97.03)	Acc@5 100.00 ( 99.34)
Epoch: [88][ 40/109]	Time  0.371 ( 0.493)	Data  0.000 ( 0.087)	Loss 0.2563395798206329 (0.1225885315003192)	Acc@1  93.75 ( 96.95)	Acc@5  98.44 ( 99.31)
Epoch: [88][ 50/109]	Time  0.381 ( 0.473)	Data  0.000 ( 0.070)	Loss 0.1254553645849228 (0.1254395373238652)	Acc@1  96.88 ( 96.75)	Acc@5  98.44 ( 99.23)
Epoch: [88][ 60/109]	Time  0.380 ( 0.464)	Data  0.000 ( 0.058)	Loss 0.2265881299972534 (0.1282411674190252)	Acc@1  95.31 ( 96.75)	Acc@5  96.88 ( 99.15)
Epoch: [88][ 70/109]	Time  0.392 ( 0.460)	Data  0.000 ( 0.050)	Loss 0.0652877837419510 (0.1344156942894341)	Acc@1  98.44 ( 96.70)	Acc@5 100.00 ( 99.05)
Epoch: [88][ 80/109]	Time  0.372 ( 0.459)	Data  0.000 ( 0.044)	Loss 0.1395058482885361 (0.1382004699359337)	Acc@1  93.75 ( 96.51)	Acc@5 100.00 ( 99.00)
Epoch: [88][ 90/109]	Time  0.430 ( 0.453)	Data  0.000 ( 0.039)	Loss 0.0525791980326176 (0.1394282033114315)	Acc@1  98.44 ( 96.41)	Acc@5 100.00 ( 98.97)
Epoch: [88][100/109]	Time  0.371 ( 0.447)	Data  0.000 ( 0.035)	Loss 0.2694956660270691 (0.1394277494954001)	Acc@1  93.75 ( 96.43)	Acc@5  95.31 ( 98.95)
epoch: 88, Avg_Loss 0.14236740060492392
Test: [ 0/28]	Time  3.446 ( 3.446)	Loss 1.6895e+00 (1.6895e+00)	Acc@1  67.19 ( 67.19)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.089 ( 0.553)	Loss 1.5697e+00 (6.6221e-01)	Acc@1  70.31 ( 86.08)	Acc@5  82.81 ( 93.61)
Test: [20/28]	Time  0.089 ( 0.395)	Loss 1.1494e+00 (9.8428e-01)	Acc@1  73.44 ( 77.53)	Acc@5  87.50 ( 90.62)
 * Acc@1 74.676 Acc@5 89.252
Epoch: [89][  0/109]	Time  2.976 ( 2.976)	Data  2.509 ( 2.509)	Loss 0.1247898563742638 (0.1247898563742638)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [89][ 10/109]	Time  0.472 ( 0.677)	Data  0.000 ( 0.262)	Loss 0.1045288518071175 (0.1398944109678268)	Acc@1  98.44 ( 97.02)	Acc@5 100.00 ( 98.72)
Epoch: [89][ 20/109]	Time  0.440 ( 0.547)	Data  0.000 ( 0.137)	Loss 0.1742941588163376 (0.1465917094832375)	Acc@1  95.31 ( 96.43)	Acc@5  98.44 ( 98.74)
Epoch: [89][ 30/109]	Time  0.494 ( 0.508)	Data  0.000 ( 0.093)	Loss 0.1008879095315933 (0.1300171004428018)	Acc@1  98.44 ( 96.88)	Acc@5 100.00 ( 99.04)
Epoch: [89][ 40/109]	Time  0.369 ( 0.485)	Data  0.000 ( 0.070)	Loss 0.3366290330886841 (0.1381084995298851)	Acc@1  90.62 ( 96.57)	Acc@5  96.88 ( 98.97)
Epoch: [89][ 50/109]	Time  0.385 ( 0.473)	Data  0.000 ( 0.057)	Loss 0.1466671377420425 (0.1278725338405838)	Acc@1  95.31 ( 96.91)	Acc@5 100.00 ( 99.14)
Epoch: [89][ 60/109]	Time  0.378 ( 0.465)	Data  0.000 ( 0.047)	Loss 0.1654659509658813 (0.1364038489209335)	Acc@1  96.88 ( 96.64)	Acc@5 100.00 ( 99.08)
Epoch: [89][ 70/109]	Time  0.488 ( 0.457)	Data  0.000 ( 0.041)	Loss 0.1709758043289185 (0.1363476199740675)	Acc@1  95.31 ( 96.68)	Acc@5  98.44 ( 99.08)
Epoch: [89][ 80/109]	Time  0.381 ( 0.452)	Data  0.000 ( 0.036)	Loss 0.2463583350181580 (0.1366137610863388)	Acc@1  93.75 ( 96.68)	Acc@5  98.44 ( 99.00)
Epoch: [89][ 90/109]	Time  0.436 ( 0.449)	Data  0.000 ( 0.032)	Loss 0.1170153915882111 (0.1343288651902924)	Acc@1  96.88 ( 96.75)	Acc@5 100.00 ( 99.02)
Epoch: [89][100/109]	Time  0.371 ( 0.444)	Data  0.000 ( 0.029)	Loss 0.0375660359859467 (0.1365382279831879)	Acc@1 100.00 ( 96.83)	Acc@5 100.00 ( 98.98)
epoch: 89, Avg_Loss 0.13641340775979222
Test: [ 0/28]	Time  3.768 ( 3.768)	Loss 1.5656e+00 (1.5656e+00)	Acc@1  62.50 ( 62.50)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.367 ( 0.564)	Loss 1.8161e+00 (6.9023e-01)	Acc@1  62.50 ( 84.80)	Acc@5  84.38 ( 93.75)
Test: [20/28]	Time  0.094 ( 0.396)	Loss 1.1781e+00 (1.0130e+00)	Acc@1  73.44 ( 76.64)	Acc@5  85.94 ( 89.96)
 * Acc@1 73.832 Acc@5 89.026
