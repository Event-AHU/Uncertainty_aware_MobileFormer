nohup: ignoring input
main.py:110: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
n_per_node: 8
gpu 4
Use GPU: 4 for training
create model mf294
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 40, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 40, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 40, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 40, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 72, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 72, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 72, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 72, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 176, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 176, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 176, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 176, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 240, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 240, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
L2G: 2 heads, inp: 240, token: 192
MobileFormer(
  (tokens): Embedding(6, 192)
  (stem): Sequential(
    (0): Conv3d(3, 24, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
    (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (resnet18_feature_extractor): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
  (features): Sequential(
    (0): DnaBlock3(
      (conv): Sequential(
        (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Sequential()
        (4): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(24, 144, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=288, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(40, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=40, bias=False)
        (1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=320, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(160, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=192, out_features=40, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
    )
    (2): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(40, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=240, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=240, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(120, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=40, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=192, out_features=40, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
    )
    (3): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(40, 240, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=40, bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=480, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(240, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(72, 288, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=72, bias=False)
        (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=576, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(288, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=40, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=192, out_features=72, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
    )
    (4): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(72, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=432, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)
        (1): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=432, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(216, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=72, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=192, out_features=72, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
    )
    (5): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(72, 432, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=72, bias=False)
        (1): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=864, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(432, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(128, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=72, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
    )
    (6): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
    )
    (7): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(128, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768, bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(768, 176, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=192, out_features=176, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
    )
    (8): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(176, 1056, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1056, 1056, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1056, bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1056, 176, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=176, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=192, out_features=176, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
    )
    (9): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(176, 1056, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=176, bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1056, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(240, 960, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=240, bias=False)
        (1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1920, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(960, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=176, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
    (10): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1440, 1440, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1440, bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1440, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=240, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
    (11): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1440, 1440, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1440, bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1440, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=240, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
  )
  (local_global): Local2Global(
    (alpha): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
      (1): h_sigmoid(
        (relu): ReLU6(inplace=True)
      )
    )
    (q): Linear(in_features=192, out_features=240, bias=True)
    (proj): Linear(in_features=240, out_features=192, bias=True)
    (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (drop_path): DropPath(drop_prob=0.000)
    (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
    (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
    (emd): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
      (1): ReLU(inplace=True)
    )
    (var): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
    )
  )
  (classifier): MergeClassifier(
    (conv): Sequential(
      (0): Sequential()
      (1): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (2): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (act): DyReLU(
      (act): ReLU6(inplace=True)
    )
    (hyper): Sequential()
    (avgpool): Sequential(
      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=1632, out_features=1920, bias=True)
      (1): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.3, inplace=False)
      (1): Linear(in_features=1920, out_features=101, bias=True)
    )
  )
)
############################### Dataset loading ###############################
/home/amax/anaconda3/envs/yuan/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
###############################  Dataset loaded  ##############################
lr 0.001
Epoch: [0][  0/109]	Time 18.682 (18.682)	Data  7.165 ( 7.165)	Loss 4.7012648582458496 (4.7012648582458496)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
Epoch: [0][ 10/109]	Time  0.501 ( 2.172)	Data  0.000 ( 0.652)	Loss 4.4089369773864746 (4.2381482774561103)	Acc@1  12.50 ( 15.34)	Acc@5  23.44 ( 27.56)
Epoch: [0][ 20/109]	Time  0.509 ( 1.387)	Data  0.000 ( 0.341)	Loss 3.9790370464324951 (4.1193760917300271)	Acc@1  14.06 ( 17.71)	Acc@5  29.69 ( 30.28)
Epoch: [0][ 30/109]	Time  0.492 ( 1.109)	Data  0.000 ( 0.231)	Loss 3.8680827617645264 (4.0502344100706038)	Acc@1  18.75 ( 17.99)	Acc@5  32.81 ( 30.24)
Epoch: [0][ 40/109]	Time  0.559 ( 0.968)	Data  0.000 ( 0.175)	Loss 4.0011777877807617 (3.9631810362746074)	Acc@1  14.06 ( 19.32)	Acc@5  31.25 ( 31.63)
Epoch: [0][ 50/109]	Time  0.498 ( 0.880)	Data  0.000 ( 0.141)	Loss 4.3694767951965332 (3.9023455077526616)	Acc@1  10.94 ( 20.28)	Acc@5  23.44 ( 32.63)
Epoch: [0][ 60/109]	Time  0.588 ( 0.824)	Data  0.000 ( 0.118)	Loss 3.6441209316253662 (3.8665008779431953)	Acc@1  21.88 ( 20.31)	Acc@5  34.38 ( 33.12)
Epoch: [0][ 70/109]	Time  0.635 ( 0.802)	Data  0.000 ( 0.103)	Loss 3.1072657108306885 (3.8040152099770559)	Acc@1  29.69 ( 21.21)	Acc@5  48.44 ( 34.46)
Epoch: [0][ 80/109]	Time  0.674 ( 0.785)	Data  0.000 ( 0.090)	Loss 3.6742699146270752 (3.7571602132585316)	Acc@1  21.88 ( 21.72)	Acc@5  34.38 ( 34.93)
Epoch: [0][ 90/109]	Time  0.514 ( 0.765)	Data  0.000 ( 0.080)	Loss 3.7643015384674072 (3.7427577265016327)	Acc@1  14.06 ( 21.91)	Acc@5  40.62 ( 35.39)
Epoch: [0][100/109]	Time  0.486 ( 0.738)	Data  0.000 ( 0.072)	Loss 3.0656423568725586 (3.7165746075091977)	Acc@1  34.38 ( 22.31)	Acc@5  51.56 ( 35.83)
epoch: 0, Avg_Loss 3.691702836150423
Test: [ 0/28]	Time  5.630 ( 5.630)	Loss 3.4411e+00 (3.4411e+00)	Acc@1  23.44 ( 23.44)	Acc@5  43.75 ( 43.75)
Test: [10/28]	Time  0.137 ( 0.651)	Loss 3.4094e+00 (3.7511e+00)	Acc@1  28.12 ( 21.02)	Acc@5  46.88 ( 35.94)
Test: [20/28]	Time  0.119 ( 0.401)	Loss 3.9948e+00 (3.7966e+00)	Acc@1  18.75 ( 21.43)	Acc@5  34.38 ( 35.64)
 * Acc@1 22.791 Acc@5 37.141
lr 0.001
Epoch: [1][  0/109]	Time  3.967 ( 3.967)	Data  3.238 ( 3.238)	Loss 3.6376991271972656 (3.6376991271972656)	Acc@1  20.31 ( 20.31)	Acc@5  37.50 ( 37.50)
Epoch: [1][ 10/109]	Time  0.567 ( 1.032)	Data  0.001 ( 0.360)	Loss 3.6988625526428223 (3.3599082556637851)	Acc@1  20.31 ( 26.28)	Acc@5  34.38 ( 43.89)
Epoch: [1][ 20/109]	Time  0.672 ( 0.839)	Data  0.000 ( 0.189)	Loss 3.7021923065185547 (3.3958838213057745)	Acc@1  23.44 ( 26.56)	Acc@5  37.50 ( 42.86)
Epoch: [1][ 30/109]	Time  0.522 ( 0.738)	Data  0.000 ( 0.128)	Loss 2.7183942794799805 (3.3534396463824856)	Acc@1  40.62 ( 26.71)	Acc@5  54.69 ( 43.40)
Epoch: [1][ 40/109]	Time  0.600 ( 0.689)	Data  0.000 ( 0.097)	Loss 2.8497383594512939 (3.3429717377918524)	Acc@1  32.81 ( 27.44)	Acc@5  48.44 ( 42.87)
Epoch: [1][ 50/109]	Time  0.544 ( 0.653)	Data  0.000 ( 0.078)	Loss 3.1040384769439697 (3.3334021054062188)	Acc@1  31.25 ( 27.54)	Acc@5  43.75 ( 43.11)
Epoch: [1][ 60/109]	Time  0.533 ( 0.630)	Data  0.000 ( 0.065)	Loss 2.9475405216217041 (3.3214703817836573)	Acc@1  34.38 ( 27.66)	Acc@5  48.44 ( 43.31)
Epoch: [1][ 70/109]	Time  0.612 ( 0.635)	Data  0.000 ( 0.056)	Loss 2.8999042510986328 (3.2974241753699074)	Acc@1  35.94 ( 27.82)	Acc@5  53.12 ( 44.10)
Epoch: [1][ 80/109]	Time  0.490 ( 0.623)	Data  0.000 ( 0.049)	Loss 3.3522093296051025 (3.2802783236091519)	Acc@1  28.12 ( 27.99)	Acc@5  48.44 ( 44.60)
Epoch: [1][ 90/109]	Time  0.485 ( 0.617)	Data  0.000 ( 0.044)	Loss 3.2381062507629395 (3.2664927440685232)	Acc@1  31.25 ( 28.16)	Acc@5  48.44 ( 44.97)
Epoch: [1][100/109]	Time  0.563 ( 0.608)	Data  0.001 ( 0.040)	Loss 3.1055104732513428 (3.2611781016434773)	Acc@1  35.94 ( 28.30)	Acc@5  46.88 ( 45.13)
epoch: 1, Avg_Loss 3.2655871417544304
Test: [ 0/28]	Time  4.991 ( 4.991)	Loss 3.7136e+00 (3.7136e+00)	Acc@1  15.62 ( 15.62)	Acc@5  34.38 ( 34.38)
Test: [10/28]	Time  0.188 ( 0.617)	Loss 3.6443e+00 (3.6228e+00)	Acc@1  17.19 ( 17.90)	Acc@5  39.06 ( 37.36)
Test: [20/28]	Time  0.133 ( 0.389)	Loss 3.6196e+00 (3.5709e+00)	Acc@1  28.12 ( 20.24)	Acc@5  32.81 ( 38.76)
 * Acc@1 19.921 Acc@5 37.985
lr 0.001
Epoch: [2][  0/109]	Time  6.429 ( 6.429)	Data  5.821 ( 5.821)	Loss 2.9278252124786377 (2.9278252124786377)	Acc@1  39.06 ( 39.06)	Acc@5  51.56 ( 51.56)
Epoch: [2][ 10/109]	Time  0.500 ( 1.111)	Data  0.000 ( 0.545)	Loss 3.1777863502502441 (3.0698665055361660)	Acc@1  32.81 ( 32.95)	Acc@5  48.44 ( 49.72)
Epoch: [2][ 20/109]	Time  1.028 ( 0.915)	Data  0.000 ( 0.286)	Loss 3.0220544338226318 (3.0654149509611583)	Acc@1  29.69 ( 31.55)	Acc@5  48.44 ( 49.40)
Epoch: [2][ 30/109]	Time  0.839 ( 0.896)	Data  0.000 ( 0.194)	Loss 2.6557698249816895 (3.0099789173372331)	Acc@1  37.50 ( 33.11)	Acc@5  57.81 ( 50.66)
Epoch: [2][ 40/109]	Time  0.586 ( 0.827)	Data  0.000 ( 0.147)	Loss 3.0173523426055908 (3.0051909307154214)	Acc@1  34.38 ( 32.66)	Acc@5  56.25 ( 51.37)
Epoch: [2][ 50/109]	Time  0.509 ( 0.773)	Data  0.000 ( 0.118)	Loss 3.1094198226928711 (3.0254058744393144)	Acc@1  28.12 ( 31.95)	Acc@5  50.00 ( 50.43)
Epoch: [2][ 60/109]	Time  0.840 ( 0.755)	Data  0.001 ( 0.099)	Loss 2.8859188556671143 (3.0039978965384062)	Acc@1  31.25 ( 32.07)	Acc@5  59.38 ( 50.85)
Epoch: [2][ 70/109]	Time  0.600 ( 0.740)	Data  0.001 ( 0.085)	Loss 2.5146620273590088 (2.9959808705558237)	Acc@1  40.62 ( 31.98)	Acc@5  62.50 ( 50.75)
Epoch: [2][ 80/109]	Time  0.504 ( 0.720)	Data  0.000 ( 0.074)	Loss 3.3963825702667236 (2.9883322097637035)	Acc@1  32.81 ( 32.08)	Acc@5  46.88 ( 50.87)
Epoch: [2][ 90/109]	Time  1.355 ( 0.711)	Data  0.001 ( 0.066)	Loss 2.7929368019104004 (2.9740899997753103)	Acc@1  35.94 ( 32.30)	Acc@5  53.12 ( 51.03)
Epoch: [2][100/109]	Time  0.941 ( 0.750)	Data  0.001 ( 0.060)	Loss 2.8892409801483154 (2.9684522907332620)	Acc@1  31.25 ( 32.22)	Acc@5  53.12 ( 51.13)
epoch: 2, Avg_Loss 2.9610129846345394
Test: [ 0/28]	Time  5.584 ( 5.584)	Loss 3.3138e+00 (3.3138e+00)	Acc@1  26.56 ( 26.56)	Acc@5  46.88 ( 46.88)
Test: [10/28]	Time  0.198 ( 0.675)	Loss 3.3310e+00 (3.6691e+00)	Acc@1  25.00 ( 19.18)	Acc@5  45.31 ( 37.07)
Test: [20/28]	Time  0.165 ( 0.428)	Loss 3.5940e+00 (3.5622e+00)	Acc@1  12.50 ( 19.27)	Acc@5  45.31 ( 39.58)
 * Acc@1 19.190 Acc@5 40.124
lr 0.001
Epoch: [3][  0/109]	Time  8.137 ( 8.137)	Data  7.521 ( 7.521)	Loss 3.4140336513519287 (3.4140336513519287)	Acc@1  25.00 ( 25.00)	Acc@5  42.19 ( 42.19)
Epoch: [3][ 10/109]	Time  0.599 ( 1.230)	Data  0.000 ( 0.692)	Loss 2.3675005435943604 (2.9616662155498159)	Acc@1  37.50 ( 29.69)	Acc@5  67.19 ( 52.56)
Epoch: [3][ 20/109]	Time  0.500 ( 0.894)	Data  0.000 ( 0.363)	Loss 2.7901577949523926 (2.8593971388680592)	Acc@1  31.25 ( 31.47)	Acc@5  54.69 ( 54.32)
Epoch: [3][ 30/109]	Time  0.555 ( 0.797)	Data  0.000 ( 0.246)	Loss 2.6052219867706299 (2.8294964067397581)	Acc@1  37.50 ( 32.21)	Acc@5  59.38 ( 54.79)
Epoch: [3][ 40/109]	Time  0.502 ( 0.735)	Data  0.000 ( 0.186)	Loss 2.6189668178558350 (2.8127037548437350)	Acc@1  37.50 ( 33.23)	Acc@5  57.81 ( 55.34)
Epoch: [3][ 50/109]	Time  0.580 ( 0.700)	Data  0.000 ( 0.149)	Loss 2.6105506420135498 (2.7976199037888470)	Acc@1  34.38 ( 34.16)	Acc@5  59.38 ( 55.58)
Epoch: [3][ 60/109]	Time  0.562 ( 0.672)	Data  0.000 ( 0.125)	Loss 2.8403043746948242 (2.7893952698004050)	Acc@1  32.81 ( 34.37)	Acc@5  50.00 ( 55.94)
Epoch: [3][ 70/109]	Time  0.586 ( 0.657)	Data  0.000 ( 0.107)	Loss 3.2923665046691895 (2.7837102043796591)	Acc@1  26.56 ( 34.51)	Acc@5  42.19 ( 55.94)
Epoch: [3][ 80/109]	Time  0.576 ( 0.642)	Data  0.000 ( 0.094)	Loss 2.5020759105682373 (2.7716072194370223)	Acc@1  40.62 ( 34.84)	Acc@5  62.50 ( 55.92)
Epoch: [3][ 90/109]	Time  0.718 ( 0.640)	Data  0.000 ( 0.084)	Loss 2.3221137523651123 (2.7627734666342265)	Acc@1  46.88 ( 35.08)	Acc@5  65.62 ( 55.99)
Epoch: [3][100/109]	Time  0.492 ( 0.628)	Data  0.000 ( 0.076)	Loss 2.7600188255310059 (2.7590584424462650)	Acc@1  39.06 ( 35.18)	Acc@5  53.12 ( 56.08)
epoch: 3, Avg_Loss 2.758932664853717
Test: [ 0/28]	Time  4.688 ( 4.688)	Loss 3.0596e+00 (3.0596e+00)	Acc@1  31.25 ( 31.25)	Acc@5  51.56 ( 51.56)
Test: [10/28]	Time  0.242 ( 0.720)	Loss 3.0026e+00 (2.8975e+00)	Acc@1  29.69 ( 32.81)	Acc@5  48.44 ( 51.56)
Test: [20/28]	Time  0.119 ( 0.442)	Loss 3.2889e+00 (2.8922e+00)	Acc@1  26.56 ( 33.56)	Acc@5  45.31 ( 51.34)
 * Acc@1 32.977 Acc@5 51.210
lr 0.001
Epoch: [4][  0/109]	Time  6.024 ( 6.024)	Data  5.390 ( 5.390)	Loss 2.8433513641357422 (2.8433513641357422)	Acc@1  31.25 ( 31.25)	Acc@5  51.56 ( 51.56)
Epoch: [4][ 10/109]	Time  0.505 ( 1.048)	Data  0.001 ( 0.490)	Loss 2.5683920383453369 (2.5558832775462759)	Acc@1  37.50 ( 37.22)	Acc@5  57.81 ( 61.51)
Epoch: [4][ 20/109]	Time  0.709 ( 0.849)	Data  0.000 ( 0.257)	Loss 2.7780587673187256 (2.6369645482017878)	Acc@1  31.25 ( 36.31)	Acc@5  43.75 ( 59.23)
Epoch: [4][ 30/109]	Time  0.943 ( 0.892)	Data  0.001 ( 0.174)	Loss 2.4667148590087891 (2.6188139069464897)	Acc@1  40.62 ( 36.49)	Acc@5  59.38 ( 59.43)
Epoch: [4][ 40/109]	Time  0.895 ( 0.921)	Data  0.000 ( 0.132)	Loss 2.7700302600860596 (2.6106148463923757)	Acc@1  34.38 ( 37.04)	Acc@5  54.69 ( 59.53)
Epoch: [4][ 50/109]	Time  0.686 ( 0.864)	Data  0.000 ( 0.106)	Loss 2.4403855800628662 (2.6187961569019391)	Acc@1  40.62 ( 37.04)	Acc@5  64.06 ( 59.28)
Epoch: [4][ 60/109]	Time  1.616 ( 0.920)	Data  0.000 ( 0.089)	Loss 2.2764105796813965 (2.6001695531313538)	Acc@1  43.75 ( 37.42)	Acc@5  67.19 ( 59.89)
Epoch: [4][ 70/109]	Time  0.510 ( 0.906)	Data  0.000 ( 0.076)	Loss 2.4532482624053955 (2.6012784595220859)	Acc@1  45.31 ( 37.32)	Acc@5  65.62 ( 59.93)
Epoch: [4][ 80/109]	Time  0.502 ( 0.860)	Data  0.000 ( 0.067)	Loss 2.8713009357452393 (2.6072107891977567)	Acc@1  31.25 ( 37.36)	Acc@5  53.12 ( 59.93)
Epoch: [4][ 90/109]	Time  0.537 ( 0.823)	Data  0.000 ( 0.060)	Loss 2.6084063053131104 (2.6117938193646104)	Acc@1  39.06 ( 37.21)	Acc@5  59.38 ( 59.72)
Epoch: [4][100/109]	Time  0.503 ( 0.792)	Data  0.000 ( 0.054)	Loss 2.2133657932281494 (2.5987801646242046)	Acc@1  46.88 ( 37.58)	Acc@5  64.06 ( 59.75)
epoch: 4, Avg_Loss 2.592192588596169
Test: [ 0/28]	Time  4.287 ( 4.287)	Loss 3.4896e+00 (3.4896e+00)	Acc@1  25.00 ( 25.00)	Acc@5  39.06 ( 39.06)
Test: [10/28]	Time  0.388 ( 0.907)	Loss 3.4208e+00 (3.2446e+00)	Acc@1  25.00 ( 27.84)	Acc@5  42.19 ( 47.02)
Test: [20/28]	Time  0.233 ( 0.595)	Loss 3.2086e+00 (3.2324e+00)	Acc@1  28.12 ( 29.46)	Acc@5  45.31 ( 47.40)
 * Acc@1 29.038 Acc@5 47.608
lr 0.001
Epoch: [5][  0/109]	Time  6.525 ( 6.525)	Data  5.751 ( 5.751)	Loss 2.7179121971130371 (2.7179121971130371)	Acc@1  31.25 ( 31.25)	Acc@5  60.94 ( 60.94)
Epoch: [5][ 10/109]	Time  0.603 ( 1.160)	Data  0.001 ( 0.523)	Loss 2.9950087070465088 (2.6287419145757500)	Acc@1  34.38 ( 35.94)	Acc@5  54.69 ( 59.52)
Epoch: [5][ 20/109]	Time  0.620 ( 0.865)	Data  0.000 ( 0.274)	Loss 2.7178788185119629 (2.5584081297829036)	Acc@1  29.69 ( 38.17)	Acc@5  65.62 ( 61.01)
Epoch: [5][ 30/109]	Time  0.897 ( 0.920)	Data  0.000 ( 0.186)	Loss 2.1301629543304443 (2.4836904541138680)	Acc@1  50.00 ( 39.36)	Acc@5  73.44 ( 62.90)
Epoch: [5][ 40/109]	Time  0.494 ( 0.842)	Data  0.000 ( 0.141)	Loss 2.8193786144256592 (2.4540640348341407)	Acc@1  43.75 ( 40.21)	Acc@5  56.25 ( 63.15)
Epoch: [5][ 50/109]	Time  0.490 ( 0.779)	Data  0.000 ( 0.113)	Loss 2.7723331451416016 (2.4622275665694593)	Acc@1  31.25 ( 39.77)	Acc@5  54.69 ( 63.14)
Epoch: [5][ 60/109]	Time  1.335 ( 0.768)	Data  0.001 ( 0.095)	Loss 2.7736103534698486 (2.4645657480740155)	Acc@1  31.25 ( 39.86)	Acc@5  54.69 ( 62.94)
Epoch: [5][ 70/109]	Time  0.497 ( 0.847)	Data  0.000 ( 0.082)	Loss 3.0436744689941406 (2.4670776867530715)	Acc@1  29.69 ( 39.81)	Acc@5  53.12 ( 62.81)
Epoch: [5][ 80/109]	Time  0.522 ( 0.808)	Data  0.000 ( 0.072)	Loss 3.1110301017761230 (2.4851675931318304)	Acc@1  34.38 ( 39.80)	Acc@5  57.81 ( 62.38)
Epoch: [5][ 90/109]	Time  0.549 ( 0.775)	Data  0.000 ( 0.064)	Loss 2.2485754489898682 (2.4818846799515106)	Acc@1  50.00 ( 39.78)	Acc@5  64.06 ( 62.24)
Epoch: [5][100/109]	Time  0.616 ( 0.750)	Data  0.000 ( 0.057)	Loss 2.2120752334594727 (2.4756388864894903)	Acc@1  50.00 ( 39.96)	Acc@5  64.06 ( 62.19)
epoch: 5, Avg_Loss 2.4733949330968596
Test: [ 0/28]	Time  5.200 ( 5.200)	Loss 4.3386e+00 (4.3386e+00)	Acc@1  15.62 ( 15.62)	Acc@5  35.94 ( 35.94)
Test: [10/28]	Time  0.170 ( 0.715)	Loss 3.8170e+00 (3.9108e+00)	Acc@1  31.25 ( 22.44)	Acc@5  43.75 ( 43.61)
Test: [20/28]	Time  0.130 ( 0.440)	Loss 4.2372e+00 (3.9770e+00)	Acc@1  15.62 ( 21.28)	Acc@5  34.38 ( 41.15)
 * Acc@1 21.553 Acc@5 41.418
lr 0.001
Epoch: [6][  0/109]	Time  5.760 ( 5.760)	Data  4.995 ( 4.995)	Loss 2.1243836879730225 (2.1243836879730225)	Acc@1  50.00 ( 50.00)	Acc@5  67.19 ( 67.19)
Epoch: [6][ 10/109]	Time  0.622 ( 1.059)	Data  0.001 ( 0.454)	Loss 2.0870432853698730 (2.1989872780713169)	Acc@1  54.69 ( 45.17)	Acc@5  75.00 ( 68.32)
Epoch: [6][ 20/109]	Time  0.689 ( 0.873)	Data  0.000 ( 0.239)	Loss 2.2564818859100342 (2.2308708599635532)	Acc@1  43.75 ( 45.76)	Acc@5  67.19 ( 67.93)
Epoch: [6][ 30/109]	Time  0.674 ( 0.794)	Data  0.000 ( 0.162)	Loss 2.7024688720703125 (2.3017914218287312)	Acc@1  34.38 ( 44.61)	Acc@5  62.50 ( 66.94)
Epoch: [6][ 40/109]	Time  0.655 ( 0.753)	Data  0.001 ( 0.122)	Loss 2.3200130462646484 (2.3243671161372488)	Acc@1  39.06 ( 44.13)	Acc@5  65.62 ( 66.65)
Epoch: [6][ 50/109]	Time  0.652 ( 0.731)	Data  0.000 ( 0.098)	Loss 2.3882129192352295 (2.2934425321279788)	Acc@1  37.50 ( 44.36)	Acc@5  62.50 ( 67.10)
Epoch: [6][ 60/109]	Time  0.531 ( 0.702)	Data  0.000 ( 0.082)	Loss 2.4945447444915771 (2.3150938241208188)	Acc@1  39.06 ( 43.88)	Acc@5  62.50 ( 66.55)
Epoch: [6][ 70/109]	Time  0.511 ( 0.681)	Data  0.000 ( 0.071)	Loss 2.1390204429626465 (2.2901970416727200)	Acc@1  53.12 ( 44.59)	Acc@5  71.88 ( 66.77)
Epoch: [6][ 80/109]	Time  0.493 ( 0.663)	Data  0.000 ( 0.062)	Loss 1.8823276758193970 (2.2909964131720271)	Acc@1  56.25 ( 44.39)	Acc@5  73.44 ( 66.78)
Epoch: [6][ 90/109]	Time  0.506 ( 0.650)	Data  0.000 ( 0.055)	Loss 2.3234572410583496 (2.3110156530862325)	Acc@1  45.31 ( 43.90)	Acc@5  59.38 ( 66.29)
Epoch: [6][100/109]	Time  0.502 ( 0.636)	Data  0.000 ( 0.050)	Loss 2.0262882709503174 (2.3083714718865878)	Acc@1  43.75 ( 43.97)	Acc@5  73.44 ( 66.35)
epoch: 6, Avg_Loss 2.313164281188895
Test: [ 0/28]	Time  6.000 ( 6.000)	Loss 2.3045e+00 (2.3045e+00)	Acc@1  48.44 ( 48.44)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.197 ( 0.765)	Loss 2.5057e+00 (2.4322e+00)	Acc@1  42.19 ( 41.62)	Acc@5  64.06 ( 66.48)
Test: [20/28]	Time  0.140 ( 0.482)	Loss 2.5873e+00 (2.4361e+00)	Acc@1  32.81 ( 42.04)	Acc@5  59.38 ( 65.33)
 * Acc@1 40.293 Acc@5 64.491
lr 0.001
Epoch: [7][  0/109]	Time  4.565 ( 4.565)	Data  3.913 ( 3.913)	Loss 2.1216759681701660 (2.1216759681701660)	Acc@1  42.19 ( 42.19)	Acc@5  67.19 ( 67.19)
Epoch: [7][ 10/109]	Time  0.493 ( 1.016)	Data  0.001 ( 0.421)	Loss 1.7044396400451660 (2.1678320928053423)	Acc@1  51.56 ( 43.47)	Acc@5  76.56 ( 69.03)
Epoch: [7][ 20/109]	Time  0.509 ( 0.793)	Data  0.000 ( 0.221)	Loss 2.3206517696380615 (2.1347041754495528)	Acc@1  42.19 ( 45.39)	Acc@5  68.75 ( 69.94)
Epoch: [7][ 30/109]	Time  0.574 ( 0.710)	Data  0.000 ( 0.150)	Loss 2.6894283294677734 (2.1573332817323747)	Acc@1  32.81 ( 44.76)	Acc@5  57.81 ( 69.46)
Epoch: [7][ 40/109]	Time  0.657 ( 0.709)	Data  0.000 ( 0.113)	Loss 2.4918611049652100 (2.1769550951515755)	Acc@1  35.94 ( 44.66)	Acc@5  60.94 ( 69.21)
Epoch: [7][ 50/109]	Time  0.515 ( 0.678)	Data  0.000 ( 0.091)	Loss 2.3394823074340820 (2.2030126534256280)	Acc@1  46.88 ( 44.58)	Acc@5  68.75 ( 68.72)
Epoch: [7][ 60/109]	Time  0.553 ( 0.654)	Data  0.000 ( 0.076)	Loss 2.0754046440124512 (2.2048158469747325)	Acc@1  48.44 ( 44.49)	Acc@5  70.31 ( 69.01)
Epoch: [7][ 70/109]	Time  0.573 ( 0.640)	Data  0.000 ( 0.066)	Loss 2.0469756126403809 (2.2124188466810844)	Acc@1  46.88 ( 44.41)	Acc@5  68.75 ( 68.77)
Epoch: [7][ 80/109]	Time  0.507 ( 0.625)	Data  0.000 ( 0.057)	Loss 2.0118877887725830 (2.2032318277123535)	Acc@1  53.12 ( 44.98)	Acc@5  78.12 ( 68.96)
Epoch: [7][ 90/109]	Time  0.488 ( 0.612)	Data  0.000 ( 0.051)	Loss 2.4130601882934570 (2.2134167388245301)	Acc@1  39.06 ( 44.69)	Acc@5  62.50 ( 68.66)
Epoch: [7][100/109]	Time  0.497 ( 0.601)	Data  0.000 ( 0.046)	Loss 1.7089731693267822 (2.2001559498286483)	Acc@1  54.69 ( 44.94)	Acc@5  78.12 ( 68.89)
epoch: 7, Avg_Loss 2.1942106944705366
Test: [ 0/28]	Time  6.968 ( 6.968)	Loss 2.9203e+00 (2.9203e+00)	Acc@1  35.94 ( 35.94)	Acc@5  54.69 ( 54.69)
Test: [10/28]	Time  0.151 ( 0.778)	Loss 2.6910e+00 (2.7408e+00)	Acc@1  34.38 ( 34.38)	Acc@5  59.38 ( 61.22)
Test: [20/28]	Time  0.119 ( 0.471)	Loss 2.5117e+00 (2.7304e+00)	Acc@1  29.69 ( 34.45)	Acc@5  64.06 ( 61.68)
 * Acc@1 34.947 Acc@5 61.283
lr 0.001
Epoch: [8][  0/109]	Time  6.410 ( 6.410)	Data  5.613 ( 5.613)	Loss 2.1360137462615967 (2.1360137462615967)	Acc@1  54.69 ( 54.69)	Acc@5  68.75 ( 68.75)
Epoch: [8][ 10/109]	Time  1.105 ( 1.401)	Data  0.010 ( 0.604)	Loss 1.9253847599029541 (2.1636504585092720)	Acc@1  50.00 ( 47.30)	Acc@5  73.44 ( 69.60)
Epoch: [8][ 20/109]	Time  0.545 ( 0.997)	Data  0.000 ( 0.316)	Loss 1.8893823623657227 (2.1520030044374012)	Acc@1  53.12 ( 48.29)	Acc@5  73.44 ( 69.87)
Epoch: [8][ 30/109]	Time  0.494 ( 0.861)	Data  0.000 ( 0.214)	Loss 2.0578522682189941 (2.1250003960824784)	Acc@1  46.88 ( 47.88)	Acc@5  68.75 ( 70.26)
Epoch: [8][ 40/109]	Time  0.909 ( 0.832)	Data  0.001 ( 0.162)	Loss 1.8760651350021362 (2.1144037799137396)	Acc@1  56.25 ( 48.06)	Acc@5  71.88 ( 70.16)
Epoch: [8][ 50/109]	Time  0.724 ( 0.813)	Data  0.000 ( 0.130)	Loss 2.0434308052062988 (2.0669541358947754)	Acc@1  43.75 ( 48.65)	Acc@5  73.44 ( 70.80)
Epoch: [8][ 60/109]	Time  0.604 ( 0.785)	Data  0.000 ( 0.109)	Loss 2.3884067535400391 (2.0999392564179469)	Acc@1  40.62 ( 47.87)	Acc@5  64.06 ( 70.26)
Epoch: [8][ 70/109]	Time  0.579 ( 0.760)	Data  0.000 ( 0.094)	Loss 2.3766241073608398 (2.1132288801837973)	Acc@1  35.94 ( 47.51)	Acc@5  65.62 ( 70.18)
Epoch: [8][ 80/109]	Time  0.915 ( 0.767)	Data  0.000 ( 0.082)	Loss 2.0699439048767090 (2.0988307514308411)	Acc@1  51.56 ( 47.82)	Acc@5  71.88 ( 70.41)
Epoch: [8][ 90/109]	Time  0.516 ( 0.762)	Data  0.000 ( 0.073)	Loss 2.0524950027465820 (2.0808802188097775)	Acc@1  48.44 ( 48.18)	Acc@5  76.56 ( 71.02)
Epoch: [8][100/109]	Time  0.572 ( 0.739)	Data  0.000 ( 0.066)	Loss 1.9818478822708130 (2.0692406550492390)	Acc@1  50.00 ( 48.39)	Acc@5  64.06 ( 71.15)
epoch: 8, Avg_Loss 2.0690844890174516
Test: [ 0/28]	Time  5.040 ( 5.040)	Loss 2.5096e+00 (2.5096e+00)	Acc@1  40.62 ( 40.62)	Acc@5  68.75 ( 68.75)
Test: [10/28]	Time  0.153 ( 0.725)	Loss 2.5814e+00 (2.7719e+00)	Acc@1  40.62 ( 34.94)	Acc@5  64.06 ( 58.95)
Test: [20/28]	Time  0.128 ( 0.442)	Loss 2.3486e+00 (2.8110e+00)	Acc@1  45.31 ( 33.48)	Acc@5  64.06 ( 58.63)
 * Acc@1 33.877 Acc@5 57.850
lr 0.001
Epoch: [9][  0/109]	Time  4.948 ( 4.948)	Data  4.212 ( 4.212)	Loss 1.8336029052734375 (1.8336029052734375)	Acc@1  51.56 ( 51.56)	Acc@5  75.00 ( 75.00)
Epoch: [9][ 10/109]	Time  1.174 ( 1.167)	Data  0.002 ( 0.393)	Loss 1.9418904781341553 (2.0443482615730981)	Acc@1  48.44 ( 46.88)	Acc@5  75.00 ( 72.87)
Epoch: [9][ 20/109]	Time  0.512 ( 0.961)	Data  0.000 ( 0.206)	Loss 2.0168886184692383 (1.9946763515472412)	Acc@1  50.00 ( 48.88)	Acc@5  71.88 ( 73.44)
Epoch: [9][ 30/109]	Time  0.674 ( 0.840)	Data  0.000 ( 0.140)	Loss 2.0815396308898926 (1.9544532837406281)	Acc@1  43.75 ( 49.40)	Acc@5  71.88 ( 74.09)
Epoch: [9][ 40/109]	Time  0.492 ( 0.775)	Data  0.000 ( 0.106)	Loss 1.9244202375411987 (1.9742112566785115)	Acc@1  56.25 ( 49.62)	Acc@5  70.31 ( 73.89)
Epoch: [9][ 50/109]	Time  1.004 ( 0.744)	Data  0.000 ( 0.085)	Loss 2.3299155235290527 (1.9865413015963984)	Acc@1  40.62 ( 49.30)	Acc@5  65.62 ( 73.81)
Epoch: [9][ 60/109]	Time  1.124 ( 0.790)	Data  0.001 ( 0.071)	Loss 2.4833173751831055 (1.9963773039520765)	Acc@1  39.06 ( 48.98)	Acc@5  59.38 ( 73.23)
Epoch: [9][ 70/109]	Time  0.596 ( 0.754)	Data  0.000 ( 0.061)	Loss 1.7015018463134766 (1.9784060397618253)	Acc@1  53.12 ( 49.41)	Acc@5  73.44 ( 73.31)
Epoch: [9][ 80/109]	Time  0.496 ( 0.726)	Data  0.000 ( 0.054)	Loss 1.8973408937454224 (1.9676667319403753)	Acc@1  50.00 ( 49.73)	Acc@5  76.56 ( 73.61)
Epoch: [9][ 90/109]	Time  0.552 ( 0.703)	Data  0.000 ( 0.048)	Loss 1.6985747814178467 (1.9588400361302134)	Acc@1  59.38 ( 50.02)	Acc@5  79.69 ( 73.78)
Epoch: [9][100/109]	Time  0.572 ( 0.700)	Data  0.000 ( 0.043)	Loss 1.8722083568572998 (1.9681872105834508)	Acc@1  50.00 ( 49.81)	Acc@5  79.69 ( 73.56)
epoch: 9, Avg_Loss 1.9685205888310704
Test: [ 0/28]	Time  5.730 ( 5.730)	Loss 2.6328e+00 (2.6328e+00)	Acc@1  40.62 ( 40.62)	Acc@5  67.19 ( 67.19)
Test: [10/28]	Time  0.131 ( 0.700)	Loss 2.4095e+00 (2.4885e+00)	Acc@1  35.94 ( 41.48)	Acc@5  64.06 ( 64.77)
Test: [20/28]	Time  0.138 ( 0.442)	Loss 2.2902e+00 (2.5157e+00)	Acc@1  35.94 ( 38.84)	Acc@5  73.44 ( 65.48)
 * Acc@1 38.886 Acc@5 65.110
lr 0.001
Epoch: [10][  0/109]	Time  5.205 ( 5.205)	Data  4.533 ( 4.533)	Loss 1.7227176427841187 (1.7227176427841187)	Acc@1  54.69 ( 54.69)	Acc@5  75.00 ( 75.00)
Epoch: [10][ 10/109]	Time  0.488 ( 1.113)	Data  0.001 ( 0.523)	Loss 1.7889779806137085 (1.8878390355543657)	Acc@1  51.56 ( 51.70)	Acc@5  76.56 ( 75.28)
Epoch: [10][ 20/109]	Time  0.539 ( 0.848)	Data  0.000 ( 0.274)	Loss 1.9105224609375000 (1.8320594628651936)	Acc@1  53.12 ( 52.38)	Acc@5  71.88 ( 77.01)
Epoch: [10][ 30/109]	Time  0.546 ( 0.766)	Data  0.000 ( 0.186)	Loss 2.3310539722442627 (1.8539874361407371)	Acc@1  50.00 ( 51.92)	Acc@5  67.19 ( 76.21)
Epoch: [10][ 40/109]	Time  1.095 ( 0.749)	Data  0.000 ( 0.140)	Loss 1.8678026199340820 (1.8240768444247362)	Acc@1  51.56 ( 52.82)	Acc@5  76.56 ( 76.71)
Epoch: [10][ 50/109]	Time  1.100 ( 0.784)	Data  0.001 ( 0.113)	Loss 2.1914556026458740 (1.8601080366209441)	Acc@1  51.56 ( 52.39)	Acc@5  68.75 ( 75.89)
Epoch: [10][ 60/109]	Time  1.299 ( 0.825)	Data  0.000 ( 0.095)	Loss 2.5874161720275879 (1.8786849741075859)	Acc@1  35.94 ( 51.82)	Acc@5  67.19 ( 75.59)
Epoch: [10][ 70/109]	Time  0.491 ( 0.787)	Data  0.000 ( 0.082)	Loss 2.0980966091156006 (1.8837341204495497)	Acc@1  50.00 ( 51.89)	Acc@5  73.44 ( 75.55)
Epoch: [10][ 80/109]	Time  0.475 ( 0.753)	Data  0.000 ( 0.072)	Loss 2.2632281780242920 (1.8933442345371954)	Acc@1  46.88 ( 51.81)	Acc@5  64.06 ( 75.10)
Epoch: [10][ 90/109]	Time  0.493 ( 0.725)	Data  0.000 ( 0.064)	Loss 1.9143867492675781 (1.8961347800034742)	Acc@1  43.75 ( 51.61)	Acc@5  78.12 ( 75.00)
Epoch: [10][100/109]	Time  0.561 ( 0.704)	Data  0.000 ( 0.057)	Loss 1.5577685832977295 (1.9007388105486880)	Acc@1  59.38 ( 51.42)	Acc@5  79.69 ( 74.88)
epoch: 10, Avg_Loss 1.9016306126883271
Test: [ 0/28]	Time  7.657 ( 7.657)	Loss 2.8355e+00 (2.8355e+00)	Acc@1  37.50 ( 37.50)	Acc@5  57.81 ( 57.81)
Test: [10/28]	Time  0.156 ( 0.871)	Loss 2.8538e+00 (2.6267e+00)	Acc@1  40.62 ( 40.34)	Acc@5  56.25 ( 61.36)
Test: [20/28]	Time  0.133 ( 0.526)	Loss 2.6774e+00 (2.6209e+00)	Acc@1  37.50 ( 39.14)	Acc@5  62.50 ( 62.05)
 * Acc@1 39.955 Acc@5 62.577
lr 0.001
Epoch: [11][  0/109]	Time  6.581 ( 6.581)	Data  5.988 ( 5.988)	Loss 1.9028080701828003 (1.9028080701828003)	Acc@1  50.00 ( 50.00)	Acc@5  76.56 ( 76.56)
Epoch: [11][ 10/109]	Time  0.984 ( 1.323)	Data  0.001 ( 0.545)	Loss 1.5701287984848022 (1.8374387892809780)	Acc@1  57.81 ( 52.13)	Acc@5  87.50 ( 76.70)
Epoch: [11][ 20/109]	Time  1.187 ( 1.091)	Data  0.001 ( 0.286)	Loss 1.7005304098129272 (1.8470625082651775)	Acc@1  54.69 ( 52.53)	Acc@5  75.00 ( 76.79)
Epoch: [11][ 30/109]	Time  0.581 ( 0.916)	Data  0.000 ( 0.194)	Loss 1.9032752513885498 (1.8432805691995928)	Acc@1  50.00 ( 53.38)	Acc@5  73.44 ( 76.92)
Epoch: [11][ 40/109]	Time  0.542 ( 0.829)	Data  0.000 ( 0.146)	Loss 1.7498364448547363 (1.8305138233231335)	Acc@1  54.69 ( 53.39)	Acc@5  73.44 ( 77.13)
Epoch: [11][ 50/109]	Time  0.775 ( 0.778)	Data  0.000 ( 0.118)	Loss 1.9659723043441772 (1.8391875542846381)	Acc@1  50.00 ( 52.76)	Acc@5  71.88 ( 76.81)
Epoch: [11][ 60/109]	Time  0.617 ( 0.779)	Data  0.000 ( 0.099)	Loss 1.7224881649017334 (1.8231243989506707)	Acc@1  57.81 ( 53.33)	Acc@5  73.44 ( 76.82)
Epoch: [11][ 70/109]	Time  0.574 ( 0.760)	Data  0.000 ( 0.085)	Loss 1.7398798465728760 (1.8248051556063369)	Acc@1  50.00 ( 52.99)	Acc@5  76.56 ( 76.83)
Epoch: [11][ 80/109]	Time  0.487 ( 0.730)	Data  0.000 ( 0.074)	Loss 1.7699558734893799 (1.8086868097752700)	Acc@1  51.56 ( 53.32)	Acc@5  79.69 ( 77.06)
Epoch: [11][ 90/109]	Time  0.590 ( 0.707)	Data  0.000 ( 0.066)	Loss 1.7418636083602905 (1.8254739714192820)	Acc@1  54.69 ( 53.16)	Acc@5  75.00 ( 76.79)
Epoch: [11][100/109]	Time  0.592 ( 0.695)	Data  0.000 ( 0.060)	Loss 2.3253448009490967 (1.8268715320247235)	Acc@1  50.00 ( 53.33)	Acc@5  64.06 ( 76.52)
epoch: 11, Avg_Loss 1.8229129095689967
Test: [ 0/28]	Time  6.457 ( 6.457)	Loss 2.7819e+00 (2.7819e+00)	Acc@1  31.25 ( 31.25)	Acc@5  53.12 ( 53.12)
Test: [10/28]	Time  0.206 ( 0.742)	Loss 2.2620e+00 (2.3634e+00)	Acc@1  32.81 ( 42.33)	Acc@5  71.88 ( 66.34)
Test: [20/28]	Time  0.138 ( 0.455)	Loss 2.2774e+00 (2.3058e+00)	Acc@1  46.88 ( 43.38)	Acc@5  68.75 ( 67.71)
 * Acc@1 43.613 Acc@5 67.923
lr 0.001
Epoch: [12][  0/109]	Time  6.617 ( 6.617)	Data  5.998 ( 5.998)	Loss 2.1134788990020752 (2.1134788990020752)	Acc@1  45.31 ( 45.31)	Acc@5  67.19 ( 67.19)
Epoch: [12][ 10/109]	Time  0.510 ( 1.099)	Data  0.001 ( 0.546)	Loss 1.7766052484512329 (1.6868829185312444)	Acc@1  50.00 ( 54.69)	Acc@5  73.44 ( 78.98)
Epoch: [12][ 20/109]	Time  0.508 ( 0.881)	Data  0.000 ( 0.286)	Loss 2.0335805416107178 (1.7313480944860549)	Acc@1  50.00 ( 54.84)	Acc@5  68.75 ( 78.27)
Epoch: [12][ 30/109]	Time  0.492 ( 0.767)	Data  0.000 ( 0.194)	Loss 1.6745575666427612 (1.7084865070158435)	Acc@1  46.88 ( 55.04)	Acc@5  81.25 ( 78.73)
Epoch: [12][ 40/109]	Time  0.550 ( 0.715)	Data  0.000 ( 0.147)	Loss 1.9064055681228638 (1.6922069235545834)	Acc@1  50.00 ( 55.75)	Acc@5  73.44 ( 79.15)
Epoch: [12][ 50/109]	Time  0.482 ( 0.676)	Data  0.000 ( 0.118)	Loss 1.9140959978103638 (1.7249190550224454)	Acc@1  43.75 ( 55.51)	Acc@5  76.56 ( 78.34)
Epoch: [12][ 60/109]	Time  0.732 ( 0.671)	Data  0.000 ( 0.099)	Loss 1.8799742460250854 (1.7313610510747941)	Acc@1  50.00 ( 55.25)	Acc@5  71.88 ( 78.30)
Epoch: [12][ 70/109]	Time  0.879 ( 0.678)	Data  0.000 ( 0.085)	Loss 1.6398684978485107 (1.7270382458055522)	Acc@1  57.81 ( 55.13)	Acc@5  78.12 ( 78.57)
Epoch: [12][ 80/109]	Time  0.656 ( 0.680)	Data  0.000 ( 0.074)	Loss 2.0320801734924316 (1.7309456784048198)	Acc@1  43.75 ( 55.15)	Acc@5  76.56 ( 78.47)
Epoch: [12][ 90/109]	Time  0.506 ( 0.662)	Data  0.000 ( 0.066)	Loss 1.7242614030838013 (1.7377415070166955)	Acc@1  54.69 ( 55.22)	Acc@5  78.12 ( 78.16)
Epoch: [12][100/109]	Time  0.497 ( 0.646)	Data  0.000 ( 0.060)	Loss 1.3636605739593506 (1.7321077561614537)	Acc@1  64.06 ( 55.28)	Acc@5  85.94 ( 78.23)
epoch: 12, Avg_Loss 1.7291978521084568
Test: [ 0/28]	Time  6.049 ( 6.049)	Loss 2.2917e+00 (2.2917e+00)	Acc@1  39.06 ( 39.06)	Acc@5  67.19 ( 67.19)
Test: [10/28]	Time  0.170 ( 0.708)	Loss 2.1176e+00 (2.3280e+00)	Acc@1  46.88 ( 43.75)	Acc@5  73.44 ( 67.90)
Test: [20/28]	Time  0.119 ( 0.433)	Loss 2.6233e+00 (2.2796e+00)	Acc@1  43.75 ( 45.61)	Acc@5  64.06 ( 69.72)
 * Acc@1 44.344 Acc@5 68.711
lr 0.001
Epoch: [13][  0/109]	Time  6.959 ( 6.959)	Data  5.402 ( 5.402)	Loss 1.4659734964370728 (1.4659734964370728)	Acc@1  60.94 ( 60.94)	Acc@5  81.25 ( 81.25)
Epoch: [13][ 10/109]	Time  0.524 ( 1.207)	Data  0.001 ( 0.491)	Loss 1.7408422231674194 (1.6503071134740657)	Acc@1  57.81 ( 57.95)	Acc@5  71.88 ( 79.55)
Epoch: [13][ 20/109]	Time  0.498 ( 0.877)	Data  0.000 ( 0.258)	Loss 1.4824988842010498 (1.6313623133159818)	Acc@1  68.75 ( 58.18)	Acc@5  84.38 ( 80.43)
Epoch: [13][ 30/109]	Time  0.539 ( 0.765)	Data  0.000 ( 0.175)	Loss 2.3880939483642578 (1.6528075472001107)	Acc@1  43.75 ( 58.22)	Acc@5  60.94 ( 79.59)
Epoch: [13][ 40/109]	Time  0.520 ( 0.713)	Data  0.000 ( 0.132)	Loss 1.6736943721771240 (1.6463293156972745)	Acc@1  53.12 ( 58.31)	Acc@5  79.69 ( 79.31)
Epoch: [13][ 50/109]	Time  0.577 ( 0.678)	Data  0.000 ( 0.106)	Loss 1.8703699111938477 (1.6308792852887921)	Acc@1  53.12 ( 58.52)	Acc@5  71.88 ( 79.53)
Epoch: [13][ 60/109]	Time  0.523 ( 0.667)	Data  0.000 ( 0.089)	Loss 1.4400734901428223 (1.6249234793616123)	Acc@1  57.81 ( 58.63)	Acc@5  81.25 ( 79.79)
Epoch: [13][ 70/109]	Time  0.740 ( 0.660)	Data  0.000 ( 0.076)	Loss 1.1660968065261841 (1.6222212784726855)	Acc@1  68.75 ( 58.65)	Acc@5  89.06 ( 80.02)
Epoch: [13][ 80/109]	Time  0.698 ( 0.659)	Data  0.000 ( 0.067)	Loss 1.9126639366149902 (1.6444042464833202)	Acc@1  57.81 ( 58.33)	Acc@5  70.31 ( 79.69)
Epoch: [13][ 90/109]	Time  0.609 ( 0.651)	Data  0.000 ( 0.060)	Loss 1.8261680603027344 (1.6508578887352576)	Acc@1  50.00 ( 57.93)	Acc@5  73.44 ( 79.70)
Epoch: [13][100/109]	Time  0.502 ( 0.643)	Data  0.000 ( 0.054)	Loss 1.6762056350708008 (1.6576104777874332)	Acc@1  54.69 ( 57.81)	Acc@5  81.25 ( 79.63)
epoch: 13, Avg_Loss 1.6551265432200302
Test: [ 0/28]	Time  5.122 ( 5.122)	Loss 2.3643e+00 (2.3643e+00)	Acc@1  46.88 ( 46.88)	Acc@5  70.31 ( 70.31)
Test: [10/28]	Time  0.123 ( 0.688)	Loss 2.4876e+00 (2.3130e+00)	Acc@1  42.19 ( 45.88)	Acc@5  65.62 ( 70.60)
Test: [20/28]	Time  0.150 ( 0.421)	Loss 2.2086e+00 (2.2781e+00)	Acc@1  42.19 ( 46.13)	Acc@5  70.31 ( 70.61)
 * Acc@1 47.946 Acc@5 71.525
lr 0.001
Epoch: [14][  0/109]	Time  6.150 ( 6.150)	Data  5.473 ( 5.473)	Loss 1.4951500892639160 (1.4951500892639160)	Acc@1  67.19 ( 67.19)	Acc@5  82.81 ( 82.81)
Epoch: [14][ 10/109]	Time  0.519 ( 1.211)	Data  0.001 ( 0.498)	Loss 1.3591747283935547 (1.4777352376417681)	Acc@1  60.94 ( 61.08)	Acc@5  87.50 ( 81.82)
Epoch: [14][ 20/109]	Time  0.616 ( 0.899)	Data  0.000 ( 0.261)	Loss 1.7600616216659546 (1.5380595014208840)	Acc@1  53.12 ( 59.45)	Acc@5  73.44 ( 81.70)
Epoch: [14][ 30/109]	Time  0.497 ( 0.777)	Data  0.000 ( 0.177)	Loss 1.7811319828033447 (1.5747178754498881)	Acc@1  50.00 ( 58.37)	Acc@5  73.44 ( 80.59)
Epoch: [14][ 40/109]	Time  0.661 ( 0.739)	Data  0.000 ( 0.134)	Loss 1.6744461059570312 (1.5757966274168433)	Acc@1  59.38 ( 58.16)	Acc@5  79.69 ( 80.83)
Epoch: [14][ 50/109]	Time  0.907 ( 0.770)	Data  0.002 ( 0.108)	Loss 1.5151005983352661 (1.6027862254311056)	Acc@1  59.38 ( 57.54)	Acc@5  79.69 ( 80.67)
Epoch: [14][ 60/109]	Time  0.593 ( 0.729)	Data  0.000 ( 0.090)	Loss 1.8496319055557251 (1.6094950789310893)	Acc@1  53.12 ( 57.33)	Acc@5  79.69 ( 80.48)
Epoch: [14][ 70/109]	Time  0.625 ( 0.714)	Data  0.000 ( 0.077)	Loss 1.3332202434539795 (1.6038401345132103)	Acc@1  62.50 ( 57.61)	Acc@5  85.94 ( 80.61)
Epoch: [14][ 80/109]	Time  0.500 ( 0.696)	Data  0.000 ( 0.068)	Loss 1.6176258325576782 (1.5993567234204140)	Acc@1  60.94 ( 57.70)	Acc@5  79.69 ( 80.86)
Epoch: [14][ 90/109]	Time  0.504 ( 0.675)	Data  0.000 ( 0.060)	Loss 1.8444581031799316 (1.6006366643276844)	Acc@1  53.12 ( 57.86)	Acc@5  75.00 ( 80.96)
Epoch: [14][100/109]	Time  0.485 ( 0.657)	Data  0.000 ( 0.055)	Loss 1.4859797954559326 (1.5885990622020003)	Acc@1  65.62 ( 58.20)	Acc@5  79.69 ( 81.02)
epoch: 14, Avg_Loss 1.5859663125571855
Test: [ 0/28]	Time  4.610 ( 4.610)	Loss 2.1479e+00 (2.1479e+00)	Acc@1  48.44 ( 48.44)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.124 ( 0.716)	Loss 2.3162e+00 (2.3475e+00)	Acc@1  50.00 ( 43.47)	Acc@5  67.19 ( 68.89)
Test: [20/28]	Time  0.121 ( 0.439)	Loss 2.1212e+00 (2.3071e+00)	Acc@1  48.44 ( 43.97)	Acc@5  76.56 ( 69.42)
 * Acc@1 42.656 Acc@5 69.162
lr 0.001
Epoch: [15][  0/109]	Time  4.608 ( 4.608)	Data  3.997 ( 3.997)	Loss 1.4163063764572144 (1.4163063764572144)	Acc@1  59.38 ( 59.38)	Acc@5  84.38 ( 84.38)
Epoch: [15][ 10/109]	Time  0.496 ( 0.985)	Data  0.001 ( 0.364)	Loss 1.4487415552139282 (1.6053811528465964)	Acc@1  56.25 ( 55.68)	Acc@5  89.06 ( 82.95)
Epoch: [15][ 20/109]	Time  0.490 ( 0.769)	Data  0.001 ( 0.191)	Loss 1.4125045537948608 (1.5714299565269834)	Acc@1  57.81 ( 56.99)	Acc@5  87.50 ( 82.59)
Epoch: [15][ 30/109]	Time  0.522 ( 0.691)	Data  0.000 ( 0.129)	Loss 1.4602208137512207 (1.5745858761572069)	Acc@1  60.94 ( 57.56)	Acc@5  85.94 ( 81.91)
Epoch: [15][ 40/109]	Time  0.597 ( 0.658)	Data  0.000 ( 0.098)	Loss 2.1995449066162109 (1.5778163584267222)	Acc@1  46.88 ( 58.19)	Acc@5  70.31 ( 81.90)
Epoch: [15][ 50/109]	Time  1.742 ( 0.687)	Data  0.001 ( 0.079)	Loss 1.7614552974700928 (1.5849128961563110)	Acc@1  53.12 ( 57.97)	Acc@5  79.69 ( 81.74)
Epoch: [15][ 60/109]	Time  0.683 ( 0.718)	Data  0.000 ( 0.066)	Loss 1.3777061700820923 (1.5849808415428537)	Acc@1  59.38 ( 57.97)	Acc@5  84.38 ( 81.61)
Epoch: [15][ 70/109]	Time  0.560 ( 0.704)	Data  0.000 ( 0.057)	Loss 1.6180659532546997 (1.5781290799799099)	Acc@1  54.69 ( 58.08)	Acc@5  84.38 ( 81.58)
Epoch: [15][ 80/109]	Time  0.500 ( 0.684)	Data  0.000 ( 0.050)	Loss 1.2895985841751099 (1.5732536934040211)	Acc@1  65.62 ( 58.24)	Acc@5  85.94 ( 81.85)
Epoch: [15][ 90/109]	Time  0.510 ( 0.664)	Data  0.000 ( 0.044)	Loss 1.1203540563583374 (1.5715731264470698)	Acc@1  75.00 ( 58.34)	Acc@5  87.50 ( 81.71)
Epoch: [15][100/109]	Time  0.496 ( 0.651)	Data  0.000 ( 0.040)	Loss 1.2127659320831299 (1.5606633755240109)	Acc@1  71.88 ( 58.79)	Acc@5  85.94 ( 81.75)
epoch: 15, Avg_Loss 1.555871532597673
Test: [ 0/28]	Time  5.748 ( 5.748)	Loss 2.4534e+00 (2.4534e+00)	Acc@1  35.94 ( 35.94)	Acc@5  67.19 ( 67.19)
Test: [10/28]	Time  0.120 ( 0.754)	Loss 2.2814e+00 (2.3201e+00)	Acc@1  46.88 ( 44.74)	Acc@5  62.50 ( 68.04)
Test: [20/28]	Time  0.127 ( 0.456)	Loss 2.3656e+00 (2.2295e+00)	Acc@1  46.88 ( 47.32)	Acc@5  67.19 ( 69.05)
 * Acc@1 45.920 Acc@5 69.218
lr 0.001
Epoch: [16][  0/109]	Time  5.968 ( 5.968)	Data  5.278 ( 5.278)	Loss 1.3712695837020874 (1.3712695837020874)	Acc@1  57.81 ( 57.81)	Acc@5  90.62 ( 90.62)
Epoch: [16][ 10/109]	Time  0.582 ( 1.055)	Data  0.001 ( 0.480)	Loss 1.5874178409576416 (1.5255099860104648)	Acc@1  51.56 ( 60.09)	Acc@5  79.69 ( 82.39)
Epoch: [16][ 20/109]	Time  0.534 ( 0.799)	Data  0.000 ( 0.252)	Loss 1.1910948753356934 (1.4568476790473575)	Acc@1  70.31 ( 61.68)	Acc@5  84.38 ( 83.26)
Epoch: [16][ 30/109]	Time  0.558 ( 0.720)	Data  0.000 ( 0.170)	Loss 1.2301445007324219 (1.4710906474821028)	Acc@1  71.88 ( 61.95)	Acc@5  90.62 ( 82.71)
Epoch: [16][ 40/109]	Time  0.987 ( 0.714)	Data  0.000 ( 0.129)	Loss 1.4998346567153931 (1.4817210842923421)	Acc@1  65.62 ( 61.97)	Acc@5  82.81 ( 82.81)
Epoch: [16][ 50/109]	Time  0.715 ( 0.718)	Data  0.000 ( 0.104)	Loss 1.8286901712417603 (1.5005463618858188)	Acc@1  53.12 ( 61.73)	Acc@5  82.81 ( 82.54)
Epoch: [16][ 60/109]	Time  0.634 ( 0.711)	Data  0.000 ( 0.087)	Loss 1.2909204959869385 (1.4816498697781173)	Acc@1  64.06 ( 62.04)	Acc@5  82.81 ( 82.48)
Epoch: [16][ 70/109]	Time  0.544 ( 0.694)	Data  0.000 ( 0.075)	Loss 1.6690138578414917 (1.4825177881079661)	Acc@1  56.25 ( 61.97)	Acc@5  73.44 ( 82.35)
Epoch: [16][ 80/109]	Time  0.773 ( 0.690)	Data  0.000 ( 0.065)	Loss 1.4311920404434204 (1.4808999770953331)	Acc@1  56.25 ( 61.82)	Acc@5  82.81 ( 82.35)
Epoch: [16][ 90/109]	Time  0.485 ( 0.671)	Data  0.000 ( 0.058)	Loss 1.5168482065200806 (1.4794181153014465)	Acc@1  62.50 ( 61.73)	Acc@5  78.12 ( 82.42)
Epoch: [16][100/109]	Time  0.490 ( 0.654)	Data  0.000 ( 0.053)	Loss 1.3281831741333008 (1.4764668174309306)	Acc@1  64.06 ( 61.87)	Acc@5  84.38 ( 82.50)
epoch: 16, Avg_Loss 1.4702553858450793
Test: [ 0/28]	Time  5.448 ( 5.448)	Loss 1.9961e+00 (1.9961e+00)	Acc@1  53.12 ( 53.12)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.146 ( 0.644)	Loss 2.5219e+00 (2.0645e+00)	Acc@1  35.94 ( 47.30)	Acc@5  70.31 ( 74.86)
Test: [20/28]	Time  0.128 ( 0.405)	Loss 2.2544e+00 (2.0298e+00)	Acc@1  45.31 ( 48.29)	Acc@5  71.88 ( 74.48)
 * Acc@1 48.621 Acc@5 74.395
lr 0.001
Epoch: [17][  0/109]	Time  6.085 ( 6.085)	Data  5.123 ( 5.123)	Loss 1.0418092012405396 (1.0418092012405396)	Acc@1  64.06 ( 64.06)	Acc@5  92.19 ( 92.19)
Epoch: [17][ 10/109]	Time  0.529 ( 1.080)	Data  0.001 ( 0.466)	Loss 1.0839494466781616 (1.3534971909089522)	Acc@1  68.75 ( 61.79)	Acc@5  90.62 ( 87.07)
Epoch: [17][ 20/109]	Time  0.504 ( 0.841)	Data  0.000 ( 0.245)	Loss 1.5329804420471191 (1.3794419595173426)	Acc@1  64.06 ( 62.50)	Acc@5  82.81 ( 85.71)
Epoch: [17][ 30/109]	Time  0.491 ( 0.760)	Data  0.000 ( 0.166)	Loss 1.2521018981933594 (1.3877010153185936)	Acc@1  65.62 ( 62.65)	Acc@5  87.50 ( 85.69)
Epoch: [17][ 40/109]	Time  0.588 ( 0.741)	Data  0.000 ( 0.125)	Loss 1.7027584314346313 (1.4032720734433430)	Acc@1  56.25 ( 62.73)	Acc@5  82.81 ( 85.29)
Epoch: [17][ 50/109]	Time  0.569 ( 0.707)	Data  0.000 ( 0.101)	Loss 1.5333541631698608 (1.4278229288026398)	Acc@1  60.94 ( 62.35)	Acc@5  81.25 ( 84.80)
Epoch: [17][ 60/109]	Time  0.517 ( 0.674)	Data  0.000 ( 0.084)	Loss 1.5934631824493408 (1.4220714666804328)	Acc@1  65.62 ( 62.58)	Acc@5  79.69 ( 84.68)
Epoch: [17][ 70/109]	Time  0.539 ( 0.662)	Data  0.000 ( 0.073)	Loss 1.1409096717834473 (1.4190499513921604)	Acc@1  68.75 ( 62.61)	Acc@5  85.94 ( 84.66)
Epoch: [17][ 80/109]	Time  0.557 ( 0.683)	Data  0.000 ( 0.064)	Loss 1.6170512437820435 (1.4120999103710976)	Acc@1  60.94 ( 62.71)	Acc@5  84.38 ( 84.86)
Epoch: [17][ 90/109]	Time  0.484 ( 0.666)	Data  0.000 ( 0.057)	Loss 1.1832154989242554 (1.4089797067118215)	Acc@1  62.50 ( 62.93)	Acc@5  85.94 ( 84.84)
Epoch: [17][100/109]	Time  0.507 ( 0.649)	Data  0.000 ( 0.051)	Loss 1.3864610195159912 (1.4107133598610906)	Acc@1  67.19 ( 63.04)	Acc@5  87.50 ( 84.79)
epoch: 17, Avg_Loss 1.4063799742164962
Test: [ 0/28]	Time  5.250 ( 5.250)	Loss 1.8362e+00 (1.8362e+00)	Acc@1  53.12 ( 53.12)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.149 ( 0.692)	Loss 1.9067e+00 (2.3755e+00)	Acc@1  60.94 ( 44.89)	Acc@5  79.69 ( 71.73)
Test: [20/28]	Time  0.119 ( 0.429)	Loss 2.5732e+00 (2.3438e+00)	Acc@1  43.75 ( 45.39)	Acc@5  67.19 ( 72.25)
 * Acc@1 45.020 Acc@5 72.313
lr 0.001
Epoch: [18][  0/109]	Time  6.116 ( 6.116)	Data  5.322 ( 5.322)	Loss 1.0568655729293823 (1.0568655729293823)	Acc@1  71.88 ( 71.88)	Acc@5  89.06 ( 89.06)
Epoch: [18][ 10/109]	Time  0.577 ( 1.120)	Data  0.001 ( 0.484)	Loss 1.3445683717727661 (1.3386810476129705)	Acc@1  67.19 ( 64.49)	Acc@5  85.94 ( 85.65)
Epoch: [18][ 20/109]	Time  0.653 ( 0.879)	Data  0.000 ( 0.254)	Loss 1.1144478321075439 (1.3070329569634938)	Acc@1  73.44 ( 65.92)	Acc@5  95.31 ( 86.31)
Epoch: [18][ 30/109]	Time  0.847 ( 0.794)	Data  0.000 ( 0.172)	Loss 1.1562470197677612 (1.2793498827565102)	Acc@1  67.19 ( 66.03)	Acc@5  89.06 ( 86.24)
Epoch: [18][ 40/109]	Time  0.489 ( 0.781)	Data  0.001 ( 0.130)	Loss 1.7675962448120117 (1.3028871882252577)	Acc@1  51.56 ( 64.94)	Acc@5  76.56 ( 85.59)
Epoch: [18][ 50/109]	Time  0.582 ( 0.727)	Data  0.000 ( 0.105)	Loss 1.0184435844421387 (1.2901535221174651)	Acc@1  73.44 ( 65.41)	Acc@5  90.62 ( 85.66)
Epoch: [18][ 60/109]	Time  0.558 ( 0.702)	Data  0.000 ( 0.088)	Loss 1.1384317874908447 (1.2997392826393002)	Acc@1  71.88 ( 65.24)	Acc@5  87.50 ( 85.55)
Epoch: [18][ 70/109]	Time  0.488 ( 0.677)	Data  0.000 ( 0.075)	Loss 1.2834395170211792 (1.2946646037236067)	Acc@1  60.94 ( 65.56)	Acc@5  87.50 ( 85.65)
Epoch: [18][ 80/109]	Time  0.488 ( 0.660)	Data  0.000 ( 0.066)	Loss 1.2059472799301147 (1.2921376309277099)	Acc@1  75.00 ( 65.80)	Acc@5  84.38 ( 85.74)
Epoch: [18][ 90/109]	Time  0.563 ( 0.646)	Data  0.000 ( 0.059)	Loss 1.2929248809814453 (1.2898795794654678)	Acc@1  67.19 ( 65.99)	Acc@5  87.50 ( 85.75)
Epoch: [18][100/109]	Time  0.544 ( 0.662)	Data  0.000 ( 0.053)	Loss 1.8285634517669678 (1.3016506144315889)	Acc@1  50.00 ( 65.62)	Acc@5  78.12 ( 85.74)
epoch: 18, Avg_Loss 1.311131939428662
Test: [ 0/28]	Time  4.349 ( 4.349)	Loss 1.8888e+00 (1.8888e+00)	Acc@1  54.69 ( 54.69)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.317 ( 0.740)	Loss 1.8423e+00 (1.9850e+00)	Acc@1  54.69 ( 52.56)	Acc@5  76.56 ( 74.72)
Test: [20/28]	Time  0.146 ( 0.464)	Loss 1.9495e+00 (1.9489e+00)	Acc@1  46.88 ( 52.60)	Acc@5  71.88 ( 76.19)
 * Acc@1 52.392 Acc@5 76.196
lr 0.001
Epoch: [19][  0/109]	Time  5.074 ( 5.074)	Data  4.420 ( 4.420)	Loss 1.1370371580123901 (1.1370371580123901)	Acc@1  70.31 ( 70.31)	Acc@5  89.06 ( 89.06)
Epoch: [19][ 10/109]	Time  0.581 ( 0.987)	Data  0.001 ( 0.402)	Loss 1.3328065872192383 (1.3465451760725542)	Acc@1  57.81 ( 64.06)	Acc@5  79.69 ( 85.65)
Epoch: [19][ 20/109]	Time  0.486 ( 0.767)	Data  0.000 ( 0.211)	Loss 1.2579911947250366 (1.3629783675784157)	Acc@1  68.75 ( 63.76)	Acc@5  84.38 ( 84.97)
Epoch: [19][ 30/109]	Time  0.651 ( 0.698)	Data  0.000 ( 0.143)	Loss 1.0363466739654541 (1.3500197202928605)	Acc@1  70.31 ( 64.11)	Acc@5  90.62 ( 85.13)
Epoch: [19][ 40/109]	Time  1.305 ( 0.699)	Data  0.000 ( 0.108)	Loss 1.4079635143280029 (1.3125870387728622)	Acc@1  67.19 ( 65.32)	Acc@5  81.25 ( 85.56)
Epoch: [19][ 50/109]	Time  0.764 ( 0.727)	Data  0.000 ( 0.087)	Loss 0.7323350310325623 (1.3125215254577935)	Acc@1  82.81 ( 65.56)	Acc@5  92.19 ( 85.72)
Epoch: [19][ 60/109]	Time  0.599 ( 0.694)	Data  0.000 ( 0.073)	Loss 1.2589082717895508 (1.3087702051537935)	Acc@1  73.44 ( 66.09)	Acc@5  89.06 ( 85.86)
Epoch: [19][ 70/109]	Time  0.766 ( 0.676)	Data  0.000 ( 0.063)	Loss 1.0514031648635864 (1.2976654868730357)	Acc@1  68.75 ( 66.31)	Acc@5  90.62 ( 86.14)
Epoch: [19][ 80/109]	Time  0.988 ( 0.694)	Data  0.000 ( 0.055)	Loss 0.9426042437553406 (1.2963686879770255)	Acc@1  70.31 ( 66.17)	Acc@5  89.06 ( 86.09)
Epoch: [19][ 90/109]	Time  0.484 ( 0.675)	Data  0.000 ( 0.049)	Loss 1.0619344711303711 (1.3115129857272891)	Acc@1  71.88 ( 65.95)	Acc@5  90.62 ( 86.01)
Epoch: [19][100/109]	Time  0.514 ( 0.657)	Data  0.000 ( 0.044)	Loss 1.5302695035934448 (1.3184286845792639)	Acc@1  60.94 ( 65.70)	Acc@5  76.56 ( 85.94)
epoch: 19, Avg_Loss 1.319529972492008
Test: [ 0/28]	Time  6.621 ( 6.621)	Loss 1.7024e+00 (1.7024e+00)	Acc@1  56.25 ( 56.25)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.136 ( 0.751)	Loss 1.9367e+00 (1.7687e+00)	Acc@1  45.31 ( 54.97)	Acc@5  71.88 ( 77.13)
Test: [20/28]	Time  0.118 ( 0.469)	Loss 1.6338e+00 (1.7318e+00)	Acc@1  62.50 ( 56.03)	Acc@5  79.69 ( 78.05)
 * Acc@1 55.543 Acc@5 78.222
lr 0.001
Epoch: [20][  0/109]	Time  5.949 ( 5.949)	Data  5.359 ( 5.359)	Loss 1.1022566556930542 (1.1022566556930542)	Acc@1  68.75 ( 68.75)	Acc@5  84.38 ( 84.38)
Epoch: [20][ 10/109]	Time  0.566 ( 1.057)	Data  0.001 ( 0.487)	Loss 1.0940228700637817 (1.1297919858585705)	Acc@1  68.75 ( 70.03)	Acc@5  85.94 ( 89.06)
Epoch: [20][ 20/109]	Time  0.573 ( 0.807)	Data  0.000 ( 0.255)	Loss 1.0565040111541748 (1.1404944431214106)	Acc@1  73.44 ( 68.82)	Acc@5  87.50 ( 88.84)
Epoch: [20][ 30/109]	Time  0.574 ( 0.713)	Data  0.000 ( 0.173)	Loss 1.3116441965103149 (1.1947561848548152)	Acc@1  64.06 ( 67.94)	Acc@5  87.50 ( 88.46)
Epoch: [20][ 40/109]	Time  0.503 ( 0.665)	Data  0.000 ( 0.131)	Loss 1.1027023792266846 (1.1895764673628457)	Acc@1  76.56 ( 68.48)	Acc@5  87.50 ( 88.34)
Epoch: [20][ 50/109]	Time  0.583 ( 0.650)	Data  0.000 ( 0.105)	Loss 1.7936652898788452 (1.2048536013154423)	Acc@1  45.31 ( 68.01)	Acc@5  79.69 ( 88.05)
Epoch: [20][ 60/109]	Time  0.556 ( 0.638)	Data  0.000 ( 0.088)	Loss 1.1273903846740723 (1.2039785678269432)	Acc@1  60.94 ( 67.67)	Acc@5  92.19 ( 88.06)
Epoch: [20][ 70/109]	Time  0.753 ( 0.635)	Data  0.000 ( 0.076)	Loss 1.2735255956649780 (1.2114509604346584)	Acc@1  59.38 ( 67.30)	Acc@5  87.50 ( 87.76)
Epoch: [20][ 80/109]	Time  1.368 ( 0.679)	Data  0.000 ( 0.066)	Loss 1.4563295841217041 (1.2079564767119326)	Acc@1  65.62 ( 67.34)	Acc@5  85.94 ( 87.85)
Epoch: [20][ 90/109]	Time  0.824 ( 0.704)	Data  0.000 ( 0.059)	Loss 1.3038076162338257 (1.2060705416805142)	Acc@1  62.50 ( 67.50)	Acc@5  87.50 ( 87.84)
Epoch: [20][100/109]	Time  0.495 ( 0.710)	Data  0.000 ( 0.053)	Loss 1.0280678272247314 (1.2114856898194493)	Acc@1  75.00 ( 67.40)	Acc@5  87.50 ( 87.64)
epoch: 20, Avg_Loss 1.210772756589662
Test: [ 0/28]	Time  4.759 ( 4.759)	Loss 1.7270e+00 (1.7270e+00)	Acc@1  50.00 ( 50.00)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.186 ( 0.752)	Loss 2.3859e+00 (2.0469e+00)	Acc@1  50.00 ( 48.44)	Acc@5  70.31 ( 75.85)
Test: [20/28]	Time  0.177 ( 0.489)	Loss 2.4516e+00 (2.0806e+00)	Acc@1  45.31 ( 48.81)	Acc@5  68.75 ( 74.93)
 * Acc@1 50.028 Acc@5 74.395
lr 0.001
Epoch: [21][  0/109]	Time  5.600 ( 5.600)	Data  4.960 ( 4.960)	Loss 1.2894585132598877 (1.2894585132598877)	Acc@1  70.31 ( 70.31)	Acc@5  89.06 ( 89.06)
Epoch: [21][ 10/109]	Time  0.489 ( 1.111)	Data  0.000 ( 0.482)	Loss 1.2450457811355591 (1.1968859813430093)	Acc@1  65.62 ( 69.18)	Acc@5  87.50 ( 89.20)
Epoch: [21][ 20/109]	Time  0.850 ( 0.893)	Data  0.001 ( 0.253)	Loss 1.2260855436325073 (1.2289664716947646)	Acc@1  67.19 ( 67.93)	Acc@5  89.06 ( 87.87)
Epoch: [21][ 30/109]	Time  0.522 ( 0.837)	Data  0.000 ( 0.171)	Loss 1.0399893522262573 (1.1804043592945221)	Acc@1  68.75 ( 68.95)	Acc@5  90.62 ( 88.16)
Epoch: [21][ 40/109]	Time  0.478 ( 0.763)	Data  0.000 ( 0.130)	Loss 1.0891181230545044 (1.1791479529404059)	Acc@1  71.88 ( 69.13)	Acc@5  89.06 ( 88.19)
Epoch: [21][ 50/109]	Time  0.602 ( 0.719)	Data  0.000 ( 0.104)	Loss 1.2322576045989990 (1.1753579623558943)	Acc@1  70.31 ( 69.03)	Acc@5  90.62 ( 87.99)
Epoch: [21][ 60/109]	Time  1.185 ( 0.736)	Data  0.000 ( 0.087)	Loss 1.0781894922256470 (1.1713923958481336)	Acc@1  73.44 ( 69.21)	Acc@5  90.62 ( 88.27)
Epoch: [21][ 70/109]	Time  0.609 ( 0.752)	Data  0.000 ( 0.075)	Loss 1.0652484893798828 (1.1857701254562594)	Acc@1  71.88 ( 68.64)	Acc@5  92.19 ( 88.07)
Epoch: [21][ 80/109]	Time  0.492 ( 0.722)	Data  0.000 ( 0.066)	Loss 1.1682621240615845 (1.1919650692998627)	Acc@1  60.94 ( 68.36)	Acc@5  87.50 ( 87.83)
Epoch: [21][ 90/109]	Time  0.527 ( 0.698)	Data  0.000 ( 0.059)	Loss 1.1088838577270508 (1.1932616829872131)	Acc@1  71.88 ( 68.41)	Acc@5  90.62 ( 87.77)
Epoch: [21][100/109]	Time  0.491 ( 0.691)	Data  0.000 ( 0.053)	Loss 1.0898981094360352 (1.1810184835207345)	Acc@1  71.88 ( 68.83)	Acc@5  87.50 ( 87.81)
epoch: 21, Avg_Loss 1.1819353639532666
Test: [ 0/28]	Time  5.563 ( 5.563)	Loss 1.7692e+00 (1.7692e+00)	Acc@1  56.25 ( 56.25)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.143 ( 0.671)	Loss 2.0612e+00 (1.7711e+00)	Acc@1  51.56 ( 56.11)	Acc@5  75.00 ( 77.27)
Test: [20/28]	Time  0.131 ( 0.423)	Loss 2.1584e+00 (1.8432e+00)	Acc@1  46.88 ( 53.94)	Acc@5  71.88 ( 76.41)
 * Acc@1 54.530 Acc@5 77.153
lr 0.001
Epoch: [22][  0/109]	Time  5.717 ( 5.717)	Data  5.114 ( 5.114)	Loss 1.2825667858123779 (1.2825667858123779)	Acc@1  64.06 ( 64.06)	Acc@5  81.25 ( 81.25)
Epoch: [22][ 10/109]	Time  0.476 ( 1.036)	Data  0.001 ( 0.465)	Loss 1.3098006248474121 (1.2586803327907214)	Acc@1  64.06 ( 64.35)	Acc@5  84.38 ( 86.51)
Epoch: [22][ 20/109]	Time  0.493 ( 0.809)	Data  0.000 ( 0.244)	Loss 1.2980343103408813 (1.2464415913536435)	Acc@1  67.19 ( 66.29)	Acc@5  85.94 ( 86.53)
Epoch: [22][ 30/109]	Time  0.505 ( 0.715)	Data  0.000 ( 0.165)	Loss 1.3481982946395874 (1.2179212454826600)	Acc@1  68.75 ( 67.34)	Acc@5  82.81 ( 86.90)
Epoch: [22][ 40/109]	Time  0.617 ( 0.668)	Data  0.000 ( 0.125)	Loss 1.2731029987335205 (1.2096424277235822)	Acc@1  65.62 ( 67.45)	Acc@5  87.50 ( 87.00)
Epoch: [22][ 50/109]	Time  0.908 ( 0.693)	Data  0.001 ( 0.101)	Loss 1.3565039634704590 (1.2208606776069193)	Acc@1  64.06 ( 67.56)	Acc@5  84.38 ( 86.67)
Epoch: [22][ 60/109]	Time  0.552 ( 0.746)	Data  0.000 ( 0.084)	Loss 0.9276607036590576 (1.2104837552445833)	Acc@1  71.88 ( 67.32)	Acc@5  90.62 ( 87.01)
Epoch: [22][ 70/109]	Time  0.501 ( 0.720)	Data  0.000 ( 0.072)	Loss 1.1224514245986938 (1.2005640965112498)	Acc@1  70.31 ( 67.52)	Acc@5  90.62 ( 87.15)
Epoch: [22][ 80/109]	Time  0.482 ( 0.696)	Data  0.000 ( 0.063)	Loss 1.0499699115753174 (1.2173451751838495)	Acc@1  70.31 ( 67.26)	Acc@5  87.50 ( 86.84)
Epoch: [22][ 90/109]	Time  0.525 ( 0.682)	Data  0.000 ( 0.057)	Loss 1.1847726106643677 (1.2028741764498281)	Acc@1  67.19 ( 67.70)	Acc@5  89.06 ( 87.00)
Epoch: [22][100/109]	Time  0.514 ( 0.664)	Data  0.000 ( 0.051)	Loss 1.0891450643539429 (1.1945898509261632)	Acc@1  68.75 ( 67.88)	Acc@5  85.94 ( 87.05)
epoch: 22, Avg_Loss 1.194545622265667
Test: [ 0/28]	Time  5.295 ( 5.295)	Loss 1.8075e+00 (1.8075e+00)	Acc@1  54.69 ( 54.69)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.333 ( 0.799)	Loss 1.9647e+00 (1.7650e+00)	Acc@1  46.88 ( 56.25)	Acc@5  75.00 ( 79.26)
Test: [20/28]	Time  0.131 ( 0.485)	Loss 2.1211e+00 (1.8587e+00)	Acc@1  46.88 ( 54.17)	Acc@5  73.44 ( 77.75)
 * Acc@1 53.630 Acc@5 77.603
lr 0.001
Epoch: [23][  0/109]	Time  7.226 ( 7.226)	Data  6.622 ( 6.622)	Loss 0.6150278449058533 (0.6150278449058533)	Acc@1  82.81 ( 82.81)	Acc@5  96.88 ( 96.88)
Epoch: [23][ 10/109]	Time  0.536 ( 1.206)	Data  0.001 ( 0.603)	Loss 0.8388553857803345 (1.0577507452531294)	Acc@1  76.56 ( 69.89)	Acc@5  92.19 ( 91.48)
Epoch: [23][ 20/109]	Time  0.674 ( 0.918)	Data  0.000 ( 0.316)	Loss 0.9409956336021423 (1.0739754211334955)	Acc@1  78.12 ( 70.24)	Acc@5  90.62 ( 90.10)
Epoch: [23][ 30/109]	Time  0.489 ( 0.815)	Data  0.000 ( 0.214)	Loss 1.1191488504409790 (1.0757961946149026)	Acc@1  67.19 ( 70.61)	Acc@5  89.06 ( 89.72)
Epoch: [23][ 40/109]	Time  0.491 ( 0.747)	Data  0.000 ( 0.162)	Loss 1.1099915504455566 (1.1003979415428349)	Acc@1  75.00 ( 70.05)	Acc@5  89.06 ( 89.25)
Epoch: [23][ 50/109]	Time  0.494 ( 0.704)	Data  0.000 ( 0.130)	Loss 1.1159138679504395 (1.1036832624790716)	Acc@1  71.88 ( 69.82)	Acc@5  85.94 ( 89.31)
Epoch: [23][ 60/109]	Time  0.620 ( 0.685)	Data  0.001 ( 0.109)	Loss 1.0895028114318848 (1.1043362578407663)	Acc@1  73.44 ( 69.85)	Acc@5  89.06 ( 89.24)
Epoch: [23][ 70/109]	Time  0.948 ( 0.699)	Data  0.001 ( 0.094)	Loss 0.8920906186103821 (1.1142927760809240)	Acc@1  70.31 ( 69.37)	Acc@5  96.88 ( 89.30)
Epoch: [23][ 80/109]	Time  0.470 ( 0.686)	Data  0.000 ( 0.082)	Loss 0.8648028373718262 (1.0965633495354359)	Acc@1  76.56 ( 69.79)	Acc@5  90.62 ( 89.58)
Epoch: [23][ 90/109]	Time  0.528 ( 0.669)	Data  0.000 ( 0.073)	Loss 0.7894945740699768 (1.0897082581624880)	Acc@1  76.56 ( 70.02)	Acc@5  93.75 ( 89.44)
Epoch: [23][100/109]	Time  0.532 ( 0.654)	Data  0.000 ( 0.066)	Loss 0.9970982074737549 (1.0824472137016825)	Acc@1  73.44 ( 70.36)	Acc@5  93.75 ( 89.45)
epoch: 23, Avg_Loss 1.0846430068715998
Test: [ 0/28]	Time  6.735 ( 6.735)	Loss 2.3365e+00 (2.3365e+00)	Acc@1  45.31 ( 45.31)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.132 ( 0.744)	Loss 2.6815e+00 (2.2590e+00)	Acc@1  43.75 ( 51.28)	Acc@5  62.50 ( 70.17)
Test: [20/28]	Time  0.118 ( 0.447)	Loss 1.8174e+00 (2.2472e+00)	Acc@1  54.69 ( 50.89)	Acc@5  76.56 ( 71.65)
 * Acc@1 49.747 Acc@5 71.469
lr 0.001
Epoch: [24][  0/109]	Time  4.104 ( 4.104)	Data  3.327 ( 3.327)	Loss 0.9580341577529907 (0.9580341577529907)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 89.06)
Epoch: [24][ 10/109]	Time  0.578 ( 1.089)	Data  0.001 ( 0.386)	Loss 0.9466124176979065 (1.0179470018907026)	Acc@1  71.88 ( 71.31)	Acc@5  89.06 ( 90.77)
Epoch: [24][ 20/109]	Time  0.550 ( 0.849)	Data  0.000 ( 0.202)	Loss 1.1018037796020508 (1.0219534805842809)	Acc@1  67.19 ( 72.17)	Acc@5  85.94 ( 90.48)
Epoch: [24][ 30/109]	Time  0.491 ( 0.760)	Data  0.000 ( 0.137)	Loss 1.0825215578079224 (1.0485503462053114)	Acc@1  68.75 ( 71.32)	Acc@5  89.06 ( 90.12)
Epoch: [24][ 40/109]	Time  0.547 ( 0.704)	Data  0.000 ( 0.104)	Loss 0.7214726805686951 (1.0476534948116396)	Acc@1  81.25 ( 71.00)	Acc@5  92.19 ( 90.05)
Epoch: [24][ 50/109]	Time  0.531 ( 0.671)	Data  0.000 ( 0.084)	Loss 1.1990723609924316 (1.0523837711296828)	Acc@1  60.94 ( 70.96)	Acc@5  87.50 ( 89.55)
Epoch: [24][ 60/109]	Time  0.506 ( 0.657)	Data  0.000 ( 0.070)	Loss 0.8459102511405945 (1.0372137456643777)	Acc@1  76.56 ( 71.26)	Acc@5  89.06 ( 89.81)
Epoch: [24][ 70/109]	Time  0.646 ( 0.639)	Data  0.000 ( 0.060)	Loss 0.8133826851844788 (1.0265583454723088)	Acc@1  82.81 ( 71.59)	Acc@5  93.75 ( 89.90)
Epoch: [24][ 80/109]	Time  0.479 ( 0.624)	Data  0.000 ( 0.053)	Loss 0.9139137864112854 (1.0282404856917300)	Acc@1  70.31 ( 71.41)	Acc@5  92.19 ( 89.81)
Epoch: [24][ 90/109]	Time  0.573 ( 0.612)	Data  0.000 ( 0.047)	Loss 1.0819106101989746 (1.0402780050759788)	Acc@1  70.31 ( 71.17)	Acc@5  84.38 ( 89.54)
Epoch: [24][100/109]	Time  0.676 ( 0.609)	Data  0.000 ( 0.042)	Loss 1.2087336778640747 (1.0367105325849930)	Acc@1  70.31 ( 71.36)	Acc@5  84.38 ( 89.67)
epoch: 24, Avg_Loss 1.038076308342295
Test: [ 0/28]	Time  5.849 ( 5.849)	Loss 2.2763e+00 (2.2763e+00)	Acc@1  46.88 ( 46.88)	Acc@5  73.44 ( 73.44)
Test: [10/28]	Time  0.144 ( 0.702)	Loss 2.3856e+00 (2.1770e+00)	Acc@1  57.81 ( 49.72)	Acc@5  67.19 ( 74.01)
Test: [20/28]	Time  0.118 ( 0.430)	Loss 2.2611e+00 (2.1269e+00)	Acc@1  46.88 ( 50.37)	Acc@5  71.88 ( 74.78)
 * Acc@1 50.816 Acc@5 74.902
lr 0.001
Epoch: [25][  0/109]	Time  7.031 ( 7.031)	Data  6.415 ( 6.415)	Loss 1.2024667263031006 (1.2024667263031006)	Acc@1  71.88 ( 71.88)	Acc@5  84.38 ( 84.38)
Epoch: [25][ 10/109]	Time  0.567 ( 1.168)	Data  0.001 ( 0.583)	Loss 1.3815481662750244 (1.0206448002295061)	Acc@1  65.62 ( 72.44)	Acc@5  84.38 ( 90.91)
Epoch: [25][ 20/109]	Time  0.517 ( 0.911)	Data  0.000 ( 0.306)	Loss 0.8897523880004883 (0.9844829042752584)	Acc@1  75.00 ( 73.29)	Acc@5  93.75 ( 91.07)
Epoch: [25][ 30/109]	Time  0.697 ( 0.814)	Data  0.000 ( 0.207)	Loss 1.2116222381591797 (0.9930253471097639)	Acc@1  70.31 ( 73.34)	Acc@5  84.38 ( 90.73)
Epoch: [25][ 40/109]	Time  0.720 ( 0.793)	Data  0.000 ( 0.157)	Loss 0.8385722041130066 (1.0111310176733064)	Acc@1  71.88 ( 73.02)	Acc@5  95.31 ( 90.74)
Epoch: [25][ 50/109]	Time  0.659 ( 0.799)	Data  0.000 ( 0.126)	Loss 0.8828013539314270 (1.0123175020311392)	Acc@1  78.12 ( 73.01)	Acc@5  90.62 ( 90.35)
Epoch: [25][ 60/109]	Time  0.617 ( 0.764)	Data  0.000 ( 0.106)	Loss 1.2135741710662842 (0.9977132570548136)	Acc@1  71.88 ( 73.18)	Acc@5  87.50 ( 90.55)
Epoch: [25][ 70/109]	Time  0.493 ( 0.740)	Data  0.000 ( 0.091)	Loss 1.0298554897308350 (1.0017309642173875)	Acc@1  71.88 ( 73.13)	Acc@5  95.31 ( 90.67)
Epoch: [25][ 80/109]	Time  0.584 ( 0.719)	Data  0.000 ( 0.080)	Loss 1.1209671497344971 (1.0067179482660176)	Acc@1  68.75 ( 72.90)	Acc@5  92.19 ( 90.57)
Epoch: [25][ 90/109]	Time  1.330 ( 0.735)	Data  0.000 ( 0.071)	Loss 0.8033104538917542 (1.0026264426472422)	Acc@1  73.44 ( 72.89)	Acc@5  95.31 ( 90.62)
Epoch: [25][100/109]	Time  0.480 ( 0.714)	Data  0.000 ( 0.064)	Loss 1.2717276811599731 (1.0108817750864689)	Acc@1  70.31 ( 72.77)	Acc@5  85.94 ( 90.45)
epoch: 25, Avg_Loss 1.0183926837159953
Test: [ 0/28]	Time  6.630 ( 6.630)	Loss 2.0118e+00 (2.0118e+00)	Acc@1  51.56 ( 51.56)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.153 ( 0.773)	Loss 2.0737e+00 (2.0458e+00)	Acc@1  53.12 ( 49.29)	Acc@5  78.12 ( 75.00)
Test: [20/28]	Time  0.131 ( 0.477)	Loss 2.1619e+00 (2.0640e+00)	Acc@1  43.75 ( 49.85)	Acc@5  73.44 ( 75.30)
 * Acc@1 50.028 Acc@5 75.408
lr 0.001
Epoch: [26][  0/109]	Time  5.826 ( 5.826)	Data  5.179 ( 5.179)	Loss 0.5862364768981934 (0.5862364768981934)	Acc@1  87.50 ( 87.50)	Acc@5  95.31 ( 95.31)
Epoch: [26][ 10/109]	Time  0.520 ( 1.103)	Data  0.001 ( 0.508)	Loss 1.0307034254074097 (0.9476471760056235)	Acc@1  76.56 ( 75.43)	Acc@5  87.50 ( 90.20)
Epoch: [26][ 20/109]	Time  0.661 ( 0.848)	Data  0.000 ( 0.267)	Loss 0.9977110028266907 (0.9103537372180394)	Acc@1  71.88 ( 75.67)	Acc@5  90.62 ( 91.67)
Epoch: [26][ 30/109]	Time  0.526 ( 0.744)	Data  0.000 ( 0.181)	Loss 0.9727562665939331 (0.8963032883982505)	Acc@1  76.56 ( 75.96)	Acc@5  89.06 ( 91.94)
Epoch: [26][ 40/109]	Time  0.553 ( 0.697)	Data  0.000 ( 0.137)	Loss 0.9579808712005615 (0.8968270101198336)	Acc@1  71.88 ( 75.80)	Acc@5  92.19 ( 91.84)
Epoch: [26][ 50/109]	Time  0.635 ( 0.675)	Data  0.000 ( 0.110)	Loss 1.1366468667984009 (0.9210274979179981)	Acc@1  67.19 ( 75.03)	Acc@5  89.06 ( 91.45)
Epoch: [26][ 60/109]	Time  0.692 ( 0.665)	Data  0.001 ( 0.092)	Loss 0.9564176797866821 (0.9368958610003112)	Acc@1  73.44 ( 74.33)	Acc@5  92.19 ( 91.42)
Epoch: [26][ 70/109]	Time  0.546 ( 0.653)	Data  0.000 ( 0.079)	Loss 1.1264591217041016 (0.9562450664144166)	Acc@1  64.06 ( 73.66)	Acc@5  87.50 ( 91.18)
Epoch: [26][ 80/109]	Time  0.483 ( 0.637)	Data  0.000 ( 0.069)	Loss 0.9797019958496094 (0.9687252419966238)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 90.95)
Epoch: [26][ 90/109]	Time  0.479 ( 0.620)	Data  0.000 ( 0.062)	Loss 1.3678653240203857 (0.9739550404496246)	Acc@1  60.94 ( 73.45)	Acc@5  84.38 ( 90.83)
Epoch: [26][100/109]	Time  0.502 ( 0.607)	Data  0.000 ( 0.056)	Loss 0.7913212776184082 (0.9653165971878732)	Acc@1  76.56 ( 73.58)	Acc@5  93.75 ( 90.89)
epoch: 26, Avg_Loss 0.9659749985834875
Test: [ 0/28]	Time  5.626 ( 5.626)	Loss 2.2786e+00 (2.2786e+00)	Acc@1  50.00 ( 50.00)	Acc@5  65.62 ( 65.62)
Test: [10/28]	Time  0.147 ( 0.684)	Loss 1.8746e+00 (1.8665e+00)	Acc@1  53.12 ( 56.68)	Acc@5  73.44 ( 76.56)
Test: [20/28]	Time  0.127 ( 0.423)	Loss 2.0782e+00 (1.9859e+00)	Acc@1  51.56 ( 54.32)	Acc@5  71.88 ( 75.97)
 * Acc@1 54.811 Acc@5 76.308
lr 0.001
Epoch: [27][  0/109]	Time  7.932 ( 7.932)	Data  7.133 ( 7.133)	Loss 0.5513036847114563 (0.5513036847114563)	Acc@1  87.50 ( 87.50)	Acc@5  96.88 ( 96.88)
Epoch: [27][ 10/109]	Time  0.527 ( 1.354)	Data  0.000 ( 0.774)	Loss 1.3542069196701050 (0.9330315644090826)	Acc@1  64.06 ( 75.71)	Acc@5  85.94 ( 92.05)
Epoch: [27][ 20/109]	Time  0.491 ( 0.953)	Data  0.000 ( 0.406)	Loss 0.9520111083984375 (0.9868763827142262)	Acc@1  68.75 ( 74.55)	Acc@5  92.19 ( 90.77)
Epoch: [27][ 30/109]	Time  0.647 ( 0.884)	Data  0.000 ( 0.275)	Loss 0.9125880002975464 (0.9563734146856493)	Acc@1  73.44 ( 74.85)	Acc@5  90.62 ( 91.18)
Epoch: [27][ 40/109]	Time  0.540 ( 0.813)	Data  0.000 ( 0.208)	Loss 0.5991180539131165 (0.9500434311424814)	Acc@1  85.94 ( 74.77)	Acc@5  93.75 ( 91.39)
Epoch: [27][ 50/109]	Time  0.490 ( 0.756)	Data  0.000 ( 0.167)	Loss 0.8971444964408875 (0.9544433144962087)	Acc@1  78.12 ( 74.66)	Acc@5  92.19 ( 91.12)
Epoch: [27][ 60/109]	Time  0.641 ( 0.722)	Data  0.000 ( 0.140)	Loss 0.5887875556945801 (0.9441529571032915)	Acc@1  85.94 ( 74.92)	Acc@5  95.31 ( 91.34)
Epoch: [27][ 70/109]	Time  0.558 ( 0.733)	Data  0.000 ( 0.120)	Loss 0.9479213356971741 (0.9556549132709772)	Acc@1  71.88 ( 74.78)	Acc@5  85.94 ( 91.13)
Epoch: [27][ 80/109]	Time  0.628 ( 0.718)	Data  0.000 ( 0.105)	Loss 0.9522594213485718 (0.9512953309365261)	Acc@1  71.88 ( 74.73)	Acc@5  90.62 ( 91.24)
Epoch: [27][ 90/109]	Time  0.482 ( 0.693)	Data  0.000 ( 0.094)	Loss 1.2540520429611206 (0.9539750028442551)	Acc@1  68.75 ( 74.55)	Acc@5  85.94 ( 91.23)
Epoch: [27][100/109]	Time  0.717 ( 0.682)	Data  0.000 ( 0.085)	Loss 0.7670699954032898 (0.9571114294599778)	Acc@1  73.44 ( 74.49)	Acc@5  96.88 ( 91.12)
epoch: 27, Avg_Loss 0.9589780913580448
Test: [ 0/28]	Time  5.086 ( 5.086)	Loss 2.4222e+00 (2.4222e+00)	Acc@1  50.00 ( 50.00)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.122 ( 0.639)	Loss 2.1237e+00 (2.1114e+00)	Acc@1  56.25 ( 51.85)	Acc@5  76.56 ( 74.29)
Test: [20/28]	Time  0.134 ( 0.425)	Loss 1.6492e+00 (2.0182e+00)	Acc@1  57.81 ( 52.08)	Acc@5  79.69 ( 75.67)
 * Acc@1 52.560 Acc@5 75.802
lr 0.001
Epoch: [28][  0/109]	Time  6.297 ( 6.297)	Data  5.420 ( 5.420)	Loss 0.7159270644187927 (0.7159270644187927)	Acc@1  82.81 ( 82.81)	Acc@5  92.19 ( 92.19)
Epoch: [28][ 10/109]	Time  0.567 ( 1.157)	Data  0.001 ( 0.493)	Loss 0.7849151492118835 (0.9036199775609103)	Acc@1  82.81 ( 76.14)	Acc@5  93.75 ( 90.48)
Epoch: [28][ 20/109]	Time  0.555 ( 0.869)	Data  0.000 ( 0.258)	Loss 1.0706826448440552 (0.9069212050664992)	Acc@1  76.56 ( 76.12)	Acc@5  90.62 ( 90.48)
Epoch: [28][ 30/109]	Time  0.496 ( 0.761)	Data  0.000 ( 0.175)	Loss 1.0194039344787598 (0.9119313166987512)	Acc@1  70.31 ( 76.01)	Acc@5  90.62 ( 90.98)
Epoch: [28][ 40/109]	Time  0.485 ( 0.706)	Data  0.000 ( 0.132)	Loss 0.8306810855865479 (0.8986751597102095)	Acc@1  78.12 ( 76.14)	Acc@5  95.31 ( 91.31)
Epoch: [28][ 50/109]	Time  0.499 ( 0.672)	Data  0.000 ( 0.107)	Loss 0.7668022513389587 (0.8907241423924764)	Acc@1  78.12 ( 75.95)	Acc@5  90.62 ( 91.42)
Epoch: [28][ 60/109]	Time  0.738 ( 0.659)	Data  0.000 ( 0.089)	Loss 0.7709444165229797 (0.8853055971567748)	Acc@1  79.69 ( 75.79)	Acc@5  93.75 ( 91.78)
Epoch: [28][ 70/109]	Time  0.486 ( 0.666)	Data  0.000 ( 0.077)	Loss 0.5741583108901978 (0.9024981973876416)	Acc@1  85.94 ( 75.35)	Acc@5  98.44 ( 91.53)
Epoch: [28][ 80/109]	Time  0.471 ( 0.649)	Data  0.000 ( 0.067)	Loss 1.0214512348175049 (0.9093089309739478)	Acc@1  65.62 ( 75.19)	Acc@5  92.19 ( 91.44)
Epoch: [28][ 90/109]	Time  0.519 ( 0.632)	Data  0.000 ( 0.060)	Loss 0.7508516311645508 (0.9075916697690775)	Acc@1  79.69 ( 75.10)	Acc@5  92.19 ( 91.50)
Epoch: [28][100/109]	Time  0.925 ( 0.641)	Data  0.001 ( 0.054)	Loss 0.7529511451721191 (0.9090603955901495)	Acc@1  76.56 ( 75.06)	Acc@5  93.75 ( 91.55)
epoch: 28, Avg_Loss 0.922377099684619
Test: [ 0/28]	Time  5.370 ( 5.370)	Loss 1.5622e+00 (1.5622e+00)	Acc@1  65.62 ( 65.62)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.122 ( 0.633)	Loss 1.9652e+00 (2.0761e+00)	Acc@1  54.69 ( 52.27)	Acc@5  82.81 ( 76.56)
Test: [20/28]	Time  0.126 ( 0.402)	Loss 1.7469e+00 (2.0867e+00)	Acc@1  57.81 ( 52.46)	Acc@5  76.56 ( 76.41)
 * Acc@1 51.829 Acc@5 76.871
lr 0.001
Epoch: [29][  0/109]	Time  6.719 ( 6.719)	Data  6.140 ( 6.140)	Loss 1.1602330207824707 (1.1602330207824707)	Acc@1  67.19 ( 67.19)	Acc@5  89.06 ( 89.06)
Epoch: [29][ 10/109]	Time  0.576 ( 1.113)	Data  0.001 ( 0.558)	Loss 1.1518434286117554 (0.8318278085101735)	Acc@1  65.62 ( 76.85)	Acc@5  90.62 ( 92.61)
Epoch: [29][ 20/109]	Time  0.619 ( 0.840)	Data  0.000 ( 0.293)	Loss 0.7759781479835510 (0.8336470155488878)	Acc@1  73.44 ( 76.19)	Acc@5  92.19 ( 93.30)
Epoch: [29][ 30/109]	Time  0.553 ( 0.751)	Data  0.000 ( 0.198)	Loss 0.5644900798797607 (0.8474056451551376)	Acc@1  84.38 ( 76.26)	Acc@5  95.31 ( 92.39)
Epoch: [29][ 40/109]	Time  0.561 ( 0.709)	Data  0.000 ( 0.150)	Loss 0.8579109311103821 (0.8659538888349766)	Acc@1  79.69 ( 75.84)	Acc@5  92.19 ( 92.49)
Epoch: [29][ 50/109]	Time  0.527 ( 0.671)	Data  0.000 ( 0.121)	Loss 0.7027051448822021 (0.8893856721765855)	Acc@1  82.81 ( 75.34)	Acc@5  93.75 ( 91.97)
Epoch: [29][ 60/109]	Time  0.509 ( 0.648)	Data  0.000 ( 0.101)	Loss 0.8418777585029602 (0.8916740779016838)	Acc@1  78.12 ( 75.33)	Acc@5  90.62 ( 91.78)
Epoch: [29][ 70/109]	Time  0.543 ( 0.653)	Data  0.000 ( 0.087)	Loss 0.7697287201881409 (0.9155822219982953)	Acc@1  79.69 ( 75.00)	Acc@5  92.19 ( 91.35)
Epoch: [29][ 80/109]	Time  0.481 ( 0.642)	Data  0.000 ( 0.076)	Loss 0.7139766812324524 (0.9099201736626802)	Acc@1  79.69 ( 75.29)	Acc@5  95.31 ( 91.53)
Epoch: [29][ 90/109]	Time  0.471 ( 0.624)	Data  0.000 ( 0.068)	Loss 1.3481445312500000 (0.9186837437388661)	Acc@1  62.50 ( 75.05)	Acc@5  84.38 ( 91.45)
Epoch: [29][100/109]	Time  0.654 ( 0.630)	Data  0.000 ( 0.061)	Loss 0.7776838541030884 (0.9206656064137374)	Acc@1  78.12 ( 74.91)	Acc@5  93.75 ( 91.46)
epoch: 29, Avg_Loss 0.9202018210647303
Test: [ 0/28]	Time  5.062 ( 5.062)	Loss 1.6463e+00 (1.6463e+00)	Acc@1  57.81 ( 57.81)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.143 ( 0.604)	Loss 1.4914e+00 (1.7999e+00)	Acc@1  64.06 ( 58.38)	Acc@5  89.06 ( 78.55)
Test: [20/28]	Time  0.117 ( 0.378)	Loss 1.4268e+00 (1.8615e+00)	Acc@1  64.06 ( 56.92)	Acc@5  79.69 ( 77.98)
 * Acc@1 57.062 Acc@5 77.884
lr 0.001
Epoch: [30][  0/109]	Time  5.793 ( 5.793)	Data  5.217 ( 5.217)	Loss 1.0770925283432007 (1.0770925283432007)	Acc@1  68.75 ( 68.75)	Acc@5  90.62 ( 90.62)
Epoch: [30][ 10/109]	Time  0.629 ( 1.206)	Data  0.001 ( 0.475)	Loss 0.4343510866165161 (0.8415774269537493)	Acc@1  89.06 ( 77.41)	Acc@5  95.31 ( 91.76)
Epoch: [30][ 20/109]	Time  0.548 ( 0.885)	Data  0.000 ( 0.249)	Loss 0.9625287055969238 (0.8352420784178234)	Acc@1  76.56 ( 77.60)	Acc@5  98.44 ( 92.49)
Epoch: [30][ 30/109]	Time  0.556 ( 0.773)	Data  0.000 ( 0.169)	Loss 0.9781283140182495 (0.7970748832148891)	Acc@1  76.56 ( 78.28)	Acc@5  92.19 ( 93.30)
Epoch: [30][ 40/109]	Time  0.536 ( 0.716)	Data  0.002 ( 0.128)	Loss 0.6515686511993408 (0.7906960336173453)	Acc@1  78.12 ( 78.12)	Acc@5  96.88 ( 93.33)
Epoch: [30][ 50/109]	Time  0.890 ( 0.719)	Data  0.000 ( 0.103)	Loss 0.7292775511741638 (0.7988795006976408)	Acc@1  78.12 ( 78.03)	Acc@5  95.31 ( 93.38)
Epoch: [30][ 60/109]	Time  0.613 ( 0.690)	Data  0.000 ( 0.086)	Loss 1.0428326129913330 (0.8154106589614368)	Acc@1  71.88 ( 77.51)	Acc@5  90.62 ( 93.06)
Epoch: [30][ 70/109]	Time  0.502 ( 0.675)	Data  0.000 ( 0.074)	Loss 0.8283879160881042 (0.8239625331381677)	Acc@1  79.69 ( 77.09)	Acc@5  92.19 ( 92.98)
Epoch: [30][ 80/109]	Time  0.518 ( 0.656)	Data  0.000 ( 0.065)	Loss 0.7567796111106873 (0.8259909542990319)	Acc@1  76.56 ( 76.95)	Acc@5  93.75 ( 93.11)
Epoch: [30][ 90/109]	Time  0.555 ( 0.645)	Data  0.000 ( 0.058)	Loss 0.5104840993881226 (0.8353840093036274)	Acc@1  85.94 ( 76.73)	Acc@5  98.44 ( 92.93)
Epoch: [30][100/109]	Time  0.474 ( 0.632)	Data  0.000 ( 0.052)	Loss 0.8183252215385437 (0.8391438061648077)	Acc@1  81.25 ( 76.75)	Acc@5  93.75 ( 92.81)
epoch: 30, Avg_Loss 0.8455580486616957
Test: [ 0/28]	Time  4.342 ( 4.342)	Loss 1.7517e+00 (1.7517e+00)	Acc@1  60.94 ( 60.94)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.144 ( 0.650)	Loss 1.7938e+00 (1.9826e+00)	Acc@1  53.12 ( 54.69)	Acc@5  76.56 ( 77.27)
Test: [20/28]	Time  0.124 ( 0.402)	Loss 2.1803e+00 (1.8551e+00)	Acc@1  56.25 ( 57.81)	Acc@5  73.44 ( 78.94)
 * Acc@1 58.244 Acc@5 79.291
lr 0.001
Epoch: [31][  0/109]	Time  4.665 ( 4.665)	Data  3.981 ( 3.981)	Loss 0.8370608687400818 (0.8370608687400818)	Acc@1  75.00 ( 75.00)	Acc@5  92.19 ( 92.19)
Epoch: [31][ 10/109]	Time  0.539 ( 1.036)	Data  0.002 ( 0.461)	Loss 0.8221144676208496 (0.8016875115307894)	Acc@1  73.44 ( 77.41)	Acc@5  95.31 ( 93.47)
Epoch: [31][ 20/109]	Time  0.561 ( 0.796)	Data  0.000 ( 0.243)	Loss 0.5935209393501282 (0.7994018140293303)	Acc@1  78.12 ( 77.75)	Acc@5  96.88 ( 93.45)
Epoch: [31][ 30/109]	Time  0.549 ( 0.707)	Data  0.000 ( 0.164)	Loss 0.8691638112068176 (0.8103044725233509)	Acc@1  76.56 ( 77.97)	Acc@5  92.19 ( 93.30)
Epoch: [31][ 40/109]	Time  0.526 ( 0.666)	Data  0.000 ( 0.124)	Loss 0.7486289739608765 (0.8056336408708153)	Acc@1  81.25 ( 77.90)	Acc@5  90.62 ( 93.22)
Epoch: [31][ 50/109]	Time  0.572 ( 0.648)	Data  0.000 ( 0.100)	Loss 0.5461427569389343 (0.8113850197371315)	Acc@1  82.81 ( 77.85)	Acc@5  96.88 ( 93.14)
Epoch: [31][ 60/109]	Time  0.554 ( 0.637)	Data  0.000 ( 0.084)	Loss 0.4887871742248535 (0.8054557125099370)	Acc@1  89.06 ( 78.07)	Acc@5  95.31 ( 93.06)
Epoch: [31][ 70/109]	Time  0.614 ( 0.635)	Data  0.000 ( 0.072)	Loss 0.8447940349578857 (0.8175435036840574)	Acc@1  76.56 ( 77.71)	Acc@5  96.88 ( 93.07)
Epoch: [31][ 80/109]	Time  0.595 ( 0.631)	Data  0.000 ( 0.063)	Loss 0.9133625626564026 (0.8204227579228672)	Acc@1  76.56 ( 77.60)	Acc@5  92.19 ( 93.15)
Epoch: [31][ 90/109]	Time  0.546 ( 0.623)	Data  0.000 ( 0.056)	Loss 0.7204622626304626 (0.8203907946308890)	Acc@1  79.69 ( 77.64)	Acc@5  92.19 ( 92.99)
Epoch: [31][100/109]	Time  0.491 ( 0.612)	Data  0.000 ( 0.051)	Loss 1.0027021169662476 (0.8353616438879825)	Acc@1  73.44 ( 77.18)	Acc@5  89.06 ( 92.82)
epoch: 31, Avg_Loss 0.8282938618725593
Test: [ 0/28]	Time  4.203 ( 4.203)	Loss 2.8817e+00 (2.8817e+00)	Acc@1  46.88 ( 46.88)	Acc@5  64.06 ( 64.06)
Test: [10/28]	Time  0.142 ( 0.699)	Loss 3.0910e+00 (2.6617e+00)	Acc@1  35.94 ( 44.03)	Acc@5  62.50 ( 66.48)
Test: [20/28]	Time  0.125 ( 0.431)	Loss 2.7285e+00 (2.6913e+00)	Acc@1  43.75 ( 42.26)	Acc@5  71.88 ( 66.89)
 * Acc@1 43.444 Acc@5 67.980
lr 0.001
Epoch: [32][  0/109]	Time  7.099 ( 7.099)	Data  6.533 ( 6.533)	Loss 0.8871943950653076 (0.8871943950653076)	Acc@1  78.12 ( 78.12)	Acc@5  93.75 ( 93.75)
Epoch: [32][ 10/109]	Time  0.518 ( 1.181)	Data  0.001 ( 0.616)	Loss 0.5189053416252136 (0.7284554026343606)	Acc@1  82.81 ( 80.26)	Acc@5  98.44 ( 94.74)
Epoch: [32][ 20/109]	Time  0.486 ( 0.868)	Data  0.000 ( 0.323)	Loss 0.7691139578819275 (0.7479600140026638)	Acc@1  76.56 ( 80.28)	Acc@5  95.31 ( 94.05)
Epoch: [32][ 30/109]	Time  1.075 ( 0.822)	Data  0.000 ( 0.219)	Loss 0.6873235702514648 (0.7396645228708943)	Acc@1  78.12 ( 80.24)	Acc@5  95.31 ( 93.90)
Epoch: [32][ 40/109]	Time  0.557 ( 0.764)	Data  0.000 ( 0.166)	Loss 0.9762908220291138 (0.7459309093835877)	Acc@1  71.88 ( 80.26)	Acc@5  90.62 ( 93.90)
Epoch: [32][ 50/109]	Time  0.474 ( 0.718)	Data  0.000 ( 0.133)	Loss 0.9746870994567871 (0.7625300597910788)	Acc@1  71.88 ( 79.84)	Acc@5  89.06 ( 93.75)
Epoch: [32][ 60/109]	Time  0.622 ( 0.687)	Data  0.000 ( 0.111)	Loss 0.6396946310997009 (0.7603130247749266)	Acc@1  81.25 ( 79.79)	Acc@5  96.88 ( 93.80)
Epoch: [32][ 70/109]	Time  0.629 ( 0.706)	Data  0.000 ( 0.096)	Loss 0.9450723528862000 (0.7925621795822198)	Acc@1  73.44 ( 78.87)	Acc@5  89.06 ( 93.46)
Epoch: [32][ 80/109]	Time  0.495 ( 0.683)	Data  0.000 ( 0.084)	Loss 0.5728478431701660 (0.7943228155742457)	Acc@1  85.94 ( 78.68)	Acc@5  98.44 ( 93.60)
Epoch: [32][ 90/109]	Time  0.478 ( 0.661)	Data  0.000 ( 0.075)	Loss 0.6837512254714966 (0.7962601076770615)	Acc@1  82.81 ( 78.59)	Acc@5  92.19 ( 93.44)
Epoch: [32][100/109]	Time  0.506 ( 0.645)	Data  0.000 ( 0.067)	Loss 0.7796301245689392 (0.7956421242492033)	Acc@1  81.25 ( 78.60)	Acc@5  90.62 ( 93.36)
epoch: 32, Avg_Loss 0.7868915891975438
Test: [ 0/28]	Time  5.069 ( 5.069)	Loss 2.0032e+00 (2.0032e+00)	Acc@1  57.81 ( 57.81)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.134 ( 0.667)	Loss 1.6658e+00 (1.7150e+00)	Acc@1  56.25 ( 58.10)	Acc@5  79.69 ( 79.12)
Test: [20/28]	Time  0.159 ( 0.416)	Loss 1.7864e+00 (1.7477e+00)	Acc@1  59.38 ( 57.81)	Acc@5  81.25 ( 79.39)
 * Acc@1 58.526 Acc@5 79.460
lr 0.001
Epoch: [33][  0/109]	Time  5.698 ( 5.698)	Data  4.956 ( 4.956)	Loss 0.9025044441223145 (0.9025044441223145)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Epoch: [33][ 10/109]	Time  0.591 ( 1.130)	Data  0.001 ( 0.451)	Loss 0.5021286010742188 (0.6742660836739973)	Acc@1  89.06 ( 81.11)	Acc@5  98.44 ( 95.03)
Epoch: [33][ 20/109]	Time  1.200 ( 0.977)	Data  0.001 ( 0.236)	Loss 0.7597905397415161 (0.7293388545513153)	Acc@1  76.56 ( 80.36)	Acc@5  93.75 ( 94.05)
Epoch: [33][ 30/109]	Time  0.769 ( 0.952)	Data  0.000 ( 0.160)	Loss 0.6993100643157959 (0.7578523687777980)	Acc@1  78.12 ( 79.54)	Acc@5  95.31 ( 93.60)
Epoch: [33][ 40/109]	Time  0.551 ( 0.866)	Data  0.000 ( 0.121)	Loss 0.5236132740974426 (0.7518516589955586)	Acc@1  81.25 ( 79.84)	Acc@5  98.44 ( 93.56)
Epoch: [33][ 50/109]	Time  0.701 ( 0.839)	Data  0.001 ( 0.098)	Loss 0.6694227457046509 (0.7494228575743881)	Acc@1  79.69 ( 79.84)	Acc@5  95.31 ( 93.66)
Epoch: [33][ 60/109]	Time  0.680 ( 0.868)	Data  0.000 ( 0.082)	Loss 0.8149788975715637 (0.7584028371044846)	Acc@1  73.44 ( 79.51)	Acc@5  93.75 ( 93.57)
Epoch: [33][ 70/109]	Time  0.641 ( 0.828)	Data  0.000 ( 0.070)	Loss 1.1875783205032349 (0.7703988833326689)	Acc@1  70.31 ( 78.94)	Acc@5  92.19 ( 93.46)
Epoch: [33][ 80/109]	Time  0.517 ( 0.797)	Data  0.000 ( 0.062)	Loss 0.9387510418891907 (0.7750344912946960)	Acc@1  76.56 ( 78.90)	Acc@5  92.19 ( 93.38)
Epoch: [33][ 90/109]	Time  0.528 ( 0.766)	Data  0.000 ( 0.055)	Loss 0.9662652611732483 (0.7837007887415833)	Acc@1  75.00 ( 78.73)	Acc@5  92.19 ( 93.34)
Epoch: [33][100/109]	Time  0.545 ( 0.749)	Data  0.000 ( 0.049)	Loss 1.2888115644454956 (0.7897361372366990)	Acc@1  67.19 ( 78.51)	Acc@5  84.38 ( 93.32)
epoch: 33, Avg_Loss 0.7828719167534365
Test: [ 0/28]	Time  7.264 ( 7.264)	Loss 2.2948e+00 (2.2948e+00)	Acc@1  45.31 ( 45.31)	Acc@5  73.44 ( 73.44)
Test: [10/28]	Time  0.232 ( 0.848)	Loss 1.6437e+00 (1.7415e+00)	Acc@1  62.50 ( 58.52)	Acc@5  82.81 ( 80.82)
Test: [20/28]	Time  0.133 ( 0.518)	Loss 1.5267e+00 (1.6713e+00)	Acc@1  59.38 ( 59.52)	Acc@5  81.25 ( 82.29)
 * Acc@1 58.920 Acc@5 81.598
lr 0.001
Epoch: [34][  0/109]	Time  6.897 ( 6.897)	Data  6.260 ( 6.260)	Loss 0.9901525378227234 (0.9901525378227234)	Acc@1  75.00 ( 75.00)	Acc@5  90.62 ( 90.62)
Epoch: [34][ 10/109]	Time  0.483 ( 1.275)	Data  0.001 ( 0.577)	Loss 0.5949082374572754 (0.7205687300725416)	Acc@1  84.38 ( 80.97)	Acc@5  95.31 ( 94.18)
Epoch: [34][ 20/109]	Time  0.563 ( 0.917)	Data  0.000 ( 0.302)	Loss 0.8423148393630981 (0.7174125611782074)	Acc@1  73.44 ( 80.36)	Acc@5  90.62 ( 94.20)
Epoch: [34][ 30/109]	Time  0.500 ( 0.789)	Data  0.000 ( 0.205)	Loss 0.7129393815994263 (0.7202298035544734)	Acc@1  76.56 ( 79.64)	Acc@5  98.44 ( 94.41)
Epoch: [34][ 40/109]	Time  0.928 ( 0.769)	Data  0.000 ( 0.155)	Loss 0.7923642992973328 (0.7200409108545722)	Acc@1  79.69 ( 79.46)	Acc@5  93.75 ( 94.70)
Epoch: [34][ 50/109]	Time  0.550 ( 0.740)	Data  0.000 ( 0.125)	Loss 0.9251351356506348 (0.7288861899983650)	Acc@1  75.00 ( 79.17)	Acc@5  90.62 ( 94.55)
Epoch: [34][ 60/109]	Time  0.612 ( 0.723)	Data  0.000 ( 0.104)	Loss 0.8339255452156067 (0.7503231128708261)	Acc@1  73.44 ( 78.66)	Acc@5  95.31 ( 94.31)
Epoch: [34][ 70/109]	Time  0.601 ( 0.697)	Data  0.000 ( 0.090)	Loss 0.9289004206657410 (0.7612330577742885)	Acc@1  71.88 ( 78.72)	Acc@5  84.38 ( 93.86)
Epoch: [34][ 80/109]	Time  0.505 ( 0.684)	Data  0.000 ( 0.079)	Loss 0.7491641640663147 (0.7580668021131445)	Acc@1  81.25 ( 78.74)	Acc@5  93.75 ( 93.94)
Epoch: [34][ 90/109]	Time  0.485 ( 0.667)	Data  0.000 ( 0.070)	Loss 0.7951001524925232 (0.7631990503478836)	Acc@1  78.12 ( 78.67)	Acc@5  93.75 ( 93.87)
Epoch: [34][100/109]	Time  0.475 ( 0.651)	Data  0.000 ( 0.063)	Loss 0.5124801397323608 (0.7662041759727025)	Acc@1  85.94 ( 78.54)	Acc@5  96.88 ( 93.75)
epoch: 34, Avg_Loss 0.7719200450346011
Test: [ 0/28]	Time  6.458 ( 6.458)	Loss 1.9951e+00 (1.9951e+00)	Acc@1  46.88 ( 46.88)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.125 ( 0.752)	Loss 3.0057e+00 (2.2647e+00)	Acc@1  37.50 ( 50.14)	Acc@5  56.25 ( 72.73)
Test: [20/28]	Time  0.118 ( 0.452)	Loss 2.3946e+00 (2.2986e+00)	Acc@1  48.44 ( 49.18)	Acc@5  71.88 ( 72.10)
 * Acc@1 49.634 Acc@5 71.694
lr 0.001
Epoch: [35][  0/109]	Time  4.965 ( 4.965)	Data  4.324 ( 4.324)	Loss 0.6871538162231445 (0.6871538162231445)	Acc@1  85.94 ( 85.94)	Acc@5  95.31 ( 95.31)
Epoch: [35][ 10/109]	Time  0.566 ( 0.990)	Data  0.001 ( 0.393)	Loss 0.8085955977439880 (0.7540530128912493)	Acc@1  76.56 ( 79.83)	Acc@5  93.75 ( 94.74)
Epoch: [35][ 20/109]	Time  0.493 ( 0.776)	Data  0.000 ( 0.206)	Loss 0.9530839920043945 (0.7716427913733891)	Acc@1  71.88 ( 79.09)	Acc@5  90.62 ( 94.05)
Epoch: [35][ 30/109]	Time  0.555 ( 0.699)	Data  0.000 ( 0.140)	Loss 0.8256108760833740 (0.7701041381205281)	Acc@1  82.81 ( 79.69)	Acc@5  92.19 ( 93.85)
Epoch: [35][ 40/109]	Time  0.739 ( 0.681)	Data  0.000 ( 0.106)	Loss 0.6223568916320801 (0.7478064320436338)	Acc@1  84.38 ( 79.76)	Acc@5  95.31 ( 94.05)
Epoch: [35][ 50/109]	Time  0.811 ( 0.720)	Data  0.000 ( 0.085)	Loss 0.6745389103889465 (0.7463580153736413)	Acc@1  82.81 ( 79.60)	Acc@5  95.31 ( 93.93)
Epoch: [35][ 60/109]	Time  0.488 ( 0.688)	Data  0.000 ( 0.071)	Loss 0.6342747211456299 (0.7442610913612804)	Acc@1  81.25 ( 79.69)	Acc@5  95.31 ( 93.93)
Epoch: [35][ 70/109]	Time  0.611 ( 0.665)	Data  0.000 ( 0.061)	Loss 0.6046062707901001 (0.7454466332852001)	Acc@1  85.94 ( 79.80)	Acc@5  92.19 ( 93.73)
Epoch: [35][ 80/109]	Time  0.473 ( 0.647)	Data  0.000 ( 0.054)	Loss 0.6265874505043030 (0.7486363288796978)	Acc@1  89.06 ( 79.80)	Acc@5  95.31 ( 93.67)
Epoch: [35][ 90/109]	Time  0.504 ( 0.631)	Data  0.000 ( 0.048)	Loss 0.8482838273048401 (0.7537628124048422)	Acc@1  82.81 ( 79.70)	Acc@5  93.75 ( 93.63)
Epoch: [35][100/109]	Time  0.489 ( 0.617)	Data  0.000 ( 0.043)	Loss 1.0658404827117920 (0.7624015365496720)	Acc@1  70.31 ( 79.61)	Acc@5  92.19 ( 93.61)
epoch: 35, Avg_Loss 0.7572068593917637
Test: [ 0/28]	Time  4.307 ( 4.307)	Loss 2.4745e+00 (2.4745e+00)	Acc@1  51.56 ( 51.56)	Acc@5  73.44 ( 73.44)
Test: [10/28]	Time  0.155 ( 0.634)	Loss 1.9231e+00 (2.2886e+00)	Acc@1  43.75 ( 50.57)	Acc@5  79.69 ( 74.43)
Test: [20/28]	Time  0.119 ( 0.400)	Loss 2.3726e+00 (2.2959e+00)	Acc@1  43.75 ( 49.78)	Acc@5  76.56 ( 73.74)
 * Acc@1 49.409 Acc@5 73.889
lr 0.001
Epoch: [36][  0/109]	Time  4.578 ( 4.578)	Data  3.954 ( 3.954)	Loss 0.6197733879089355 (0.6197733879089355)	Acc@1  87.50 ( 87.50)	Acc@5  95.31 ( 95.31)
Epoch: [36][ 10/109]	Time  0.559 ( 1.108)	Data  0.001 ( 0.488)	Loss 0.6962633132934570 (0.6782157366926019)	Acc@1  81.25 ( 81.96)	Acc@5  92.19 ( 94.18)
Epoch: [36][ 20/109]	Time  0.486 ( 0.835)	Data  0.000 ( 0.256)	Loss 0.9157595634460449 (0.6762785854793730)	Acc@1  73.44 ( 81.03)	Acc@5  92.19 ( 94.49)
Epoch: [36][ 30/109]	Time  0.528 ( 0.767)	Data  0.000 ( 0.173)	Loss 0.6781387925148010 (0.6832875147942574)	Acc@1  84.38 ( 81.10)	Acc@5  89.06 ( 94.15)
Epoch: [36][ 40/109]	Time  0.952 ( 0.773)	Data  0.000 ( 0.131)	Loss 0.7479751110076904 (0.6762388857399545)	Acc@1  85.94 ( 81.29)	Acc@5  90.62 ( 94.09)
Epoch: [36][ 50/109]	Time  0.722 ( 0.799)	Data  0.001 ( 0.106)	Loss 0.7281535863876343 (0.6947205101742464)	Acc@1  85.94 ( 81.25)	Acc@5  93.75 ( 93.84)
Epoch: [36][ 60/109]	Time  0.573 ( 0.757)	Data  0.000 ( 0.088)	Loss 0.3753037750720978 (0.6963261507573675)	Acc@1  90.62 ( 81.35)	Acc@5  98.44 ( 93.95)
Epoch: [36][ 70/109]	Time  0.550 ( 0.723)	Data  0.000 ( 0.076)	Loss 1.3645263910293579 (0.7088742008511449)	Acc@1  64.06 ( 80.90)	Acc@5  84.38 ( 93.95)
Epoch: [36][ 80/109]	Time  0.659 ( 0.703)	Data  0.000 ( 0.067)	Loss 0.9457495212554932 (0.7142079498296903)	Acc@1  73.44 ( 80.88)	Acc@5  92.19 ( 93.79)
Epoch: [36][ 90/109]	Time  0.645 ( 0.694)	Data  0.000 ( 0.059)	Loss 0.8254854679107666 (0.7162991745786352)	Acc@1  78.12 ( 80.70)	Acc@5  90.62 ( 93.82)
Epoch: [36][100/109]	Time  0.510 ( 0.681)	Data  0.000 ( 0.054)	Loss 0.7076566219329834 (0.7174703983387144)	Acc@1  78.12 ( 80.52)	Acc@5  93.75 ( 93.98)
epoch: 36, Avg_Loss 0.717725458221698
Test: [ 0/28]	Time  5.648 ( 5.648)	Loss 2.1000e+00 (2.1000e+00)	Acc@1  57.81 ( 57.81)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.183 ( 0.788)	Loss 1.6388e+00 (1.9847e+00)	Acc@1  59.38 ( 55.26)	Acc@5  81.25 ( 78.12)
Test: [20/28]	Time  0.143 ( 0.498)	Loss 1.5329e+00 (1.8845e+00)	Acc@1  65.62 ( 56.25)	Acc@5  79.69 ( 79.24)
 * Acc@1 56.106 Acc@5 78.953
lr 0.001
Epoch: [37][  0/109]	Time  5.777 ( 5.777)	Data  5.094 ( 5.094)	Loss 0.6024876236915588 (0.6024876236915588)	Acc@1  82.81 ( 82.81)	Acc@5  96.88 ( 96.88)
Epoch: [37][ 10/109]	Time  0.507 ( 1.053)	Data  0.001 ( 0.493)	Loss 0.6232303380966187 (0.6057416227730837)	Acc@1  85.94 ( 84.23)	Acc@5  93.75 ( 95.45)
Epoch: [37][ 20/109]	Time  0.536 ( 0.795)	Data  0.001 ( 0.258)	Loss 0.7424670457839966 (0.6343332259427934)	Acc@1  71.88 ( 82.74)	Acc@5  96.88 ( 95.46)
Epoch: [37][ 30/109]	Time  0.504 ( 0.757)	Data  0.000 ( 0.175)	Loss 0.6928747892379761 (0.6264592764839050)	Acc@1  84.38 ( 82.81)	Acc@5  92.19 ( 95.56)
Epoch: [37][ 40/109]	Time  0.675 ( 0.716)	Data  0.000 ( 0.132)	Loss 0.8715847730636597 (0.6399134390237855)	Acc@1  73.44 ( 82.16)	Acc@5  92.19 ( 95.20)
Epoch: [37][ 50/109]	Time  0.573 ( 0.699)	Data  0.000 ( 0.107)	Loss 0.5861932039260864 (0.6432104017220291)	Acc@1  81.25 ( 81.77)	Acc@5  98.44 ( 95.22)
Epoch: [37][ 60/109]	Time  0.534 ( 0.677)	Data  0.000 ( 0.089)	Loss 0.5920943021774292 (0.6596839393748611)	Acc@1  87.50 ( 81.45)	Acc@5  95.31 ( 95.06)
Epoch: [37][ 70/109]	Time  0.607 ( 0.668)	Data  0.000 ( 0.077)	Loss 0.6533651947975159 (0.6565223995228888)	Acc@1  82.81 ( 81.67)	Acc@5  96.88 ( 95.11)
Epoch: [37][ 80/109]	Time  0.489 ( 0.655)	Data  0.000 ( 0.067)	Loss 0.6871687173843384 (0.6545294192102220)	Acc@1  78.12 ( 81.54)	Acc@5  96.88 ( 95.14)
Epoch: [37][ 90/109]	Time  0.504 ( 0.642)	Data  0.000 ( 0.060)	Loss 1.0410575866699219 (0.6638103730075962)	Acc@1  73.44 ( 81.27)	Acc@5  92.19 ( 94.95)
Epoch: [37][100/109]	Time  0.539 ( 0.628)	Data  0.000 ( 0.054)	Loss 0.7735930085182190 (0.6653480659617056)	Acc@1  82.81 ( 81.30)	Acc@5  93.75 ( 94.89)
epoch: 37, Avg_Loss 0.6787905315740392
Test: [ 0/28]	Time  4.858 ( 4.858)	Loss 1.8286e+00 (1.8286e+00)	Acc@1  57.81 ( 57.81)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.127 ( 0.649)	Loss 2.0285e+00 (2.0356e+00)	Acc@1  54.69 ( 51.14)	Acc@5  81.25 ( 77.41)
Test: [20/28]	Time  0.119 ( 0.401)	Loss 1.7935e+00 (1.9801e+00)	Acc@1  56.25 ( 53.57)	Acc@5  79.69 ( 77.83)
 * Acc@1 53.855 Acc@5 77.603
lr 0.001
Epoch: [38][  0/109]	Time  4.952 ( 4.952)	Data  4.357 ( 4.357)	Loss 0.5104076266288757 (0.5104076266288757)	Acc@1  81.25 ( 81.25)	Acc@5  96.88 ( 96.88)
Epoch: [38][ 10/109]	Time  0.509 ( 1.054)	Data  0.001 ( 0.396)	Loss 0.6299946904182434 (0.6294449540701780)	Acc@1  85.94 ( 83.66)	Acc@5  93.75 ( 94.46)
Epoch: [38][ 20/109]	Time  0.717 ( 0.836)	Data  0.000 ( 0.208)	Loss 0.6772685647010803 (0.6663405668167841)	Acc@1  78.12 ( 82.14)	Acc@5  96.88 ( 94.57)
Epoch: [38][ 30/109]	Time  1.435 ( 0.837)	Data  0.000 ( 0.141)	Loss 0.5574812293052673 (0.6868446603898080)	Acc@1  85.94 ( 81.10)	Acc@5  96.88 ( 94.56)
Epoch: [38][ 40/109]	Time  0.597 ( 0.796)	Data  0.000 ( 0.107)	Loss 0.4880482554435730 (0.6724764115926696)	Acc@1  87.50 ( 81.29)	Acc@5  96.88 ( 94.70)
Epoch: [38][ 50/109]	Time  0.573 ( 0.750)	Data  0.000 ( 0.086)	Loss 0.9217838644981384 (0.6639440591428795)	Acc@1  75.00 ( 81.77)	Acc@5  95.31 ( 94.79)
Epoch: [38][ 60/109]	Time  0.880 ( 0.727)	Data  0.000 ( 0.072)	Loss 0.4808194339275360 (0.6673809133592199)	Acc@1  84.38 ( 81.56)	Acc@5 100.00 ( 94.85)
Epoch: [38][ 70/109]	Time  0.720 ( 0.775)	Data  0.000 ( 0.062)	Loss 0.8152322769165039 (0.6922600781413871)	Acc@1  78.12 ( 80.99)	Acc@5  90.62 ( 94.50)
Epoch: [38][ 80/109]	Time  0.507 ( 0.746)	Data  0.000 ( 0.054)	Loss 0.5660948753356934 (0.6920917965011832)	Acc@1  84.38 ( 80.86)	Acc@5  96.88 ( 94.46)
Epoch: [38][ 90/109]	Time  0.597 ( 0.721)	Data  0.000 ( 0.048)	Loss 0.6003556251525879 (0.6895569333663354)	Acc@1  84.38 ( 80.91)	Acc@5  96.88 ( 94.52)
Epoch: [38][100/109]	Time  0.676 ( 0.711)	Data  0.000 ( 0.043)	Loss 0.7321910858154297 (0.6888152841884311)	Acc@1  79.69 ( 80.93)	Acc@5  89.06 ( 94.42)
epoch: 38, Avg_Loss 0.6891480700685344
Test: [ 0/28]	Time  5.520 ( 5.520)	Loss 1.7406e+00 (1.7406e+00)	Acc@1  51.56 ( 51.56)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.135 ( 0.673)	Loss 1.8142e+00 (2.0179e+00)	Acc@1  56.25 ( 52.84)	Acc@5  76.56 ( 75.57)
Test: [20/28]	Time  0.119 ( 0.415)	Loss 1.8521e+00 (1.9679e+00)	Acc@1  48.44 ( 53.20)	Acc@5  82.81 ( 76.64)
 * Acc@1 52.167 Acc@5 75.858
lr 0.001
Epoch: [39][  0/109]	Time  5.677 ( 5.677)	Data  4.929 ( 4.929)	Loss 0.6856700778007507 (0.6856700778007507)	Acc@1  81.25 ( 81.25)	Acc@5  92.19 ( 92.19)
Epoch: [39][ 10/109]	Time  0.699 ( 1.109)	Data  0.001 ( 0.448)	Loss 0.8206330537796021 (0.6095176284963434)	Acc@1  73.44 ( 82.53)	Acc@5  93.75 ( 96.16)
Epoch: [39][ 20/109]	Time  0.833 ( 0.869)	Data  0.000 ( 0.235)	Loss 0.3212850689888000 (0.6077493727207184)	Acc@1  95.31 ( 82.89)	Acc@5 100.00 ( 95.76)
Epoch: [39][ 30/109]	Time  0.562 ( 0.768)	Data  0.000 ( 0.159)	Loss 0.5488764047622681 (0.6260202517432552)	Acc@1  84.38 ( 82.96)	Acc@5  96.88 ( 95.36)
Epoch: [39][ 40/109]	Time  0.586 ( 0.719)	Data  0.001 ( 0.121)	Loss 0.5811089277267456 (0.6102069325563384)	Acc@1  79.69 ( 83.04)	Acc@5  95.31 ( 95.66)
Epoch: [39][ 50/109]	Time  0.713 ( 0.687)	Data  0.000 ( 0.097)	Loss 0.7085261344909668 (0.6364418443511514)	Acc@1  82.81 ( 82.11)	Acc@5  95.31 ( 95.31)
Epoch: [39][ 60/109]	Time  0.731 ( 0.705)	Data  0.000 ( 0.081)	Loss 0.7164367437362671 (0.6454446198510342)	Acc@1  82.81 ( 81.94)	Acc@5  95.31 ( 95.26)
Epoch: [39][ 70/109]	Time  0.616 ( 0.691)	Data  0.000 ( 0.070)	Loss 0.8143153190612793 (0.6726947863337019)	Acc@1  75.00 ( 81.14)	Acc@5  93.75 ( 94.96)
Epoch: [39][ 80/109]	Time  0.818 ( 0.685)	Data  0.001 ( 0.061)	Loss 0.5371790528297424 (0.6650923542034479)	Acc@1  82.81 ( 81.29)	Acc@5  95.31 ( 94.95)
Epoch: [39][ 90/109]	Time  1.484 ( 0.718)	Data  0.000 ( 0.054)	Loss 0.7413591742515564 (0.6684182721834916)	Acc@1  84.38 ( 81.28)	Acc@5  93.75 ( 94.99)
Epoch: [39][100/109]	Time  0.485 ( 0.702)	Data  0.000 ( 0.049)	Loss 0.6466180682182312 (0.6677417424645754)	Acc@1  82.81 ( 81.28)	Acc@5  92.19 ( 94.97)
epoch: 39, Avg_Loss 0.6683262838136166
Test: [ 0/28]	Time  3.785 ( 3.785)	Loss 2.0118e+00 (2.0118e+00)	Acc@1  53.12 ( 53.12)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.167 ( 0.590)	Loss 1.9405e+00 (1.8698e+00)	Acc@1  57.81 ( 56.25)	Acc@5  78.12 ( 79.55)
Test: [20/28]	Time  0.119 ( 0.375)	Loss 1.8309e+00 (1.8786e+00)	Acc@1  64.06 ( 58.18)	Acc@5  79.69 ( 78.79)
 * Acc@1 58.751 Acc@5 79.572
lr 0.001
Epoch: [40][  0/109]	Time  6.244 ( 6.244)	Data  5.624 ( 5.624)	Loss 0.6268356442451477 (0.6268356442451477)	Acc@1  79.69 ( 79.69)	Acc@5  96.88 ( 96.88)
Epoch: [40][ 10/109]	Time  0.488 ( 1.092)	Data  0.001 ( 0.512)	Loss 1.0581035614013672 (0.6670580316673625)	Acc@1  76.56 ( 81.39)	Acc@5  89.06 ( 94.89)
Epoch: [40][ 20/109]	Time  0.538 ( 0.834)	Data  0.000 ( 0.268)	Loss 0.4024616777896881 (0.6279086640902928)	Acc@1  89.06 ( 82.07)	Acc@5 100.00 ( 95.31)
Epoch: [40][ 30/109]	Time  0.751 ( 0.762)	Data  0.000 ( 0.182)	Loss 0.4257568120956421 (0.6341953787111467)	Acc@1  87.50 ( 82.16)	Acc@5  93.75 ( 95.11)
Epoch: [40][ 40/109]	Time  0.585 ( 0.730)	Data  0.000 ( 0.137)	Loss 0.7664126157760620 (0.6389193193214696)	Acc@1  78.12 ( 82.13)	Acc@5  92.19 ( 94.89)
Epoch: [40][ 50/109]	Time  0.749 ( 0.702)	Data  0.000 ( 0.111)	Loss 0.6023693084716797 (0.6297874292906593)	Acc@1  81.25 ( 82.54)	Acc@5  95.31 ( 95.10)
Epoch: [40][ 60/109]	Time  0.660 ( 0.693)	Data  0.000 ( 0.093)	Loss 0.5096692442893982 (0.6475053180436618)	Acc@1  85.94 ( 82.40)	Acc@5  96.88 ( 94.98)
Epoch: [40][ 70/109]	Time  0.833 ( 0.701)	Data  0.001 ( 0.080)	Loss 0.7023581862449646 (0.6484967344243762)	Acc@1  79.69 ( 82.42)	Acc@5  95.31 ( 94.94)
Epoch: [40][ 80/109]	Time  0.550 ( 0.728)	Data  0.000 ( 0.070)	Loss 0.6593906283378601 (0.6524836483560963)	Acc@1  82.81 ( 82.29)	Acc@5  93.75 ( 94.85)
Epoch: [40][ 90/109]	Time  0.493 ( 0.708)	Data  0.000 ( 0.062)	Loss 0.5646107196807861 (0.6619628045585130)	Acc@1  84.38 ( 82.02)	Acc@5  95.31 ( 94.76)
Epoch: [40][100/109]	Time  0.487 ( 0.688)	Data  0.000 ( 0.056)	Loss 0.4208068549633026 (0.6598052462138752)	Acc@1  87.50 ( 82.16)	Acc@5  96.88 ( 94.86)
epoch: 40, Avg_Loss 0.6754289020638947
Test: [ 0/28]	Time  3.557 ( 3.557)	Loss 2.8289e+00 (2.8289e+00)	Acc@1  39.06 ( 39.06)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.153 ( 0.636)	Loss 2.5504e+00 (2.8186e+00)	Acc@1  32.81 ( 40.62)	Acc@5  75.00 ( 73.15)
Test: [20/28]	Time  0.118 ( 0.394)	Loss 3.4634e+00 (2.8862e+00)	Acc@1  37.50 ( 40.40)	Acc@5  57.81 ( 71.43)
 * Acc@1 40.461 Acc@5 71.469
lr 0.001
Epoch: [41][  0/109]	Time  5.075 ( 5.075)	Data  4.369 ( 4.369)	Loss 0.5153475999832153 (0.5153475999832153)	Acc@1  84.38 ( 84.38)	Acc@5  96.88 ( 96.88)
Epoch: [41][ 10/109]	Time  0.529 ( 1.065)	Data  0.001 ( 0.499)	Loss 0.7437868118286133 (0.6577078781344674)	Acc@1  78.12 ( 81.96)	Acc@5  92.19 ( 94.74)
Epoch: [41][ 20/109]	Time  0.519 ( 0.818)	Data  0.000 ( 0.261)	Loss 0.5687041282653809 (0.6754313295795804)	Acc@1  81.25 ( 80.80)	Acc@5  92.19 ( 94.87)
Epoch: [41][ 30/109]	Time  0.601 ( 0.725)	Data  0.000 ( 0.177)	Loss 0.5237472653388977 (0.6557233795042960)	Acc@1  90.62 ( 81.60)	Acc@5  96.88 ( 95.16)
Epoch: [41][ 40/109]	Time  0.595 ( 0.685)	Data  0.000 ( 0.134)	Loss 0.3915537893772125 (0.6392562411180357)	Acc@1  90.62 ( 82.36)	Acc@5  98.44 ( 95.27)
Epoch: [41][ 50/109]	Time  0.665 ( 0.706)	Data  0.000 ( 0.108)	Loss 0.6866772174835205 (0.6456562344934426)	Acc@1  81.25 ( 82.26)	Acc@5  92.19 ( 95.10)
Epoch: [41][ 60/109]	Time  0.517 ( 0.690)	Data  0.000 ( 0.091)	Loss 0.5251145362854004 (0.6395607136312078)	Acc@1  84.38 ( 82.43)	Acc@5  96.88 ( 95.31)
Epoch: [41][ 70/109]	Time  0.498 ( 0.667)	Data  0.000 ( 0.078)	Loss 0.7710385322570801 (0.6401222738581644)	Acc@1  81.25 ( 82.53)	Acc@5  95.31 ( 95.16)
Epoch: [41][ 80/109]	Time  0.486 ( 0.653)	Data  0.000 ( 0.068)	Loss 0.6427891850471497 (0.6405194850615513)	Acc@1  79.69 ( 82.35)	Acc@5  95.31 ( 95.20)
Epoch: [41][ 90/109]	Time  0.501 ( 0.637)	Data  0.000 ( 0.061)	Loss 0.6684213876724243 (0.6501365834540063)	Acc@1  79.69 ( 82.19)	Acc@5  95.31 ( 94.99)
Epoch: [41][100/109]	Time  0.504 ( 0.623)	Data  0.000 ( 0.055)	Loss 0.7444700598716736 (0.6508791859787290)	Acc@1  76.56 ( 82.15)	Acc@5  95.31 ( 94.97)
epoch: 41, Avg_Loss 0.641983749943042
Test: [ 0/28]	Time  5.959 ( 5.959)	Loss 1.5641e+00 (1.5641e+00)	Acc@1  65.62 ( 65.62)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.183 ( 0.707)	Loss 2.0455e+00 (1.9226e+00)	Acc@1  51.56 ( 53.69)	Acc@5  75.00 ( 77.13)
Test: [20/28]	Time  0.150 ( 0.455)	Loss 1.9527e+00 (1.8819e+00)	Acc@1  56.25 ( 56.03)	Acc@5  81.25 ( 78.12)
 * Acc@1 56.050 Acc@5 78.053
lr 0.001
Epoch: [42][  0/109]	Time  8.365 ( 8.365)	Data  7.752 ( 7.752)	Loss 0.8234262466430664 (0.8234262466430664)	Acc@1  81.25 ( 81.25)	Acc@5  90.62 ( 90.62)
Epoch: [42][ 10/109]	Time  0.562 ( 1.273)	Data  0.001 ( 0.705)	Loss 0.7200281620025635 (0.5681826905770735)	Acc@1  81.25 ( 84.80)	Acc@5  95.31 ( 96.16)
Epoch: [42][ 20/109]	Time  0.498 ( 0.916)	Data  0.000 ( 0.369)	Loss 0.5228513479232788 (0.5790372136093321)	Acc@1  82.81 ( 83.71)	Acc@5  96.88 ( 95.76)
Epoch: [42][ 30/109]	Time  0.564 ( 0.795)	Data  0.000 ( 0.250)	Loss 0.7283414602279663 (0.5537219855093187)	Acc@1  79.69 ( 84.32)	Acc@5  92.19 ( 96.07)
Epoch: [42][ 40/109]	Time  0.489 ( 0.756)	Data  0.000 ( 0.189)	Loss 0.4815024137496948 (0.5702674236239457)	Acc@1  84.38 ( 83.92)	Acc@5  98.44 ( 95.96)
Epoch: [42][ 50/109]	Time  0.519 ( 0.715)	Data  0.000 ( 0.152)	Loss 0.5952767133712769 (0.5698160085023618)	Acc@1  85.94 ( 84.19)	Acc@5  93.75 ( 95.93)
Epoch: [42][ 60/109]	Time  0.692 ( 0.715)	Data  0.000 ( 0.127)	Loss 0.4238725006580353 (0.5647573011820434)	Acc@1  89.06 ( 84.48)	Acc@5  96.88 ( 95.88)
Epoch: [42][ 70/109]	Time  0.851 ( 0.727)	Data  0.001 ( 0.110)	Loss 0.8194127082824707 (0.5840447746532064)	Acc@1  76.56 ( 83.91)	Acc@5  95.31 ( 95.71)
Epoch: [42][ 80/109]	Time  0.543 ( 0.712)	Data  0.000 ( 0.096)	Loss 0.4089633226394653 (0.5940987725316742)	Acc@1  92.19 ( 83.58)	Acc@5 100.00 ( 95.78)
Epoch: [42][ 90/109]	Time  0.527 ( 0.690)	Data  0.000 ( 0.086)	Loss 0.7585101723670959 (0.5926848695828364)	Acc@1  75.00 ( 83.59)	Acc@5  93.75 ( 95.72)
Epoch: [42][100/109]	Time  0.506 ( 0.671)	Data  0.000 ( 0.077)	Loss 0.5768477320671082 (0.5948214790608624)	Acc@1  84.38 ( 83.62)	Acc@5  96.88 ( 95.71)
epoch: 42, Avg_Loss 0.5994876174751772
Test: [ 0/28]	Time  6.410 ( 6.410)	Loss 1.9096e+00 (1.9096e+00)	Acc@1  46.88 ( 46.88)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.290 ( 0.840)	Loss 1.9131e+00 (1.6954e+00)	Acc@1  54.69 ( 58.52)	Acc@5  73.44 ( 80.97)
Test: [20/28]	Time  0.195 ( 0.517)	Loss 2.0660e+00 (1.7248e+00)	Acc@1  53.12 ( 58.63)	Acc@5  75.00 ( 80.13)
 * Acc@1 58.526 Acc@5 79.629
lr 0.001
Epoch: [43][  0/109]	Time  5.313 ( 5.313)	Data  4.580 ( 4.580)	Loss 0.5087318420410156 (0.5087318420410156)	Acc@1  84.38 ( 84.38)	Acc@5  95.31 ( 95.31)
Epoch: [43][ 10/109]	Time  0.475 ( 0.990)	Data  0.001 ( 0.417)	Loss 0.5567114949226379 (0.5834571475332434)	Acc@1  87.50 ( 84.94)	Acc@5  96.88 ( 95.45)
Epoch: [43][ 20/109]	Time  0.793 ( 0.841)	Data  0.001 ( 0.218)	Loss 0.4017439186573029 (0.5587024802253360)	Acc@1  90.62 ( 85.19)	Acc@5  98.44 ( 95.54)
Epoch: [43][ 30/109]	Time  0.492 ( 0.822)	Data  0.000 ( 0.148)	Loss 0.5864843130111694 (0.5684676987509574)	Acc@1  82.81 ( 85.23)	Acc@5  96.88 ( 95.41)
Epoch: [43][ 40/109]	Time  0.558 ( 0.750)	Data  0.000 ( 0.112)	Loss 0.6891702413558960 (0.5810530803552488)	Acc@1  82.81 ( 84.98)	Acc@5  93.75 ( 95.27)
Epoch: [43][ 50/109]	Time  0.574 ( 0.709)	Data  0.001 ( 0.090)	Loss 0.3756337165832520 (0.5973694014782999)	Acc@1  89.06 ( 84.44)	Acc@5  96.88 ( 95.04)
Epoch: [43][ 60/109]	Time  0.622 ( 0.705)	Data  0.000 ( 0.076)	Loss 0.4653421044349670 (0.6024322016317336)	Acc@1  84.38 ( 83.91)	Acc@5  96.88 ( 95.13)
Epoch: [43][ 70/109]	Time  0.547 ( 0.687)	Data  0.000 ( 0.065)	Loss 0.3728501498699188 (0.6041049369623963)	Acc@1  87.50 ( 83.71)	Acc@5  98.44 ( 95.14)
Epoch: [43][ 80/109]	Time  0.503 ( 0.682)	Data  0.000 ( 0.057)	Loss 0.2734037637710571 (0.6042663407178572)	Acc@1  95.31 ( 83.70)	Acc@5  98.44 ( 95.10)
Epoch: [43][ 90/109]	Time  0.481 ( 0.665)	Data  0.000 ( 0.051)	Loss 0.6081017851829529 (0.6140576768052447)	Acc@1  85.94 ( 83.52)	Acc@5  93.75 ( 95.00)
Epoch: [43][100/109]	Time  0.470 ( 0.648)	Data  0.000 ( 0.046)	Loss 0.6493318676948547 (0.6161161976875645)	Acc@1  79.69 ( 83.49)	Acc@5  96.88 ( 95.05)
epoch: 43, Avg_Loss 0.6111131731523286
Test: [ 0/28]	Time  3.752 ( 3.752)	Loss 2.1810e+00 (2.1810e+00)	Acc@1  54.69 ( 54.69)	Acc@5  68.75 ( 68.75)
Test: [10/28]	Time  0.119 ( 0.621)	Loss 2.1041e+00 (1.9697e+00)	Acc@1  46.88 ( 53.55)	Acc@5  73.44 ( 77.41)
Test: [20/28]	Time  0.119 ( 0.389)	Loss 2.0882e+00 (1.9666e+00)	Acc@1  54.69 ( 54.32)	Acc@5  70.31 ( 76.93)
 * Acc@1 54.530 Acc@5 77.884
lr 0.001
Epoch: [44][  0/109]	Time  5.027 ( 5.027)	Data  4.433 ( 4.433)	Loss 0.3504119217395782 (0.3504119217395782)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [44][ 10/109]	Time  0.561 ( 1.285)	Data  0.001 ( 0.461)	Loss 0.5435189008712769 (0.4837602187286724)	Acc@1  84.38 ( 87.22)	Acc@5  96.88 ( 96.31)
Epoch: [44][ 20/109]	Time  0.547 ( 0.971)	Data  0.000 ( 0.242)	Loss 0.4177026152610779 (0.4875465376036508)	Acc@1  89.06 ( 87.28)	Acc@5  98.44 ( 96.65)
Epoch: [44][ 30/109]	Time  0.537 ( 0.857)	Data  0.000 ( 0.164)	Loss 0.4125986695289612 (0.4944188580397637)	Acc@1  89.06 ( 86.79)	Acc@5  98.44 ( 96.32)
Epoch: [44][ 40/109]	Time  0.488 ( 0.820)	Data  0.000 ( 0.124)	Loss 0.5033605098724365 (0.5240991409958863)	Acc@1  84.38 ( 86.09)	Acc@5  95.31 ( 95.88)
Epoch: [44][ 50/109]	Time  0.524 ( 0.763)	Data  0.000 ( 0.100)	Loss 0.5340287089347839 (0.5310058590828204)	Acc@1  85.94 ( 85.81)	Acc@5  96.88 ( 95.89)
Epoch: [44][ 60/109]	Time  0.615 ( 0.724)	Data  0.000 ( 0.084)	Loss 0.7780350446701050 (0.5268639548391593)	Acc@1  81.25 ( 85.94)	Acc@5  90.62 ( 95.85)
Epoch: [44][ 70/109]	Time  0.481 ( 0.694)	Data  0.000 ( 0.072)	Loss 1.0718363523483276 (0.5412458548663368)	Acc@1  71.88 ( 85.32)	Acc@5  89.06 ( 95.73)
Epoch: [44][ 80/109]	Time  0.611 ( 0.694)	Data  0.000 ( 0.066)	Loss 0.6182259917259216 (0.5573904711155244)	Acc@1  82.81 ( 84.78)	Acc@5  95.31 ( 95.49)
Epoch: [44][ 90/109]	Time  1.039 ( 0.698)	Data  0.001 ( 0.059)	Loss 0.6627390980720520 (0.5626202168372961)	Acc@1  87.50 ( 84.74)	Acc@5  92.19 ( 95.42)
Epoch: [44][100/109]	Time  0.584 ( 0.723)	Data  0.000 ( 0.053)	Loss 0.5421253442764282 (0.5659854304377395)	Acc@1  87.50 ( 84.68)	Acc@5  95.31 ( 95.48)
epoch: 44, Avg_Loss 0.5758539220882118
Test: [ 0/28]	Time  5.786 ( 5.786)	Loss 1.2724e+00 (1.2724e+00)	Acc@1  71.88 ( 71.88)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.135 ( 0.658)	Loss 1.3173e+00 (1.7206e+00)	Acc@1  65.62 ( 62.07)	Acc@5  81.25 ( 78.98)
Test: [20/28]	Time  0.125 ( 0.404)	Loss 1.4689e+00 (1.7453e+00)	Acc@1  67.19 ( 61.01)	Acc@5  81.25 ( 79.09)
 * Acc@1 60.777 Acc@5 79.403
lr 0.001
Epoch: [45][  0/109]	Time  4.854 ( 4.854)	Data  4.194 ( 4.194)	Loss 0.5829887986183167 (0.5829887986183167)	Acc@1  84.38 ( 84.38)	Acc@5  96.88 ( 96.88)
Epoch: [45][ 10/109]	Time  0.490 ( 0.966)	Data  0.001 ( 0.394)	Loss 0.5297746062278748 (0.5415228794921528)	Acc@1  82.81 ( 85.09)	Acc@5  96.88 ( 96.02)
Epoch: [45][ 20/109]	Time  0.537 ( 0.756)	Data  0.000 ( 0.206)	Loss 0.5106672048568726 (0.6010410090287527)	Acc@1  85.94 ( 83.18)	Acc@5  93.75 ( 95.46)
Epoch: [45][ 30/109]	Time  0.646 ( 0.735)	Data  0.000 ( 0.140)	Loss 0.7948712110519409 (0.6006519804077763)	Acc@1  71.88 ( 83.01)	Acc@5  95.31 ( 95.21)
Epoch: [45][ 40/109]	Time  0.824 ( 0.710)	Data  0.000 ( 0.106)	Loss 0.8775282502174377 (0.6023934548947869)	Acc@1  78.12 ( 83.12)	Acc@5  93.75 ( 95.39)
Epoch: [45][ 50/109]	Time  0.547 ( 0.726)	Data  0.000 ( 0.085)	Loss 0.6860776543617249 (0.5963336387101341)	Acc@1  79.69 ( 83.30)	Acc@5  95.31 ( 95.34)
Epoch: [45][ 60/109]	Time  0.491 ( 0.694)	Data  0.000 ( 0.071)	Loss 0.6726112365722656 (0.6035754763689197)	Acc@1  82.81 ( 83.07)	Acc@5  90.62 ( 95.21)
Epoch: [45][ 70/109]	Time  0.574 ( 0.673)	Data  0.000 ( 0.061)	Loss 0.4592731595039368 (0.5962731909583991)	Acc@1  85.94 ( 83.14)	Acc@5  95.31 ( 95.36)
Epoch: [45][ 80/109]	Time  0.511 ( 0.651)	Data  0.000 ( 0.054)	Loss 0.5122496485710144 (0.5889775977458482)	Acc@1  82.81 ( 83.26)	Acc@5  96.88 ( 95.52)
Epoch: [45][ 90/109]	Time  0.493 ( 0.633)	Data  0.000 ( 0.048)	Loss 0.6198660135269165 (0.6012476279840364)	Acc@1  84.38 ( 83.14)	Acc@5  98.44 ( 95.54)
Epoch: [45][100/109]	Time  0.480 ( 0.618)	Data  0.000 ( 0.043)	Loss 0.5609138011932373 (0.6037178461504454)	Acc@1  82.81 ( 83.03)	Acc@5  95.31 ( 95.47)
epoch: 45, Avg_Loss 0.6064073364122198
Test: [ 0/28]	Time  4.942 ( 4.942)	Loss 2.0102e+00 (2.0102e+00)	Acc@1  59.38 ( 59.38)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.209 ( 0.677)	Loss 1.8404e+00 (1.9411e+00)	Acc@1  64.06 ( 57.10)	Acc@5  79.69 ( 78.12)
Test: [20/28]	Time  0.122 ( 0.415)	Loss 2.0726e+00 (1.9666e+00)	Acc@1  59.38 ( 56.47)	Acc@5  75.00 ( 77.38)
 * Acc@1 55.656 Acc@5 77.040
lr 0.001
Epoch: [46][  0/109]	Time  4.888 ( 4.888)	Data  4.218 ( 4.218)	Loss 0.4610570669174194 (0.4610570669174194)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
Epoch: [46][ 10/109]	Time  0.466 ( 0.940)	Data  0.001 ( 0.384)	Loss 0.4163184165954590 (0.5621655718846754)	Acc@1  89.06 ( 84.94)	Acc@5  96.88 ( 96.02)
Epoch: [46][ 20/109]	Time  0.627 ( 0.751)	Data  0.000 ( 0.201)	Loss 0.8274098634719849 (0.5896977072670346)	Acc@1  82.81 ( 84.45)	Acc@5  90.62 ( 95.01)
Epoch: [46][ 30/109]	Time  0.583 ( 0.703)	Data  0.001 ( 0.136)	Loss 0.6413137316703796 (0.5790696480581837)	Acc@1  84.38 ( 84.12)	Acc@5  93.75 ( 95.61)
Epoch: [46][ 40/109]	Time  0.648 ( 0.674)	Data  0.000 ( 0.103)	Loss 0.7537261247634888 (0.6060740686044460)	Acc@1  76.56 ( 83.23)	Acc@5  95.31 ( 95.27)
Epoch: [46][ 50/109]	Time  0.550 ( 0.657)	Data  0.000 ( 0.083)	Loss 0.5750139951705933 (0.6086396867153692)	Acc@1  87.50 ( 83.06)	Acc@5  93.75 ( 95.28)
Epoch: [46][ 60/109]	Time  1.193 ( 0.660)	Data  0.001 ( 0.070)	Loss 0.5698704719543457 (0.6026568686375853)	Acc@1  87.50 ( 83.07)	Acc@5  95.31 ( 95.31)
Epoch: [46][ 70/109]	Time  0.541 ( 0.647)	Data  0.000 ( 0.060)	Loss 0.6440324187278748 (0.6017950244352851)	Acc@1  81.25 ( 83.16)	Acc@5  95.31 ( 95.51)
Epoch: [46][ 80/109]	Time  0.490 ( 0.634)	Data  0.000 ( 0.052)	Loss 0.4421382248401642 (0.6035078881699362)	Acc@1  87.50 ( 83.20)	Acc@5  96.88 ( 95.51)
Epoch: [46][ 90/109]	Time  0.494 ( 0.620)	Data  0.000 ( 0.047)	Loss 0.5231680870056152 (0.6046710679164300)	Acc@1  84.38 ( 83.14)	Acc@5  98.44 ( 95.57)
Epoch: [46][100/109]	Time  0.569 ( 0.614)	Data  0.000 ( 0.042)	Loss 0.7324886918067932 (0.6137852223202733)	Acc@1  81.25 ( 82.97)	Acc@5  92.19 ( 95.47)
epoch: 46, Avg_Loss 0.6161501716583146
Test: [ 0/28]	Time  4.566 ( 4.566)	Loss 1.1412e+00 (1.1412e+00)	Acc@1  71.88 ( 71.88)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.136 ( 0.722)	Loss 2.2067e+00 (1.6629e+00)	Acc@1  54.69 ( 62.50)	Acc@5  76.56 ( 84.94)
Test: [20/28]	Time  0.129 ( 0.437)	Loss 1.3892e+00 (1.7536e+00)	Acc@1  68.75 ( 60.94)	Acc@5  87.50 ( 82.89)
 * Acc@1 60.833 Acc@5 83.061
lr 0.001
Epoch: [47][  0/109]	Time  6.922 ( 6.922)	Data  6.348 ( 6.348)	Loss 0.4373276531696320 (0.4373276531696320)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Epoch: [47][ 10/109]	Time  0.567 ( 1.220)	Data  0.001 ( 0.578)	Loss 0.5120059847831726 (0.5616103248162703)	Acc@1  82.81 ( 84.80)	Acc@5  98.44 ( 96.73)
Epoch: [47][ 20/109]	Time  0.654 ( 1.020)	Data  0.001 ( 0.303)	Loss 0.6869298815727234 (0.5752219571953728)	Acc@1  81.25 ( 84.30)	Acc@5  93.75 ( 96.06)
Epoch: [47][ 30/109]	Time  0.597 ( 0.874)	Data  0.000 ( 0.205)	Loss 0.6457982063293457 (0.5570054304215216)	Acc@1  84.38 ( 84.53)	Acc@5  93.75 ( 96.42)
Epoch: [47][ 40/109]	Time  0.513 ( 0.787)	Data  0.000 ( 0.155)	Loss 0.6464301943778992 (0.5550722472551393)	Acc@1  85.94 ( 84.72)	Acc@5  93.75 ( 96.34)
Epoch: [47][ 50/109]	Time  0.617 ( 0.759)	Data  0.001 ( 0.125)	Loss 0.5885677933692932 (0.5573408825724733)	Acc@1  85.94 ( 84.41)	Acc@5  95.31 ( 96.32)
Epoch: [47][ 60/109]	Time  0.933 ( 0.790)	Data  0.001 ( 0.105)	Loss 0.5875636935234070 (0.5551679730415344)	Acc@1  84.38 ( 84.48)	Acc@5  96.88 ( 96.13)
Epoch: [47][ 70/109]	Time  0.708 ( 0.781)	Data  0.000 ( 0.090)	Loss 0.9312332868576050 (0.5580220340003430)	Acc@1  76.56 ( 84.18)	Acc@5  89.06 ( 95.99)
Epoch: [47][ 80/109]	Time  0.590 ( 0.755)	Data  0.000 ( 0.079)	Loss 0.8581348061561584 (0.5624889672538380)	Acc@1  76.56 ( 84.07)	Acc@5  93.75 ( 96.08)
Epoch: [47][ 90/109]	Time  0.529 ( 0.729)	Data  0.000 ( 0.070)	Loss 0.5144007205963135 (0.5701698932673905)	Acc@1  84.38 ( 83.95)	Acc@5  95.31 ( 95.88)
Epoch: [47][100/109]	Time  0.535 ( 0.713)	Data  0.000 ( 0.063)	Loss 0.6404371857643127 (0.5715456717085130)	Acc@1  82.81 ( 83.91)	Acc@5  93.75 ( 95.84)
epoch: 47, Avg_Loss 0.5674682479659352
Test: [ 0/28]	Time  6.381 ( 6.381)	Loss 1.9186e+00 (1.9186e+00)	Acc@1  62.50 ( 62.50)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.131 ( 0.712)	Loss 1.7348e+00 (1.9495e+00)	Acc@1  64.06 ( 57.24)	Acc@5  81.25 ( 81.53)
Test: [20/28]	Time  0.117 ( 0.431)	Loss 1.8586e+00 (1.8773e+00)	Acc@1  53.12 ( 57.81)	Acc@5  85.94 ( 81.40)
 * Acc@1 56.218 Acc@5 81.092
lr 0.001
Epoch: [48][  0/109]	Time  4.983 ( 4.983)	Data  4.369 ( 4.369)	Loss 0.7403023242950439 (0.7403023242950439)	Acc@1  84.38 ( 84.38)	Acc@5  89.06 ( 89.06)
Epoch: [48][ 10/109]	Time  0.976 ( 1.356)	Data  0.002 ( 0.493)	Loss 0.5908405184745789 (0.5781634775075045)	Acc@1  78.12 ( 83.24)	Acc@5 100.00 ( 96.45)
Epoch: [48][ 20/109]	Time  1.045 ( 1.349)	Data  0.001 ( 0.259)	Loss 0.3904779255390167 (0.5556584170886448)	Acc@1  92.19 ( 84.82)	Acc@5  98.44 ( 96.13)
Epoch: [48][ 30/109]	Time  0.513 ( 1.186)	Data  0.000 ( 0.175)	Loss 0.3030201196670532 (0.5432754831929361)	Acc@1  89.06 ( 84.53)	Acc@5 100.00 ( 96.42)
Epoch: [48][ 40/109]	Time  0.713 ( 1.039)	Data  0.000 ( 0.133)	Loss 0.5565468668937683 (0.5613857093380719)	Acc@1  85.94 ( 84.34)	Acc@5  96.88 ( 96.34)
Epoch: [48][ 50/109]	Time  0.726 ( 0.953)	Data  0.000 ( 0.107)	Loss 0.3487341701984406 (0.5679816521850287)	Acc@1  89.06 ( 84.31)	Acc@5 100.00 ( 96.05)
Epoch: [48][ 60/109]	Time  0.555 ( 0.923)	Data  0.000 ( 0.089)	Loss 0.2979142963886261 (0.5597219823813829)	Acc@1  90.62 ( 84.35)	Acc@5  98.44 ( 96.18)
Epoch: [48][ 70/109]	Time  0.553 ( 0.877)	Data  0.000 ( 0.077)	Loss 0.4611591398715973 (0.5665972178250971)	Acc@1  85.94 ( 84.00)	Acc@5  96.88 ( 96.10)
Epoch: [48][ 80/109]	Time  0.482 ( 0.839)	Data  0.000 ( 0.067)	Loss 0.3209257721900940 (0.5696161179630844)	Acc@1  90.62 ( 83.80)	Acc@5  98.44 ( 95.99)
Epoch: [48][ 90/109]	Time  0.483 ( 0.800)	Data  0.000 ( 0.060)	Loss 0.4508588612079620 (0.5734449638115181)	Acc@1  89.06 ( 83.89)	Acc@5  93.75 ( 95.98)
Epoch: [48][100/109]	Time  0.500 ( 0.770)	Data  0.000 ( 0.054)	Loss 0.3707767426967621 (0.5653217319804843)	Acc@1  92.19 ( 83.94)	Acc@5  98.44 ( 96.12)
epoch: 48, Avg_Loss 0.5633884260960675
Test: [ 0/28]	Time  8.236 ( 8.236)	Loss 1.9978e+00 (1.9978e+00)	Acc@1  64.06 ( 64.06)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.266 ( 0.907)	Loss 1.4070e+00 (1.8164e+00)	Acc@1  70.31 ( 60.37)	Acc@5  79.69 ( 80.26)
Test: [20/28]	Time  0.130 ( 0.539)	Loss 1.6667e+00 (1.8213e+00)	Acc@1  57.81 ( 59.08)	Acc@5  79.69 ( 80.21)
 * Acc@1 59.707 Acc@5 80.304
lr 0.001
Epoch: [49][  0/109]	Time  5.882 ( 5.882)	Data  5.250 ( 5.250)	Loss 0.4394468665122986 (0.4394468665122986)	Acc@1  85.94 ( 85.94)	Acc@5  98.44 ( 98.44)
Epoch: [49][ 10/109]	Time  0.983 ( 1.164)	Data  0.001 ( 0.478)	Loss 0.7978160977363586 (0.5751948844302784)	Acc@1  76.56 ( 85.23)	Acc@5  93.75 ( 95.03)
Epoch: [49][ 20/109]	Time  0.825 ( 1.002)	Data  0.000 ( 0.250)	Loss 0.4358312785625458 (0.5473235050837199)	Acc@1  87.50 ( 84.82)	Acc@5 100.00 ( 95.91)
Epoch: [49][ 30/109]	Time  0.541 ( 0.947)	Data  0.000 ( 0.170)	Loss 0.3930875658988953 (0.5238985948024257)	Acc@1  87.50 ( 85.48)	Acc@5  98.44 ( 96.27)
Epoch: [49][ 40/109]	Time  0.569 ( 0.871)	Data  0.000 ( 0.128)	Loss 0.3742460608482361 (0.5171755494140997)	Acc@1  89.06 ( 85.63)	Acc@5 100.00 ( 96.57)
Epoch: [49][ 50/109]	Time  0.479 ( 0.828)	Data  0.000 ( 0.103)	Loss 0.7167734503746033 (0.5250156936692256)	Acc@1  76.56 ( 85.05)	Acc@5  93.75 ( 96.54)
Epoch: [49][ 60/109]	Time  0.605 ( 0.789)	Data  0.000 ( 0.086)	Loss 0.4562492072582245 (0.5374360905318963)	Acc@1  85.94 ( 84.78)	Acc@5  96.88 ( 96.23)
Epoch: [49][ 70/109]	Time  0.532 ( 0.761)	Data  0.000 ( 0.074)	Loss 0.5019298195838928 (0.5417501808891834)	Acc@1  85.94 ( 84.68)	Acc@5  96.88 ( 96.21)
Epoch: [49][ 80/109]	Time  0.494 ( 0.733)	Data  0.000 ( 0.065)	Loss 0.4650780260562897 (0.5474197897646162)	Acc@1  82.81 ( 84.41)	Acc@5 100.00 ( 96.12)
Epoch: [49][ 90/109]	Time  0.587 ( 0.711)	Data  0.000 ( 0.058)	Loss 0.6114410758018494 (0.5525996501629169)	Acc@1  81.25 ( 84.29)	Acc@5  92.19 ( 96.02)
Epoch: [49][100/109]	Time  0.475 ( 0.694)	Data  0.000 ( 0.052)	Loss 0.6888197660446167 (0.5526590660066888)	Acc@1  82.81 ( 84.31)	Acc@5  93.75 ( 95.99)
epoch: 49, Avg_Loss 0.5511783435257203
Test: [ 0/28]	Time  6.096 ( 6.096)	Loss 1.9722e+00 (1.9722e+00)	Acc@1  60.94 ( 60.94)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.170 ( 0.721)	Loss 1.2201e+00 (1.7722e+00)	Acc@1  70.31 ( 62.50)	Acc@5  85.94 ( 80.40)
Test: [20/28]	Time  0.120 ( 0.438)	Loss 2.3359e+00 (1.8758e+00)	Acc@1  51.56 ( 60.34)	Acc@5  73.44 ( 79.91)
 * Acc@1 59.201 Acc@5 79.066
lr 0.001
Epoch: [50][  0/109]	Time  5.058 ( 5.058)	Data  4.411 ( 4.411)	Loss 0.4100526273250580 (0.4100526273250580)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Epoch: [50][ 10/109]	Time  0.663 ( 0.983)	Data  0.000 ( 0.401)	Loss 0.2277959734201431 (0.4423999203877015)	Acc@1  93.75 ( 88.92)	Acc@5  98.44 ( 96.88)
Epoch: [50][ 20/109]	Time  0.529 ( 0.762)	Data  0.000 ( 0.210)	Loss 0.6115466952323914 (0.4806898413669495)	Acc@1  82.81 ( 87.43)	Acc@5  93.75 ( 96.35)
Epoch: [50][ 30/109]	Time  0.580 ( 0.719)	Data  0.000 ( 0.143)	Loss 0.4796666800975800 (0.4997307259228922)	Acc@1  85.94 ( 86.14)	Acc@5  96.88 ( 96.27)
Epoch: [50][ 40/109]	Time  0.674 ( 0.697)	Data  0.000 ( 0.108)	Loss 0.4094048142433167 (0.4935723212434024)	Acc@1  90.62 ( 86.24)	Acc@5  98.44 ( 96.42)
Epoch: [50][ 50/109]	Time  0.659 ( 0.695)	Data  0.000 ( 0.087)	Loss 0.6825755834579468 (0.5015220142462674)	Acc@1  85.94 ( 86.03)	Acc@5  92.19 ( 96.20)
Epoch: [50][ 60/109]	Time  0.492 ( 0.677)	Data  0.000 ( 0.073)	Loss 0.5366381406784058 (0.5071664533165635)	Acc@1  81.25 ( 85.76)	Acc@5  96.88 ( 96.18)
Epoch: [50][ 70/109]	Time  0.482 ( 0.655)	Data  0.000 ( 0.062)	Loss 0.4605599045753479 (0.5102891237802909)	Acc@1  87.50 ( 85.52)	Acc@5  98.44 ( 96.32)
Epoch: [50][ 80/109]	Time  0.478 ( 0.638)	Data  0.000 ( 0.055)	Loss 0.5800989270210266 (0.5104535041767874)	Acc@1  84.38 ( 85.57)	Acc@5  95.31 ( 96.33)
Epoch: [50][ 90/109]	Time  0.538 ( 0.624)	Data  0.000 ( 0.049)	Loss 0.7174712419509888 (0.5158199756355076)	Acc@1  84.38 ( 85.49)	Acc@5  92.19 ( 96.26)
Epoch: [50][100/109]	Time  0.540 ( 0.618)	Data  0.000 ( 0.044)	Loss 0.6541594266891479 (0.5237518950264053)	Acc@1  84.38 ( 85.38)	Acc@5  95.31 ( 96.19)
epoch: 50, Avg_Loss 0.5247351013192343
Test: [ 0/28]	Time  4.584 ( 4.584)	Loss 2.0086e+00 (2.0086e+00)	Acc@1  54.69 ( 54.69)	Acc@5  78.12 ( 78.12)
Test: [10/28]	Time  0.338 ( 0.809)	Loss 2.4478e+00 (2.0683e+00)	Acc@1  56.25 ( 56.82)	Acc@5  73.44 ( 77.56)
Test: [20/28]	Time  0.168 ( 0.502)	Loss 2.2621e+00 (2.0527e+00)	Acc@1  57.81 ( 56.47)	Acc@5  75.00 ( 78.20)
 * Acc@1 57.513 Acc@5 79.010
lr 0.001
Epoch: [51][  0/109]	Time  7.307 ( 7.307)	Data  6.702 ( 6.702)	Loss 0.5628868341445923 (0.5628868341445923)	Acc@1  81.25 ( 81.25)	Acc@5  95.31 ( 95.31)
Epoch: [51][ 10/109]	Time  0.554 ( 1.148)	Data  0.001 ( 0.609)	Loss 0.5329742431640625 (0.4979659806598317)	Acc@1  85.94 ( 85.23)	Acc@5  93.75 ( 96.73)
Epoch: [51][ 20/109]	Time  0.669 ( 0.857)	Data  0.000 ( 0.319)	Loss 0.4344638884067535 (0.4900959432125092)	Acc@1  87.50 ( 85.79)	Acc@5  98.44 ( 96.88)
Epoch: [51][ 30/109]	Time  0.532 ( 0.782)	Data  0.000 ( 0.216)	Loss 0.4359896481037140 (0.4776676484654027)	Acc@1  84.38 ( 85.89)	Acc@5  98.44 ( 97.03)
Epoch: [51][ 40/109]	Time  0.478 ( 0.752)	Data  0.000 ( 0.164)	Loss 0.6379396915435791 (0.4878683602664529)	Acc@1  85.94 ( 86.09)	Acc@5  90.62 ( 96.61)
Epoch: [51][ 50/109]	Time  0.498 ( 0.711)	Data  0.000 ( 0.132)	Loss 0.5539146661758423 (0.4857996845362233)	Acc@1  82.81 ( 86.27)	Acc@5  93.75 ( 96.57)
Epoch: [51][ 60/109]	Time  0.666 ( 0.689)	Data  0.000 ( 0.110)	Loss 0.4975756704807281 (0.4900766320404459)	Acc@1  81.25 ( 85.99)	Acc@5  98.44 ( 96.52)
Epoch: [51][ 70/109]	Time  0.605 ( 0.681)	Data  0.000 ( 0.095)	Loss 0.7233730554580688 (0.4941066270562964)	Acc@1  81.25 ( 85.89)	Acc@5  92.19 ( 96.52)
Epoch: [51][ 80/109]	Time  0.477 ( 0.661)	Data  0.000 ( 0.083)	Loss 0.3209823668003082 (0.4919713225997525)	Acc@1  90.62 ( 85.90)	Acc@5 100.00 ( 96.53)
Epoch: [51][ 90/109]	Time  0.484 ( 0.641)	Data  0.000 ( 0.074)	Loss 0.3990468382835388 (0.4955105326332889)	Acc@1  89.06 ( 85.92)	Acc@5  98.44 ( 96.48)
Epoch: [51][100/109]	Time  0.593 ( 0.631)	Data  0.000 ( 0.067)	Loss 0.5954428315162659 (0.5025469197495149)	Acc@1  85.94 ( 85.98)	Acc@5  93.75 ( 96.33)
epoch: 51, Avg_Loss 0.4991311342070956
Test: [ 0/28]	Time  6.162 ( 6.162)	Loss 2.0267e+00 (2.0267e+00)	Acc@1  59.38 ( 59.38)	Acc@5  75.00 ( 75.00)
Test: [10/28]	Time  0.128 ( 0.706)	Loss 1.9374e+00 (2.1993e+00)	Acc@1  51.56 ( 51.14)	Acc@5  81.25 ( 76.28)
Test: [20/28]	Time  0.153 ( 0.441)	Loss 2.2012e+00 (2.1330e+00)	Acc@1  51.56 ( 52.46)	Acc@5  75.00 ( 77.38)
 * Acc@1 53.799 Acc@5 77.828
lr 0.001
Epoch: [52][  0/109]	Time  6.277 ( 6.277)	Data  5.466 ( 5.466)	Loss 0.5032442212104797 (0.5032442212104797)	Acc@1  84.38 ( 84.38)	Acc@5 100.00 (100.00)
Epoch: [52][ 10/109]	Time  0.477 ( 1.105)	Data  0.001 ( 0.508)	Loss 0.6138228774070740 (0.5117956562475725)	Acc@1  82.81 ( 84.94)	Acc@5  96.88 ( 96.73)
Epoch: [52][ 20/109]	Time  0.600 ( 0.844)	Data  0.000 ( 0.266)	Loss 0.6348807811737061 (0.4739116160642533)	Acc@1  81.25 ( 86.31)	Acc@5  95.31 ( 96.35)
Epoch: [52][ 30/109]	Time  0.658 ( 0.807)	Data  0.000 ( 0.181)	Loss 0.6225605010986328 (0.4837423197684749)	Acc@1  85.94 ( 86.64)	Acc@5  92.19 ( 96.02)
Epoch: [52][ 40/109]	Time  0.784 ( 0.785)	Data  0.000 ( 0.137)	Loss 0.6131028532981873 (0.4774945436454401)	Acc@1  81.25 ( 86.59)	Acc@5  96.88 ( 96.23)
Epoch: [52][ 50/109]	Time  0.591 ( 0.733)	Data  0.000 ( 0.110)	Loss 0.3703850805759430 (0.4733761993109011)	Acc@1  87.50 ( 86.49)	Acc@5 100.00 ( 96.35)
Epoch: [52][ 60/109]	Time  0.570 ( 0.701)	Data  0.000 ( 0.092)	Loss 0.4124154150485992 (0.4780414441569907)	Acc@1  89.06 ( 86.40)	Acc@5  96.88 ( 96.29)
Epoch: [52][ 70/109]	Time  0.852 ( 0.691)	Data  0.000 ( 0.079)	Loss 0.5729743242263794 (0.4783815267220349)	Acc@1  84.38 ( 86.51)	Acc@5  93.75 ( 96.32)
Epoch: [52][ 80/109]	Time  0.526 ( 0.681)	Data  0.000 ( 0.069)	Loss 0.4787309765815735 (0.4830823099171674)	Acc@1  87.50 ( 86.52)	Acc@5  96.88 ( 96.28)
Epoch: [52][ 90/109]	Time  0.483 ( 0.660)	Data  0.000 ( 0.062)	Loss 0.6387827992439270 (0.4942437986751179)	Acc@1  84.38 ( 86.21)	Acc@5  93.75 ( 96.19)
Epoch: [52][100/109]	Time  0.478 ( 0.644)	Data  0.000 ( 0.056)	Loss 0.3809550404548645 (0.4890396954989669)	Acc@1  89.06 ( 86.31)	Acc@5  96.88 ( 96.26)
epoch: 52, Avg_Loss 0.4950204092428225
Test: [ 0/28]	Time  6.493 ( 6.493)	Loss 2.5526e+00 (2.5526e+00)	Acc@1  53.12 ( 53.12)	Acc@5  68.75 ( 68.75)
Test: [10/28]	Time  0.203 ( 0.731)	Loss 2.5572e+00 (2.3709e+00)	Acc@1  53.12 ( 52.56)	Acc@5  71.88 ( 72.87)
Test: [20/28]	Time  0.133 ( 0.444)	Loss 3.2750e+00 (2.4634e+00)	Acc@1  40.62 ( 51.19)	Acc@5  64.06 ( 71.43)
 * Acc@1 51.660 Acc@5 71.525
lr 0.001
Epoch: [53][  0/109]	Time  7.508 ( 7.508)	Data  6.921 ( 6.921)	Loss 0.4625133275985718 (0.4625133275985718)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
Epoch: [53][ 10/109]	Time  0.578 ( 1.180)	Data  0.001 ( 0.629)	Loss 0.4907899200916290 (0.4473643573847684)	Acc@1  82.81 ( 86.79)	Acc@5  95.31 ( 97.16)
Epoch: [53][ 20/109]	Time  0.810 ( 0.918)	Data  0.000 ( 0.330)	Loss 0.4971563816070557 (0.4952865342299144)	Acc@1  92.19 ( 86.31)	Acc@5  98.44 ( 96.50)
Epoch: [53][ 30/109]	Time  0.768 ( 1.016)	Data  0.001 ( 0.224)	Loss 0.4248300492763519 (0.4888360461881084)	Acc@1  89.06 ( 86.29)	Acc@5  95.31 ( 96.67)
Epoch: [53][ 40/109]	Time  0.514 ( 0.895)	Data  0.000 ( 0.169)	Loss 0.4479808211326599 (0.4862770034772594)	Acc@1  85.94 ( 86.36)	Acc@5  98.44 ( 96.72)
Epoch: [53][ 50/109]	Time  0.538 ( 0.829)	Data  0.000 ( 0.136)	Loss 0.4913651049137115 (0.4941280592305988)	Acc@1  82.81 ( 86.27)	Acc@5  96.88 ( 96.51)
Epoch: [53][ 60/109]	Time  0.651 ( 0.780)	Data  0.000 ( 0.114)	Loss 0.2880379855632782 (0.4936834483361635)	Acc@1  89.06 ( 86.32)	Acc@5  98.44 ( 96.47)
Epoch: [53][ 70/109]	Time  0.597 ( 0.771)	Data  0.000 ( 0.098)	Loss 0.5049042701721191 (0.4928309852388543)	Acc@1  84.38 ( 86.14)	Acc@5  96.88 ( 96.57)
Epoch: [53][ 80/109]	Time  0.493 ( 0.744)	Data  0.000 ( 0.086)	Loss 0.3833633959293365 (0.4958066618368949)	Acc@1  87.50 ( 86.00)	Acc@5  95.31 ( 96.51)
Epoch: [53][ 90/109]	Time  0.496 ( 0.716)	Data  0.000 ( 0.076)	Loss 0.9227978587150574 (0.5059028105748878)	Acc@1  70.31 ( 85.71)	Acc@5  92.19 ( 96.36)
Epoch: [53][100/109]	Time  0.544 ( 0.698)	Data  0.000 ( 0.069)	Loss 0.6089019775390625 (0.5201421083495168)	Acc@1  76.56 ( 85.40)	Acc@5  92.19 ( 96.12)
epoch: 53, Avg_Loss 0.5201652877101111
Test: [ 0/28]	Time  5.116 ( 5.116)	Loss 1.5073e+00 (1.5073e+00)	Acc@1  64.06 ( 64.06)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.162 ( 0.611)	Loss 1.9488e+00 (1.8498e+00)	Acc@1  51.56 ( 55.97)	Acc@5  75.00 ( 76.70)
Test: [20/28]	Time  0.118 ( 0.386)	Loss 1.9739e+00 (1.9008e+00)	Acc@1  48.44 ( 56.03)	Acc@5  75.00 ( 75.52)
 * Acc@1 54.868 Acc@5 75.408
lr 0.001
Epoch: [54][  0/109]	Time  5.983 ( 5.983)	Data  5.309 ( 5.309)	Loss 0.3600551486015320 (0.3600551486015320)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [54][ 10/109]	Time  0.676 ( 1.124)	Data  0.001 ( 0.495)	Loss 0.5948957800865173 (0.4755053493109616)	Acc@1  85.94 ( 87.07)	Acc@5  96.88 ( 97.59)
Epoch: [54][ 20/109]	Time  0.895 ( 0.934)	Data  0.000 ( 0.260)	Loss 0.2682915031909943 (0.4840579245771681)	Acc@1  89.06 ( 86.31)	Acc@5 100.00 ( 97.32)
Epoch: [54][ 30/109]	Time  1.077 ( 1.040)	Data  0.000 ( 0.176)	Loss 0.4530723989009857 (0.4954225843952548)	Acc@1  87.50 ( 85.84)	Acc@5  96.88 ( 96.93)
Epoch: [54][ 40/109]	Time  0.516 ( 0.958)	Data  0.000 ( 0.133)	Loss 0.3380410373210907 (0.4894336171266509)	Acc@1  90.62 ( 85.82)	Acc@5  98.44 ( 96.84)
Epoch: [54][ 50/109]	Time  0.487 ( 0.870)	Data  0.000 ( 0.107)	Loss 0.5705730915069580 (0.5004979068157720)	Acc@1  81.25 ( 85.69)	Acc@5  98.44 ( 96.72)
Epoch: [54][ 60/109]	Time  0.580 ( 0.815)	Data  0.000 ( 0.090)	Loss 0.3856619298458099 (0.5026216604670540)	Acc@1  90.62 ( 85.86)	Acc@5  93.75 ( 96.64)
Epoch: [54][ 70/109]	Time  0.731 ( 0.784)	Data  0.000 ( 0.077)	Loss 0.6007012724876404 (0.4999587943016643)	Acc@1  85.94 ( 86.03)	Acc@5  93.75 ( 96.65)
Epoch: [54][ 80/109]	Time  0.576 ( 0.759)	Data  0.000 ( 0.068)	Loss 0.7622211575508118 (0.4957304022930287)	Acc@1  81.25 ( 86.19)	Acc@5  93.75 ( 96.64)
Epoch: [54][ 90/109]	Time  0.474 ( 0.736)	Data  0.000 ( 0.060)	Loss 0.2902496457099915 (0.4977917104631990)	Acc@1  90.62 ( 86.14)	Acc@5 100.00 ( 96.60)
Epoch: [54][100/109]	Time  0.498 ( 0.719)	Data  0.000 ( 0.054)	Loss 0.6770416498184204 (0.5032017803428197)	Acc@1  79.69 ( 86.06)	Acc@5  95.31 ( 96.49)
epoch: 54, Avg_Loss 0.5085473514478142
Test: [ 0/28]	Time  4.694 ( 4.694)	Loss 1.7644e+00 (1.7644e+00)	Acc@1  62.50 ( 62.50)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.151 ( 0.684)	Loss 1.7897e+00 (1.8715e+00)	Acc@1  57.81 ( 58.95)	Acc@5  82.81 ( 78.69)
Test: [20/28]	Time  0.117 ( 0.421)	Loss 1.9697e+00 (1.8040e+00)	Acc@1  59.38 ( 60.27)	Acc@5  75.00 ( 79.99)
 * Acc@1 59.651 Acc@5 80.473
lr 0.001
Epoch: [55][  0/109]	Time  5.649 ( 5.649)	Data  5.051 ( 5.051)	Loss 0.5481911897659302 (0.5481911897659302)	Acc@1  84.38 ( 84.38)	Acc@5  95.31 ( 95.31)
Epoch: [55][ 10/109]	Time  0.652 ( 1.040)	Data  0.001 ( 0.459)	Loss 0.7257308363914490 (0.5733910961584612)	Acc@1  84.38 ( 84.80)	Acc@5  93.75 ( 95.17)
Epoch: [55][ 20/109]	Time  0.885 ( 0.990)	Data  0.000 ( 0.241)	Loss 0.5991413593292236 (0.5580923003809792)	Acc@1  79.69 ( 84.90)	Acc@5  95.31 ( 95.24)
Epoch: [55][ 30/109]	Time  0.527 ( 0.841)	Data  0.000 ( 0.163)	Loss 0.5307447910308838 (0.5355060316862599)	Acc@1  90.62 ( 86.29)	Acc@5  96.88 ( 95.67)
Epoch: [55][ 40/109]	Time  0.611 ( 0.766)	Data  0.000 ( 0.123)	Loss 0.3552700579166412 (0.5269860599826022)	Acc@1  89.06 ( 86.36)	Acc@5  98.44 ( 95.73)
Epoch: [55][ 50/109]	Time  0.483 ( 0.718)	Data  0.000 ( 0.099)	Loss 0.4729503095149994 (0.5279568547711653)	Acc@1  87.50 ( 86.21)	Acc@5  95.31 ( 95.74)
Epoch: [55][ 60/109]	Time  0.488 ( 0.687)	Data  0.000 ( 0.083)	Loss 0.6147610545158386 (0.5289746676800681)	Acc@1  81.25 ( 85.91)	Acc@5  93.75 ( 95.82)
Epoch: [55][ 70/109]	Time  0.524 ( 0.663)	Data  0.000 ( 0.071)	Loss 0.5264927148818970 (0.5217272889026454)	Acc@1  79.69 ( 85.98)	Acc@5  96.88 ( 95.93)
Epoch: [55][ 80/109]	Time  0.542 ( 0.645)	Data  0.000 ( 0.063)	Loss 0.4902318716049194 (0.5222866853446136)	Acc@1  85.94 ( 85.98)	Acc@5  95.31 ( 95.95)
Epoch: [55][ 90/109]	Time  0.467 ( 0.628)	Data  0.000 ( 0.056)	Loss 0.3312441706657410 (0.5357549149583984)	Acc@1  92.19 ( 85.71)	Acc@5 100.00 ( 95.84)
Epoch: [55][100/109]	Time  0.533 ( 0.617)	Data  0.000 ( 0.050)	Loss 0.7013623118400574 (0.5383558702645915)	Acc@1  79.69 ( 85.47)	Acc@5  95.31 ( 95.98)
epoch: 55, Avg_Loss 0.5447400498007415
Test: [ 0/28]	Time  4.995 ( 4.995)	Loss 1.1084e+00 (1.1084e+00)	Acc@1  68.75 ( 68.75)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.158 ( 0.652)	Loss 2.3977e+00 (1.8057e+00)	Acc@1  53.12 ( 60.51)	Acc@5  76.56 ( 79.97)
Test: [20/28]	Time  0.118 ( 0.402)	Loss 1.8150e+00 (1.8900e+00)	Acc@1  65.62 ( 58.41)	Acc@5  73.44 ( 78.42)
 * Acc@1 58.807 Acc@5 78.672
lr 0.001
Epoch: [56][  0/109]	Time  4.966 ( 4.966)	Data  4.318 ( 4.318)	Loss 0.2580495476722717 (0.2580495476722717)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [56][ 10/109]	Time  0.603 ( 1.073)	Data  0.001 ( 0.393)	Loss 0.6418407559394836 (0.5617558170448650)	Acc@1  82.81 ( 84.09)	Acc@5  96.88 ( 96.02)
Epoch: [56][ 20/109]	Time  0.551 ( 0.829)	Data  0.000 ( 0.206)	Loss 0.5512597560882568 (0.5525669341995603)	Acc@1  79.69 ( 84.52)	Acc@5  95.31 ( 96.21)
Epoch: [56][ 30/109]	Time  1.033 ( 0.820)	Data  0.000 ( 0.140)	Loss 0.3965027034282684 (0.5120357822987341)	Acc@1  92.19 ( 86.09)	Acc@5  96.88 ( 96.52)
Epoch: [56][ 40/109]	Time  0.628 ( 0.767)	Data  0.000 ( 0.106)	Loss 0.4318227767944336 (0.5083442824642833)	Acc@1  90.62 ( 86.36)	Acc@5  95.31 ( 96.46)
Epoch: [56][ 50/109]	Time  0.678 ( 0.735)	Data  0.000 ( 0.085)	Loss 0.4415279328823090 (0.4986391833015517)	Acc@1  92.19 ( 86.92)	Acc@5  92.19 ( 96.54)
Epoch: [56][ 60/109]	Time  0.579 ( 0.707)	Data  0.000 ( 0.071)	Loss 0.4410354495048523 (0.4922371482262846)	Acc@1  85.94 ( 86.86)	Acc@5  95.31 ( 96.57)
Epoch: [56][ 70/109]	Time  0.852 ( 0.701)	Data  0.000 ( 0.061)	Loss 0.3353859484195709 (0.5011491741932613)	Acc@1  93.75 ( 86.62)	Acc@5  96.88 ( 96.39)
Epoch: [56][ 80/109]	Time  0.892 ( 0.710)	Data  0.000 ( 0.054)	Loss 0.6299325823783875 (0.5017984984097658)	Acc@1  81.25 ( 86.36)	Acc@5  95.31 ( 96.51)
Epoch: [56][ 90/109]	Time  0.484 ( 0.701)	Data  0.000 ( 0.048)	Loss 0.5568212270736694 (0.5069570911454631)	Acc@1  82.81 ( 86.11)	Acc@5  96.88 ( 96.50)
Epoch: [56][100/109]	Time  0.511 ( 0.680)	Data  0.000 ( 0.043)	Loss 0.6640934348106384 (0.5048943787518114)	Acc@1  84.38 ( 86.14)	Acc@5  96.88 ( 96.58)
epoch: 56, Avg_Loss 0.5066010618428571
Test: [ 0/28]	Time  5.843 ( 5.843)	Loss 1.9497e+00 (1.9497e+00)	Acc@1  48.44 ( 48.44)	Acc@5  71.88 ( 71.88)
Test: [10/28]	Time  0.135 ( 0.736)	Loss 2.2818e+00 (2.2103e+00)	Acc@1  43.75 ( 50.43)	Acc@5  73.44 ( 74.15)
Test: [20/28]	Time  0.118 ( 0.443)	Loss 2.2944e+00 (2.2292e+00)	Acc@1  54.69 ( 49.70)	Acc@5  75.00 ( 73.66)
 * Acc@1 48.846 Acc@5 72.876
lr 0.001
Epoch: [57][  0/109]	Time  4.721 ( 4.721)	Data  4.071 ( 4.071)	Loss 0.4112902879714966 (0.4112902879714966)	Acc@1  87.50 ( 87.50)	Acc@5  96.88 ( 96.88)
Epoch: [57][ 10/109]	Time  0.947 ( 1.157)	Data  0.001 ( 0.452)	Loss 0.1616646796464920 (0.4542214423418045)	Acc@1  96.88 ( 87.93)	Acc@5 100.00 ( 95.88)
Epoch: [57][ 20/109]	Time  0.573 ( 0.955)	Data  0.000 ( 0.237)	Loss 0.5173590779304504 (0.4924921911387217)	Acc@1  87.50 ( 86.76)	Acc@5  95.31 ( 96.21)
Epoch: [57][ 30/109]	Time  0.646 ( 0.856)	Data  0.001 ( 0.161)	Loss 0.5007438659667969 (0.4957979576241586)	Acc@1  85.94 ( 86.69)	Acc@5  96.88 ( 96.32)
Epoch: [57][ 40/109]	Time  0.480 ( 0.789)	Data  0.000 ( 0.121)	Loss 0.5352714061737061 (0.4921049115861335)	Acc@1  85.94 ( 86.55)	Acc@5  96.88 ( 96.38)
Epoch: [57][ 50/109]	Time  0.533 ( 0.736)	Data  0.000 ( 0.098)	Loss 0.4949102103710175 (0.4922670742460326)	Acc@1  84.38 ( 86.46)	Acc@5  96.88 ( 96.54)
Epoch: [57][ 60/109]	Time  0.740 ( 0.711)	Data  0.000 ( 0.082)	Loss 0.7162060737609863 (0.4962016940116882)	Acc@1  81.25 ( 86.48)	Acc@5  89.06 ( 96.34)
Epoch: [57][ 70/109]	Time  0.538 ( 0.707)	Data  0.000 ( 0.070)	Loss 0.3711952865123749 (0.4945057890784573)	Acc@1  90.62 ( 86.44)	Acc@5  98.44 ( 96.52)
Epoch: [57][ 80/109]	Time  0.494 ( 0.682)	Data  0.000 ( 0.062)	Loss 0.6204717755317688 (0.4929575964256569)	Acc@1  76.56 ( 86.48)	Acc@5  95.31 ( 96.59)
Epoch: [57][ 90/109]	Time  0.590 ( 0.667)	Data  0.000 ( 0.055)	Loss 0.5870772004127502 (0.4965193402636182)	Acc@1  87.50 ( 86.44)	Acc@5  96.88 ( 96.48)
Epoch: [57][100/109]	Time  0.486 ( 0.661)	Data  0.000 ( 0.050)	Loss 0.3494307994842529 (0.4887131906972073)	Acc@1  89.06 ( 86.63)	Acc@5  98.44 ( 96.61)
epoch: 57, Avg_Loss 0.490102805128885
Test: [ 0/28]	Time  4.187 ( 4.187)	Loss 1.4237e+00 (1.4237e+00)	Acc@1  67.19 ( 67.19)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.134 ( 0.610)	Loss 1.7641e+00 (1.7704e+00)	Acc@1  56.25 ( 58.81)	Acc@5  78.12 ( 79.55)
Test: [20/28]	Time  0.117 ( 0.382)	Loss 1.4823e+00 (1.7750e+00)	Acc@1  62.50 ( 58.93)	Acc@5  82.81 ( 78.94)
 * Acc@1 58.582 Acc@5 79.066
lr 0.001
Epoch: [58][  0/109]	Time  6.441 ( 6.441)	Data  5.763 ( 5.763)	Loss 0.5354999303817749 (0.5354999303817749)	Acc@1  87.50 ( 87.50)	Acc@5  93.75 ( 93.75)
Epoch: [58][ 10/109]	Time  0.492 ( 1.099)	Data  0.000 ( 0.524)	Loss 0.6303867697715759 (0.4394173703410409)	Acc@1  85.94 ( 87.64)	Acc@5  93.75 ( 97.16)
Epoch: [58][ 20/109]	Time  0.798 ( 0.869)	Data  0.000 ( 0.275)	Loss 0.4314422607421875 (0.4302297121002561)	Acc@1  87.50 ( 87.87)	Acc@5  96.88 ( 97.25)
Epoch: [58][ 30/109]	Time  0.669 ( 0.890)	Data  0.000 ( 0.186)	Loss 0.6392463445663452 (0.4536073419355577)	Acc@1  78.12 ( 86.79)	Acc@5  95.31 ( 97.13)
Epoch: [58][ 40/109]	Time  0.749 ( 0.854)	Data  0.000 ( 0.141)	Loss 0.5120138525962830 (0.4486985904414479)	Acc@1  84.38 ( 87.23)	Acc@5  96.88 ( 97.18)
Epoch: [58][ 50/109]	Time  0.736 ( 0.810)	Data  0.001 ( 0.113)	Loss 0.6286262273788452 (0.4581711040992363)	Acc@1  84.38 ( 87.29)	Acc@5  98.44 ( 97.12)
Epoch: [58][ 60/109]	Time  0.506 ( 0.784)	Data  0.000 ( 0.095)	Loss 0.5911360979080200 (0.4704615038926484)	Acc@1  84.38 ( 86.86)	Acc@5  96.88 ( 96.93)
Epoch: [58][ 70/109]	Time  0.579 ( 0.750)	Data  0.000 ( 0.082)	Loss 0.5416141152381897 (0.4706345974979266)	Acc@1  85.94 ( 86.91)	Acc@5  98.44 ( 97.03)
Epoch: [58][ 80/109]	Time  0.483 ( 0.719)	Data  0.000 ( 0.072)	Loss 0.3253136575222015 (0.4766399681936075)	Acc@1  92.19 ( 86.88)	Acc@5  96.88 ( 96.91)
Epoch: [58][ 90/109]	Time  0.508 ( 0.696)	Data  0.000 ( 0.064)	Loss 0.4117268919944763 (0.4735881558486393)	Acc@1  93.75 ( 86.93)	Acc@5  96.88 ( 96.88)
Epoch: [58][100/109]	Time  0.482 ( 0.680)	Data  0.000 ( 0.057)	Loss 0.4682187139987946 (0.4762165044793988)	Acc@1  85.94 ( 86.97)	Acc@5  96.88 ( 96.86)
epoch: 58, Avg_Loss 0.48237874201678355
Test: [ 0/28]	Time  5.433 ( 5.433)	Loss 2.1366e+00 (2.1366e+00)	Acc@1  51.56 ( 51.56)	Acc@5  76.56 ( 76.56)
Test: [10/28]	Time  0.158 ( 0.729)	Loss 1.3022e+00 (1.7222e+00)	Acc@1  64.06 ( 61.08)	Acc@5  89.06 ( 83.10)
Test: [20/28]	Time  0.129 ( 0.445)	Loss 2.0947e+00 (1.7858e+00)	Acc@1  60.94 ( 60.49)	Acc@5  78.12 ( 81.99)
 * Acc@1 61.339 Acc@5 81.486
lr 0.001
Epoch: [59][  0/109]	Time  4.492 ( 4.492)	Data  3.822 ( 3.822)	Loss 0.4323809146881104 (0.4323809146881104)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Epoch: [59][ 10/109]	Time  0.486 ( 0.984)	Data  0.001 ( 0.390)	Loss 0.4791869521141052 (0.4299817952242764)	Acc@1  90.62 ( 89.06)	Acc@5  98.44 ( 97.16)
Epoch: [59][ 20/109]	Time  0.538 ( 0.764)	Data  0.000 ( 0.204)	Loss 0.4177079796791077 (0.4105223821742194)	Acc@1  90.62 ( 89.36)	Acc@5  98.44 ( 97.54)
Epoch: [59][ 30/109]	Time  0.572 ( 0.707)	Data  0.001 ( 0.139)	Loss 0.3733907043933868 (0.4278376405277560)	Acc@1  90.62 ( 88.51)	Acc@5 100.00 ( 97.18)
Epoch: [59][ 40/109]	Time  0.596 ( 0.673)	Data  0.000 ( 0.105)	Loss 0.4085651636123657 (0.4286914391488564)	Acc@1  84.38 ( 88.26)	Acc@5  98.44 ( 97.03)
Epoch: [59][ 50/109]	Time  0.573 ( 0.657)	Data  0.000 ( 0.084)	Loss 0.6066446304321289 (0.4238643783564661)	Acc@1  84.38 ( 88.39)	Acc@5  96.88 ( 97.09)
Epoch: [59][ 60/109]	Time  0.813 ( 0.665)	Data  0.000 ( 0.071)	Loss 0.3496960103511810 (0.4342997462534514)	Acc@1  90.62 ( 88.04)	Acc@5 100.00 ( 97.16)
Epoch: [59][ 70/109]	Time  0.605 ( 0.668)	Data  0.000 ( 0.061)	Loss 0.6696865558624268 (0.4448990727394400)	Acc@1  81.25 ( 87.79)	Acc@5  95.31 ( 96.96)
Epoch: [59][ 80/109]	Time  0.572 ( 0.679)	Data  0.000 ( 0.053)	Loss 0.6303339600563049 (0.4488132299832356)	Acc@1  82.81 ( 87.60)	Acc@5  93.75 ( 96.88)
Epoch: [59][ 90/109]	Time  0.493 ( 0.665)	Data  0.000 ( 0.047)	Loss 0.4382093548774719 (0.4555669677454037)	Acc@1  87.50 ( 87.36)	Acc@5 100.00 ( 96.79)
Epoch: [59][100/109]	Time  0.470 ( 0.647)	Data  0.000 ( 0.043)	Loss 0.3592586815357208 (0.4514794035418199)	Acc@1  92.19 ( 87.48)	Acc@5  98.44 ( 96.91)
epoch: 59, Avg_Loss 0.45220004842368833
Test: [ 0/28]	Time  5.162 ( 5.162)	Loss 1.3697e+00 (1.3697e+00)	Acc@1  65.62 ( 65.62)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.123 ( 0.611)	Loss 1.6105e+00 (1.6605e+00)	Acc@1  60.94 ( 60.80)	Acc@5  85.94 ( 81.82)
Test: [20/28]	Time  0.118 ( 0.383)	Loss 1.8678e+00 (1.7471e+00)	Acc@1  68.75 ( 60.64)	Acc@5  76.56 ( 79.76)
 * Acc@1 60.889 Acc@5 79.910
lr 0.0001
Epoch: [60][  0/109]	Time  7.198 ( 7.198)	Data  6.548 ( 6.548)	Loss 0.5766456127166748 (0.5766456127166748)	Acc@1  89.06 ( 89.06)	Acc@5  93.75 ( 93.75)
Epoch: [60][ 10/109]	Time  0.553 ( 1.196)	Data  0.001 ( 0.596)	Loss 0.3629291355609894 (0.4190952154723080)	Acc@1  92.19 ( 89.63)	Acc@5  96.88 ( 96.88)
Epoch: [60][ 20/109]	Time  0.506 ( 0.884)	Data  0.000 ( 0.312)	Loss 0.2573222219944000 (0.4026868073713212)	Acc@1  96.88 ( 89.73)	Acc@5  98.44 ( 97.02)
Epoch: [60][ 30/109]	Time  0.827 ( 0.814)	Data  0.000 ( 0.212)	Loss 0.4917856156826019 (0.3999477230733441)	Acc@1  87.50 ( 89.87)	Acc@5  92.19 ( 97.03)
Epoch: [60][ 40/109]	Time  0.571 ( 0.778)	Data  0.000 ( 0.160)	Loss 0.4199407398700714 (0.3855524750017538)	Acc@1  87.50 ( 90.02)	Acc@5  96.88 ( 97.14)
Epoch: [60][ 50/109]	Time  0.486 ( 0.742)	Data  0.000 ( 0.129)	Loss 0.1071624159812927 (0.3783709818826002)	Acc@1  98.44 ( 90.04)	Acc@5 100.00 ( 97.21)
Epoch: [60][ 60/109]	Time  0.574 ( 0.712)	Data  0.000 ( 0.108)	Loss 0.2979129850864410 (0.3602691786211045)	Acc@1  90.62 ( 90.45)	Acc@5  96.88 ( 97.36)
Epoch: [60][ 70/109]	Time  0.609 ( 0.715)	Data  0.000 ( 0.093)	Loss 0.2742821276187897 (0.3506361999562089)	Acc@1  90.62 ( 90.56)	Acc@5 100.00 ( 97.51)
Epoch: [60][ 80/109]	Time  0.477 ( 0.695)	Data  0.000 ( 0.081)	Loss 0.1796195209026337 (0.3412090587763139)	Acc@1  95.31 ( 90.88)	Acc@5 100.00 ( 97.65)
Epoch: [60][ 90/109]	Time  0.465 ( 0.671)	Data  0.000 ( 0.072)	Loss 0.2080651819705963 (0.3320945507058731)	Acc@1  92.19 ( 91.17)	Acc@5  98.44 ( 97.70)
Epoch: [60][100/109]	Time  0.876 ( 0.662)	Data  0.000 ( 0.065)	Loss 0.1065948158502579 (0.3344126447740168)	Acc@1  98.44 ( 91.20)	Acc@5  98.44 ( 97.65)
epoch: 60, Avg_Loss 0.33502906663428755
Test: [ 0/28]	Time  5.091 ( 5.091)	Loss 1.1465e+00 (1.1465e+00)	Acc@1  78.12 ( 78.12)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.235 ( 0.684)	Loss 1.2352e+00 (1.2619e+00)	Acc@1  67.19 ( 70.17)	Acc@5  90.62 ( 86.65)
Test: [20/28]	Time  0.127 ( 0.426)	Loss 1.3699e+00 (1.2257e+00)	Acc@1  60.94 ( 70.91)	Acc@5  85.94 ( 87.05)
 * Acc@1 70.681 Acc@5 87.057
lr 0.0001
Epoch: [61][  0/109]	Time  5.062 ( 5.062)	Data  4.392 ( 4.392)	Loss 0.2127900421619415 (0.2127900421619415)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [61][ 10/109]	Time  0.504 ( 1.223)	Data  0.001 ( 0.574)	Loss 0.3154442906379700 (0.2457498610019684)	Acc@1  92.19 ( 93.89)	Acc@5 100.00 ( 99.01)
Epoch: [61][ 20/109]	Time  0.513 ( 0.890)	Data  0.000 ( 0.301)	Loss 0.2607546150684357 (0.2502324602433613)	Acc@1  93.75 ( 93.53)	Acc@5  98.44 ( 98.66)
Epoch: [61][ 30/109]	Time  0.542 ( 0.827)	Data  0.000 ( 0.204)	Loss 0.2058912664651871 (0.2436565526070133)	Acc@1  95.31 ( 93.30)	Acc@5  96.88 ( 98.64)
Epoch: [61][ 40/109]	Time  0.916 ( 0.773)	Data  0.000 ( 0.154)	Loss 0.1396078169345856 (0.2557822989254463)	Acc@1  98.44 ( 92.84)	Acc@5  98.44 ( 98.40)
Epoch: [61][ 50/109]	Time  0.488 ( 0.752)	Data  0.000 ( 0.124)	Loss 0.4488972127437592 (0.2657288444392821)	Acc@1  90.62 ( 92.77)	Acc@5  93.75 ( 98.10)
Epoch: [61][ 60/109]	Time  0.619 ( 0.720)	Data  0.000 ( 0.104)	Loss 0.2562126219272614 (0.2728369372789977)	Acc@1  95.31 ( 92.75)	Acc@5  96.88 ( 97.95)
Epoch: [61][ 70/109]	Time  0.829 ( 0.709)	Data  0.000 ( 0.089)	Loss 0.3104977309703827 (0.2702079683962003)	Acc@1  89.06 ( 92.87)	Acc@5  98.44 ( 97.95)
Epoch: [61][ 80/109]	Time  0.541 ( 0.699)	Data  0.000 ( 0.078)	Loss 0.1557359695434570 (0.2731765499453486)	Acc@1  93.75 ( 92.88)	Acc@5 100.00 ( 97.90)
Epoch: [61][ 90/109]	Time  0.483 ( 0.677)	Data  0.000 ( 0.070)	Loss 0.1756123751401901 (0.2655934702072825)	Acc@1  95.31 ( 93.10)	Acc@5  98.44 ( 97.99)
Epoch: [61][100/109]	Time  0.735 ( 0.668)	Data  0.000 ( 0.063)	Loss 0.2517169415950775 (0.2650079286777147)	Acc@1  93.75 ( 93.18)	Acc@5  98.44 ( 98.00)
epoch: 61, Avg_Loss 0.25981861940764506
Test: [ 0/28]	Time  4.729 ( 4.729)	Loss 9.6535e-01 (9.6535e-01)	Acc@1  78.12 ( 78.12)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.164 ( 0.661)	Loss 9.8220e-01 (1.0979e+00)	Acc@1  76.56 ( 73.30)	Acc@5  93.75 ( 89.77)
Test: [20/28]	Time  0.128 ( 0.425)	Loss 8.7670e-01 (1.0942e+00)	Acc@1  79.69 ( 72.99)	Acc@5  93.75 ( 89.36)
 * Acc@1 71.919 Acc@5 88.407
lr 0.0001
Epoch: [62][  0/109]	Time  6.348 ( 6.348)	Data  5.586 ( 5.586)	Loss 0.3563930094242096 (0.3563930094242096)	Acc@1  90.62 ( 90.62)	Acc@5  96.88 ( 96.88)
Epoch: [62][ 10/109]	Time  0.630 ( 1.147)	Data  0.001 ( 0.508)	Loss 0.3150840401649475 (0.2926160544157028)	Acc@1  87.50 ( 91.62)	Acc@5  96.88 ( 97.44)
Epoch: [62][ 20/109]	Time  0.547 ( 0.879)	Data  0.000 ( 0.266)	Loss 0.2932179272174835 (0.2766657787419501)	Acc@1  93.75 ( 92.49)	Acc@5  95.31 ( 97.77)
Epoch: [62][ 30/109]	Time  0.846 ( 0.840)	Data  0.000 ( 0.181)	Loss 0.3192912340164185 (0.2727957134765963)	Acc@1  90.62 ( 92.99)	Acc@5  98.44 ( 97.73)
Epoch: [62][ 40/109]	Time  0.502 ( 0.791)	Data  0.000 ( 0.137)	Loss 0.3706032037734985 (0.2872143276944393)	Acc@1  90.62 ( 92.68)	Acc@5  93.75 ( 97.56)
Epoch: [62][ 50/109]	Time  0.518 ( 0.735)	Data  0.000 ( 0.110)	Loss 0.0802369564771652 (0.2745091300092491)	Acc@1 100.00 ( 92.98)	Acc@5 100.00 ( 97.73)
Epoch: [62][ 60/109]	Time  0.532 ( 0.708)	Data  0.000 ( 0.092)	Loss 0.4746035933494568 (0.2759392634034157)	Acc@1  90.62 ( 92.93)	Acc@5 100.00 ( 97.77)
Epoch: [62][ 70/109]	Time  0.517 ( 0.680)	Data  0.000 ( 0.079)	Loss 0.1104456111788750 (0.2663485592519733)	Acc@1  96.88 ( 93.09)	Acc@5 100.00 ( 97.98)
Epoch: [62][ 80/109]	Time  0.489 ( 0.659)	Data  0.000 ( 0.069)	Loss 0.2560072243213654 (0.2692826951359525)	Acc@1  93.75 ( 92.98)	Acc@5  98.44 ( 97.96)
Epoch: [62][ 90/109]	Time  0.853 ( 0.648)	Data  0.000 ( 0.062)	Loss 0.2949153482913971 (0.2687283706861538)	Acc@1  92.19 ( 93.03)	Acc@5  96.88 ( 97.96)
Epoch: [62][100/109]	Time  0.796 ( 0.650)	Data  0.000 ( 0.056)	Loss 0.1905652582645416 (0.2649431302405820)	Acc@1  95.31 ( 93.18)	Acc@5 100.00 ( 98.00)
epoch: 62, Avg_Loss 0.2639266689982983
Test: [ 0/28]	Time  7.311 ( 7.311)	Loss 1.2512e+00 (1.2512e+00)	Acc@1  70.31 ( 70.31)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.175 ( 0.884)	Loss 1.5076e+00 (1.0444e+00)	Acc@1  73.44 ( 76.28)	Acc@5  81.25 ( 88.35)
Test: [20/28]	Time  0.131 ( 0.528)	Loss 1.1369e+00 (1.0338e+00)	Acc@1  67.19 ( 74.63)	Acc@5  87.50 ( 89.06)
 * Acc@1 74.620 Acc@5 89.195
lr 0.0001
Epoch: [63][  0/109]	Time  5.279 ( 5.279)	Data  4.686 ( 4.686)	Loss 0.2725027203559875 (0.2725027203559875)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [63][ 10/109]	Time  1.544 ( 1.389)	Data  0.002 ( 0.427)	Loss 0.3308116495609283 (0.2054529190063477)	Acc@1  92.19 ( 95.31)	Acc@5  95.31 ( 98.72)
Epoch: [63][ 20/109]	Time  0.521 ( 1.224)	Data  0.000 ( 0.224)	Loss 0.3157316744327545 (0.2246543442209562)	Acc@1  92.19 ( 94.35)	Acc@5  96.88 ( 98.74)
Epoch: [63][ 30/109]	Time  0.959 ( 1.030)	Data  0.000 ( 0.152)	Loss 0.3147165179252625 (0.2133400812745094)	Acc@1  93.75 ( 94.76)	Acc@5  95.31 ( 98.64)
Epoch: [63][ 40/109]	Time  1.040 ( 0.977)	Data  0.000 ( 0.115)	Loss 0.4021470546722412 (0.2173620366105219)	Acc@1  90.62 ( 94.78)	Acc@5  98.44 ( 98.55)
Epoch: [63][ 50/109]	Time  0.702 ( 0.945)	Data  0.000 ( 0.092)	Loss 0.2417153567075729 (0.2204927083323984)	Acc@1  95.31 ( 94.67)	Acc@5  98.44 ( 98.53)
Epoch: [63][ 60/109]	Time  0.656 ( 0.885)	Data  0.000 ( 0.077)	Loss 0.2058866322040558 (0.2182123492487141)	Acc@1  93.75 ( 94.67)	Acc@5  98.44 ( 98.51)
Epoch: [63][ 70/109]	Time  0.687 ( 0.859)	Data  0.000 ( 0.067)	Loss 0.3435833454132080 (0.2178359902660612)	Acc@1  90.62 ( 94.67)	Acc@5  96.88 ( 98.53)
Epoch: [63][ 80/109]	Time  0.554 ( 0.866)	Data  0.000 ( 0.058)	Loss 0.2603127956390381 (0.2252538339407356)	Acc@1  92.19 ( 94.46)	Acc@5 100.00 ( 98.44)
Epoch: [63][ 90/109]	Time  0.924 ( 0.838)	Data  0.000 ( 0.052)	Loss 0.3031366169452667 (0.2232876701669378)	Acc@1  92.19 ( 94.49)	Acc@5  95.31 ( 98.44)
Epoch: [63][100/109]	Time  0.544 ( 0.831)	Data  0.000 ( 0.047)	Loss 0.2431741356849670 (0.2287989623180710)	Acc@1  93.75 ( 94.28)	Acc@5  98.44 ( 98.34)
epoch: 63, Avg_Loss 0.2326538199131642
Test: [ 0/28]	Time  4.839 ( 4.839)	Loss 1.1877e+00 (1.1877e+00)	Acc@1  78.12 ( 78.12)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.210 ( 0.742)	Loss 1.0534e+00 (1.1202e+00)	Acc@1  79.69 ( 74.29)	Acc@5  92.19 ( 89.91)
Test: [20/28]	Time  0.379 ( 0.519)	Loss 1.0019e+00 (1.0645e+00)	Acc@1  71.88 ( 75.30)	Acc@5  93.75 ( 89.73)
 * Acc@1 74.676 Acc@5 89.758
lr 0.0001
Epoch: [64][  0/109]	Time  9.581 ( 9.581)	Data  9.035 ( 9.035)	Loss 0.1982763409614563 (0.1982763409614563)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [64][ 10/109]	Time  1.039 ( 1.487)	Data  0.001 ( 0.822)	Loss 0.1289518773555756 (0.2244453701105985)	Acc@1  96.88 ( 94.18)	Acc@5  98.44 ( 98.44)
Epoch: [64][ 20/109]	Time  0.989 ( 1.474)	Data  0.001 ( 0.431)	Loss 0.1420531272888184 (0.2288746351287478)	Acc@1  95.31 ( 94.20)	Acc@5 100.00 ( 98.21)
Epoch: [64][ 30/109]	Time  0.466 ( 1.168)	Data  0.000 ( 0.292)	Loss 0.3160339593887329 (0.2228878904734888)	Acc@1  90.62 ( 94.46)	Acc@5  96.88 ( 98.34)
Epoch: [64][ 40/109]	Time  0.478 ( 1.007)	Data  0.000 ( 0.221)	Loss 0.2585878074169159 (0.2262628703582578)	Acc@1  93.75 ( 94.51)	Acc@5  95.31 ( 98.29)
Epoch: [64][ 50/109]	Time  0.814 ( 0.926)	Data  0.000 ( 0.178)	Loss 0.1203587278723717 (0.2202845693511122)	Acc@1  98.44 ( 94.76)	Acc@5 100.00 ( 98.22)
Epoch: [64][ 60/109]	Time  0.504 ( 0.866)	Data  0.000 ( 0.149)	Loss 0.2101644724607468 (0.2243028886494089)	Acc@1  93.75 ( 94.52)	Acc@5 100.00 ( 98.18)
Epoch: [64][ 70/109]	Time  0.491 ( 0.818)	Data  0.000 ( 0.128)	Loss 0.1876787841320038 (0.2167598251515711)	Acc@1  95.31 ( 94.65)	Acc@5  98.44 ( 98.33)
Epoch: [64][ 80/109]	Time  1.120 ( 0.812)	Data  0.001 ( 0.112)	Loss 0.2058540284633636 (0.2189529864692394)	Acc@1  93.75 ( 94.54)	Acc@5 100.00 ( 98.40)
Epoch: [64][ 90/109]	Time  0.950 ( 0.819)	Data  0.000 ( 0.100)	Loss 0.1248116195201874 (0.2161662308396874)	Acc@1  96.88 ( 94.61)	Acc@5 100.00 ( 98.42)
Epoch: [64][100/109]	Time  0.513 ( 0.818)	Data  0.000 ( 0.090)	Loss 0.1219888031482697 (0.2146330275895572)	Acc@1  98.44 ( 94.71)	Acc@5 100.00 ( 98.39)
epoch: 64, Avg_Loss 0.21127420885983958
Test: [ 0/28]	Time  4.284 ( 4.284)	Loss 1.0390e+00 (1.0390e+00)	Acc@1  68.75 ( 68.75)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.173 ( 0.594)	Loss 6.6188e-01 (1.1180e+00)	Acc@1  82.81 ( 72.59)	Acc@5  92.19 ( 88.21)
Test: [20/28]	Time  0.117 ( 0.369)	Loss 8.8216e-01 (1.0524e+00)	Acc@1  71.88 ( 73.59)	Acc@5  90.62 ( 89.21)
 * Acc@1 74.001 Acc@5 89.871
lr 0.0001
Epoch: [65][  0/109]	Time  5.935 ( 5.935)	Data  4.709 ( 4.709)	Loss 0.2907661795616150 (0.2907661795616150)	Acc@1  92.19 ( 92.19)	Acc@5  96.88 ( 96.88)
Epoch: [65][ 10/109]	Time  0.674 ( 1.207)	Data  0.001 ( 0.545)	Loss 0.1426692754030228 (0.2588465864008123)	Acc@1  98.44 ( 93.61)	Acc@5 100.00 ( 98.01)
Epoch: [65][ 20/109]	Time  0.753 ( 0.922)	Data  0.000 ( 0.286)	Loss 0.1318405717611313 (0.2077414730475062)	Acc@1  96.88 ( 94.87)	Acc@5  98.44 ( 98.66)
Epoch: [65][ 30/109]	Time  2.004 ( 1.202)	Data  0.001 ( 0.194)	Loss 0.1429309844970703 (0.1943821016578905)	Acc@1  96.88 ( 95.21)	Acc@5  98.44 ( 98.74)
Epoch: [65][ 40/109]	Time  1.008 ( 1.308)	Data  0.000 ( 0.147)	Loss 0.2388819307088852 (0.1901180372550720)	Acc@1  93.75 ( 95.20)	Acc@5  98.44 ( 98.82)
Epoch: [65][ 50/109]	Time  2.356 ( 1.259)	Data  0.001 ( 0.118)	Loss 0.3143913149833679 (0.1989042590207913)	Acc@1  90.62 ( 94.91)	Acc@5  98.44 ( 98.71)
Epoch: [65][ 60/109]	Time  0.490 ( 1.214)	Data  0.000 ( 0.099)	Loss 0.1241860613226891 (0.1952954466592093)	Acc@1  98.44 ( 95.13)	Acc@5 100.00 ( 98.80)
Epoch: [65][ 70/109]	Time  0.480 ( 1.119)	Data  0.000 ( 0.085)	Loss 0.3463715016841888 (0.2010370402164023)	Acc@1  92.19 ( 95.03)	Acc@5  96.88 ( 98.75)
Epoch: [65][ 80/109]	Time  0.778 ( 1.048)	Data  0.000 ( 0.075)	Loss 0.2253941446542740 (0.1966831854740043)	Acc@1  95.31 ( 95.20)	Acc@5 100.00 ( 98.78)
Epoch: [65][ 90/109]	Time  0.534 ( 1.090)	Data  0.000 ( 0.067)	Loss 0.2940103411674500 (0.1998916407944737)	Acc@1  93.75 ( 95.14)	Acc@5  96.88 ( 98.76)
Epoch: [65][100/109]	Time  0.489 ( 1.035)	Data  0.000 ( 0.060)	Loss 0.2719753980636597 (0.1999551899141014)	Acc@1  93.75 ( 95.19)	Acc@5  98.44 ( 98.72)
epoch: 65, Avg_Loss 0.20038717441739293
Test: [ 0/28]	Time  8.002 ( 8.002)	Loss 1.2821e+00 (1.2821e+00)	Acc@1  73.44 ( 73.44)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.304 ( 0.925)	Loss 8.1214e-01 (1.0564e+00)	Acc@1  84.38 ( 75.00)	Acc@5  93.75 ( 90.91)
Test: [20/28]	Time  0.138 ( 0.552)	Loss 9.1922e-01 (1.0839e+00)	Acc@1  79.69 ( 74.03)	Acc@5  93.75 ( 90.10)
 * Acc@1 73.663 Acc@5 89.814
lr 0.0001
Epoch: [66][  0/109]	Time  5.921 ( 5.921)	Data  5.192 ( 5.192)	Loss 0.3128029704093933 (0.3128029704093933)	Acc@1  93.75 ( 93.75)	Acc@5  95.31 ( 95.31)
Epoch: [66][ 10/109]	Time  0.687 ( 1.078)	Data  0.001 ( 0.472)	Loss 0.3545018434524536 (0.2115319344130429)	Acc@1  89.06 ( 93.89)	Acc@5  96.88 ( 98.58)
Epoch: [66][ 20/109]	Time  0.876 ( 0.909)	Data  0.001 ( 0.248)	Loss 0.2807374298572540 (0.2129366628470875)	Acc@1  93.75 ( 94.35)	Acc@5  98.44 ( 98.59)
Epoch: [66][ 30/109]	Time  0.644 ( 1.126)	Data  0.000 ( 0.169)	Loss 0.1521191596984863 (0.1965275072763043)	Acc@1  95.31 ( 94.71)	Acc@5 100.00 ( 98.89)
Epoch: [66][ 40/109]	Time  0.748 ( 1.056)	Data  0.000 ( 0.128)	Loss 0.2963594198226929 (0.1929004116029274)	Acc@1  92.19 ( 94.70)	Acc@5  98.44 ( 99.01)
Epoch: [66][ 50/109]	Time  0.911 ( 1.021)	Data  0.000 ( 0.103)	Loss 0.1662585288286209 (0.1906317769020212)	Acc@1  96.88 ( 94.91)	Acc@5  98.44 ( 98.99)
Epoch: [66][ 60/109]	Time  0.609 ( 0.976)	Data  0.000 ( 0.086)	Loss 0.1032719388604164 (0.1852708301338993)	Acc@1  96.88 ( 95.13)	Acc@5 100.00 ( 99.03)
Epoch: [66][ 70/109]	Time  0.732 ( 0.918)	Data  0.001 ( 0.074)	Loss 0.1939746290445328 (0.1849195963480103)	Acc@1  96.88 ( 95.18)	Acc@5  98.44 ( 98.94)
Epoch: [66][ 80/109]	Time  1.013 ( 0.887)	Data  0.000 ( 0.065)	Loss 0.3407060205936432 (0.1903404484928390)	Acc@1  90.62 ( 95.12)	Acc@5  96.88 ( 98.88)
Epoch: [66][ 90/109]	Time  0.604 ( 0.867)	Data  0.000 ( 0.058)	Loss 0.3053041398525238 (0.1916496252620613)	Acc@1  89.06 ( 94.99)	Acc@5  98.44 ( 98.90)
Epoch: [66][100/109]	Time  0.635 ( 0.837)	Data  0.000 ( 0.052)	Loss 0.1475718170404434 (0.1918003974795932)	Acc@1  95.31 ( 95.02)	Acc@5 100.00 ( 98.90)
epoch: 66, Avg_Loss 0.19670646104517334
Test: [ 0/28]	Time  5.408 ( 5.408)	Loss 9.4103e-01 (9.4103e-01)	Acc@1  75.00 ( 75.00)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.144 ( 0.705)	Loss 1.0823e+00 (1.0201e+00)	Acc@1  79.69 ( 75.85)	Acc@5  89.06 ( 90.34)
Test: [20/28]	Time  0.118 ( 0.439)	Loss 1.2955e+00 (1.0893e+00)	Acc@1  64.06 ( 73.88)	Acc@5  81.25 ( 89.51)
 * Acc@1 74.114 Acc@5 89.533
lr 0.0001
Epoch: [67][  0/109]	Time  6.641 ( 6.641)	Data  6.007 ( 6.007)	Loss 0.1246833428740501 (0.1246833428740501)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [67][ 10/109]	Time  0.955 ( 1.588)	Data  0.002 ( 0.547)	Loss 0.1152414381504059 (0.1639471860094504)	Acc@1  98.44 ( 96.02)	Acc@5 100.00 ( 99.29)
Epoch: [67][ 20/109]	Time  0.712 ( 1.212)	Data  0.001 ( 0.287)	Loss 0.1724761128425598 (0.1579397409444764)	Acc@1  96.88 ( 96.21)	Acc@5  98.44 ( 99.33)
Epoch: [67][ 30/109]	Time  0.968 ( 1.062)	Data  0.001 ( 0.194)	Loss 0.1565345376729965 (0.1662774511402653)	Acc@1  96.88 ( 96.07)	Acc@5  98.44 ( 99.19)
Epoch: [67][ 40/109]	Time  0.845 ( 1.073)	Data  0.001 ( 0.147)	Loss 0.0889179855585098 (0.1666506825060379)	Acc@1  98.44 ( 95.96)	Acc@5  98.44 ( 98.97)
Epoch: [67][ 50/109]	Time  0.724 ( 0.992)	Data  0.000 ( 0.118)	Loss 0.2002585828304291 (0.1646256543257657)	Acc@1  95.31 ( 96.02)	Acc@5  96.88 ( 98.99)
Epoch: [67][ 60/109]	Time  0.479 ( 0.927)	Data  0.000 ( 0.099)	Loss 0.2148164510726929 (0.1720659791446123)	Acc@1  95.31 ( 95.77)	Acc@5 100.00 ( 98.90)
Epoch: [67][ 70/109]	Time  0.614 ( 0.888)	Data  0.000 ( 0.085)	Loss 0.3084820806980133 (0.1791915303804505)	Acc@1  90.62 ( 95.64)	Acc@5  96.88 ( 98.81)
Epoch: [67][ 80/109]	Time  0.517 ( 0.850)	Data  0.000 ( 0.075)	Loss 0.3214312791824341 (0.1778759188306185)	Acc@1  93.75 ( 95.76)	Acc@5  96.88 ( 98.82)
Epoch: [67][ 90/109]	Time  0.598 ( 0.823)	Data  0.000 ( 0.067)	Loss 0.1433017700910568 (0.1808291943027423)	Acc@1  95.31 ( 95.59)	Acc@5 100.00 ( 98.76)
Epoch: [67][100/109]	Time  0.503 ( 0.806)	Data  0.000 ( 0.060)	Loss 0.1241578534245491 (0.1830530124209305)	Acc@1  98.44 ( 95.51)	Acc@5  98.44 ( 98.78)
epoch: 67, Avg_Loss 0.18135366797310495
Test: [ 0/28]	Time  5.034 ( 5.034)	Loss 9.4655e-01 (9.4655e-01)	Acc@1  76.56 ( 76.56)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.259 ( 0.814)	Loss 1.3074e+00 (1.0629e+00)	Acc@1  71.88 ( 73.44)	Acc@5  85.94 ( 88.49)
Test: [20/28]	Time  0.162 ( 0.527)	Loss 1.0271e+00 (1.0804e+00)	Acc@1  75.00 ( 74.03)	Acc@5  89.06 ( 88.91)
 * Acc@1 74.395 Acc@5 89.364
lr 0.0001
Epoch: [68][  0/109]	Time  7.276 ( 7.276)	Data  6.625 ( 6.625)	Loss 0.1153779774904251 (0.1153779774904251)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [68][ 10/109]	Time  0.600 ( 1.277)	Data  0.001 ( 0.603)	Loss 0.1351282149553299 (0.1855878443880515)	Acc@1  96.88 ( 95.74)	Acc@5  98.44 ( 97.73)
Epoch: [68][ 20/109]	Time  1.595 ( 1.009)	Data  0.001 ( 0.316)	Loss 0.2717531621456146 (0.2003566147316070)	Acc@1  92.19 ( 95.01)	Acc@5  96.88 ( 98.07)
Epoch: [68][ 30/109]	Time  0.505 ( 1.347)	Data  0.000 ( 0.214)	Loss 0.2191556394100189 (0.2021908651917211)	Acc@1  95.31 ( 94.81)	Acc@5  98.44 ( 98.19)
Epoch: [68][ 40/109]	Time  0.616 ( 1.146)	Data  0.000 ( 0.162)	Loss 0.2223751991987228 (0.1956555714331022)	Acc@1  92.19 ( 94.82)	Acc@5  96.88 ( 98.40)
Epoch: [68][ 50/109]	Time  0.726 ( 1.032)	Data  0.000 ( 0.130)	Loss 0.1562746912240982 (0.1940265750768138)	Acc@1  98.44 ( 94.94)	Acc@5  98.44 ( 98.41)
Epoch: [68][ 60/109]	Time  0.499 ( 1.044)	Data  0.000 ( 0.109)	Loss 0.2005685120820999 (0.1922487185382452)	Acc@1  95.31 ( 95.11)	Acc@5  96.88 ( 98.39)
Epoch: [68][ 70/109]	Time  0.907 ( 1.016)	Data  0.001 ( 0.094)	Loss 0.4901486933231354 (0.1938963498867733)	Acc@1  92.19 ( 95.20)	Acc@5  93.75 ( 98.33)
Epoch: [68][ 80/109]	Time  0.544 ( 0.958)	Data  0.000 ( 0.082)	Loss 0.1436841785907745 (0.1922051973732901)	Acc@1  95.31 ( 95.24)	Acc@5  98.44 ( 98.36)
Epoch: [68][ 90/109]	Time  0.501 ( 0.931)	Data  0.000 ( 0.073)	Loss 0.1825093775987625 (0.1917625169505130)	Acc@1  96.88 ( 95.23)	Acc@5  98.44 ( 98.40)
Epoch: [68][100/109]	Time  0.482 ( 0.892)	Data  0.000 ( 0.066)	Loss 0.0520862154662609 (0.1920319411645431)	Acc@1  98.44 ( 95.22)	Acc@5 100.00 ( 98.48)
epoch: 68, Avg_Loss 0.1932945910055156
Test: [ 0/28]	Time  5.590 ( 5.590)	Loss 9.3467e-01 (9.3467e-01)	Acc@1  76.56 ( 76.56)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.279 ( 0.688)	Loss 1.2663e+00 (1.0486e+00)	Acc@1  73.44 ( 73.30)	Acc@5  84.38 ( 89.77)
Test: [20/28]	Time  0.181 ( 0.436)	Loss 1.0498e+00 (1.0724e+00)	Acc@1  78.12 ( 73.29)	Acc@5  92.19 ( 89.81)
 * Acc@1 73.776 Acc@5 89.871
lr 0.0001
Epoch: [69][  0/109]	Time 11.674 (11.674)	Data 11.129 (11.129)	Loss 0.2406384050846100 (0.2406384050846100)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [69][ 10/109]	Time  0.470 ( 1.591)	Data  0.001 ( 1.012)	Loss 0.1418754309415817 (0.1782439754090526)	Acc@1  98.44 ( 95.60)	Acc@5  98.44 ( 98.15)
Epoch: [69][ 20/109]	Time  0.678 ( 1.099)	Data  0.000 ( 0.530)	Loss 0.2839037775993347 (0.1734549784589381)	Acc@1  92.19 ( 95.76)	Acc@5  98.44 ( 98.51)
Epoch: [69][ 30/109]	Time  0.853 ( 1.082)	Data  0.000 ( 0.359)	Loss 0.2366696149110794 (0.1649072402186932)	Acc@1  93.75 ( 96.02)	Acc@5  96.88 ( 98.79)
Epoch: [69][ 40/109]	Time  0.677 ( 0.998)	Data  0.000 ( 0.272)	Loss 0.1802680641412735 (0.1745837602491786)	Acc@1  96.88 ( 95.88)	Acc@5  96.88 ( 98.55)
Epoch: [69][ 50/109]	Time  1.475 ( 0.997)	Data  0.002 ( 0.219)	Loss 0.1543980985879898 (0.1791794369472008)	Acc@1  95.31 ( 95.68)	Acc@5 100.00 ( 98.59)
Epoch: [69][ 60/109]	Time  0.762 ( 0.956)	Data  0.000 ( 0.183)	Loss 0.2018103748559952 (0.1868707820406703)	Acc@1  95.31 ( 95.49)	Acc@5  96.88 ( 98.46)
Epoch: [69][ 70/109]	Time  0.641 ( 0.937)	Data  0.000 ( 0.157)	Loss 0.1495000123977661 (0.1820121560193284)	Acc@1  95.31 ( 95.51)	Acc@5  96.88 ( 98.57)
Epoch: [69][ 80/109]	Time  0.465 ( 0.935)	Data  0.000 ( 0.138)	Loss 0.1860884577035904 (0.1788384765386581)	Acc@1  95.31 ( 95.58)	Acc@5  98.44 ( 98.63)
Epoch: [69][ 90/109]	Time  0.482 ( 0.886)	Data  0.000 ( 0.123)	Loss 0.1787687689065933 (0.1773207074665761)	Acc@1  95.31 ( 95.67)	Acc@5  98.44 ( 98.64)
Epoch: [69][100/109]	Time  0.481 ( 0.847)	Data  0.000 ( 0.111)	Loss 0.0906749367713928 (0.1772238467958304)	Acc@1  95.31 ( 95.70)	Acc@5 100.00 ( 98.51)
epoch: 69, Avg_Loss 0.1811748644969332
Test: [ 0/28]	Time  8.849 ( 8.849)	Loss 9.2094e-01 (9.2094e-01)	Acc@1  78.12 ( 78.12)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.176 ( 1.137)	Loss 1.4948e+00 (1.0049e+00)	Acc@1  73.44 ( 75.28)	Acc@5  84.38 ( 90.20)
Test: [20/28]	Time  0.151 ( 0.674)	Loss 1.3100e+00 (1.0244e+00)	Acc@1  68.75 ( 74.26)	Acc@5  85.94 ( 89.88)
 * Acc@1 73.438 Acc@5 89.308
lr 0.0001
Epoch: [70][  0/109]	Time  8.085 ( 8.085)	Data  7.422 ( 7.422)	Loss 0.1301766484975815 (0.1301766484975815)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [70][ 10/109]	Time  0.777 ( 1.410)	Data  0.002 ( 0.675)	Loss 0.1383209973573685 (0.1640419716184789)	Acc@1  95.31 ( 95.17)	Acc@5 100.00 ( 99.01)
Epoch: [70][ 20/109]	Time  2.267 ( 1.318)	Data  0.000 ( 0.354)	Loss 0.1426837891340256 (0.1836199529823803)	Acc@1  98.44 ( 95.46)	Acc@5 100.00 ( 98.59)
Epoch: [70][ 30/109]	Time  0.599 ( 1.174)	Data  0.000 ( 0.240)	Loss 0.0968220531940460 (0.1941242835694744)	Acc@1  96.88 ( 95.06)	Acc@5 100.00 ( 98.74)
Epoch: [70][ 40/109]	Time  0.542 ( 1.048)	Data  0.000 ( 0.182)	Loss 0.1064534485340118 (0.1883378575851277)	Acc@1  98.44 ( 95.27)	Acc@5 100.00 ( 98.63)
Epoch: [70][ 50/109]	Time  0.817 ( 0.965)	Data  0.000 ( 0.146)	Loss 0.1047695353627205 (0.1798240375869414)	Acc@1  96.88 ( 95.40)	Acc@5 100.00 ( 98.84)
Epoch: [70][ 60/109]	Time  0.482 ( 0.946)	Data  0.000 ( 0.122)	Loss 0.2758666872978210 (0.1797610550630288)	Acc@1  90.62 ( 95.41)	Acc@5  96.88 ( 98.77)
Epoch: [70][ 70/109]	Time  0.492 ( 0.898)	Data  0.000 ( 0.105)	Loss 0.2914235293865204 (0.1784845482505543)	Acc@1  90.62 ( 95.44)	Acc@5  98.44 ( 98.83)
Epoch: [70][ 80/109]	Time  0.546 ( 0.851)	Data  0.000 ( 0.092)	Loss 0.1694966405630112 (0.1767962636587060)	Acc@1  95.31 ( 95.49)	Acc@5 100.00 ( 98.86)
Epoch: [70][ 90/109]	Time  0.788 ( 0.830)	Data  0.000 ( 0.082)	Loss 0.1282780617475510 (0.1783589647038952)	Acc@1  98.44 ( 95.38)	Acc@5  98.44 ( 98.78)
Epoch: [70][100/109]	Time  0.777 ( 0.861)	Data  0.000 ( 0.074)	Loss 0.2748115956783295 (0.1774829934065295)	Acc@1  92.19 ( 95.34)	Acc@5  96.88 ( 98.81)
epoch: 70, Avg_Loss 0.17816480532835383
Test: [ 0/28]	Time  5.286 ( 5.286)	Loss 9.7118e-01 (9.7118e-01)	Acc@1  78.12 ( 78.12)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.208 ( 0.769)	Loss 8.2919e-01 (1.1547e+00)	Acc@1  82.81 ( 73.01)	Acc@5  90.62 ( 88.64)
Test: [20/28]	Time  0.180 ( 0.512)	Loss 1.0855e+00 (1.0995e+00)	Acc@1  71.88 ( 73.88)	Acc@5  90.62 ( 89.29)
 * Acc@1 73.832 Acc@5 89.702
lr 0.0001
Epoch: [71][  0/109]	Time  8.574 ( 8.574)	Data  7.947 ( 7.947)	Loss 0.2085135281085968 (0.2085135281085968)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [71][ 10/109]	Time  0.625 ( 1.293)	Data  0.001 ( 0.723)	Loss 0.1103086695075035 (0.1866945035078309)	Acc@1  98.44 ( 94.74)	Acc@5 100.00 ( 98.30)
Epoch: [71][ 20/109]	Time  0.640 ( 0.943)	Data  0.001 ( 0.379)	Loss 0.2452500909566879 (0.1932407009104888)	Acc@1  92.19 ( 94.72)	Acc@5 100.00 ( 98.29)
Epoch: [71][ 30/109]	Time  1.813 ( 1.151)	Data  0.001 ( 0.257)	Loss 0.1989632397890091 (0.1883212398857840)	Acc@1  93.75 ( 95.01)	Acc@5 100.00 ( 98.39)
Epoch: [71][ 40/109]	Time  0.512 ( 1.044)	Data  0.000 ( 0.194)	Loss 0.0308586526662111 (0.1810838154448969)	Acc@1 100.00 ( 95.05)	Acc@5 100.00 ( 98.63)
Epoch: [71][ 50/109]	Time  0.539 ( 0.944)	Data  0.000 ( 0.156)	Loss 0.1876041740179062 (0.1809328615884571)	Acc@1  95.31 ( 95.13)	Acc@5  96.88 ( 98.59)
Epoch: [71][ 60/109]	Time  0.535 ( 0.894)	Data  0.000 ( 0.131)	Loss 0.0860724151134491 (0.1765073414159114)	Acc@1  96.88 ( 95.31)	Acc@5 100.00 ( 98.64)
Epoch: [71][ 70/109]	Time  0.517 ( 0.846)	Data  0.000 ( 0.113)	Loss 0.1405148655176163 (0.1781742100302182)	Acc@1  98.44 ( 95.36)	Acc@5  98.44 ( 98.55)
Epoch: [71][ 80/109]	Time  0.553 ( 0.816)	Data  0.000 ( 0.099)	Loss 0.1447950601577759 (0.1788422917648230)	Acc@1  95.31 ( 95.29)	Acc@5 100.00 ( 98.59)
Epoch: [71][ 90/109]	Time  0.718 ( 0.804)	Data  0.000 ( 0.088)	Loss 0.0785459056496620 (0.1775356738899763)	Acc@1  98.44 ( 95.38)	Acc@5  98.44 ( 98.59)
Epoch: [71][100/109]	Time  0.623 ( 0.779)	Data  0.000 ( 0.079)	Loss 0.0572513341903687 (0.1758518348641620)	Acc@1  98.44 ( 95.48)	Acc@5 100.00 ( 98.62)
epoch: 71, Avg_Loss 0.17316768238098795
Test: [ 0/28]	Time  7.404 ( 7.404)	Loss 1.3053e+00 (1.3053e+00)	Acc@1  73.44 ( 73.44)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.236 ( 0.870)	Loss 1.3037e+00 (1.1123e+00)	Acc@1  62.50 ( 74.29)	Acc@5  90.62 ( 89.49)
Test: [20/28]	Time  0.143 ( 0.549)	Loss 1.0217e+00 (1.1004e+00)	Acc@1  73.44 ( 73.74)	Acc@5  85.94 ( 89.21)
 * Acc@1 73.889 Acc@5 89.139
lr 0.0001
Epoch: [72][  0/109]	Time  5.911 ( 5.911)	Data  5.216 ( 5.216)	Loss 0.2143292278051376 (0.2143292278051376)	Acc@1  92.19 ( 92.19)	Acc@5  98.44 ( 98.44)
Epoch: [72][ 10/109]	Time  0.759 ( 1.351)	Data  0.001 ( 0.622)	Loss 0.0985710993409157 (0.1718099571087144)	Acc@1  96.88 ( 95.60)	Acc@5 100.00 ( 98.72)
Epoch: [72][ 20/109]	Time  0.547 ( 0.983)	Data  0.000 ( 0.326)	Loss 0.2777464389801025 (0.1746061710374696)	Acc@1  93.75 ( 95.54)	Acc@5  98.44 ( 98.51)
Epoch: [72][ 30/109]	Time  0.756 ( 0.948)	Data  0.001 ( 0.221)	Loss 0.1485467106103897 (0.1753570672965819)	Acc@1  96.88 ( 95.56)	Acc@5  98.44 ( 98.64)
Epoch: [72][ 40/109]	Time  1.644 ( 0.938)	Data  0.001 ( 0.167)	Loss 0.1264020800590515 (0.1729348385479392)	Acc@1  96.88 ( 95.66)	Acc@5  96.88 ( 98.67)
Epoch: [72][ 50/109]	Time  0.501 ( 0.934)	Data  0.000 ( 0.135)	Loss 0.1670243889093399 (0.1710566879779685)	Acc@1  96.88 ( 95.62)	Acc@5  98.44 ( 98.77)
Epoch: [72][ 60/109]	Time  0.495 ( 0.873)	Data  0.000 ( 0.113)	Loss 0.2934899926185608 (0.1706296019866818)	Acc@1  92.19 ( 95.67)	Acc@5  96.88 ( 98.77)
Epoch: [72][ 70/109]	Time  0.616 ( 0.824)	Data  0.000 ( 0.097)	Loss 0.4025217294692993 (0.1767284003361850)	Acc@1  92.19 ( 95.53)	Acc@5  95.31 ( 98.70)
Epoch: [72][ 80/109]	Time  0.486 ( 0.810)	Data  0.000 ( 0.085)	Loss 0.0997917428612709 (0.1750259717673431)	Acc@1  98.44 ( 95.66)	Acc@5 100.00 ( 98.75)
Epoch: [72][ 90/109]	Time  0.462 ( 0.776)	Data  0.000 ( 0.076)	Loss 0.1205468401312828 (0.1702326339270387)	Acc@1  95.31 ( 95.78)	Acc@5  98.44 ( 98.76)
Epoch: [72][100/109]	Time  0.602 ( 0.752)	Data  0.000 ( 0.068)	Loss 0.0749582648277283 (0.1721353224008390)	Acc@1  98.44 ( 95.70)	Acc@5 100.00 ( 98.75)
epoch: 72, Avg_Loss 0.17557963264097862
Test: [ 0/28]	Time  7.199 ( 7.199)	Loss 1.3124e+00 (1.3124e+00)	Acc@1  65.62 ( 65.62)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.169 ( 0.853)	Loss 1.1001e+00 (1.0167e+00)	Acc@1  76.56 ( 75.57)	Acc@5  87.50 ( 89.35)
Test: [20/28]	Time  0.175 ( 0.535)	Loss 1.3591e+00 (1.1162e+00)	Acc@1  71.88 ( 73.44)	Acc@5  85.94 ( 88.32)
 * Acc@1 73.044 Acc@5 88.576
lr 0.0001
Epoch: [73][  0/109]	Time  6.233 ( 6.233)	Data  5.538 ( 5.538)	Loss 0.2221125215291977 (0.2221125215291977)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [73][ 10/109]	Time  0.616 ( 1.222)	Data  0.001 ( 0.504)	Loss 0.0947618857026100 (0.1513807888735424)	Acc@1  95.31 ( 95.74)	Acc@5 100.00 ( 99.43)
Epoch: [73][ 20/109]	Time  0.549 ( 0.904)	Data  0.000 ( 0.264)	Loss 0.2235538363456726 (0.1597041693471727)	Acc@1  93.75 ( 95.76)	Acc@5  98.44 ( 99.03)
Epoch: [73][ 30/109]	Time  0.672 ( 0.800)	Data  0.000 ( 0.179)	Loss 0.0982424542307854 (0.1681530761622614)	Acc@1  96.88 ( 95.51)	Acc@5 100.00 ( 98.94)
Epoch: [73][ 40/109]	Time  0.815 ( 0.899)	Data  0.001 ( 0.136)	Loss 0.2994570732116699 (0.1725074158209126)	Acc@1  93.75 ( 95.58)	Acc@5  98.44 ( 98.86)
Epoch: [73][ 50/109]	Time  0.604 ( 0.865)	Data  0.000 ( 0.109)	Loss 0.3274441063404083 (0.1729548319297678)	Acc@1  93.75 ( 95.56)	Acc@5  95.31 ( 98.84)
Epoch: [73][ 60/109]	Time  0.504 ( 0.810)	Data  0.000 ( 0.091)	Loss 0.1040518581867218 (0.1719949079341576)	Acc@1  96.88 ( 95.67)	Acc@5 100.00 ( 98.77)
Epoch: [73][ 70/109]	Time  0.484 ( 0.774)	Data  0.000 ( 0.079)	Loss 0.1360973715782166 (0.1684547534710924)	Acc@1  98.44 ( 95.77)	Acc@5 100.00 ( 98.81)
Epoch: [73][ 80/109]	Time  0.590 ( 0.755)	Data  0.000 ( 0.069)	Loss 0.2948136329650879 (0.1703141335811880)	Acc@1  93.75 ( 95.76)	Acc@5  96.88 ( 98.82)
Epoch: [73][ 90/109]	Time  0.542 ( 0.732)	Data  0.000 ( 0.061)	Loss 0.1838228106498718 (0.1699741012774981)	Acc@1  95.31 ( 95.69)	Acc@5  96.88 ( 98.82)
Epoch: [73][100/109]	Time  0.728 ( 0.732)	Data  0.000 ( 0.055)	Loss 0.1002132743597031 (0.1678367706366105)	Acc@1  96.88 ( 95.75)	Acc@5 100.00 ( 98.87)
epoch: 73, Avg_Loss 0.16598822983033065
Test: [ 0/28]	Time  7.236 ( 7.236)	Loss 1.4818e+00 (1.4818e+00)	Acc@1  65.62 ( 65.62)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.131 ( 0.886)	Loss 1.1456e+00 (1.1033e+00)	Acc@1  76.56 ( 73.01)	Acc@5  87.50 ( 88.92)
Test: [20/28]	Time  0.119 ( 0.525)	Loss 1.0633e+00 (1.1442e+00)	Acc@1  73.44 ( 71.88)	Acc@5  92.19 ( 88.91)
 * Acc@1 73.776 Acc@5 89.364
lr 0.0001
Epoch: [74][  0/109]	Time  9.013 ( 9.013)	Data  8.141 ( 8.141)	Loss 0.3475351333618164 (0.3475351333618164)	Acc@1  90.62 ( 90.62)	Acc@5  96.88 ( 96.88)
Epoch: [74][ 10/109]	Time  0.543 ( 1.357)	Data  0.001 ( 0.740)	Loss 0.1569136679172516 (0.1633087701418183)	Acc@1  98.44 ( 96.31)	Acc@5  98.44 ( 98.58)
Epoch: [74][ 20/109]	Time  0.479 ( 0.964)	Data  0.000 ( 0.388)	Loss 0.2515480220317841 (0.1710936835124379)	Acc@1  96.88 ( 96.35)	Acc@5  96.88 ( 98.36)
Epoch: [74][ 30/109]	Time  0.761 ( 0.953)	Data  0.000 ( 0.263)	Loss 0.1594461351633072 (0.1645492167482453)	Acc@1  96.88 ( 96.42)	Acc@5  98.44 ( 98.44)
Epoch: [74][ 40/109]	Time  0.774 ( 0.877)	Data  0.000 ( 0.199)	Loss 0.1071566790342331 (0.1682243448023389)	Acc@1  96.88 ( 96.07)	Acc@5 100.00 ( 98.51)
Epoch: [74][ 50/109]	Time  0.674 ( 0.824)	Data  0.000 ( 0.160)	Loss 0.1969259828329086 (0.1617320112007506)	Acc@1  95.31 ( 96.11)	Acc@5  96.88 ( 98.59)
Epoch: [74][ 60/109]	Time  0.564 ( 0.783)	Data  0.000 ( 0.134)	Loss 0.1038057804107666 (0.1592355794349655)	Acc@1  95.31 ( 96.08)	Acc@5 100.00 ( 98.74)
Epoch: [74][ 70/109]	Time  0.529 ( 0.757)	Data  0.000 ( 0.116)	Loss 0.1213050559163094 (0.1609333303927536)	Acc@1  95.31 ( 95.99)	Acc@5 100.00 ( 98.77)
Epoch: [74][ 80/109]	Time  0.571 ( 0.730)	Data  0.000 ( 0.102)	Loss 0.1344562023878098 (0.1596302213492217)	Acc@1  95.31 ( 96.01)	Acc@5 100.00 ( 98.84)
Epoch: [74][ 90/109]	Time  0.713 ( 0.726)	Data  0.000 ( 0.090)	Loss 0.1650985628366470 (0.1619564386105145)	Acc@1  95.31 ( 95.93)	Acc@5  98.44 ( 98.78)
Epoch: [74][100/109]	Time  0.479 ( 0.721)	Data  0.000 ( 0.082)	Loss 0.2006989419460297 (0.1638417863240927)	Acc@1  95.31 ( 95.93)	Acc@5 100.00 ( 98.73)
epoch: 74, Avg_Loss 0.159711458797165
Test: [ 0/28]	Time  4.906 ( 4.906)	Loss 1.4011e+00 (1.4011e+00)	Acc@1  59.38 ( 59.38)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.136 ( 0.759)	Loss 9.3941e-01 (9.7011e-01)	Acc@1  76.56 ( 75.28)	Acc@5  90.62 ( 91.19)
Test: [20/28]	Time  0.120 ( 0.456)	Loss 8.2439e-01 (1.0259e+00)	Acc@1  75.00 ( 74.18)	Acc@5  90.62 ( 90.70)
 * Acc@1 73.551 Acc@5 89.308
lr 0.0001
Epoch: [75][  0/109]	Time  5.711 ( 5.711)	Data  5.015 ( 5.015)	Loss 0.2551060914993286 (0.2551060914993286)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [75][ 10/109]	Time  1.439 ( 1.526)	Data  0.002 ( 0.456)	Loss 0.0797250941395760 (0.1485323086380959)	Acc@1  96.88 ( 96.02)	Acc@5 100.00 ( 98.58)
Epoch: [75][ 20/109]	Time  1.139 ( 1.243)	Data  0.000 ( 0.240)	Loss 0.0671506598591805 (0.1319081891505491)	Acc@1  98.44 ( 96.50)	Acc@5 100.00 ( 99.03)
Epoch: [75][ 30/109]	Time  1.136 ( 1.113)	Data  0.000 ( 0.162)	Loss 0.2495798319578171 (0.1427371005617803)	Acc@1  93.75 ( 96.57)	Acc@5  98.44 ( 98.89)
Epoch: [75][ 40/109]	Time  0.701 ( 1.065)	Data  0.000 ( 0.123)	Loss 0.1305308341979980 (0.1450054997169390)	Acc@1  96.88 ( 96.68)	Acc@5 100.00 ( 98.82)
Epoch: [75][ 50/109]	Time  0.881 ( 1.018)	Data  0.001 ( 0.099)	Loss 0.2439763844013214 (0.1563104516004815)	Acc@1  93.75 ( 96.35)	Acc@5  98.44 ( 98.71)
Epoch: [75][ 60/109]	Time  0.995 ( 1.012)	Data  0.000 ( 0.083)	Loss 0.1728355288505554 (0.1547157663668765)	Acc@1  96.88 ( 96.49)	Acc@5  98.44 ( 98.77)
Epoch: [75][ 70/109]	Time  0.491 ( 0.962)	Data  0.000 ( 0.071)	Loss 0.1546049565076828 (0.1512571883348512)	Acc@1  96.88 ( 96.54)	Acc@5  98.44 ( 98.83)
Epoch: [75][ 80/109]	Time  0.797 ( 0.927)	Data  0.001 ( 0.063)	Loss 0.2581788599491119 (0.1530482735438847)	Acc@1  95.31 ( 96.47)	Acc@5  95.31 ( 98.78)
Epoch: [75][ 90/109]	Time  0.482 ( 0.933)	Data  0.000 ( 0.056)	Loss 0.0671966969966888 (0.1519367745207561)	Acc@1 100.00 ( 96.53)	Acc@5 100.00 ( 98.82)
Epoch: [75][100/109]	Time  0.479 ( 0.896)	Data  0.000 ( 0.050)	Loss 0.1502459794282913 (0.1488079799357617)	Acc@1  93.75 ( 96.63)	Acc@5 100.00 ( 98.86)
epoch: 75, Avg_Loss 0.14765750654383536
Test: [ 0/28]	Time  6.248 ( 6.248)	Loss 1.3278e+00 (1.3278e+00)	Acc@1  75.00 ( 75.00)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.221 ( 0.885)	Loss 1.3534e+00 (1.0327e+00)	Acc@1  60.94 ( 75.00)	Acc@5  84.38 ( 90.91)
Test: [20/28]	Time  0.139 ( 0.583)	Loss 9.5251e-01 (1.0510e+00)	Acc@1  78.12 ( 75.15)	Acc@5  95.31 ( 90.10)
 * Acc@1 75.014 Acc@5 89.758
lr 0.0001
Epoch: [76][  0/109]	Time  5.328 ( 5.328)	Data  4.481 ( 4.481)	Loss 0.0463234856724739 (0.0463234856724739)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [76][ 10/109]	Time  0.555 ( 1.051)	Data  0.001 ( 0.408)	Loss 0.0668882057070732 (0.1692429029128768)	Acc@1  98.44 ( 95.45)	Acc@5 100.00 ( 99.01)
Epoch: [76][ 20/109]	Time  0.609 ( 0.855)	Data  0.000 ( 0.214)	Loss 0.0706503167748451 (0.1551101984722274)	Acc@1 100.00 ( 96.06)	Acc@5 100.00 ( 99.11)
Epoch: [76][ 30/109]	Time  0.926 ( 0.895)	Data  0.000 ( 0.145)	Loss 0.3155066370964050 (0.1679285341693509)	Acc@1  92.19 ( 95.87)	Acc@5  95.31 ( 98.84)
Epoch: [76][ 40/109]	Time  3.748 ( 1.064)	Data  0.003 ( 0.110)	Loss 0.1114149913191795 (0.1565649228670248)	Acc@1  98.44 ( 96.15)	Acc@5  98.44 ( 98.97)
Epoch: [76][ 50/109]	Time  0.464 ( 1.082)	Data  0.000 ( 0.088)	Loss 0.1071718260645866 (0.1606676475528409)	Acc@1  95.31 ( 96.05)	Acc@5 100.00 ( 98.87)
Epoch: [76][ 60/109]	Time  0.645 ( 0.995)	Data  0.000 ( 0.074)	Loss 0.2212171554565430 (0.1660519820622733)	Acc@1  95.31 ( 95.85)	Acc@5  96.88 ( 98.80)
Epoch: [76][ 70/109]	Time  1.079 ( 0.966)	Data  0.001 ( 0.064)	Loss 0.2206620573997498 (0.1618856064660448)	Acc@1  95.31 ( 95.93)	Acc@5  96.88 ( 98.81)
Epoch: [76][ 80/109]	Time  1.058 ( 0.999)	Data  0.000 ( 0.056)	Loss 0.1645636111497879 (0.1633780904022264)	Acc@1  95.31 ( 95.89)	Acc@5 100.00 ( 98.80)
Epoch: [76][ 90/109]	Time  0.482 ( 0.957)	Data  0.000 ( 0.050)	Loss 0.1393054872751236 (0.1651136094888488)	Acc@1  98.44 ( 95.88)	Acc@5  98.44 ( 98.73)
Epoch: [76][100/109]	Time  0.626 ( 0.917)	Data  0.000 ( 0.045)	Loss 0.1236490756273270 (0.1602431847759993)	Acc@1  95.31 ( 96.06)	Acc@5  98.44 ( 98.76)
epoch: 76, Avg_Loss 0.15970834959811026
Test: [ 0/28]	Time  7.384 ( 7.384)	Loss 7.0093e-01 (7.0093e-01)	Acc@1  78.12 ( 78.12)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.155 ( 0.811)	Loss 1.1799e+00 (1.0785e+00)	Acc@1  75.00 ( 73.86)	Acc@5  89.06 ( 90.34)
Test: [20/28]	Time  0.140 ( 0.490)	Loss 1.0866e+00 (1.0674e+00)	Acc@1  79.69 ( 74.70)	Acc@5  90.62 ( 90.10)
 * Acc@1 74.789 Acc@5 89.589
lr 0.0001
Epoch: [77][  0/109]	Time  7.988 ( 7.988)	Data  7.368 ( 7.368)	Loss 0.1863252222537994 (0.1863252222537994)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [77][ 10/109]	Time  0.565 ( 1.252)	Data  0.001 ( 0.670)	Loss 0.1347802728414536 (0.1517546718770807)	Acc@1  96.88 ( 96.73)	Acc@5 100.00 ( 99.15)
Epoch: [77][ 20/109]	Time  0.479 ( 0.899)	Data  0.000 ( 0.351)	Loss 0.0691543519496918 (0.1341391729102248)	Acc@1  98.44 ( 96.80)	Acc@5 100.00 ( 99.26)
Epoch: [77][ 30/109]	Time  1.234 ( 1.097)	Data  0.001 ( 0.238)	Loss 0.1126816570758820 (0.1383913849149981)	Acc@1  96.88 ( 96.67)	Acc@5 100.00 ( 99.19)
Epoch: [77][ 40/109]	Time  1.056 ( 1.302)	Data  0.000 ( 0.180)	Loss 0.0966843962669373 (0.1400355900206217)	Acc@1  96.88 ( 96.68)	Acc@5 100.00 ( 99.12)
Epoch: [77][ 50/109]	Time  0.560 ( 1.161)	Data  0.000 ( 0.145)	Loss 0.1013301983475685 (0.1485828336547403)	Acc@1  96.88 ( 96.42)	Acc@5 100.00 ( 99.02)
Epoch: [77][ 60/109]	Time  0.604 ( 1.058)	Data  0.000 ( 0.121)	Loss 0.2907352745532990 (0.1470925003656599)	Acc@1  95.31 ( 96.52)	Acc@5  98.44 ( 99.08)
Epoch: [77][ 70/109]	Time  0.642 ( 1.022)	Data  0.000 ( 0.104)	Loss 0.1302742063999176 (0.1452551501685045)	Acc@1  96.88 ( 96.52)	Acc@5  98.44 ( 99.03)
Epoch: [77][ 80/109]	Time  0.519 ( 0.966)	Data  0.000 ( 0.091)	Loss 0.1128902956843376 (0.1445898867361707)	Acc@1  96.88 ( 96.53)	Acc@5 100.00 ( 99.00)
Epoch: [77][ 90/109]	Time  0.479 ( 0.914)	Data  0.000 ( 0.081)	Loss 0.0629893317818642 (0.1440347590493959)	Acc@1 100.00 ( 96.57)	Acc@5 100.00 ( 99.00)
Epoch: [77][100/109]	Time  0.519 ( 0.873)	Data  0.000 ( 0.073)	Loss 0.0916972160339355 (0.1445655952032545)	Acc@1  96.88 ( 96.58)	Acc@5 100.00 ( 98.98)
epoch: 77, Avg_Loss 0.14556067342946835
Test: [ 0/28]	Time  7.060 ( 7.060)	Loss 1.3745e+00 (1.3745e+00)	Acc@1  70.31 ( 70.31)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.180 ( 0.927)	Loss 1.0636e+00 (9.7835e-01)	Acc@1  73.44 ( 76.70)	Acc@5  89.06 ( 89.49)
Test: [20/28]	Time  0.170 ( 0.590)	Loss 1.2266e+00 (1.0252e+00)	Acc@1  76.56 ( 75.52)	Acc@5  84.38 ( 88.91)
 * Acc@1 75.070 Acc@5 89.195
lr 0.0001
Epoch: [78][  0/109]	Time  8.081 ( 8.081)	Data  7.318 ( 7.318)	Loss 0.1514460742473602 (0.1514460742473602)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [78][ 10/109]	Time  0.489 ( 1.269)	Data  0.001 ( 0.666)	Loss 0.1552555561065674 (0.1369509236379103)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 99.15)
Epoch: [78][ 20/109]	Time  1.287 ( 1.020)	Data  0.001 ( 0.349)	Loss 0.1064391583204269 (0.1284960008093289)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 99.26)
Epoch: [78][ 30/109]	Time  0.670 ( 1.119)	Data  0.000 ( 0.237)	Loss 0.2381599098443985 (0.1392637553714937)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 98.99)
Epoch: [78][ 40/109]	Time  0.570 ( 1.019)	Data  0.000 ( 0.179)	Loss 0.1541943103075027 (0.1429391804991699)	Acc@1  95.31 ( 96.72)	Acc@5 100.00 ( 99.01)
Epoch: [78][ 50/109]	Time  0.914 ( 0.963)	Data  0.000 ( 0.144)	Loss 0.1440387964248657 (0.1476877875187818)	Acc@1  96.88 ( 96.60)	Acc@5  98.44 ( 98.90)
Epoch: [78][ 60/109]	Time  0.625 ( 0.924)	Data  0.000 ( 0.121)	Loss 0.2133116424083710 (0.1510533018068212)	Acc@1  93.75 ( 96.47)	Acc@5  98.44 ( 98.87)
Epoch: [78][ 70/109]	Time  0.561 ( 0.873)	Data  0.000 ( 0.104)	Loss 0.0739758014678955 (0.1506618066153056)	Acc@1 100.00 ( 96.37)	Acc@5 100.00 ( 98.88)
Epoch: [78][ 80/109]	Time  0.494 ( 0.830)	Data  0.000 ( 0.091)	Loss 0.1503515690565109 (0.1468895911986445)	Acc@1  96.88 ( 96.47)	Acc@5  98.44 ( 98.92)
Epoch: [78][ 90/109]	Time  0.669 ( 0.803)	Data  0.000 ( 0.081)	Loss 0.0591904595494270 (0.1472211066674400)	Acc@1 100.00 ( 96.45)	Acc@5 100.00 ( 98.95)
Epoch: [78][100/109]	Time  0.560 ( 0.786)	Data  0.000 ( 0.073)	Loss 0.1782966256141663 (0.1447402865874885)	Acc@1  92.19 ( 96.49)	Acc@5 100.00 ( 98.99)
epoch: 78, Avg_Loss 0.14629285208402423
Test: [ 0/28]	Time  6.395 ( 6.395)	Loss 9.3138e-01 (9.3138e-01)	Acc@1  71.88 ( 71.88)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.119 ( 0.703)	Loss 9.4325e-01 (1.0197e+00)	Acc@1  79.69 ( 75.71)	Acc@5  93.75 ( 89.63)
Test: [20/28]	Time  0.118 ( 0.426)	Loss 1.4265e+00 (1.0885e+00)	Acc@1  67.19 ( 73.74)	Acc@5  81.25 ( 88.91)
 * Acc@1 73.438 Acc@5 89.139
lr 0.0001
Epoch: [79][  0/109]	Time  4.262 ( 4.262)	Data  3.673 ( 3.673)	Loss 0.1335960924625397 (0.1335960924625397)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [79][ 10/109]	Time  1.243 ( 1.190)	Data  0.001 ( 0.420)	Loss 0.1766223460435867 (0.1492895213040439)	Acc@1  95.31 ( 96.73)	Acc@5  96.88 ( 98.44)
Epoch: [79][ 20/109]	Time  0.707 ( 1.393)	Data  0.000 ( 0.220)	Loss 0.1095210313796997 (0.1384349021883238)	Acc@1  96.88 ( 96.50)	Acc@5 100.00 ( 98.88)
Epoch: [79][ 30/109]	Time  0.694 ( 1.250)	Data  0.000 ( 0.149)	Loss 0.2123440504074097 (0.1364003663822528)	Acc@1  95.31 ( 96.57)	Acc@5  96.88 ( 99.04)
Epoch: [79][ 40/109]	Time  1.856 ( 1.215)	Data  0.001 ( 0.113)	Loss 0.0746742710471153 (0.1401305155964886)	Acc@1  98.44 ( 96.34)	Acc@5 100.00 ( 99.09)
Epoch: [79][ 50/109]	Time  0.709 ( 1.135)	Data  0.000 ( 0.091)	Loss 0.0684489533305168 (0.1402989758142069)	Acc@1  96.88 ( 96.48)	Acc@5 100.00 ( 98.96)
Epoch: [79][ 60/109]	Time  0.472 ( 1.035)	Data  0.000 ( 0.076)	Loss 0.1037487164139748 (0.1422601795343102)	Acc@1  96.88 ( 96.54)	Acc@5 100.00 ( 98.90)
Epoch: [79][ 70/109]	Time  1.389 ( 1.012)	Data  0.001 ( 0.066)	Loss 0.2373382896184921 (0.1495077220696799)	Acc@1  93.75 ( 96.41)	Acc@5  98.44 ( 98.72)
Epoch: [79][ 80/109]	Time  0.561 ( 1.007)	Data  0.000 ( 0.058)	Loss 0.1071555167436600 (0.1519163530549885)	Acc@1  98.44 ( 96.30)	Acc@5 100.00 ( 98.71)
Epoch: [79][ 90/109]	Time  0.484 ( 0.952)	Data  0.000 ( 0.051)	Loss 0.1236490830779076 (0.1493278560893876)	Acc@1  98.44 ( 96.38)	Acc@5 100.00 ( 98.80)
Epoch: [79][100/109]	Time  0.613 ( 0.907)	Data  0.000 ( 0.046)	Loss 0.0641315802931786 (0.1493408649717227)	Acc@1  98.44 ( 96.40)	Acc@5 100.00 ( 98.79)
epoch: 79, Avg_Loss 0.14878071451542574
Test: [ 0/28]	Time  7.688 ( 7.688)	Loss 7.5427e-01 (7.5427e-01)	Acc@1  76.56 ( 76.56)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.119 ( 0.886)	Loss 1.3149e+00 (1.0551e+00)	Acc@1  67.19 ( 73.86)	Acc@5  87.50 ( 89.63)
Test: [20/28]	Time  0.381 ( 0.562)	Loss 1.0566e+00 (1.0522e+00)	Acc@1  78.12 ( 73.96)	Acc@5  87.50 ( 89.88)
 * Acc@1 73.889 Acc@5 89.645
lr 0.0001
Epoch: [80][  0/109]	Time  7.371 ( 7.371)	Data  6.731 ( 6.731)	Loss 0.1005851626396179 (0.1005851626396179)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [80][ 10/109]	Time  0.658 ( 1.237)	Data  0.001 ( 0.612)	Loss 0.1022985801100731 (0.1143280416727066)	Acc@1  98.44 ( 97.30)	Acc@5  98.44 ( 99.15)
Epoch: [80][ 20/109]	Time  0.463 ( 0.903)	Data  0.000 ( 0.321)	Loss 0.0723727419972420 (0.1410984627547718)	Acc@1  98.44 ( 96.35)	Acc@5 100.00 ( 98.81)
Epoch: [80][ 30/109]	Time  0.646 ( 0.781)	Data  0.000 ( 0.217)	Loss 0.1801292151212692 (0.1373140988571029)	Acc@1  95.31 ( 96.47)	Acc@5 100.00 ( 99.04)
Epoch: [80][ 40/109]	Time  1.462 ( 0.849)	Data  0.001 ( 0.165)	Loss 0.1478825658559799 (0.1453637130921934)	Acc@1  95.31 ( 96.30)	Acc@5 100.00 ( 98.93)
Epoch: [80][ 50/109]	Time  0.545 ( 0.895)	Data  0.000 ( 0.132)	Loss 0.2455813735723495 (0.1513739056593063)	Acc@1  92.19 ( 96.11)	Acc@5  98.44 ( 98.77)
Epoch: [80][ 60/109]	Time  0.714 ( 0.843)	Data  0.000 ( 0.111)	Loss 0.1600122451782227 (0.1539618376581395)	Acc@1  96.88 ( 96.00)	Acc@5  98.44 ( 98.72)
Epoch: [80][ 70/109]	Time  0.885 ( 0.853)	Data  0.000 ( 0.095)	Loss 0.1578326821327209 (0.1536709633459088)	Acc@1  96.88 ( 96.04)	Acc@5 100.00 ( 98.77)
Epoch: [80][ 80/109]	Time  0.594 ( 0.826)	Data  0.000 ( 0.083)	Loss 0.0911623537540436 (0.1509461032893555)	Acc@1  98.44 ( 96.16)	Acc@5  98.44 ( 98.80)
Epoch: [80][ 90/109]	Time  0.671 ( 0.880)	Data  0.000 ( 0.074)	Loss 0.0519034415483475 (0.1493776124380120)	Acc@1 100.00 ( 96.17)	Acc@5 100.00 ( 98.82)
Epoch: [80][100/109]	Time  0.732 ( 0.861)	Data  0.000 ( 0.067)	Loss 0.1290613114833832 (0.1477615026812447)	Acc@1  96.88 ( 96.29)	Acc@5  98.44 ( 98.84)
epoch: 80, Avg_Loss 0.14354865112846052
Test: [ 0/28]	Time  6.608 ( 6.608)	Loss 1.0429e+00 (1.0429e+00)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.158 ( 0.740)	Loss 9.5750e-01 (1.0412e+00)	Acc@1  76.56 ( 75.00)	Acc@5  95.31 ( 89.20)
Test: [20/28]	Time  0.117 ( 0.444)	Loss 1.0369e+00 (1.0745e+00)	Acc@1  76.56 ( 74.33)	Acc@5  87.50 ( 89.29)
 * Acc@1 74.114 Acc@5 89.252
lr 0.0001
Epoch: [81][  0/109]	Time  4.995 ( 4.995)	Data  3.794 ( 3.794)	Loss 0.2159333676099777 (0.2159333676099777)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [81][ 10/109]	Time  0.599 ( 1.302)	Data  0.001 ( 0.555)	Loss 0.1119542792439461 (0.1511835019019517)	Acc@1  96.88 ( 95.88)	Acc@5 100.00 ( 98.58)
Epoch: [81][ 20/109]	Time  1.213 ( 1.017)	Data  0.001 ( 0.291)	Loss 0.0777858495712280 (0.1516807354277089)	Acc@1  98.44 ( 96.35)	Acc@5 100.00 ( 98.81)
Epoch: [81][ 30/109]	Time  0.485 ( 1.133)	Data  0.000 ( 0.197)	Loss 0.1056342273950577 (0.1492209611160140)	Acc@1  96.88 ( 96.42)	Acc@5 100.00 ( 98.74)
Epoch: [81][ 40/109]	Time  1.017 ( 1.026)	Data  0.000 ( 0.149)	Loss 0.1450873762369156 (0.1561560617169229)	Acc@1  95.31 ( 96.27)	Acc@5 100.00 ( 98.55)
Epoch: [81][ 50/109]	Time  0.722 ( 0.973)	Data  0.000 ( 0.120)	Loss 0.4438366293907166 (0.1622356739552582)	Acc@1  90.62 ( 96.08)	Acc@5  93.75 ( 98.47)
Epoch: [81][ 60/109]	Time  0.560 ( 0.920)	Data  0.000 ( 0.100)	Loss 0.1452898830175400 (0.1584628524228198)	Acc@1  93.75 ( 96.06)	Acc@5  98.44 ( 98.49)
Epoch: [81][ 70/109]	Time  1.197 ( 0.945)	Data  0.000 ( 0.087)	Loss 0.1925822049379349 (0.1559075221524272)	Acc@1  96.88 ( 96.15)	Acc@5  98.44 ( 98.59)
Epoch: [81][ 80/109]	Time  1.638 ( 0.982)	Data  0.000 ( 0.076)	Loss 0.1682538837194443 (0.1565299207505620)	Acc@1  95.31 ( 96.18)	Acc@5  98.44 ( 98.63)
Epoch: [81][ 90/109]	Time  0.503 ( 0.928)	Data  0.000 ( 0.068)	Loss 0.1321548372507095 (0.1549406115088489)	Acc@1  96.88 ( 96.22)	Acc@5  98.44 ( 98.66)
Epoch: [81][100/109]	Time  0.479 ( 0.887)	Data  0.000 ( 0.061)	Loss 0.2140759974718094 (0.1562240404436494)	Acc@1  93.75 ( 96.21)	Acc@5  98.44 ( 98.64)
epoch: 81, Avg_Loss 0.15578028774999697
Test: [ 0/28]	Time  5.880 ( 5.880)	Loss 9.8930e-01 (9.8930e-01)	Acc@1  75.00 ( 75.00)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.170 ( 0.769)	Loss 9.1520e-01 (1.1183e+00)	Acc@1  81.25 ( 72.73)	Acc@5  93.75 ( 90.06)
Test: [20/28]	Time  0.148 ( 0.509)	Loss 6.9174e-01 (1.1053e+00)	Acc@1  78.12 ( 74.03)	Acc@5  92.19 ( 88.69)
 * Acc@1 74.451 Acc@5 89.364
lr 0.0001
Epoch: [82][  0/109]	Time  8.296 ( 8.296)	Data  7.571 ( 7.571)	Loss 0.1697980463504791 (0.1697980463504791)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [82][ 10/109]	Time  0.915 ( 1.599)	Data  0.002 ( 0.689)	Loss 0.1698028296232224 (0.1252817481078885)	Acc@1  95.31 ( 97.16)	Acc@5  98.44 ( 99.15)
Epoch: [82][ 20/109]	Time  0.559 ( 1.496)	Data  0.000 ( 0.361)	Loss 0.1376913934946060 (0.1390761039441540)	Acc@1  96.88 ( 96.50)	Acc@5  98.44 ( 98.88)
Epoch: [82][ 30/109]	Time  0.561 ( 1.181)	Data  0.000 ( 0.245)	Loss 0.1151216179132462 (0.1454246703895830)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 98.79)
Epoch: [82][ 40/109]	Time  0.633 ( 1.028)	Data  0.000 ( 0.185)	Loss 0.1339679062366486 (0.1427691952302688)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 98.89)
Epoch: [82][ 50/109]	Time  0.636 ( 1.026)	Data  0.000 ( 0.149)	Loss 0.1305854767560959 (0.1419249541473155)	Acc@1  96.88 ( 96.54)	Acc@5  98.44 ( 98.87)
Epoch: [82][ 60/109]	Time  1.824 ( 1.015)	Data  0.001 ( 0.125)	Loss 0.0453665666282177 (0.1385257423046183)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 98.90)
Epoch: [82][ 70/109]	Time  0.547 ( 0.991)	Data  0.000 ( 0.108)	Loss 0.1875570118427277 (0.1403493245827480)	Acc@1  95.31 ( 96.54)	Acc@5  96.88 ( 98.88)
Epoch: [82][ 80/109]	Time  0.556 ( 0.937)	Data  0.000 ( 0.094)	Loss 0.2255057841539383 (0.1431613692806827)	Acc@1  95.31 ( 96.53)	Acc@5  98.44 ( 98.88)
Epoch: [82][ 90/109]	Time  0.499 ( 0.889)	Data  0.000 ( 0.084)	Loss 0.0248123276978731 (0.1456039383147772)	Acc@1 100.00 ( 96.48)	Acc@5 100.00 ( 98.85)
Epoch: [82][100/109]	Time  0.542 ( 0.933)	Data  0.000 ( 0.076)	Loss 0.1475945264101028 (0.1471169209384387)	Acc@1  95.31 ( 96.38)	Acc@5  98.44 ( 98.79)
epoch: 82, Avg_Loss 0.14875237382264858
Test: [ 0/28]	Time  5.245 ( 5.245)	Loss 1.1832e+00 (1.1832e+00)	Acc@1  68.75 ( 68.75)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.148 ( 0.688)	Loss 9.4826e-01 (1.0095e+00)	Acc@1  78.12 ( 75.85)	Acc@5  89.06 ( 89.63)
Test: [20/28]	Time  0.420 ( 0.489)	Loss 8.5934e-01 (1.0426e+00)	Acc@1  76.56 ( 75.52)	Acc@5  92.19 ( 90.18)
 * Acc@1 75.689 Acc@5 89.645
lr 0.0001
Epoch: [83][  0/109]	Time  5.941 ( 5.941)	Data  5.335 ( 5.335)	Loss 0.1901002675294876 (0.1901002675294876)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [83][ 10/109]	Time  0.491 ( 1.040)	Data  0.001 ( 0.485)	Loss 0.2739666700363159 (0.1611230303956704)	Acc@1  92.19 ( 96.16)	Acc@5  96.88 ( 98.30)
Epoch: [83][ 20/109]	Time  1.654 ( 1.019)	Data  0.003 ( 0.254)	Loss 0.1648642420768738 (0.1490138266235590)	Acc@1  95.31 ( 96.13)	Acc@5 100.00 ( 98.66)
Epoch: [83][ 30/109]	Time  0.659 ( 0.958)	Data  0.001 ( 0.173)	Loss 0.0886096879839897 (0.1491021859429536)	Acc@1  98.44 ( 96.37)	Acc@5 100.00 ( 98.69)
Epoch: [83][ 40/109]	Time  0.512 ( 0.899)	Data  0.007 ( 0.131)	Loss 0.1505103409290314 (0.1481415232779776)	Acc@1  96.88 ( 96.27)	Acc@5 100.00 ( 98.63)
Epoch: [83][ 50/109]	Time  1.040 ( 0.841)	Data  0.000 ( 0.105)	Loss 0.2244323194026947 (0.1515186254811638)	Acc@1  95.31 ( 96.17)	Acc@5  98.44 ( 98.65)
Epoch: [83][ 60/109]	Time  0.566 ( 0.817)	Data  0.000 ( 0.088)	Loss 0.1161703169345856 (0.1445380847778965)	Acc@1  96.88 ( 96.39)	Acc@5  98.44 ( 98.74)
Epoch: [83][ 70/109]	Time  0.544 ( 0.782)	Data  0.000 ( 0.076)	Loss 0.1811562627553940 (0.1426509390781883)	Acc@1  95.31 ( 96.43)	Acc@5  98.44 ( 98.79)
Epoch: [83][ 80/109]	Time  0.802 ( 0.782)	Data  0.000 ( 0.066)	Loss 0.2000587880611420 (0.1433855344621855)	Acc@1  96.88 ( 96.43)	Acc@5  98.44 ( 98.82)
Epoch: [83][ 90/109]	Time  0.767 ( 0.780)	Data  0.000 ( 0.059)	Loss 0.1362141817808151 (0.1405856928450393)	Acc@1  96.88 ( 96.53)	Acc@5  98.44 ( 98.88)
Epoch: [83][100/109]	Time  0.502 ( 0.764)	Data  0.000 ( 0.053)	Loss 0.2014969438314438 (0.1396557776312722)	Acc@1  95.31 ( 96.58)	Acc@5  96.88 ( 98.87)
epoch: 83, Avg_Loss 0.13812336580263912
Test: [ 0/28]	Time 12.671 (12.671)	Loss 1.2208e+00 (1.2208e+00)	Acc@1  68.75 ( 68.75)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.132 ( 1.291)	Loss 1.1967e+00 (1.0884e+00)	Acc@1  68.75 ( 73.86)	Acc@5  87.50 ( 89.35)
Test: [20/28]	Time  0.124 ( 0.735)	Loss 1.2125e+00 (1.0641e+00)	Acc@1  68.75 ( 74.40)	Acc@5  89.06 ( 89.73)
 * Acc@1 74.508 Acc@5 89.983
lr 0.0001
Epoch: [84][  0/109]	Time  4.470 ( 4.470)	Data  3.803 ( 3.803)	Loss 0.1897380203008652 (0.1897380203008652)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [84][ 10/109]	Time  0.486 ( 0.951)	Data  0.001 ( 0.346)	Loss 0.0728701204061508 (0.1211499741131609)	Acc@1  98.44 ( 96.16)	Acc@5 100.00 ( 99.57)
Epoch: [84][ 20/109]	Time  5.558 ( 1.309)	Data  0.001 ( 0.182)	Loss 0.1728796511888504 (0.1112388509015242)	Acc@1  95.31 ( 96.80)	Acc@5  98.44 ( 99.55)
Epoch: [84][ 30/109]	Time  0.656 ( 1.116)	Data  0.000 ( 0.123)	Loss 0.1040622740983963 (0.1237937088214582)	Acc@1  96.88 ( 96.52)	Acc@5 100.00 ( 99.19)
Epoch: [84][ 40/109]	Time  0.495 ( 0.973)	Data  0.000 ( 0.093)	Loss 0.0897592157125473 (0.1255602483160612)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 99.24)
Epoch: [84][ 50/109]	Time  1.569 ( 0.913)	Data  0.000 ( 0.075)	Loss 0.1224665269255638 (0.1289748428572042)	Acc@1  96.88 ( 96.48)	Acc@5  96.88 ( 99.17)
Epoch: [84][ 60/109]	Time  0.821 ( 0.975)	Data  0.000 ( 0.063)	Loss 0.1165856495499611 (0.1293450975637944)	Acc@1  96.88 ( 96.57)	Acc@5 100.00 ( 99.21)
Epoch: [84][ 70/109]	Time  0.576 ( 0.936)	Data  0.000 ( 0.054)	Loss 0.1786701530218124 (0.1321745339098951)	Acc@1  96.88 ( 96.43)	Acc@5  98.44 ( 99.14)
Epoch: [84][ 80/109]	Time  0.611 ( 0.908)	Data  0.000 ( 0.048)	Loss 0.1507368683815002 (0.1322733826107449)	Acc@1  98.44 ( 96.51)	Acc@5 100.00 ( 99.15)
Epoch: [84][ 90/109]	Time  0.472 ( 0.865)	Data  0.000 ( 0.042)	Loss 0.0236665215343237 (0.1318018479211317)	Acc@1 100.00 ( 96.55)	Acc@5 100.00 ( 99.14)
Epoch: [84][100/109]	Time  0.777 ( 0.850)	Data  0.000 ( 0.038)	Loss 0.0341819934546947 (0.1322867296230380)	Acc@1 100.00 ( 96.61)	Acc@5 100.00 ( 99.10)
epoch: 84, Avg_Loss 0.13608779893214001
Test: [ 0/28]	Time  4.655 ( 4.655)	Loss 8.6378e-01 (8.6378e-01)	Acc@1  76.56 ( 76.56)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.177 ( 0.689)	Loss 1.3711e+00 (1.0915e+00)	Acc@1  70.31 ( 73.15)	Acc@5  85.94 ( 89.91)
Test: [20/28]	Time  0.126 ( 0.429)	Loss 7.4691e-01 (1.0579e+00)	Acc@1  79.69 ( 73.88)	Acc@5  93.75 ( 89.88)
 * Acc@1 73.270 Acc@5 89.645
lr 0.0001
Epoch: [85][  0/109]	Time  5.417 ( 5.417)	Data  4.748 ( 4.748)	Loss 0.1508896052837372 (0.1508896052837372)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [85][ 10/109]	Time  0.696 ( 1.148)	Data  0.001 ( 0.432)	Loss 0.0906402841210365 (0.1520904990082437)	Acc@1  96.88 ( 95.74)	Acc@5 100.00 ( 98.86)
Epoch: [85][ 20/109]	Time  0.819 ( 1.161)	Data  0.000 ( 0.227)	Loss 0.0524147748947144 (0.1507222762420064)	Acc@1 100.00 ( 95.98)	Acc@5 100.00 ( 98.74)
Epoch: [85][ 30/109]	Time  0.956 ( 1.083)	Data  0.000 ( 0.154)	Loss 0.1758707314729691 (0.1476289980834530)	Acc@1  95.31 ( 96.17)	Acc@5  98.44 ( 98.69)
Epoch: [85][ 40/109]	Time  1.270 ( 1.059)	Data  0.001 ( 0.116)	Loss 0.1651344895362854 (0.1399534987058581)	Acc@1  95.31 ( 96.42)	Acc@5  98.44 ( 98.78)
Epoch: [85][ 50/109]	Time  0.814 ( 1.018)	Data  0.000 ( 0.094)	Loss 0.0822799950838089 (0.1399796532795710)	Acc@1  98.44 ( 96.57)	Acc@5 100.00 ( 98.77)
Epoch: [85][ 60/109]	Time  0.496 ( 0.949)	Data  0.000 ( 0.078)	Loss 0.1146776229143143 (0.1367679211448451)	Acc@1  96.88 ( 96.70)	Acc@5 100.00 ( 98.85)
Epoch: [85][ 70/109]	Time  0.543 ( 0.888)	Data  0.000 ( 0.067)	Loss 0.2514758408069611 (0.1373262696073089)	Acc@1  93.75 ( 96.61)	Acc@5  96.88 ( 98.86)
Epoch: [85][ 80/109]	Time  0.768 ( 0.846)	Data  0.000 ( 0.059)	Loss 0.1937763988971710 (0.1405423058219898)	Acc@1  95.31 ( 96.55)	Acc@5  98.44 ( 98.80)
Epoch: [85][ 90/109]	Time  1.115 ( 0.919)	Data  0.000 ( 0.053)	Loss 0.1950921416282654 (0.1456484189564055)	Acc@1  95.31 ( 96.45)	Acc@5  98.44 ( 98.71)
Epoch: [85][100/109]	Time  1.836 ( 0.946)	Data  0.001 ( 0.047)	Loss 0.0547735653817654 (0.1433452192214456)	Acc@1 100.00 ( 96.52)	Acc@5 100.00 ( 98.75)
epoch: 85, Avg_Loss 0.14039742601437305
Test: [ 0/28]	Time  6.001 ( 6.001)	Loss 1.0200e+00 (1.0200e+00)	Acc@1  78.12 ( 78.12)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.204 ( 0.694)	Loss 9.0434e-01 (1.1030e+00)	Acc@1  76.56 ( 74.43)	Acc@5  92.19 ( 88.78)
Test: [20/28]	Time  0.119 ( 0.427)	Loss 1.2879e+00 (1.0645e+00)	Acc@1  70.31 ( 75.15)	Acc@5  82.81 ( 88.91)
 * Acc@1 75.858 Acc@5 89.645
lr 0.0001
Epoch: [86][  0/109]	Time  5.483 ( 5.483)	Data  4.789 ( 4.789)	Loss 0.1341511160135269 (0.1341511160135269)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [86][ 10/109]	Time  0.512 ( 1.032)	Data  0.001 ( 0.436)	Loss 0.0608559362590313 (0.1029093245213682)	Acc@1 100.00 ( 98.01)	Acc@5 100.00 ( 99.43)
Epoch: [86][ 20/109]	Time  2.425 ( 1.004)	Data  0.000 ( 0.228)	Loss 0.2221497297286987 (0.1118168749269985)	Acc@1  96.88 ( 97.69)	Acc@5  98.44 ( 99.26)
Epoch: [86][ 30/109]	Time  0.535 ( 1.196)	Data  0.000 ( 0.155)	Loss 0.0645805448293686 (0.1154068523356991)	Acc@1  98.44 ( 97.33)	Acc@5 100.00 ( 99.34)
Epoch: [86][ 40/109]	Time  0.653 ( 1.035)	Data  0.000 ( 0.117)	Loss 0.1159152537584305 (0.1187706758699766)	Acc@1  98.44 ( 97.33)	Acc@5  98.44 ( 99.28)
Epoch: [86][ 50/109]	Time  0.489 ( 0.931)	Data  0.000 ( 0.094)	Loss 0.1609109044075012 (0.1225379114130548)	Acc@1  96.88 ( 97.33)	Acc@5  98.44 ( 99.11)
Epoch: [86][ 60/109]	Time  1.078 ( 0.891)	Data  0.000 ( 0.079)	Loss 0.0476291142404079 (0.1209087672597561)	Acc@1 100.00 ( 97.36)	Acc@5 100.00 ( 99.10)
Epoch: [86][ 70/109]	Time  0.539 ( 0.874)	Data  0.000 ( 0.068)	Loss 0.1224959641695023 (0.1232423692364508)	Acc@1  98.44 ( 97.29)	Acc@5  98.44 ( 99.01)
Epoch: [86][ 80/109]	Time  0.664 ( 0.846)	Data  0.000 ( 0.060)	Loss 0.1782336086034775 (0.1272791152429066)	Acc@1  95.31 ( 97.13)	Acc@5  96.88 ( 98.96)
Epoch: [86][ 90/109]	Time  0.828 ( 0.842)	Data  0.000 ( 0.053)	Loss 0.1619833558797836 (0.1349734312107602)	Acc@1  96.88 ( 96.94)	Acc@5  96.88 ( 98.85)
Epoch: [86][100/109]	Time  0.584 ( 0.820)	Data  0.000 ( 0.048)	Loss 0.1354581713676453 (0.1351152999455681)	Acc@1  96.88 ( 96.94)	Acc@5 100.00 ( 98.86)
epoch: 86, Avg_Loss 0.13358025218642086
Test: [ 0/28]	Time  8.138 ( 8.138)	Loss 9.6163e-01 (9.6163e-01)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.135 ( 0.881)	Loss 1.1498e+00 (1.0160e+00)	Acc@1  75.00 ( 75.71)	Acc@5  89.06 ( 89.06)
Test: [20/28]	Time  0.117 ( 0.518)	Loss 8.7575e-01 (1.1063e+00)	Acc@1  78.12 ( 74.33)	Acc@5  89.06 ( 88.54)
 * Acc@1 74.057 Acc@5 88.633
lr 0.0001
Epoch: [87][  0/109]	Time  6.142 ( 6.142)	Data  5.547 ( 5.547)	Loss 0.0960342362523079 (0.0960342362523079)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [87][ 10/109]	Time  1.109 ( 1.663)	Data  0.002 ( 0.505)	Loss 0.1044060438871384 (0.1143680563704534)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 99.15)
Epoch: [87][ 20/109]	Time  0.499 ( 1.146)	Data  0.000 ( 0.265)	Loss 0.2680483460426331 (0.1418609099373931)	Acc@1  93.75 ( 96.50)	Acc@5  96.88 ( 98.74)
Epoch: [87][ 30/109]	Time  0.522 ( 1.095)	Data  0.000 ( 0.179)	Loss 0.1439124345779419 (0.1224269076220451)	Acc@1  95.31 ( 97.08)	Acc@5  98.44 ( 99.04)
Epoch: [87][ 40/109]	Time  1.102 ( 1.073)	Data  0.002 ( 0.136)	Loss 0.1585456579923630 (0.1210610439501158)	Acc@1  95.31 ( 96.91)	Acc@5  98.44 ( 99.01)
Epoch: [87][ 50/109]	Time  1.079 ( 1.134)	Data  0.001 ( 0.109)	Loss 0.0796140283346176 (0.1203037510607757)	Acc@1  98.44 ( 97.03)	Acc@5  98.44 ( 99.05)
Epoch: [87][ 60/109]	Time  0.584 ( 1.073)	Data  0.000 ( 0.092)	Loss 0.1324951052665710 (0.1214395983785879)	Acc@1  96.88 ( 96.95)	Acc@5  98.44 ( 99.08)
Epoch: [87][ 70/109]	Time  0.738 ( 1.020)	Data  0.000 ( 0.079)	Loss 0.1214093491435051 (0.1248864496887570)	Acc@1  96.88 ( 96.92)	Acc@5  98.44 ( 99.08)
Epoch: [87][ 80/109]	Time  0.903 ( 0.983)	Data  0.000 ( 0.069)	Loss 0.1356770396232605 (0.1266793154272032)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 ( 99.09)
Epoch: [87][ 90/109]	Time  0.483 ( 0.932)	Data  0.000 ( 0.061)	Loss 0.2498820126056671 (0.1272430701570196)	Acc@1  93.75 ( 96.86)	Acc@5  95.31 ( 99.02)
Epoch: [87][100/109]	Time  0.606 ( 0.890)	Data  0.000 ( 0.055)	Loss 0.1307169497013092 (0.1295803907779184)	Acc@1  96.88 ( 96.74)	Acc@5 100.00 ( 99.03)
epoch: 87, Avg_Loss 0.13200422981326734
Test: [ 0/28]	Time  5.966 ( 5.966)	Loss 1.3891e+00 (1.3891e+00)	Acc@1  67.19 ( 67.19)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.241 ( 0.868)	Loss 8.1702e-01 (1.2712e+00)	Acc@1  81.25 ( 72.30)	Acc@5  92.19 ( 87.07)
Test: [20/28]	Time  0.178 ( 0.553)	Loss 1.1783e+00 (1.1596e+00)	Acc@1  71.88 ( 74.48)	Acc@5  93.75 ( 88.47)
 * Acc@1 74.676 Acc@5 88.914
lr 0.0001
Epoch: [88][  0/109]	Time  7.228 ( 7.228)	Data  6.592 ( 6.592)	Loss 0.2196552753448486 (0.2196552753448486)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [88][ 10/109]	Time  0.494 ( 1.237)	Data  0.001 ( 0.664)	Loss 0.1028477549552917 (0.1515468169342388)	Acc@1  98.44 ( 96.31)	Acc@5 100.00 ( 98.86)
Epoch: [88][ 20/109]	Time  0.595 ( 0.903)	Data  0.000 ( 0.348)	Loss 0.2435968220233917 (0.1361407244666701)	Acc@1  92.19 ( 96.50)	Acc@5  98.44 ( 99.11)
Epoch: [88][ 30/109]	Time  0.818 ( 0.876)	Data  0.001 ( 0.236)	Loss 0.2241923511028290 (0.1463769028383878)	Acc@1  95.31 ( 96.22)	Acc@5  96.88 ( 98.99)
Epoch: [88][ 40/109]	Time  0.476 ( 0.805)	Data  0.000 ( 0.178)	Loss 0.3523752689361572 (0.1585618835851187)	Acc@1  93.75 ( 96.07)	Acc@5  95.31 ( 98.74)
Epoch: [88][ 50/109]	Time  0.493 ( 0.750)	Data  0.000 ( 0.143)	Loss 0.0824970304965973 (0.1600504191409723)	Acc@1  95.31 ( 96.02)	Acc@5 100.00 ( 98.68)
Epoch: [88][ 60/109]	Time  0.629 ( 0.721)	Data  0.000 ( 0.120)	Loss 0.1060547679662704 (0.1593986876369988)	Acc@1  96.88 ( 95.98)	Acc@5  98.44 ( 98.67)
Epoch: [88][ 70/109]	Time  2.506 ( 0.787)	Data  0.002 ( 0.103)	Loss 0.1353787481784821 (0.1554199680423653)	Acc@1  96.88 ( 96.02)	Acc@5  98.44 ( 98.72)
Epoch: [88][ 80/109]	Time  0.478 ( 0.779)	Data  0.000 ( 0.091)	Loss 0.1913171559572220 (0.1523261618237069)	Acc@1  95.31 ( 96.03)	Acc@5  98.44 ( 98.78)
Epoch: [88][ 90/109]	Time  0.513 ( 0.754)	Data  0.000 ( 0.081)	Loss 0.0431903749704361 (0.1476611967638626)	Acc@1  98.44 ( 96.10)	Acc@5 100.00 ( 98.82)
Epoch: [88][100/109]	Time  0.514 ( 0.745)	Data  0.000 ( 0.073)	Loss 0.1580445766448975 (0.1458003164849954)	Acc@1  96.88 ( 96.21)	Acc@5  96.88 ( 98.81)
epoch: 88, Avg_Loss 0.14161490308924005
Test: [ 0/28]	Time  5.461 ( 5.461)	Loss 1.4630e+00 (1.4630e+00)	Acc@1  68.75 ( 68.75)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.844 ( 1.050)	Loss 1.2496e+00 (1.1376e+00)	Acc@1  68.75 ( 74.43)	Acc@5  84.38 ( 88.49)
Test: [20/28]	Time  0.196 ( 0.715)	Loss 9.6614e-01 (1.1080e+00)	Acc@1  84.38 ( 75.07)	Acc@5  85.94 ( 88.62)
 * Acc@1 74.733 Acc@5 89.252
lr 0.0001
Epoch: [89][  0/109]	Time  6.075 ( 6.075)	Data  5.405 ( 5.405)	Loss 0.0514254271984100 (0.0514254271984100)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [89][ 10/109]	Time  0.861 ( 1.228)	Data  0.001 ( 0.492)	Loss 0.1224955916404724 (0.0897148619829254)	Acc@1  96.88 ( 97.87)	Acc@5  98.44 ( 99.29)
Epoch: [89][ 20/109]	Time  1.743 ( 1.049)	Data  0.000 ( 0.258)	Loss 0.1610879749059677 (0.1033555114464391)	Acc@1  95.31 ( 97.40)	Acc@5  96.88 ( 99.26)
Epoch: [89][ 30/109]	Time  0.880 ( 0.960)	Data  0.000 ( 0.175)	Loss 0.1267702877521515 (0.1173232437802419)	Acc@1  96.88 ( 96.98)	Acc@5  98.44 ( 99.19)
Epoch: [89][ 40/109]	Time  0.488 ( 0.891)	Data  0.000 ( 0.132)	Loss 0.0990164950489998 (0.1257264766524114)	Acc@1  96.88 ( 96.80)	Acc@5 100.00 ( 99.09)
Epoch: [89][ 50/109]	Time  0.486 ( 0.822)	Data  0.000 ( 0.107)	Loss 0.0911159217357635 (0.1265642138051928)	Acc@1  98.44 ( 96.84)	Acc@5 100.00 ( 99.11)
Epoch: [89][ 60/109]	Time  0.823 ( 0.777)	Data  0.000 ( 0.089)	Loss 0.2620181441307068 (0.1261299944894969)	Acc@1  90.62 ( 96.82)	Acc@5  96.88 ( 99.08)
Epoch: [89][ 70/109]	Time  0.481 ( 0.832)	Data  0.000 ( 0.077)	Loss 0.2003817558288574 (0.1290483461745398)	Acc@1  95.31 ( 96.81)	Acc@5  98.44 ( 99.01)
Epoch: [89][ 80/109]	Time  0.543 ( 0.809)	Data  0.000 ( 0.068)	Loss 0.0642278119921684 (0.1274810133179949)	Acc@1 100.00 ( 96.91)	Acc@5 100.00 ( 99.07)
Epoch: [89][ 90/109]	Time  0.484 ( 0.790)	Data  0.000 ( 0.060)	Loss 0.1278673112392426 (0.1275729378685355)	Acc@1  96.88 ( 96.86)	Acc@5  98.44 ( 99.07)
Epoch: [89][100/109]	Time  0.479 ( 0.782)	Data  0.000 ( 0.054)	Loss 0.1366039961576462 (0.1291219715932661)	Acc@1  95.31 ( 96.78)	Acc@5  98.44 ( 99.06)
epoch: 89, Avg_Loss 0.12746225734061878
Test: [ 0/28]	Time  4.167 ( 4.167)	Loss 1.6322e+00 (1.6322e+00)	Acc@1  70.31 ( 70.31)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.166 ( 0.620)	Loss 9.1075e-01 (1.0705e+00)	Acc@1  73.44 ( 74.43)	Acc@5  93.75 ( 89.49)
Test: [20/28]	Time  0.120 ( 0.387)	Loss 1.1594e+00 (1.1234e+00)	Acc@1  70.31 ( 73.88)	Acc@5  87.50 ( 88.69)
 * Acc@1 74.226 Acc@5 88.970
lr 0.0001
Epoch: [90][  0/109]	Time  8.947 ( 8.947)	Data  8.273 ( 8.273)	Loss 0.1036202833056450 (0.1036202833056450)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [90][ 10/109]	Time  0.616 ( 1.345)	Data  0.002 ( 0.753)	Loss 0.3565332591533661 (0.1116000849076293)	Acc@1  90.62 ( 97.16)	Acc@5  96.88 ( 99.57)
Epoch: [90][ 20/109]	Time  0.581 ( 0.968)	Data  0.000 ( 0.394)	Loss 0.1053488925099373 (0.1171392260030622)	Acc@1  95.31 ( 97.10)	Acc@5 100.00 ( 99.40)
Epoch: [90][ 30/109]	Time  0.881 ( 0.923)	Data  0.000 ( 0.267)	Loss 0.0372110083699226 (0.1131873042472909)	Acc@1 100.00 ( 97.33)	Acc@5 100.00 ( 99.45)
Epoch: [90][ 40/109]	Time  1.141 ( 1.017)	Data  0.001 ( 0.202)	Loss 0.1222778707742691 (0.1189898555507747)	Acc@1  96.88 ( 97.14)	Acc@5  98.44 ( 99.20)
Epoch: [90][ 50/109]	Time  0.599 ( 0.942)	Data  0.029 ( 0.163)	Loss 0.3038670420646667 (0.1205873920892676)	Acc@1  92.19 ( 97.12)	Acc@5  96.88 ( 99.20)
Epoch: [90][ 60/109]	Time  0.612 ( 0.881)	Data  0.000 ( 0.137)	Loss 0.2135889232158661 (0.1201186077058560)	Acc@1  93.75 ( 97.03)	Acc@5  96.88 ( 99.23)
Epoch: [90][ 70/109]	Time  0.543 ( 0.852)	Data  0.000 ( 0.118)	Loss 0.1281650960445404 (0.1229189202110742)	Acc@1  95.31 ( 96.92)	Acc@5 100.00 ( 99.19)
Epoch: [90][ 80/109]	Time  0.481 ( 0.809)	Data  0.000 ( 0.103)	Loss 0.0743808895349503 (0.1242493321705196)	Acc@1  96.88 ( 96.91)	Acc@5 100.00 ( 99.19)
Epoch: [90][ 90/109]	Time  0.481 ( 0.774)	Data  0.000 ( 0.092)	Loss 0.0760863348841667 (0.1214789651784596)	Acc@1  98.44 ( 96.89)	Acc@5 100.00 ( 99.21)
Epoch: [90][100/109]	Time  0.486 ( 0.750)	Data  0.000 ( 0.083)	Loss 0.1013829857110977 (0.1262964903017377)	Acc@1  96.88 ( 96.78)	Acc@5 100.00 ( 99.12)
epoch: 90, Avg_Loss 0.1250194648639598
Test: [ 0/28]	Time  3.668 ( 3.668)	Loss 1.0949e+00 (1.0949e+00)	Acc@1  75.00 ( 75.00)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.138 ( 0.662)	Loss 1.0976e+00 (1.2502e+00)	Acc@1  71.88 ( 72.16)	Acc@5  89.06 ( 87.22)
Test: [20/28]	Time  0.118 ( 0.409)	Loss 8.9840e-01 (1.1410e+00)	Acc@1  75.00 ( 73.36)	Acc@5  93.75 ( 88.69)
 * Acc@1 73.044 Acc@5 88.239
lr 0.0001
Epoch: [91][  0/109]	Time  8.800 ( 8.800)	Data  7.862 ( 7.862)	Loss 0.1852243393659592 (0.1852243393659592)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [91][ 10/109]	Time  0.556 ( 1.677)	Data  0.002 ( 0.940)	Loss 0.2246941924095154 (0.1239332443272526)	Acc@1  95.31 ( 96.59)	Acc@5  98.44 ( 99.29)
Epoch: [91][ 20/109]	Time  1.032 ( 1.193)	Data  0.000 ( 0.492)	Loss 0.0922679230570793 (0.1078970479291110)	Acc@1  98.44 ( 97.25)	Acc@5  98.44 ( 99.26)
Epoch: [91][ 30/109]	Time  1.208 ( 1.279)	Data  0.001 ( 0.334)	Loss 0.1269378215074539 (0.1112905055765183)	Acc@1  98.44 ( 97.33)	Acc@5  98.44 ( 99.09)
Epoch: [91][ 40/109]	Time  1.067 ( 1.204)	Data  0.000 ( 0.253)	Loss 0.0547873340547085 (0.1058531575722665)	Acc@1  98.44 ( 97.45)	Acc@5 100.00 ( 99.05)
Epoch: [91][ 50/109]	Time  1.042 ( 1.143)	Data  0.000 ( 0.203)	Loss 0.1555570214986801 (0.1066618763713860)	Acc@1  96.88 ( 97.43)	Acc@5 100.00 ( 99.17)
Epoch: [91][ 60/109]	Time  0.524 ( 1.050)	Data  0.000 ( 0.170)	Loss 0.0265672728419304 (0.1026630530775082)	Acc@1 100.00 ( 97.59)	Acc@5 100.00 ( 99.23)
Epoch: [91][ 70/109]	Time  1.009 ( 0.984)	Data  0.000 ( 0.146)	Loss 0.2770662307739258 (0.1085912340359998)	Acc@1  93.75 ( 97.40)	Acc@5  96.88 ( 99.08)
Epoch: [91][ 80/109]	Time  0.534 ( 0.928)	Data  0.000 ( 0.128)	Loss 0.0834129825234413 (0.1097903300513640)	Acc@1  96.88 ( 97.38)	Acc@5 100.00 ( 99.05)
Epoch: [91][ 90/109]	Time  0.600 ( 0.893)	Data  0.000 ( 0.114)	Loss 0.1251703053712845 (0.1109734375009334)	Acc@1  95.31 ( 97.32)	Acc@5  98.44 ( 99.07)
Epoch: [91][100/109]	Time  0.853 ( 0.893)	Data  0.000 ( 0.103)	Loss 0.1328787803649902 (0.1149729703562242)	Acc@1  96.88 ( 97.11)	Acc@5  98.44 ( 99.06)
epoch: 91, Avg_Loss 0.11337039036112367
Test: [ 0/28]	Time  6.082 ( 6.082)	Loss 1.1344e+00 (1.1344e+00)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.123 ( 0.705)	Loss 8.5979e-01 (1.1990e+00)	Acc@1  81.25 ( 72.59)	Acc@5  89.06 ( 88.49)
Test: [20/28]	Time  0.117 ( 0.427)	Loss 6.9237e-01 (1.0719e+00)	Acc@1  82.81 ( 75.00)	Acc@5  95.31 ( 89.88)
 * Acc@1 74.902 Acc@5 89.871
lr 0.0001
Epoch: [92][  0/109]	Time  8.771 ( 8.771)	Data  7.937 ( 7.937)	Loss 0.1689171493053436 (0.1689171493053436)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [92][ 10/109]	Time  0.722 ( 1.485)	Data  0.002 ( 0.722)	Loss 0.0376023203134537 (0.1257694620977748)	Acc@1  98.44 ( 97.16)	Acc@5 100.00 ( 98.72)
Epoch: [92][ 20/109]	Time  3.203 ( 1.763)	Data  0.033 ( 0.380)	Loss 0.0983699783682823 (0.1130654006486847)	Acc@1  96.88 ( 97.25)	Acc@5 100.00 ( 99.03)
Epoch: [92][ 30/109]	Time  0.625 ( 1.445)	Data  0.000 ( 0.258)	Loss 0.1053571105003357 (0.1078905437381998)	Acc@1  96.88 ( 97.53)	Acc@5 100.00 ( 99.14)
Epoch: [92][ 40/109]	Time  0.541 ( 1.242)	Data  0.000 ( 0.195)	Loss 0.0216761119663715 (0.1089125883015918)	Acc@1 100.00 ( 97.48)	Acc@5 100.00 ( 99.24)
Epoch: [92][ 50/109]	Time  0.742 ( 1.142)	Data  0.000 ( 0.157)	Loss 0.0309795681387186 (0.1101926817540445)	Acc@1 100.00 ( 97.40)	Acc@5 100.00 ( 99.20)
Epoch: [92][ 60/109]	Time  1.597 ( 1.117)	Data  0.016 ( 0.132)	Loss 0.2539335489273071 (0.1121426060124010)	Acc@1  93.75 ( 97.26)	Acc@5  96.88 ( 99.18)
Epoch: [92][ 70/109]	Time  0.764 ( 1.085)	Data  0.000 ( 0.114)	Loss 0.1348047405481339 (0.1118840604076083)	Acc@1  96.88 ( 97.23)	Acc@5 100.00 ( 99.21)
Epoch: [92][ 80/109]	Time  1.215 ( 1.059)	Data  0.000 ( 0.100)	Loss 0.1744192242622375 (0.1087504498384617)	Acc@1  98.44 ( 97.36)	Acc@5  98.44 ( 99.27)
Epoch: [92][ 90/109]	Time  0.703 ( 1.072)	Data  0.000 ( 0.089)	Loss 0.1912245005369186 (0.1117631079281097)	Acc@1  93.75 ( 97.36)	Acc@5  98.44 ( 99.21)
Epoch: [92][100/109]	Time  0.561 ( 1.026)	Data  0.000 ( 0.080)	Loss 0.2322082817554474 (0.1149298880101726)	Acc@1  93.75 ( 97.22)	Acc@5  98.44 ( 99.16)
epoch: 92, Avg_Loss 0.11529599121609412
Test: [ 0/28]	Time  4.721 ( 4.721)	Loss 7.6384e-01 (7.6384e-01)	Acc@1  79.69 ( 79.69)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.205 ( 0.683)	Loss 1.3548e+00 (1.0446e+00)	Acc@1  73.44 ( 75.71)	Acc@5  87.50 ( 89.35)
Test: [20/28]	Time  0.184 ( 0.454)	Loss 1.0603e+00 (1.1015e+00)	Acc@1  75.00 ( 75.07)	Acc@5  90.62 ( 88.76)
 * Acc@1 74.451 Acc@5 88.970
lr 0.0001
Epoch: [93][  0/109]	Time 10.918 (10.918)	Data 10.153 (10.153)	Loss 0.1494549959897995 (0.1494549959897995)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [93][ 10/109]	Time  0.550 ( 1.916)	Data  0.001 ( 1.051)	Loss 0.0723311603069305 (0.1172767461023547)	Acc@1  98.44 ( 96.73)	Acc@5  98.44 ( 99.15)
Epoch: [93][ 20/109]	Time  1.534 ( 1.494)	Data  0.001 ( 0.551)	Loss 0.1480034142732620 (0.0997452143402327)	Acc@1  96.88 ( 97.17)	Acc@5  98.44 ( 99.40)
Epoch: [93][ 30/109]	Time  0.939 ( 1.370)	Data  0.000 ( 0.374)	Loss 0.1906896084547043 (0.1144539090173860)	Acc@1  95.31 ( 97.08)	Acc@5  98.44 ( 99.09)
Epoch: [93][ 40/109]	Time  2.291 ( 1.293)	Data  0.001 ( 0.283)	Loss 0.2230781912803650 (0.1251389496937031)	Acc@1  93.75 ( 96.80)	Acc@5  98.44 ( 98.93)
Epoch: [93][ 50/109]	Time  0.481 ( 1.296)	Data  0.000 ( 0.227)	Loss 0.0649138167500496 (0.1184589091469260)	Acc@1  98.44 ( 96.91)	Acc@5 100.00 ( 99.08)
Epoch: [93][ 60/109]	Time  0.828 ( 1.191)	Data  0.000 ( 0.190)	Loss 0.2568466663360596 (0.1206902002946275)	Acc@1  93.75 ( 96.90)	Acc@5  96.88 ( 99.08)
Epoch: [93][ 70/109]	Time  2.191 ( 1.138)	Data  0.001 ( 0.163)	Loss 0.0778288021683693 (0.1194489179047900)	Acc@1  98.44 ( 96.94)	Acc@5 100.00 ( 99.08)
Epoch: [93][ 80/109]	Time  0.778 ( 1.181)	Data  0.000 ( 0.143)	Loss 0.2115744948387146 (0.1189586343588652)	Acc@1  93.75 ( 96.86)	Acc@5  98.44 ( 99.11)
Epoch: [93][ 90/109]	Time  0.767 ( 1.142)	Data  0.000 ( 0.128)	Loss 0.0710545256733894 (0.1223307777973977)	Acc@1  98.44 ( 96.82)	Acc@5 100.00 ( 99.11)
Epoch: [93][100/109]	Time  0.498 ( 1.087)	Data  0.000 ( 0.115)	Loss 0.1132941171526909 (0.1241185424277688)	Acc@1  98.44 ( 96.75)	Acc@5 100.00 ( 99.07)
epoch: 93, Avg_Loss 0.12929425501358618
Test: [ 0/28]	Time  7.227 ( 7.227)	Loss 1.2867e+00 (1.2867e+00)	Acc@1  71.88 ( 71.88)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.122 ( 0.795)	Loss 1.0635e+00 (1.1042e+00)	Acc@1  70.31 ( 75.00)	Acc@5  87.50 ( 89.06)
Test: [20/28]	Time  0.118 ( 0.474)	Loss 8.8124e-01 (1.0946e+00)	Acc@1  75.00 ( 74.93)	Acc@5  93.75 ( 89.14)
 * Acc@1 75.521 Acc@5 89.814
lr 0.0001
Epoch: [94][  0/109]	Time  5.644 ( 5.644)	Data  4.910 ( 4.910)	Loss 0.0406234152615070 (0.0406234152615070)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [94][ 10/109]	Time  1.775 ( 1.678)	Data  0.003 ( 0.505)	Loss 0.0241936519742012 (0.0928481065414169)	Acc@1 100.00 ( 97.59)	Acc@5 100.00 ( 99.57)
Epoch: [94][ 20/109]	Time  0.595 ( 1.593)	Data  0.000 ( 0.265)	Loss 0.1216217800974846 (0.1263921271477427)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 99.11)
Epoch: [94][ 30/109]	Time  0.816 ( 1.263)	Data  0.000 ( 0.180)	Loss 0.0892218053340912 (0.1156098192497607)	Acc@1  96.88 ( 97.23)	Acc@5  98.44 ( 99.14)
Epoch: [94][ 40/109]	Time  0.895 ( 1.127)	Data  0.000 ( 0.136)	Loss 0.0953476428985596 (0.1276070160291544)	Acc@1  98.44 ( 96.95)	Acc@5  98.44 ( 98.93)
Epoch: [94][ 50/109]	Time  1.832 ( 1.058)	Data  0.000 ( 0.110)	Loss 0.1514510065317154 (0.1308405679084507)	Acc@1  95.31 ( 96.88)	Acc@5 100.00 ( 98.96)
Epoch: [94][ 60/109]	Time  0.473 ( 1.026)	Data  0.000 ( 0.092)	Loss 0.1252627521753311 (0.1349433485235347)	Acc@1  98.44 ( 96.77)	Acc@5  98.44 ( 98.87)
Epoch: [94][ 70/109]	Time  0.488 ( 0.955)	Data  0.000 ( 0.079)	Loss 0.1546330451965332 (0.1342901474940525)	Acc@1  98.44 ( 96.74)	Acc@5  98.44 ( 98.88)
Epoch: [94][ 80/109]	Time  0.568 ( 0.951)	Data  0.000 ( 0.069)	Loss 0.1670771688222885 (0.1300316297759612)	Acc@1  95.31 ( 96.80)	Acc@5  98.44 ( 98.96)
Epoch: [94][ 90/109]	Time  0.532 ( 0.909)	Data  0.000 ( 0.062)	Loss 0.0614985078573227 (0.1290512904934176)	Acc@1 100.00 ( 96.84)	Acc@5 100.00 ( 98.97)
Epoch: [94][100/109]	Time  0.815 ( 0.886)	Data  0.000 ( 0.056)	Loss 0.1772783547639847 (0.1284840136102521)	Acc@1  95.31 ( 96.83)	Acc@5  96.88 ( 98.93)
epoch: 94, Avg_Loss 0.1266553115885739
Test: [ 0/28]	Time  6.365 ( 6.365)	Loss 8.9891e-01 (8.9891e-01)	Acc@1  70.31 ( 70.31)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.226 ( 0.821)	Loss 1.2269e+00 (9.9947e-01)	Acc@1  73.44 ( 77.56)	Acc@5  84.38 ( 89.91)
Test: [20/28]	Time  0.139 ( 0.501)	Loss 9.9331e-01 (1.0600e+00)	Acc@1  79.69 ( 76.26)	Acc@5  85.94 ( 88.99)
 * Acc@1 75.127 Acc@5 88.689
lr 0.0001
Epoch: [95][  0/109]	Time  6.454 ( 6.454)	Data  5.863 ( 5.863)	Loss 0.1691937446594238 (0.1691937446594238)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [95][ 10/109]	Time  3.388 ( 2.178)	Data  0.022 ( 0.535)	Loss 0.0556918531656265 (0.0992128337648782)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.15)
Epoch: [95][ 20/109]	Time  0.544 ( 1.449)	Data  0.000 ( 0.281)	Loss 0.1392573267221451 (0.1043950608000159)	Acc@1  95.31 ( 97.40)	Acc@5  98.44 ( 98.96)
Epoch: [95][ 30/109]	Time  0.525 ( 1.205)	Data  0.000 ( 0.190)	Loss 0.0347577892243862 (0.1158328243501244)	Acc@1 100.00 ( 97.03)	Acc@5 100.00 ( 98.89)
Epoch: [95][ 40/109]	Time  0.967 ( 1.139)	Data  0.000 ( 0.144)	Loss 0.0853116065263748 (0.1163749364772584)	Acc@1  98.44 ( 97.10)	Acc@5 100.00 ( 98.89)
Epoch: [95][ 50/109]	Time  0.526 ( 1.055)	Data  0.000 ( 0.116)	Loss 0.0766099020838737 (0.1168088874067454)	Acc@1  98.44 ( 97.09)	Acc@5 100.00 ( 98.96)
Epoch: [95][ 60/109]	Time  0.583 ( 0.967)	Data  0.000 ( 0.097)	Loss 0.0592114180326462 (0.1211922602178376)	Acc@1 100.00 ( 97.08)	Acc@5 100.00 ( 98.90)
Epoch: [95][ 70/109]	Time  0.757 ( 0.911)	Data  0.000 ( 0.083)	Loss 0.1530360877513885 (0.1222687740219941)	Acc@1  96.88 ( 97.10)	Acc@5  98.44 ( 98.90)
Epoch: [95][ 80/109]	Time  0.581 ( 0.952)	Data  0.000 ( 0.073)	Loss 0.2132396548986435 (0.1239725800093125)	Acc@1  93.75 ( 97.05)	Acc@5  98.44 ( 98.88)
Epoch: [95][ 90/109]	Time  0.523 ( 0.910)	Data  0.000 ( 0.065)	Loss 0.1650250554084778 (0.1253587415974055)	Acc@1  96.88 ( 97.10)	Acc@5  96.88 ( 98.82)
Epoch: [95][100/109]	Time  0.483 ( 0.874)	Data  0.000 ( 0.059)	Loss 0.0675419121980667 (0.1217046593878381)	Acc@1 100.00 ( 97.20)	Acc@5 100.00 ( 98.86)
epoch: 95, Avg_Loss 0.12065113968976321
Test: [ 0/28]	Time  6.782 ( 6.782)	Loss 1.0640e+00 (1.0640e+00)	Acc@1  76.56 ( 76.56)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.133 ( 0.752)	Loss 1.3441e+00 (1.0660e+00)	Acc@1  60.94 ( 75.14)	Acc@5  89.06 ( 88.92)
Test: [20/28]	Time  0.135 ( 0.452)	Loss 1.0917e+00 (1.1066e+00)	Acc@1  71.88 ( 74.55)	Acc@5  92.19 ( 88.84)
 * Acc@1 74.339 Acc@5 88.689
lr 0.0001
Epoch: [96][  0/109]	Time  7.426 ( 7.426)	Data  6.874 ( 6.874)	Loss 0.1619719564914703 (0.1619719564914703)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 96.88)
Epoch: [96][ 10/109]	Time  0.690 ( 1.335)	Data  0.001 ( 0.625)	Loss 0.0425343774259090 (0.1723266941579905)	Acc@1 100.00 ( 95.31)	Acc@5 100.00 ( 98.01)
Epoch: [96][ 20/109]	Time  0.689 ( 1.519)	Data  0.000 ( 0.328)	Loss 0.1397258490324020 (0.1446045115590096)	Acc@1  96.88 ( 95.83)	Acc@5  98.44 ( 98.59)
Epoch: [96][ 30/109]	Time  0.499 ( 1.228)	Data  0.000 ( 0.222)	Loss 0.1608866602182388 (0.1323007556699937)	Acc@1  93.75 ( 96.17)	Acc@5 100.00 ( 98.89)
Epoch: [96][ 40/109]	Time  0.558 ( 1.058)	Data  0.000 ( 0.168)	Loss 0.1608255654573441 (0.1331547294266340)	Acc@1  95.31 ( 96.15)	Acc@5 100.00 ( 98.93)
Epoch: [96][ 50/109]	Time  0.928 ( 1.096)	Data  0.000 ( 0.135)	Loss 0.0182405151426792 (0.1240611174965606)	Acc@1 100.00 ( 96.63)	Acc@5 100.00 ( 98.99)
Epoch: [96][ 60/109]	Time  0.537 ( 1.022)	Data  0.000 ( 0.113)	Loss 0.1269270181655884 (0.1256527785883575)	Acc@1  96.88 ( 96.62)	Acc@5 100.00 ( 99.03)
Epoch: [96][ 70/109]	Time  0.559 ( 0.952)	Data  0.000 ( 0.097)	Loss 0.0430871546268463 (0.1200545799564308)	Acc@1  98.44 ( 96.81)	Acc@5 100.00 ( 99.12)
Epoch: [96][ 80/109]	Time  0.540 ( 0.908)	Data  0.000 ( 0.085)	Loss 0.0184491723775864 (0.1214331926111086)	Acc@1 100.00 ( 96.84)	Acc@5 100.00 ( 99.11)
Epoch: [96][ 90/109]	Time  0.545 ( 0.890)	Data  0.000 ( 0.076)	Loss 0.1251236796379089 (0.1203097488608334)	Acc@1  95.31 ( 96.84)	Acc@5 100.00 ( 99.12)
Epoch: [96][100/109]	Time  0.543 ( 0.856)	Data  0.000 ( 0.069)	Loss 0.0755463019013405 (0.1252342042430203)	Acc@1  98.44 ( 96.72)	Acc@5  98.44 ( 99.04)
epoch: 96, Avg_Loss 0.12174231801053868
Test: [ 0/28]	Time  6.159 ( 6.159)	Loss 1.2019e+00 (1.2019e+00)	Acc@1  70.31 ( 70.31)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.133 ( 0.784)	Loss 5.9726e-01 (1.0717e+00)	Acc@1  79.69 ( 74.01)	Acc@5 100.00 ( 89.49)
Test: [20/28]	Time  0.121 ( 0.484)	Loss 1.2424e+00 (1.1162e+00)	Acc@1  75.00 ( 73.96)	Acc@5  87.50 ( 89.21)
 * Acc@1 74.395 Acc@5 89.477
lr 0.0001
Epoch: [97][  0/109]	Time  7.627 ( 7.627)	Data  7.040 ( 7.040)	Loss 0.0365970991551876 (0.0365970991551876)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [97][ 10/109]	Time  0.570 ( 1.591)	Data  0.001 ( 0.640)	Loss 0.0756288021802902 (0.1099700778722763)	Acc@1  98.44 ( 97.59)	Acc@5  98.44 ( 98.86)
Epoch: [97][ 20/109]	Time  1.403 ( 1.226)	Data  0.000 ( 0.336)	Loss 0.1326896995306015 (0.1138933744458925)	Acc@1  96.88 ( 97.40)	Acc@5  98.44 ( 98.74)
Epoch: [97][ 30/109]	Time  0.698 ( 1.029)	Data  0.000 ( 0.228)	Loss 0.0893650949001312 (0.1021039830821176)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 ( 98.99)
Epoch: [97][ 40/109]	Time  1.548 ( 1.004)	Data  0.001 ( 0.172)	Loss 0.0444270372390747 (0.1083802003867742)	Acc@1 100.00 ( 97.56)	Acc@5 100.00 ( 99.05)
Epoch: [97][ 50/109]	Time  0.738 ( 0.985)	Data  0.000 ( 0.139)	Loss 0.0835160017013550 (0.1072195540821435)	Acc@1  96.88 ( 97.55)	Acc@5 100.00 ( 99.11)
Epoch: [97][ 60/109]	Time  1.138 ( 0.947)	Data  0.000 ( 0.116)	Loss 0.1135856062173843 (0.1039134262770903)	Acc@1  96.88 ( 97.62)	Acc@5 100.00 ( 99.18)
Epoch: [97][ 70/109]	Time  0.681 ( 0.939)	Data  0.001 ( 0.100)	Loss 0.0422408655285835 (0.1049253318826078)	Acc@1 100.00 ( 97.58)	Acc@5 100.00 ( 99.16)
Epoch: [97][ 80/109]	Time  0.557 ( 0.913)	Data  0.000 ( 0.087)	Loss 0.0563292913138866 (0.1102608058279679)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 ( 99.09)
Epoch: [97][ 90/109]	Time  0.488 ( 0.877)	Data  0.000 ( 0.078)	Loss 0.3115662634372711 (0.1171618337732750)	Acc@1  92.19 ( 97.24)	Acc@5  95.31 ( 98.95)
Epoch: [97][100/109]	Time  0.481 ( 0.838)	Data  0.000 ( 0.070)	Loss 0.1192681491374969 (0.1166028628254881)	Acc@1  96.88 ( 97.23)	Acc@5  98.44 ( 98.96)
epoch: 97, Avg_Loss 0.11494967811356444
Test: [ 0/28]	Time  6.859 ( 6.859)	Loss 9.3804e-01 (9.3804e-01)	Acc@1  70.31 ( 70.31)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.148 ( 0.774)	Loss 1.6193e+00 (1.1758e+00)	Acc@1  71.88 ( 73.30)	Acc@5  84.38 ( 88.78)
Test: [20/28]	Time  0.117 ( 0.463)	Loss 1.4606e+00 (1.1734e+00)	Acc@1  70.31 ( 72.99)	Acc@5  87.50 ( 88.54)
 * Acc@1 73.607 Acc@5 89.083
lr 0.0001
Epoch: [98][  0/109]	Time  7.989 ( 7.989)	Data  7.200 ( 7.200)	Loss 0.2132158577442169 (0.2132158577442169)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [98][ 10/109]	Time  0.835 ( 1.759)	Data  0.002 ( 0.655)	Loss 0.1541180014610291 (0.1439532773061232)	Acc@1  95.31 ( 95.60)	Acc@5  98.44 ( 98.72)
Epoch: [98][ 20/109]	Time  0.714 ( 1.350)	Data  0.000 ( 0.344)	Loss 0.0724317133426666 (0.1330424839453328)	Acc@1  98.44 ( 96.06)	Acc@5 100.00 ( 98.96)
Epoch: [98][ 30/109]	Time  1.434 ( 1.192)	Data  0.001 ( 0.233)	Loss 0.1066803336143494 (0.1289807276559934)	Acc@1  96.88 ( 96.52)	Acc@5 100.00 ( 98.94)
Epoch: [98][ 40/109]	Time  1.249 ( 1.277)	Data  0.001 ( 0.176)	Loss 0.1335169076919556 (0.1223926350428927)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 ( 99.05)
Epoch: [98][ 50/109]	Time  0.623 ( 1.249)	Data  0.000 ( 0.142)	Loss 0.1345949023962021 (0.1162910404998590)	Acc@1  96.88 ( 97.09)	Acc@5  96.88 ( 99.14)
Epoch: [98][ 60/109]	Time  0.570 ( 1.144)	Data  0.000 ( 0.119)	Loss 0.4086068868637085 (0.1190874332745300)	Acc@1  89.06 ( 97.00)	Acc@5  96.88 ( 99.13)
Epoch: [98][ 70/109]	Time  0.810 ( 1.085)	Data  0.000 ( 0.102)	Loss 0.1248131543397903 (0.1207296977764074)	Acc@1  96.88 ( 96.96)	Acc@5  98.44 ( 99.03)
Epoch: [98][ 80/109]	Time  0.922 ( 1.170)	Data  0.001 ( 0.090)	Loss 0.0798865631222725 (0.1169003349280468)	Acc@1  98.44 ( 97.09)	Acc@5 100.00 ( 99.07)
Epoch: [98][ 90/109]	Time  0.582 ( 1.141)	Data  0.000 ( 0.080)	Loss 0.1837230324745178 (0.1160761324156608)	Acc@1  93.75 ( 97.12)	Acc@5  96.88 ( 99.06)
Epoch: [98][100/109]	Time  0.731 ( 1.105)	Data  0.000 ( 0.072)	Loss 0.0621637031435966 (0.1170278942064926)	Acc@1  96.88 ( 97.01)	Acc@5 100.00 ( 99.07)
epoch: 98, Avg_Loss 0.12026898818381063
Test: [ 0/28]	Time  5.433 ( 5.433)	Loss 1.4186e+00 (1.4186e+00)	Acc@1  71.88 ( 71.88)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.161 ( 0.646)	Loss 9.7883e-01 (1.1693e+00)	Acc@1  75.00 ( 74.43)	Acc@5  89.06 ( 88.64)
Test: [20/28]	Time  0.166 ( 0.438)	Loss 1.7043e+00 (1.1759e+00)	Acc@1  68.75 ( 73.88)	Acc@5  84.38 ( 88.99)
 * Acc@1 73.663 Acc@5 89.308
lr 0.0001
Epoch: [99][  0/109]	Time  5.975 ( 5.975)	Data  5.073 ( 5.073)	Loss 0.2424868345260620 (0.2424868345260620)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [99][ 10/109]	Time  1.247 ( 1.293)	Data  0.002 ( 0.462)	Loss 0.0927578732371330 (0.1096911191601645)	Acc@1  96.88 ( 97.30)	Acc@5 100.00 ( 99.15)
Epoch: [99][ 20/109]	Time  0.933 ( 1.218)	Data  0.000 ( 0.242)	Loss 0.0818790197372437 (0.1207596766984179)	Acc@1  96.88 ( 96.95)	Acc@5 100.00 ( 99.03)
Epoch: [99][ 30/109]	Time  0.491 ( 1.082)	Data  0.000 ( 0.164)	Loss 0.0758486092090607 (0.1206925990240228)	Acc@1  98.44 ( 97.03)	Acc@5  98.44 ( 98.94)
Epoch: [99][ 40/109]	Time  0.652 ( 0.950)	Data  0.000 ( 0.124)	Loss 0.3193120062351227 (0.1230885673132611)	Acc@1  92.19 ( 96.91)	Acc@5  95.31 ( 98.89)
Epoch: [99][ 50/109]	Time  0.946 ( 0.887)	Data  0.001 ( 0.100)	Loss 0.1492070704698563 (0.1149949261589962)	Acc@1  98.44 ( 97.18)	Acc@5  98.44 ( 99.02)
Epoch: [99][ 60/109]	Time  1.274 ( 0.921)	Data  0.001 ( 0.084)	Loss 0.0857332572340965 (0.1184937324313844)	Acc@1  96.88 ( 97.13)	Acc@5 100.00 ( 98.90)
Epoch: [99][ 70/109]	Time  0.542 ( 0.885)	Data  0.000 ( 0.072)	Loss 0.0959174633026123 (0.1206355049261745)	Acc@1  95.31 ( 97.03)	Acc@5 100.00 ( 98.88)
Epoch: [99][ 80/109]	Time  0.684 ( 0.849)	Data  0.000 ( 0.063)	Loss 0.0986380204558372 (0.1226735196455761)	Acc@1  96.88 ( 96.86)	Acc@5 100.00 ( 98.92)
Epoch: [99][ 90/109]	Time  0.755 ( 0.839)	Data  0.000 ( 0.056)	Loss 0.0250834003090858 (0.1258846746941844)	Acc@1 100.00 ( 96.77)	Acc@5 100.00 ( 98.88)
Epoch: [99][100/109]	Time  0.867 ( 0.852)	Data  0.000 ( 0.051)	Loss 0.1487097591161728 (0.1262000748832332)	Acc@1  95.31 ( 96.78)	Acc@5  98.44 ( 98.84)
epoch: 99, Avg_Loss 0.12528618993323057
Test: [ 0/28]	Time  8.002 ( 8.002)	Loss 1.0198e+00 (1.0198e+00)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.301 ( 1.127)	Loss 7.3696e-01 (1.0580e+00)	Acc@1  84.38 ( 74.57)	Acc@5  93.75 ( 89.35)
Test: [20/28]	Time  0.224 ( 0.697)	Loss 1.6522e+00 (1.0817e+00)	Acc@1  64.06 ( 75.15)	Acc@5  78.12 ( 89.21)
 * Acc@1 74.395 Acc@5 89.083
lr 0.0001
Epoch: [100][  0/109]	Time  7.801 ( 7.801)	Data  7.164 ( 7.164)	Loss 0.0558877848088741 (0.0558877848088741)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [100][ 10/109]	Time  0.747 ( 1.268)	Data  0.001 ( 0.651)	Loss 0.1480378955602646 (0.1189097189767794)	Acc@1  96.88 ( 97.44)	Acc@5  98.44 ( 99.29)
Epoch: [100][ 20/109]	Time  1.342 ( 1.328)	Data  0.001 ( 0.342)	Loss 0.1145051717758179 (0.0917431065546615)	Acc@1  96.88 ( 97.99)	Acc@5 100.00 ( 99.55)
Epoch: [100][ 30/109]	Time  0.935 ( 1.306)	Data  0.000 ( 0.232)	Loss 0.0831103175878525 (0.0945109247620548)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.50)
Epoch: [100][ 40/109]	Time  0.568 ( 1.238)	Data  0.000 ( 0.175)	Loss 0.0543362647294998 (0.0971592750809178)	Acc@1 100.00 ( 97.90)	Acc@5 100.00 ( 99.47)
Epoch: [100][ 50/109]	Time  0.563 ( 1.141)	Data  0.000 ( 0.141)	Loss 0.0120632406324148 (0.1050481359638712)	Acc@1 100.00 ( 97.61)	Acc@5 100.00 ( 99.36)
Epoch: [100][ 60/109]	Time  0.585 ( 1.042)	Data  0.000 ( 0.118)	Loss 0.0209722854197025 (0.1053316174991062)	Acc@1 100.00 ( 97.59)	Acc@5 100.00 ( 99.31)
Epoch: [100][ 70/109]	Time  0.635 ( 1.010)	Data  0.000 ( 0.101)	Loss 0.0316978618502617 (0.1079237635942622)	Acc@1 100.00 ( 97.56)	Acc@5 100.00 ( 99.23)
Epoch: [100][ 80/109]	Time  0.834 ( 0.973)	Data  0.000 ( 0.089)	Loss 0.1146264448761940 (0.1060429843096637)	Acc@1  98.44 ( 97.63)	Acc@5  98.44 ( 99.25)
Epoch: [100][ 90/109]	Time  0.485 ( 0.927)	Data  0.000 ( 0.079)	Loss 0.0187806691974401 (0.1066620492857400)	Acc@1 100.00 ( 97.61)	Acc@5 100.00 ( 99.18)
Epoch: [100][100/109]	Time  0.581 ( 0.894)	Data  0.000 ( 0.071)	Loss 0.1357852965593338 (0.1078520932944842)	Acc@1  96.88 ( 97.56)	Acc@5  98.44 ( 99.13)
epoch: 100, Avg_Loss 0.11293080352554354
Test: [ 0/28]	Time  4.238 ( 4.238)	Loss 7.9156e-01 (7.9156e-01)	Acc@1  75.00 ( 75.00)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.129 ( 0.684)	Loss 1.2671e+00 (1.0376e+00)	Acc@1  68.75 ( 75.14)	Acc@5  90.62 ( 89.91)
Test: [20/28]	Time  0.127 ( 0.418)	Loss 7.8696e-01 (1.1168e+00)	Acc@1  82.81 ( 74.48)	Acc@5  89.06 ( 88.69)
 * Acc@1 74.902 Acc@5 88.520
lr 0.0001
Epoch: [101][  0/109]	Time  6.252 ( 6.252)	Data  5.625 ( 5.625)	Loss 0.1243919879198074 (0.1243919879198074)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [101][ 10/109]	Time  0.631 ( 1.096)	Data  0.001 ( 0.512)	Loss 0.1763103008270264 (0.0978381274776025)	Acc@1  92.19 ( 97.16)	Acc@5 100.00 ( 99.29)
Epoch: [101][ 20/109]	Time  0.760 ( 0.933)	Data  0.000 ( 0.268)	Loss 0.0215907953679562 (0.1012058906434547)	Acc@1 100.00 ( 97.40)	Acc@5 100.00 ( 99.03)
Epoch: [101][ 30/109]	Time  0.999 ( 0.941)	Data  0.000 ( 0.182)	Loss 0.0363758727908134 (0.0951983327226293)	Acc@1 100.00 ( 97.63)	Acc@5 100.00 ( 99.29)
Epoch: [101][ 40/109]	Time  0.916 ( 1.013)	Data  0.001 ( 0.138)	Loss 0.1863582879304886 (0.1006358644311748)	Acc@1  95.31 ( 97.41)	Acc@5  98.44 ( 99.28)
Epoch: [101][ 50/109]	Time  0.493 ( 0.980)	Data  0.000 ( 0.111)	Loss 0.1465190947055817 (0.1087247474739949)	Acc@1  96.88 ( 97.24)	Acc@5  98.44 ( 99.17)
Epoch: [101][ 60/109]	Time  0.553 ( 0.908)	Data  0.000 ( 0.093)	Loss 0.0748131200671196 (0.1113731189035490)	Acc@1  96.88 ( 97.13)	Acc@5 100.00 ( 99.13)
Epoch: [101][ 70/109]	Time  0.526 ( 0.855)	Data  0.000 ( 0.080)	Loss 0.0525625087320805 (0.1074430760468396)	Acc@1  98.44 ( 97.29)	Acc@5 100.00 ( 99.23)
Epoch: [101][ 80/109]	Time  0.629 ( 0.823)	Data  0.000 ( 0.070)	Loss 0.0469267964363098 (0.1086813526251066)	Acc@1  98.44 ( 97.24)	Acc@5 100.00 ( 99.23)
Epoch: [101][ 90/109]	Time  0.540 ( 0.797)	Data  0.000 ( 0.062)	Loss 0.1324802935123444 (0.1086781825870275)	Acc@1  93.75 ( 97.25)	Acc@5 100.00 ( 99.18)
Epoch: [101][100/109]	Time  0.755 ( 0.771)	Data  0.000 ( 0.056)	Loss 0.1597708463668823 (0.1090123407026329)	Acc@1  95.31 ( 97.23)	Acc@5  98.44 ( 99.18)
epoch: 101, Avg_Loss 0.10659561955600703
Test: [ 0/28]	Time  5.118 ( 5.118)	Loss 9.8537e-01 (9.8537e-01)	Acc@1  76.56 ( 76.56)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.155 ( 0.719)	Loss 8.1137e-01 (1.1302e+00)	Acc@1  82.81 ( 75.28)	Acc@5  92.19 ( 88.92)
Test: [20/28]	Time  0.136 ( 0.451)	Loss 8.7090e-01 (1.1260e+00)	Acc@1  78.12 ( 74.26)	Acc@5  92.19 ( 88.99)
 * Acc@1 74.395 Acc@5 88.858
lr 0.0001
Epoch: [102][  0/109]	Time  9.031 ( 9.031)	Data  8.315 ( 8.315)	Loss 0.1892532706260681 (0.1892532706260681)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [102][ 10/109]	Time  0.690 ( 1.435)	Data  0.001 ( 0.756)	Loss 0.0903819650411606 (0.1141150485385548)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.01)
Epoch: [102][ 20/109]	Time  1.152 ( 1.159)	Data  0.001 ( 0.396)	Loss 0.1594778746366501 (0.1114031221894991)	Acc@1  96.88 ( 97.17)	Acc@5  98.44 ( 99.18)
Epoch: [102][ 30/109]	Time  0.601 ( 1.027)	Data  0.000 ( 0.269)	Loss 0.1014427319169044 (0.1162515505547485)	Acc@1  96.88 ( 97.03)	Acc@5 100.00 ( 99.19)
Epoch: [102][ 40/109]	Time  0.620 ( 0.919)	Data  0.000 ( 0.203)	Loss 0.1644704043865204 (0.1072859466984505)	Acc@1  95.31 ( 97.22)	Acc@5  96.88 ( 99.28)
Epoch: [102][ 50/109]	Time  0.823 ( 0.893)	Data  0.000 ( 0.164)	Loss 0.0266436561942101 (0.1071870056729691)	Acc@1 100.00 ( 97.40)	Acc@5 100.00 ( 99.26)
Epoch: [102][ 60/109]	Time  0.665 ( 0.870)	Data  0.000 ( 0.137)	Loss 0.1246661841869354 (0.1103752012990537)	Acc@1  98.44 ( 97.44)	Acc@5  98.44 ( 99.26)
Epoch: [102][ 70/109]	Time  0.649 ( 0.840)	Data  0.000 ( 0.118)	Loss 0.1541555374860764 (0.1130557434869484)	Acc@1  95.31 ( 97.34)	Acc@5  98.44 ( 99.12)
Epoch: [102][ 80/109]	Time  0.796 ( 0.824)	Data  0.000 ( 0.103)	Loss 0.0437005795538425 (0.1150019697293087)	Acc@1  98.44 ( 97.20)	Acc@5 100.00 ( 99.05)
Epoch: [102][ 90/109]	Time  0.774 ( 0.805)	Data  0.000 ( 0.092)	Loss 0.1937607079744339 (0.1166150672668284)	Acc@1  93.75 ( 97.12)	Acc@5  98.44 ( 99.04)
Epoch: [102][100/109]	Time  0.553 ( 0.782)	Data  0.000 ( 0.083)	Loss 0.0890252813696861 (0.1152112442668122)	Acc@1  98.44 ( 97.15)	Acc@5  98.44 ( 99.03)
epoch: 102, Avg_Loss 0.11768927671220325
Test: [ 0/28]	Time  3.926 ( 3.926)	Loss 9.9999e-01 (9.9999e-01)	Acc@1  79.69 ( 79.69)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.191 ( 0.629)	Loss 1.2332e+00 (1.1640e+00)	Acc@1  76.56 ( 74.86)	Acc@5  89.06 ( 89.49)
Test: [20/28]	Time  0.133 ( 0.411)	Loss 7.3478e-01 (1.1832e+00)	Acc@1  81.25 ( 73.59)	Acc@5  89.06 ( 88.69)
 * Acc@1 74.902 Acc@5 89.364
lr 0.0001
Epoch: [103][  0/109]	Time  4.638 ( 4.638)	Data  3.977 ( 3.977)	Loss 0.1857678443193436 (0.1857678443193436)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 96.88)
Epoch: [103][ 10/109]	Time  1.196 ( 1.266)	Data  0.001 ( 0.405)	Loss 0.1363379657268524 (0.1328378990292549)	Acc@1  95.31 ( 96.88)	Acc@5  98.44 ( 98.86)
Epoch: [103][ 20/109]	Time  1.201 ( 1.086)	Data  0.000 ( 0.212)	Loss 0.0899574309587479 (0.1098200269043446)	Acc@1  98.44 ( 97.32)	Acc@5  98.44 ( 99.26)
Epoch: [103][ 30/109]	Time  1.047 ( 1.078)	Data  0.000 ( 0.144)	Loss 0.0651229172945023 (0.1144604750217930)	Acc@1  98.44 ( 97.28)	Acc@5  98.44 ( 99.19)
Epoch: [103][ 40/109]	Time  0.547 ( 1.019)	Data  0.000 ( 0.109)	Loss 0.1217854991555214 (0.1195391452212523)	Acc@1  95.31 ( 97.10)	Acc@5  98.44 ( 99.05)
Epoch: [103][ 50/109]	Time  0.644 ( 0.937)	Data  0.000 ( 0.088)	Loss 0.1436161398887634 (0.1148617333531672)	Acc@1  96.88 ( 97.18)	Acc@5 100.00 ( 99.20)
Epoch: [103][ 60/109]	Time  0.506 ( 0.877)	Data  0.000 ( 0.073)	Loss 0.0694080293178558 (0.1120703246780351)	Acc@1  98.44 ( 97.26)	Acc@5 100.00 ( 99.23)
Epoch: [103][ 70/109]	Time  0.631 ( 0.856)	Data  0.000 ( 0.063)	Loss 0.1048392802476883 (0.1135983814052503)	Acc@1  98.44 ( 97.29)	Acc@5  98.44 ( 99.16)
Epoch: [103][ 80/109]	Time  0.560 ( 0.830)	Data  0.000 ( 0.055)	Loss 0.0478569604456425 (0.1136924671009183)	Acc@1 100.00 ( 97.32)	Acc@5 100.00 ( 99.15)
Epoch: [103][ 90/109]	Time  0.722 ( 0.818)	Data  0.000 ( 0.049)	Loss 0.0857592523097992 (0.1142306955080930)	Acc@1  98.44 ( 97.24)	Acc@5  98.44 ( 99.16)
Epoch: [103][100/109]	Time  0.549 ( 0.795)	Data  0.000 ( 0.044)	Loss 0.1601860672235489 (0.1132590677312548)	Acc@1  95.31 ( 97.29)	Acc@5  98.44 ( 99.15)
epoch: 103, Avg_Loss 0.11631345901843332
Test: [ 0/28]	Time  3.560 ( 3.560)	Loss 9.3313e-01 (9.3313e-01)	Acc@1  75.00 ( 75.00)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.569 ( 1.009)	Loss 1.0670e+00 (1.1599e+00)	Acc@1  75.00 ( 74.29)	Acc@5  87.50 ( 88.64)
Test: [20/28]	Time  0.315 ( 0.657)	Loss 1.1540e+00 (1.1626e+00)	Acc@1  67.19 ( 73.14)	Acc@5  87.50 ( 88.17)
 * Acc@1 73.720 Acc@5 88.464
lr 0.0001
Epoch: [104][  0/109]	Time  9.489 ( 9.489)	Data  8.807 ( 8.807)	Loss 0.2018662542104721 (0.2018662542104721)	Acc@1  93.75 ( 93.75)	Acc@5  96.88 ( 96.88)
Epoch: [104][ 10/109]	Time  0.493 ( 1.534)	Data  0.001 ( 0.869)	Loss 0.1342392414808273 (0.1045526841824705)	Acc@1  95.31 ( 97.30)	Acc@5 100.00 ( 99.01)
Epoch: [104][ 20/109]	Time  0.535 ( 1.093)	Data  0.000 ( 0.455)	Loss 0.1087207645177841 (0.1114386898421106)	Acc@1  98.44 ( 97.40)	Acc@5  98.44 ( 98.96)
Epoch: [104][ 30/109]	Time  0.527 ( 0.966)	Data  0.000 ( 0.309)	Loss 0.1420641243457794 (0.1228592580845279)	Acc@1  96.88 ( 97.23)	Acc@5  96.88 ( 98.84)
Epoch: [104][ 40/109]	Time  0.544 ( 0.860)	Data  0.000 ( 0.233)	Loss 0.0856404602527618 (0.1290335565260271)	Acc@1  96.88 ( 96.91)	Acc@5  98.44 ( 98.78)
Epoch: [104][ 50/109]	Time  0.536 ( 0.809)	Data  0.000 ( 0.188)	Loss 0.1868064254522324 (0.1198916852328123)	Acc@1  93.75 ( 97.18)	Acc@5  96.88 ( 98.84)
Epoch: [104][ 60/109]	Time  0.524 ( 0.784)	Data  0.000 ( 0.157)	Loss 0.0431625433266163 (0.1153224918258483)	Acc@1  98.44 ( 97.23)	Acc@5 100.00 ( 98.92)
Epoch: [104][ 70/109]	Time  0.651 ( 0.761)	Data  0.000 ( 0.135)	Loss 0.1120801791548729 (0.1162416829504597)	Acc@1  95.31 ( 97.14)	Acc@5 100.00 ( 98.92)
Epoch: [104][ 80/109]	Time  0.698 ( 0.799)	Data  0.000 ( 0.118)	Loss 0.0597907043993473 (0.1118340102702747)	Acc@1  98.44 ( 97.16)	Acc@5 100.00 ( 99.02)
Epoch: [104][ 90/109]	Time  0.497 ( 0.774)	Data  0.000 ( 0.105)	Loss 0.1207577288150787 (0.1085863467919957)	Acc@1  96.88 ( 97.29)	Acc@5  98.44 ( 99.04)
Epoch: [104][100/109]	Time  0.844 ( 0.752)	Data  0.000 ( 0.095)	Loss 0.0506564080715179 (0.1094824310650330)	Acc@1  98.44 ( 97.29)	Acc@5 100.00 ( 99.04)
epoch: 104, Avg_Loss 0.10918644296193342
Test: [ 0/28]	Time  8.072 ( 8.072)	Loss 1.2881e+00 (1.2881e+00)	Acc@1  67.19 ( 67.19)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.131 ( 0.925)	Loss 1.6487e+00 (1.2466e+00)	Acc@1  71.88 ( 74.01)	Acc@5  82.81 ( 87.78)
Test: [20/28]	Time  0.118 ( 0.541)	Loss 1.2068e+00 (1.2114e+00)	Acc@1  76.56 ( 74.18)	Acc@5  87.50 ( 88.02)
 * Acc@1 74.170 Acc@5 88.351
lr 0.0001
Epoch: [105][  0/109]	Time  8.703 ( 8.703)	Data  7.730 ( 7.730)	Loss 0.1717602759599686 (0.1717602759599686)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [105][ 10/109]	Time  1.932 ( 1.983)	Data  0.008 ( 0.704)	Loss 0.1898133456707001 (0.1133152227848768)	Acc@1  95.31 ( 97.16)	Acc@5  95.31 ( 98.72)
Epoch: [105][ 20/109]	Time  1.086 ( 1.495)	Data  0.001 ( 0.369)	Loss 0.1151893064379692 (0.1059819008445456)	Acc@1  96.88 ( 97.25)	Acc@5  98.44 ( 98.96)
Epoch: [105][ 30/109]	Time  0.554 ( 1.259)	Data  0.000 ( 0.250)	Loss 0.0138261923566461 (0.1001587256248439)	Acc@1 100.00 ( 97.63)	Acc@5 100.00 ( 99.09)
Epoch: [105][ 40/109]	Time  0.594 ( 1.167)	Data  0.000 ( 0.190)	Loss 0.0512268394231796 (0.1081097219366489)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 ( 99.05)
Epoch: [105][ 50/109]	Time  0.726 ( 1.075)	Data  0.001 ( 0.153)	Loss 0.0760746598243713 (0.1112258211326073)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 ( 99.11)
Epoch: [105][ 60/109]	Time  0.708 ( 1.082)	Data  0.000 ( 0.128)	Loss 0.1185319870710373 (0.1115339049214467)	Acc@1  96.88 ( 97.31)	Acc@5 100.00 ( 99.10)
Epoch: [105][ 70/109]	Time  0.552 ( 1.066)	Data  0.000 ( 0.110)	Loss 0.0600505024194717 (0.1085479033743622)	Acc@1 100.00 ( 97.38)	Acc@5 100.00 ( 99.14)
Epoch: [105][ 80/109]	Time  1.077 ( 1.033)	Data  0.001 ( 0.096)	Loss 0.2379045039415359 (0.1074346750169809)	Acc@1  95.31 ( 97.40)	Acc@5  95.31 ( 99.13)
Epoch: [105][ 90/109]	Time  0.697 ( 1.017)	Data  0.000 ( 0.086)	Loss 0.0693792849779129 (0.1079118269096528)	Acc@1  96.88 ( 97.32)	Acc@5 100.00 ( 99.19)
Epoch: [105][100/109]	Time  0.485 ( 0.971)	Data  0.000 ( 0.077)	Loss 0.0269035808742046 (0.1084831896708301)	Acc@1 100.00 ( 97.39)	Acc@5 100.00 ( 99.15)
epoch: 105, Avg_Loss 0.11027855276548808
Test: [ 0/28]	Time  8.994 ( 8.994)	Loss 1.1038e+00 (1.1038e+00)	Acc@1  73.44 ( 73.44)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.122 ( 1.038)	Loss 1.2370e+00 (1.2475e+00)	Acc@1  70.31 ( 72.30)	Acc@5  82.81 ( 87.36)
Test: [20/28]	Time  0.119 ( 0.605)	Loss 6.3413e-01 (1.1658e+00)	Acc@1  82.81 ( 73.81)	Acc@5  93.75 ( 88.10)
 * Acc@1 74.676 Acc@5 88.914
lr 0.0001
Epoch: [106][  0/109]	Time  7.600 ( 7.600)	Data  6.782 ( 6.782)	Loss 0.0799435004591942 (0.0799435004591942)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [106][ 10/109]	Time  0.737 ( 1.378)	Data  0.001 ( 0.617)	Loss 0.0798533707857132 (0.1323334185237234)	Acc@1  98.44 ( 96.73)	Acc@5 100.00 ( 98.72)
Epoch: [106][ 20/109]	Time  0.824 ( 1.072)	Data  0.000 ( 0.323)	Loss 0.1537653207778931 (0.1210669461815130)	Acc@1  95.31 ( 96.95)	Acc@5 100.00 ( 98.88)
Epoch: [106][ 30/109]	Time  0.561 ( 1.005)	Data  0.000 ( 0.219)	Loss 0.2417288571596146 (0.1188498042644032)	Acc@1  95.31 ( 96.98)	Acc@5  98.44 ( 99.04)
Epoch: [106][ 40/109]	Time  0.926 ( 0.910)	Data  0.000 ( 0.166)	Loss 0.1240591630339622 (0.1110619322464960)	Acc@1  96.88 ( 97.22)	Acc@5  98.44 ( 99.16)
Epoch: [106][ 50/109]	Time  0.493 ( 0.891)	Data  0.000 ( 0.133)	Loss 0.0388787090778351 (0.1124256665580997)	Acc@1 100.00 ( 97.21)	Acc@5 100.00 ( 99.20)
Epoch: [106][ 60/109]	Time  0.569 ( 0.838)	Data  0.000 ( 0.112)	Loss 0.0751930549740791 (0.1076531436324852)	Acc@1  96.88 ( 97.26)	Acc@5 100.00 ( 99.33)
Epoch: [106][ 70/109]	Time  0.496 ( 0.791)	Data  0.000 ( 0.096)	Loss 0.2097957283258438 (0.1072719097006279)	Acc@1  95.31 ( 97.25)	Acc@5  98.44 ( 99.32)
Epoch: [106][ 80/109]	Time  0.573 ( 0.761)	Data  0.001 ( 0.084)	Loss 0.0462765544652939 (0.1084253488476446)	Acc@1  98.44 ( 97.22)	Acc@5 100.00 ( 99.25)
Epoch: [106][ 90/109]	Time  0.666 ( 0.748)	Data  0.000 ( 0.075)	Loss 0.0154038229957223 (0.1060205794625230)	Acc@1 100.00 ( 97.27)	Acc@5 100.00 ( 99.30)
Epoch: [106][100/109]	Time  0.574 ( 0.731)	Data  0.000 ( 0.068)	Loss 0.1884226799011230 (0.1056660779263123)	Acc@1  96.88 ( 97.31)	Acc@5  98.44 ( 99.30)
epoch: 106, Avg_Loss 0.10888092134387121
Test: [ 0/28]	Time  5.249 ( 5.249)	Loss 1.0351e+00 (1.0351e+00)	Acc@1  76.56 ( 76.56)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.315 ( 1.097)	Loss 7.9909e-01 (1.2091e+00)	Acc@1  82.81 ( 73.30)	Acc@5  90.62 ( 88.64)
Test: [20/28]	Time  0.246 ( 0.687)	Loss 1.4954e+00 (1.2218e+00)	Acc@1  65.62 ( 73.14)	Acc@5  84.38 ( 87.80)
 * Acc@1 73.945 Acc@5 88.407
lr 0.0001
Epoch: [107][  0/109]	Time  7.867 ( 7.867)	Data  7.160 ( 7.160)	Loss 0.0951100066304207 (0.0951100066304207)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [107][ 10/109]	Time  0.613 ( 1.233)	Data  0.001 ( 0.651)	Loss 0.0561583861708641 (0.1015638231553815)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 98.86)
Epoch: [107][ 20/109]	Time  3.766 ( 1.202)	Data  0.002 ( 0.341)	Loss 0.0324112065136433 (0.1122581748114455)	Acc@1 100.00 ( 97.54)	Acc@5 100.00 ( 98.88)
Epoch: [107][ 30/109]	Time  1.015 ( 1.285)	Data  0.000 ( 0.232)	Loss 0.0826588943600655 (0.1178736113792946)	Acc@1  96.88 ( 97.18)	Acc@5 100.00 ( 98.94)
Epoch: [107][ 40/109]	Time  0.926 ( 1.376)	Data  0.000 ( 0.175)	Loss 0.0932633951306343 (0.1231116162067870)	Acc@1  96.88 ( 97.10)	Acc@5  98.44 ( 98.89)
Epoch: [107][ 50/109]	Time  0.545 ( 1.248)	Data  0.000 ( 0.141)	Loss 0.0540991537272930 (0.1232093301072132)	Acc@1 100.00 ( 97.15)	Acc@5 100.00 ( 98.90)
Epoch: [107][ 60/109]	Time  0.744 ( 1.162)	Data  0.000 ( 0.118)	Loss 0.1371883749961853 (0.1188448490574956)	Acc@1  96.88 ( 97.21)	Acc@5  98.44 ( 98.98)
Epoch: [107][ 70/109]	Time  0.694 ( 1.119)	Data  0.000 ( 0.101)	Loss 0.0814129114151001 (0.1145054960203633)	Acc@1  98.44 ( 97.38)	Acc@5 100.00 ( 99.01)
Epoch: [107][ 80/109]	Time  0.739 ( 1.180)	Data  0.000 ( 0.089)	Loss 0.2991468906402588 (0.1142742991516436)	Acc@1  92.19 ( 97.38)	Acc@5  96.88 ( 99.02)
Epoch: [107][ 90/109]	Time  0.528 ( 1.126)	Data  0.000 ( 0.079)	Loss 0.0815157368779182 (0.1135979764634273)	Acc@1  96.88 ( 97.39)	Acc@5 100.00 ( 99.02)
Epoch: [107][100/109]	Time  0.800 ( 1.080)	Data  0.000 ( 0.071)	Loss 0.1030766889452934 (0.1145555780979224)	Acc@1  96.88 ( 97.35)	Acc@5  98.44 ( 98.98)
epoch: 107, Avg_Loss 0.115974144283853
Test: [ 0/28]	Time 10.241 (10.241)	Loss 8.5399e-01 (8.5399e-01)	Acc@1  75.00 ( 75.00)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.160 ( 1.056)	Loss 9.1732e-01 (1.1303e+00)	Acc@1  75.00 ( 72.87)	Acc@5  95.31 ( 88.35)
Test: [20/28]	Time  0.117 ( 0.611)	Loss 1.0616e+00 (1.1130e+00)	Acc@1  75.00 ( 73.44)	Acc@5  90.62 ( 88.69)
 * Acc@1 74.114 Acc@5 88.858
lr 0.0001
Epoch: [108][  0/109]	Time  5.299 ( 5.299)	Data  4.605 ( 4.605)	Loss 0.0902958810329437 (0.0902958810329437)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [108][ 10/109]	Time  0.658 ( 1.003)	Data  0.001 ( 0.419)	Loss 0.0134778125211596 (0.0772663242268291)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.43)
Epoch: [108][ 20/109]	Time  1.106 ( 1.008)	Data  0.001 ( 0.220)	Loss 0.2110942751169205 (0.0930256848445251)	Acc@1  93.75 ( 98.07)	Acc@5  96.88 ( 99.26)
Epoch: [108][ 30/109]	Time  1.098 ( 0.975)	Data  0.000 ( 0.149)	Loss 0.1849837750196457 (0.0925309454361277)	Acc@1  95.31 ( 98.08)	Acc@5  98.44 ( 99.34)
Epoch: [108][ 40/109]	Time  0.604 ( 0.929)	Data  0.000 ( 0.113)	Loss 0.0513111539185047 (0.0944930151014066)	Acc@1  98.44 ( 97.87)	Acc@5 100.00 ( 99.28)
Epoch: [108][ 50/109]	Time  0.615 ( 0.868)	Data  0.000 ( 0.091)	Loss 0.1931698620319366 (0.0966833069847495)	Acc@1  95.31 ( 97.89)	Acc@5  98.44 ( 99.26)
Epoch: [108][ 60/109]	Time  0.485 ( 0.820)	Data  0.000 ( 0.076)	Loss 0.0752952322363853 (0.1001981046417209)	Acc@1  98.44 ( 97.80)	Acc@5  98.44 ( 99.21)
Epoch: [108][ 70/109]	Time  0.554 ( 0.780)	Data  0.000 ( 0.065)	Loss 0.1821729838848114 (0.1065995714981371)	Acc@1  96.88 ( 97.65)	Acc@5  98.44 ( 99.08)
Epoch: [108][ 80/109]	Time  0.617 ( 0.772)	Data  0.000 ( 0.057)	Loss 0.0751939341425896 (0.1035859666442798)	Acc@1  98.44 ( 97.70)	Acc@5  98.44 ( 99.15)
Epoch: [108][ 90/109]	Time  2.156 ( 0.865)	Data  0.001 ( 0.051)	Loss 0.1081839278340340 (0.1061714194244245)	Acc@1  96.88 ( 97.60)	Acc@5  98.44 ( 99.09)
Epoch: [108][100/109]	Time  1.071 ( 0.885)	Data  0.001 ( 0.046)	Loss 0.0690192133188248 (0.1063884699274555)	Acc@1  96.88 ( 97.54)	Acc@5 100.00 ( 99.03)
epoch: 108, Avg_Loss 0.1055374812898696
Test: [ 0/28]	Time  7.983 ( 7.983)	Loss 8.6441e-01 (8.6441e-01)	Acc@1  82.81 ( 82.81)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.172 ( 0.931)	Loss 9.9366e-01 (9.8518e-01)	Acc@1  73.44 ( 75.99)	Acc@5  90.62 ( 90.62)
Test: [20/28]	Time  0.152 ( 0.560)	Loss 9.5474e-01 (1.0837e+00)	Acc@1  75.00 ( 75.07)	Acc@5  90.62 ( 89.29)
 * Acc@1 75.127 Acc@5 89.533
lr 0.0001
Epoch: [109][  0/109]	Time  6.732 ( 6.732)	Data  6.044 ( 6.044)	Loss 0.1369094550609589 (0.1369094550609589)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [109][ 10/109]	Time  0.758 ( 1.374)	Data  0.001 ( 0.616)	Loss 0.0825996622443199 (0.0852038161829114)	Acc@1  98.44 ( 97.87)	Acc@5  98.44 ( 99.29)
Epoch: [109][ 20/109]	Time  0.753 ( 1.369)	Data  0.000 ( 0.323)	Loss 0.0275864973664284 (0.0965914908530457)	Acc@1 100.00 ( 97.32)	Acc@5 100.00 ( 99.33)
Epoch: [109][ 30/109]	Time  1.033 ( 1.195)	Data  0.000 ( 0.219)	Loss 0.1116518154740334 (0.1022819879975530)	Acc@1  96.88 ( 97.33)	Acc@5 100.00 ( 99.29)
Epoch: [109][ 40/109]	Time  0.885 ( 1.079)	Data  0.000 ( 0.166)	Loss 0.1362276822328568 (0.0915174500153559)	Acc@1  93.75 ( 97.68)	Acc@5 100.00 ( 99.47)
Epoch: [109][ 50/109]	Time  0.774 ( 1.022)	Data  0.000 ( 0.133)	Loss 0.1301659941673279 (0.0939313516239910)	Acc@1  98.44 ( 97.64)	Acc@5  98.44 ( 99.42)
Epoch: [109][ 60/109]	Time  0.984 ( 1.108)	Data  0.000 ( 0.112)	Loss 0.0899792537093163 (0.0958619056971835)	Acc@1  96.88 ( 97.54)	Acc@5 100.00 ( 99.36)
Epoch: [109][ 70/109]	Time  0.601 ( 1.026)	Data  0.000 ( 0.096)	Loss 0.1366347968578339 (0.1054049615131717)	Acc@1  96.88 ( 97.34)	Acc@5  98.44 ( 99.25)
Epoch: [109][ 80/109]	Time  0.562 ( 0.966)	Data  0.000 ( 0.084)	Loss 0.1355754137039185 (0.1065201750370087)	Acc@1  95.31 ( 97.34)	Acc@5 100.00 ( 99.23)
Epoch: [109][ 90/109]	Time  2.197 ( 0.981)	Data  0.001 ( 0.075)	Loss 0.1338165998458862 (0.1079551091028766)	Acc@1  96.88 ( 97.25)	Acc@5  98.44 ( 99.23)
Epoch: [109][100/109]	Time  0.602 ( 0.967)	Data  0.000 ( 0.067)	Loss 0.2057707011699677 (0.1097900008616766)	Acc@1  92.19 ( 97.22)	Acc@5  98.44 ( 99.21)
epoch: 109, Avg_Loss 0.11044719041145723
Test: [ 0/28]	Time  6.084 ( 6.084)	Loss 1.0814e+00 (1.0814e+00)	Acc@1  75.00 ( 75.00)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.380 ( 0.807)	Loss 1.1169e+00 (1.1816e+00)	Acc@1  76.56 ( 74.43)	Acc@5  87.50 ( 89.35)
Test: [20/28]	Time  0.285 ( 0.572)	Loss 9.8080e-01 (1.1022e+00)	Acc@1  75.00 ( 75.00)	Acc@5  90.62 ( 90.10)
 * Acc@1 74.451 Acc@5 89.477
lr 0.0001
Epoch: [110][  0/109]	Time 12.435 (12.435)	Data 11.819 (11.819)	Loss 0.0700371488928795 (0.0700371488928795)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [110][ 10/109]	Time  0.517 ( 1.669)	Data  0.001 ( 1.088)	Loss 0.1758504807949066 (0.1316155981780453)	Acc@1  96.88 ( 96.45)	Acc@5  98.44 ( 99.43)
Epoch: [110][ 20/109]	Time  0.781 ( 1.182)	Data  0.001 ( 0.570)	Loss 0.0272182412445545 (0.1116696656903341)	Acc@1 100.00 ( 97.32)	Acc@5 100.00 ( 99.40)
Epoch: [110][ 30/109]	Time  0.479 ( 1.240)	Data  0.000 ( 0.386)	Loss 0.0572510622441769 (0.1139317534924034)	Acc@1  98.44 ( 97.28)	Acc@5  98.44 ( 99.19)
Epoch: [110][ 40/109]	Time  0.486 ( 1.065)	Data  0.000 ( 0.292)	Loss 0.0629711821675301 (0.1070547936393357)	Acc@1  98.44 ( 97.45)	Acc@5 100.00 ( 99.20)
Epoch: [110][ 50/109]	Time  0.740 ( 0.975)	Data  0.000 ( 0.237)	Loss 0.0770496502518654 (0.1007502696604705)	Acc@1  96.88 ( 97.61)	Acc@5 100.00 ( 99.30)
Epoch: [110][ 60/109]	Time  1.800 ( 0.952)	Data  0.001 ( 0.198)	Loss 0.1349239796400070 (0.1006925526212473)	Acc@1  98.44 ( 97.59)	Acc@5  98.44 ( 99.31)
Epoch: [110][ 70/109]	Time  0.565 ( 0.912)	Data  0.000 ( 0.170)	Loss 0.2396275401115417 (0.0990207921975935)	Acc@1  93.75 ( 97.62)	Acc@5  96.88 ( 99.27)
Epoch: [110][ 80/109]	Time  0.581 ( 0.876)	Data  0.000 ( 0.150)	Loss 0.0904398486018181 (0.0968226314878758)	Acc@1  98.44 ( 97.70)	Acc@5  98.44 ( 99.27)
Epoch: [110][ 90/109]	Time  0.652 ( 0.842)	Data  0.000 ( 0.133)	Loss 0.0441844239830971 (0.0979649939748285)	Acc@1 100.00 ( 97.63)	Acc@5 100.00 ( 99.31)
Epoch: [110][100/109]	Time  1.666 ( 0.845)	Data  0.001 ( 0.120)	Loss 0.1192486286163330 (0.0995136558419407)	Acc@1  98.44 ( 97.63)	Acc@5  98.44 ( 99.32)
epoch: 110, Avg_Loss 0.09751762924801319
Test: [ 0/28]	Time  5.088 ( 5.088)	Loss 1.1905e+00 (1.1905e+00)	Acc@1  78.12 ( 78.12)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.241 ( 0.794)	Loss 9.1026e-01 (1.0802e+00)	Acc@1  78.12 ( 75.28)	Acc@5  92.19 ( 90.20)
Test: [20/28]	Time  0.167 ( 0.513)	Loss 1.1386e+00 (1.1078e+00)	Acc@1  73.44 ( 74.70)	Acc@5  93.75 ( 90.18)
 * Acc@1 74.564 Acc@5 89.533
lr 0.0001
Epoch: [111][  0/109]	Time 10.582 (10.582)	Data  9.823 ( 9.823)	Loss 0.0197244342416525 (0.0197244342416525)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [111][ 10/109]	Time  0.764 ( 1.640)	Data  0.001 ( 0.893)	Loss 0.0803222879767418 (0.1090563760901039)	Acc@1  98.44 ( 97.44)	Acc@5  98.44 ( 99.01)
Epoch: [111][ 20/109]	Time  1.371 ( 1.256)	Data  0.000 ( 0.468)	Loss 0.0968992337584496 (0.1193749431875490)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 98.81)
Epoch: [111][ 30/109]	Time  0.581 ( 1.188)	Data  0.000 ( 0.318)	Loss 0.0965410917997360 (0.1168502416581877)	Acc@1  96.88 ( 97.03)	Acc@5 100.00 ( 98.84)
Epoch: [111][ 40/109]	Time  0.768 ( 1.046)	Data  0.000 ( 0.240)	Loss 0.0359133854508400 (0.1157982074542016)	Acc@1 100.00 ( 97.14)	Acc@5 100.00 ( 98.82)
Epoch: [111][ 50/109]	Time  0.570 ( 0.941)	Data  0.000 ( 0.193)	Loss 0.0675120502710342 (0.1139119126487012)	Acc@1 100.00 ( 97.18)	Acc@5 100.00 ( 98.93)
Epoch: [111][ 60/109]	Time  0.507 ( 0.882)	Data  0.000 ( 0.162)	Loss 0.0973600372672081 (0.1120390617212311)	Acc@1  98.44 ( 97.26)	Acc@5 100.00 ( 98.92)
Epoch: [111][ 70/109]	Time  0.486 ( 0.837)	Data  0.000 ( 0.139)	Loss 0.2356259077787399 (0.1116145122796297)	Acc@1  95.31 ( 97.27)	Acc@5  98.44 ( 98.90)
Epoch: [111][ 80/109]	Time  0.542 ( 0.803)	Data  0.000 ( 0.122)	Loss 0.0231469776481390 (0.1098283089950313)	Acc@1 100.00 ( 97.34)	Acc@5 100.00 ( 98.96)
Epoch: [111][ 90/109]	Time  0.519 ( 0.770)	Data  0.000 ( 0.108)	Loss 0.0436511635780334 (0.1080332661538825)	Acc@1 100.00 ( 97.41)	Acc@5 100.00 ( 98.99)
Epoch: [111][100/109]	Time  0.495 ( 0.741)	Data  0.000 ( 0.098)	Loss 0.1321275681257248 (0.1060556108132005)	Acc@1  96.88 ( 97.40)	Acc@5  98.44 ( 99.03)
epoch: 111, Avg_Loss 0.1121887374549694
Test: [ 0/28]	Time  8.020 ( 8.020)	Loss 1.1696e+00 (1.1696e+00)	Acc@1  76.56 ( 76.56)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.117 ( 0.984)	Loss 1.1094e+00 (1.2533e+00)	Acc@1  71.88 ( 72.73)	Acc@5  87.50 ( 87.22)
Test: [20/28]	Time  0.118 ( 0.571)	Loss 8.0163e-01 (1.1829e+00)	Acc@1  76.56 ( 73.07)	Acc@5  90.62 ( 88.10)
 * Acc@1 74.226 Acc@5 88.239
lr 0.0001
Epoch: [112][  0/109]	Time  8.071 ( 8.071)	Data  7.114 ( 7.114)	Loss 0.0396478250622749 (0.0396478250622749)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [112][ 10/109]	Time  1.055 ( 1.412)	Data  0.001 ( 0.647)	Loss 0.0833185613155365 (0.0849808991294016)	Acc@1  95.31 ( 97.73)	Acc@5 100.00 ( 99.57)
Epoch: [112][ 20/109]	Time  0.463 ( 1.294)	Data  0.001 ( 0.339)	Loss 0.1190147474408150 (0.0894561610406353)	Acc@1  96.88 ( 97.62)	Acc@5 100.00 ( 99.40)
Epoch: [112][ 30/109]	Time  0.487 ( 1.041)	Data  0.000 ( 0.230)	Loss 0.0117857493460178 (0.0928143451531087)	Acc@1 100.00 ( 97.58)	Acc@5 100.00 ( 99.34)
Epoch: [112][ 40/109]	Time  0.577 ( 0.916)	Data  0.000 ( 0.174)	Loss 0.1125364080071449 (0.0946175436511999)	Acc@1  96.88 ( 97.56)	Acc@5  96.88 ( 99.24)
Epoch: [112][ 50/109]	Time  2.583 ( 0.990)	Data  0.002 ( 0.140)	Loss 0.0783038809895515 (0.0986360300003606)	Acc@1 100.00 ( 97.58)	Acc@5 100.00 ( 99.17)
Epoch: [112][ 60/109]	Time  0.577 ( 0.960)	Data  0.000 ( 0.117)	Loss 0.0831977576017380 (0.1023751725213694)	Acc@1  98.44 ( 97.49)	Acc@5 100.00 ( 99.21)
Epoch: [112][ 70/109]	Time  0.524 ( 0.897)	Data  0.000 ( 0.101)	Loss 0.1655206978321075 (0.1066856623141908)	Acc@1  98.44 ( 97.47)	Acc@5  98.44 ( 99.10)
Epoch: [112][ 80/109]	Time  0.483 ( 0.870)	Data  0.000 ( 0.089)	Loss 0.1016700044274330 (0.1077280594265939)	Acc@1  98.44 ( 97.42)	Acc@5  98.44 ( 99.07)
Epoch: [112][ 90/109]	Time  0.475 ( 0.828)	Data  0.000 ( 0.079)	Loss 0.1554055213928223 (0.1067297879995389)	Acc@1  96.88 ( 97.42)	Acc@5  98.44 ( 99.09)
Epoch: [112][100/109]	Time  0.488 ( 0.795)	Data  0.000 ( 0.071)	Loss 0.1350465267896652 (0.1046461167256578)	Acc@1  95.31 ( 97.49)	Acc@5 100.00 ( 99.12)
epoch: 112, Avg_Loss 0.10846614223315355
Test: [ 0/28]	Time  8.916 ( 8.916)	Loss 1.2383e+00 (1.2383e+00)	Acc@1  76.56 ( 76.56)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.241 ( 0.986)	Loss 6.4939e-01 (1.0944e+00)	Acc@1  87.50 ( 76.14)	Acc@5  92.19 ( 88.35)
Test: [20/28]	Time  0.132 ( 0.580)	Loss 1.0355e+00 (1.1583e+00)	Acc@1  75.00 ( 73.88)	Acc@5  87.50 ( 88.39)
 * Acc@1 74.733 Acc@5 89.252
lr 0.0001
Epoch: [113][  0/109]	Time  7.953 ( 7.953)	Data  7.094 ( 7.094)	Loss 0.1490151137113571 (0.1490151137113571)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [113][ 10/109]	Time  0.495 ( 1.277)	Data  0.001 ( 0.645)	Loss 0.1607509404420853 (0.1565210626206615)	Acc@1  96.88 ( 96.02)	Acc@5  96.88 ( 98.15)
Epoch: [113][ 20/109]	Time  0.601 ( 0.923)	Data  0.000 ( 0.338)	Loss 0.1074894368648529 (0.1224008002096698)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 98.74)
Epoch: [113][ 30/109]	Time  1.247 ( 1.026)	Data  0.001 ( 0.229)	Loss 0.0623739995062351 (0.1096696055103694)	Acc@1  98.44 ( 97.33)	Acc@5 100.00 ( 98.94)
Epoch: [113][ 40/109]	Time  0.709 ( 0.988)	Data  0.000 ( 0.174)	Loss 0.0363699421286583 (0.1028689663948082)	Acc@1 100.00 ( 97.37)	Acc@5 100.00 ( 99.05)
Epoch: [113][ 50/109]	Time  0.698 ( 0.941)	Data  0.001 ( 0.140)	Loss 0.0278765205293894 (0.1031432949810051)	Acc@1 100.00 ( 97.43)	Acc@5 100.00 ( 98.99)
Epoch: [113][ 60/109]	Time  0.487 ( 0.879)	Data  0.000 ( 0.117)	Loss 0.0360659956932068 (0.1004614224046713)	Acc@1  98.44 ( 97.46)	Acc@5 100.00 ( 99.08)
Epoch: [113][ 70/109]	Time  0.554 ( 0.828)	Data  0.000 ( 0.100)	Loss 0.0659528225660324 (0.0983033148886662)	Acc@1  98.44 ( 97.56)	Acc@5 100.00 ( 99.12)
Epoch: [113][ 80/109]	Time  1.390 ( 0.823)	Data  0.001 ( 0.088)	Loss 0.0556728616356850 (0.1003576244951950)	Acc@1  98.44 ( 97.53)	Acc@5 100.00 ( 99.09)
Epoch: [113][ 90/109]	Time  0.752 ( 0.835)	Data  0.000 ( 0.078)	Loss 0.0771803036332130 (0.1026014245248267)	Acc@1  96.88 ( 97.44)	Acc@5 100.00 ( 99.06)
Epoch: [113][100/109]	Time  0.980 ( 0.830)	Data  0.000 ( 0.071)	Loss 0.2292774319648743 (0.1063534003119953)	Acc@1  96.88 ( 97.39)	Acc@5  96.88 ( 98.99)
epoch: 113, Avg_Loss 0.10984197999735218
Test: [ 0/28]	Time  5.937 ( 5.937)	Loss 1.2407e+00 (1.2407e+00)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.149 ( 0.891)	Loss 1.0148e+00 (1.2046e+00)	Acc@1  73.44 ( 72.59)	Acc@5  87.50 ( 88.49)
Test: [20/28]	Time  0.118 ( 0.530)	Loss 8.2768e-01 (1.2146e+00)	Acc@1  82.81 ( 72.77)	Acc@5  93.75 ( 88.39)
 * Acc@1 72.763 Acc@5 88.407
lr 0.0001
Epoch: [114][  0/109]	Time  4.896 ( 4.896)	Data  4.205 ( 4.205)	Loss 0.0593192875385284 (0.0593192875385284)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [114][ 10/109]	Time  0.665 ( 1.086)	Data  0.001 ( 0.469)	Loss 0.1701490879058838 (0.1052008271217346)	Acc@1  96.88 ( 97.73)	Acc@5  98.44 ( 99.15)
Epoch: [114][ 20/109]	Time  0.563 ( 0.853)	Data  0.000 ( 0.246)	Loss 0.2819524705410004 (0.1196360306016036)	Acc@1  93.75 ( 97.17)	Acc@5  95.31 ( 98.74)
Epoch: [114][ 30/109]	Time  0.524 ( 0.768)	Data  0.000 ( 0.167)	Loss 0.1038059890270233 (0.1150659630375524)	Acc@1  98.44 ( 97.28)	Acc@5  98.44 ( 98.89)
Epoch: [114][ 40/109]	Time  0.814 ( 0.767)	Data  0.000 ( 0.126)	Loss 0.0313338972628117 (0.1131502455781873)	Acc@1 100.00 ( 97.37)	Acc@5 100.00 ( 98.93)
Epoch: [114][ 50/109]	Time  0.940 ( 0.777)	Data  0.001 ( 0.102)	Loss 0.0729361623525620 (0.1175020112491706)	Acc@1  98.44 ( 97.24)	Acc@5 100.00 ( 98.84)
Epoch: [114][ 60/109]	Time  0.693 ( 0.789)	Data  0.001 ( 0.085)	Loss 0.0625721365213394 (0.1101968856986429)	Acc@1  98.44 ( 97.44)	Acc@5 100.00 ( 98.95)
Epoch: [114][ 70/109]	Time  0.487 ( 0.770)	Data  0.000 ( 0.073)	Loss 0.1472799926996231 (0.1072193193970851)	Acc@1  96.88 ( 97.49)	Acc@5  98.44 ( 98.99)
Epoch: [114][ 80/109]	Time  0.509 ( 0.746)	Data  0.000 ( 0.064)	Loss 0.1078375130891800 (0.1065708747892468)	Acc@1  96.88 ( 97.45)	Acc@5 100.00 ( 99.05)
Epoch: [114][ 90/109]	Time  0.484 ( 0.719)	Data  0.000 ( 0.057)	Loss 0.1284896284341812 (0.1058532146348076)	Acc@1  96.88 ( 97.51)	Acc@5  98.44 ( 99.07)
Epoch: [114][100/109]	Time  0.567 ( 0.697)	Data  0.000 ( 0.051)	Loss 0.0386870317161083 (0.1055217042270273)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 ( 99.06)
epoch: 114, Avg_Loss 0.10507027189665978
Test: [ 0/28]	Time  4.707 ( 4.707)	Loss 1.4187e+00 (1.4187e+00)	Acc@1  75.00 ( 75.00)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.174 ( 0.738)	Loss 1.0494e+00 (1.0062e+00)	Acc@1  76.56 ( 74.72)	Acc@5  89.06 ( 91.34)
Test: [20/28]	Time  0.117 ( 0.445)	Loss 1.3867e+00 (1.0536e+00)	Acc@1  64.06 ( 73.88)	Acc@5  85.94 ( 90.18)
 * Acc@1 74.001 Acc@5 89.758
lr 0.0001
Epoch: [115][  0/109]	Time  7.180 ( 7.180)	Data  6.430 ( 6.430)	Loss 0.0211748443543911 (0.0211748443543911)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [115][ 10/109]	Time  0.665 ( 1.213)	Data  0.001 ( 0.585)	Loss 0.1590247303247452 (0.1396459446034648)	Acc@1  95.31 ( 96.16)	Acc@5 100.00 ( 99.29)
Epoch: [115][ 20/109]	Time  0.706 ( 0.943)	Data  0.000 ( 0.306)	Loss 0.1178946718573570 (0.1095082199954916)	Acc@1  95.31 ( 97.17)	Acc@5 100.00 ( 99.48)
Epoch: [115][ 30/109]	Time  0.687 ( 0.841)	Data  0.000 ( 0.208)	Loss 0.0332074947655201 (0.1030542157560347)	Acc@1  98.44 ( 97.23)	Acc@5 100.00 ( 99.45)
Epoch: [115][ 40/109]	Time  0.640 ( 0.867)	Data  0.000 ( 0.157)	Loss 0.1458587944507599 (0.1026994977941419)	Acc@1  98.44 ( 97.45)	Acc@5  98.44 ( 99.31)
Epoch: [115][ 50/109]	Time  1.022 ( 0.865)	Data  0.002 ( 0.127)	Loss 0.1565439403057098 (0.1000777676829374)	Acc@1  95.31 ( 97.46)	Acc@5  96.88 ( 99.33)
Epoch: [115][ 60/109]	Time  0.526 ( 0.887)	Data  0.000 ( 0.106)	Loss 0.1742242425680161 (0.0984131990260154)	Acc@1  93.75 ( 97.44)	Acc@5  98.44 ( 99.39)
Epoch: [115][ 70/109]	Time  0.543 ( 0.835)	Data  0.001 ( 0.091)	Loss 0.1181162297725677 (0.1028159763991938)	Acc@1  96.88 ( 97.32)	Acc@5  98.44 ( 99.27)
Epoch: [115][ 80/109]	Time  0.465 ( 0.797)	Data  0.000 ( 0.080)	Loss 0.0784499198198318 (0.1033291179790265)	Acc@1  98.44 ( 97.38)	Acc@5  98.44 ( 99.27)
Epoch: [115][ 90/109]	Time  0.545 ( 0.775)	Data  0.000 ( 0.071)	Loss 0.1249612942337990 (0.1051856974948320)	Acc@1  96.88 ( 97.32)	Acc@5  98.44 ( 99.21)
Epoch: [115][100/109]	Time  0.503 ( 0.747)	Data  0.000 ( 0.064)	Loss 0.1218503639101982 (0.1041081216195506)	Acc@1  96.88 ( 97.34)	Acc@5  98.44 ( 99.21)
epoch: 115, Avg_Loss 0.10602954254323325
Test: [ 0/28]	Time  5.035 ( 5.035)	Loss 8.2730e-01 (8.2730e-01)	Acc@1  78.12 ( 78.12)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.193 ( 0.658)	Loss 8.1290e-01 (1.1835e+00)	Acc@1  82.81 ( 72.73)	Acc@5  90.62 ( 88.07)
Test: [20/28]	Time  0.267 ( 0.459)	Loss 1.1359e+00 (1.1867e+00)	Acc@1  76.56 ( 72.25)	Acc@5  89.06 ( 88.76)
 * Acc@1 72.257 Acc@5 88.745
lr 0.0001
Epoch: [116][  0/109]	Time  7.843 ( 7.843)	Data  6.874 ( 6.874)	Loss 0.0535111725330353 (0.0535111725330353)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [116][ 10/109]	Time  0.673 ( 1.284)	Data  0.001 ( 0.625)	Loss 0.1705601662397385 (0.1341800246049057)	Acc@1  96.88 ( 96.45)	Acc@5  96.88 ( 99.01)
Epoch: [116][ 20/109]	Time  0.536 ( 0.921)	Data  0.000 ( 0.328)	Loss 0.0281937029212713 (0.1299545439403682)	Acc@1 100.00 ( 96.58)	Acc@5 100.00 ( 98.81)
Epoch: [116][ 30/109]	Time  0.738 ( 0.805)	Data  0.000 ( 0.222)	Loss 0.1235259175300598 (0.1145907735391971)	Acc@1  96.88 ( 96.98)	Acc@5  98.44 ( 98.94)
Epoch: [116][ 40/109]	Time  0.573 ( 0.781)	Data  0.000 ( 0.168)	Loss 0.0308535005897284 (0.1078636979275360)	Acc@1 100.00 ( 97.41)	Acc@5 100.00 ( 99.16)
Epoch: [116][ 50/109]	Time  0.870 ( 0.737)	Data  0.000 ( 0.135)	Loss 0.0565403401851654 (0.1068123953015197)	Acc@1 100.00 ( 97.52)	Acc@5 100.00 ( 99.23)
Epoch: [116][ 60/109]	Time  0.955 ( 0.791)	Data  0.000 ( 0.113)	Loss 0.0969169810414314 (0.1071895345068369)	Acc@1  96.88 ( 97.41)	Acc@5  98.44 ( 99.18)
Epoch: [116][ 70/109]	Time  1.075 ( 0.806)	Data  0.000 ( 0.097)	Loss 0.1317187547683716 (0.1057713085287054)	Acc@1  98.44 ( 97.45)	Acc@5  98.44 ( 99.21)
Epoch: [116][ 80/109]	Time  0.550 ( 0.804)	Data  0.000 ( 0.085)	Loss 0.0901539176702499 (0.1034296537622993)	Acc@1  98.44 ( 97.51)	Acc@5  98.44 ( 99.23)
Epoch: [116][ 90/109]	Time  0.486 ( 0.771)	Data  0.000 ( 0.076)	Loss 0.1108929738402367 (0.1011062989441248)	Acc@1  95.31 ( 97.54)	Acc@5 100.00 ( 99.23)
Epoch: [116][100/109]	Time  0.690 ( 0.762)	Data  0.000 ( 0.068)	Loss 0.0074880858883262 (0.0996956982105823)	Acc@1 100.00 ( 97.56)	Acc@5 100.00 ( 99.24)
epoch: 116, Avg_Loss 0.0999541671673229
Test: [ 0/28]	Time  5.704 ( 5.704)	Loss 1.0627e+00 (1.0627e+00)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.207 ( 0.836)	Loss 1.2144e+00 (1.1676e+00)	Acc@1  78.12 ( 73.44)	Acc@5  87.50 ( 88.78)
Test: [20/28]	Time  0.129 ( 0.511)	Loss 8.7022e-01 (1.1958e+00)	Acc@1  71.88 ( 72.92)	Acc@5  96.88 ( 89.73)
 * Acc@1 73.663 Acc@5 90.096
lr 0.0001
Epoch: [117][  0/109]	Time  6.584 ( 6.584)	Data  5.768 ( 5.768)	Loss 0.1163708642125130 (0.1163708642125130)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [117][ 10/109]	Time  2.078 ( 1.571)	Data  0.001 ( 0.526)	Loss 0.0660572126507759 (0.1228258222002875)	Acc@1  98.44 ( 97.16)	Acc@5 100.00 ( 98.72)
Epoch: [117][ 20/109]	Time  0.927 ( 1.377)	Data  0.000 ( 0.276)	Loss 0.1331948339939117 (0.0979345518474777)	Acc@1  95.31 ( 97.54)	Acc@5  98.44 ( 99.03)
Epoch: [117][ 30/109]	Time  0.597 ( 1.163)	Data  0.000 ( 0.187)	Loss 0.0808074772357941 (0.0899451125653521)	Acc@1  96.88 ( 97.73)	Acc@5 100.00 ( 99.24)
Epoch: [117][ 40/109]	Time  0.924 ( 1.065)	Data  0.000 ( 0.141)	Loss 0.1207421123981476 (0.0903551338422226)	Acc@1  96.88 ( 97.79)	Acc@5  98.44 ( 99.24)
Epoch: [117][ 50/109]	Time  0.642 ( 1.018)	Data  0.000 ( 0.114)	Loss 0.1245868727564812 (0.0953969166376719)	Acc@1  98.44 ( 97.64)	Acc@5  98.44 ( 99.14)
Epoch: [117][ 60/109]	Time  1.824 ( 1.059)	Data  0.004 ( 0.095)	Loss 0.1068806126713753 (0.0908518654798142)	Acc@1  98.44 ( 97.82)	Acc@5  98.44 ( 99.18)
Epoch: [117][ 70/109]	Time  0.596 ( 1.017)	Data  0.000 ( 0.082)	Loss 0.0949046015739441 (0.0879497682728188)	Acc@1  96.88 ( 97.89)	Acc@5  98.44 ( 99.21)
Epoch: [117][ 80/109]	Time  0.486 ( 0.958)	Data  0.000 ( 0.072)	Loss 0.0479294098913670 (0.0839753180719268)	Acc@1  98.44 ( 97.96)	Acc@5 100.00 ( 99.31)
Epoch: [117][ 90/109]	Time  0.515 ( 0.907)	Data  0.000 ( 0.064)	Loss 0.0974424928426743 (0.0859932489002349)	Acc@1  96.88 ( 97.92)	Acc@5 100.00 ( 99.30)
Epoch: [117][100/109]	Time  0.578 ( 0.889)	Data  0.000 ( 0.058)	Loss 0.0162959154695272 (0.0845666353032915)	Acc@1 100.00 ( 97.97)	Acc@5 100.00 ( 99.30)
epoch: 117, Avg_Loss 0.08608444449662683
Test: [ 0/28]	Time  5.357 ( 5.357)	Loss 1.0350e+00 (1.0350e+00)	Acc@1  79.69 ( 79.69)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.152 ( 0.645)	Loss 5.9160e-01 (1.1136e+00)	Acc@1  82.81 ( 76.42)	Acc@5  96.88 ( 88.92)
Test: [20/28]	Time  0.117 ( 0.400)	Loss 1.4137e+00 (1.0846e+00)	Acc@1  73.44 ( 75.00)	Acc@5  84.38 ( 89.21)
 * Acc@1 75.408 Acc@5 89.364
lr 0.0001
Epoch: [118][  0/109]	Time  5.344 ( 5.344)	Data  4.651 ( 4.651)	Loss 0.0728820711374283 (0.0728820711374283)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [118][ 10/109]	Time  0.527 ( 1.121)	Data  0.001 ( 0.543)	Loss 0.1151231974363327 (0.0873198383911089)	Acc@1  98.44 ( 97.73)	Acc@5  98.44 ( 99.43)
Epoch: [118][ 20/109]	Time  0.489 ( 0.829)	Data  0.000 ( 0.285)	Loss 0.1815054863691330 (0.0823571320090975)	Acc@1  93.75 ( 97.77)	Acc@5  98.44 ( 99.55)
Epoch: [118][ 30/109]	Time  1.824 ( 0.819)	Data  0.001 ( 0.193)	Loss 0.1961483061313629 (0.0891546713368547)	Acc@1  93.75 ( 97.53)	Acc@5  96.88 ( 99.45)
Epoch: [118][ 40/109]	Time  0.664 ( 0.869)	Data  0.000 ( 0.146)	Loss 0.0425374843180180 (0.0945145678592891)	Acc@1  96.88 ( 97.45)	Acc@5 100.00 ( 99.31)
Epoch: [118][ 50/109]	Time  1.128 ( 0.906)	Data  0.001 ( 0.118)	Loss 0.0941303297877312 (0.0924756980555899)	Acc@1  98.44 ( 97.52)	Acc@5  98.44 ( 99.39)
Epoch: [118][ 60/109]	Time  0.519 ( 0.847)	Data  0.001 ( 0.099)	Loss 0.1923986673355103 (0.0921192459578885)	Acc@1  95.31 ( 97.54)	Acc@5  96.88 ( 99.39)
Epoch: [118][ 70/109]	Time  0.561 ( 0.800)	Data  0.000 ( 0.085)	Loss 0.0364884585142136 (0.0882626416712580)	Acc@1 100.00 ( 97.78)	Acc@5 100.00 ( 99.41)
Epoch: [118][ 80/109]	Time  1.192 ( 0.798)	Data  0.000 ( 0.074)	Loss 0.1358135342597961 (0.0876528669470622)	Acc@1  95.31 ( 97.80)	Acc@5  98.44 ( 99.40)
Epoch: [118][ 90/109]	Time  0.479 ( 0.815)	Data  0.000 ( 0.066)	Loss 0.2226584851741791 (0.0886533133644652)	Acc@1  93.75 ( 97.77)	Acc@5  96.88 ( 99.36)
Epoch: [118][100/109]	Time  0.558 ( 0.788)	Data  0.000 ( 0.060)	Loss 0.1302817165851593 (0.0902164688167891)	Acc@1  95.31 ( 97.73)	Acc@5 100.00 ( 99.38)
epoch: 118, Avg_Loss 0.09449616981960765
Test: [ 0/28]	Time  6.517 ( 6.517)	Loss 1.0901e+00 (1.0901e+00)	Acc@1  76.56 ( 76.56)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.188 ( 0.744)	Loss 8.6014e-01 (1.1111e+00)	Acc@1  76.56 ( 74.01)	Acc@5  95.31 ( 90.06)
Test: [20/28]	Time  0.145 ( 0.454)	Loss 1.3898e+00 (1.1269e+00)	Acc@1  73.44 ( 74.55)	Acc@5  87.50 ( 89.21)
 * Acc@1 74.958 Acc@5 90.152
lr 0.0001
Epoch: [119][  0/109]	Time  6.372 ( 6.372)	Data  5.428 ( 5.428)	Loss 0.0084673305973411 (0.0084673305973411)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [119][ 10/109]	Time  1.790 ( 1.487)	Data  0.003 ( 0.494)	Loss 0.0895029306411743 (0.1174592259763317)	Acc@1  96.88 ( 97.16)	Acc@5  98.44 ( 98.86)
Epoch: [119][ 20/109]	Time  1.012 ( 1.224)	Data  0.001 ( 0.259)	Loss 0.0118848355486989 (0.1072565432460535)	Acc@1 100.00 ( 97.40)	Acc@5 100.00 ( 99.11)
Epoch: [119][ 30/109]	Time  0.735 ( 1.060)	Data  0.000 ( 0.176)	Loss 0.2097869962453842 (0.1043253244772073)	Acc@1  95.31 ( 97.58)	Acc@5  98.44 ( 99.09)
Epoch: [119][ 40/109]	Time  0.787 ( 0.994)	Data  0.000 ( 0.133)	Loss 0.0746804028749466 (0.1020276146236716)	Acc@1  95.31 ( 97.52)	Acc@5 100.00 ( 99.20)
Epoch: [119][ 50/109]	Time  1.154 ( 0.961)	Data  0.001 ( 0.107)	Loss 0.0537880398333073 (0.1020919580889099)	Acc@1  98.44 ( 97.55)	Acc@5 100.00 ( 99.11)
Epoch: [119][ 60/109]	Time  1.498 ( 0.958)	Data  0.001 ( 0.090)	Loss 0.0787444561719894 (0.1033225704106640)	Acc@1  98.44 ( 97.57)	Acc@5  98.44 ( 99.13)
Epoch: [119][ 70/109]	Time  0.720 ( 0.942)	Data  0.000 ( 0.077)	Loss 0.1017250493168831 (0.1045049833737209)	Acc@1  96.88 ( 97.62)	Acc@5  98.44 ( 99.08)
Epoch: [119][ 80/109]	Time  0.568 ( 0.903)	Data  0.000 ( 0.068)	Loss 0.1148328632116318 (0.1063466518427487)	Acc@1  98.44 ( 97.59)	Acc@5  98.44 ( 99.00)
Epoch: [119][ 90/109]	Time  0.547 ( 0.894)	Data  0.000 ( 0.060)	Loss 0.1210789382457733 (0.1053066619845864)	Acc@1  95.31 ( 97.58)	Acc@5 100.00 ( 99.04)
Epoch: [119][100/109]	Time  1.080 ( 0.883)	Data  0.000 ( 0.054)	Loss 0.2101164013147354 (0.1049725905724681)	Acc@1  98.44 ( 97.60)	Acc@5  98.44 ( 99.07)
epoch: 119, Avg_Loss 0.10348991537039433
Test: [ 0/28]	Time  6.287 ( 6.287)	Loss 7.4826e-01 (7.4826e-01)	Acc@1  82.81 ( 82.81)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.139 ( 0.709)	Loss 1.2533e+00 (1.0162e+00)	Acc@1  70.31 ( 75.99)	Acc@5  85.94 ( 89.91)
Test: [20/28]	Time  0.136 ( 0.440)	Loss 7.9552e-01 (1.0796e+00)	Acc@1  79.69 ( 75.74)	Acc@5  92.19 ( 88.99)
 * Acc@1 74.958 Acc@5 88.633
lr 1.0000000000000003e-05
Epoch: [120][  0/109]	Time  6.920 ( 6.920)	Data  6.031 ( 6.031)	Loss 0.1597145944833755 (0.1597145944833755)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [120][ 10/109]	Time  0.485 ( 1.187)	Data  0.001 ( 0.568)	Loss 0.2275930196046829 (0.1402123170820150)	Acc@1  95.31 ( 96.88)	Acc@5  95.31 ( 98.44)
Epoch: [120][ 20/109]	Time  0.887 ( 1.032)	Data  0.001 ( 0.298)	Loss 0.0227513797581196 (0.1160911586845205)	Acc@1 100.00 ( 97.47)	Acc@5 100.00 ( 98.88)
Epoch: [120][ 30/109]	Time  0.926 ( 0.977)	Data  0.001 ( 0.202)	Loss 0.0649575591087341 (0.1094089805959694)	Acc@1  98.44 ( 97.43)	Acc@5 100.00 ( 99.04)
Epoch: [120][ 40/109]	Time  0.817 ( 0.942)	Data  0.000 ( 0.153)	Loss 0.1522619575262070 (0.1160739664351795)	Acc@1  93.75 ( 97.26)	Acc@5 100.00 ( 98.97)
Epoch: [120][ 50/109]	Time  0.983 ( 0.892)	Data  0.001 ( 0.123)	Loss 0.0276162214577198 (0.1089167368105229)	Acc@1 100.00 ( 97.43)	Acc@5 100.00 ( 99.08)
Epoch: [120][ 60/109]	Time  1.398 ( 1.022)	Data  0.001 ( 0.103)	Loss 0.0548933483660221 (0.1032725822058369)	Acc@1  98.44 ( 97.54)	Acc@5 100.00 ( 99.15)
Epoch: [120][ 70/109]	Time  0.516 ( 0.951)	Data  0.001 ( 0.088)	Loss 0.1353123784065247 (0.1051923841710242)	Acc@1  96.88 ( 97.45)	Acc@5  98.44 ( 99.10)
Epoch: [120][ 80/109]	Time  0.597 ( 0.902)	Data  0.000 ( 0.078)	Loss 0.1755266338586807 (0.1050362064859565)	Acc@1  93.75 ( 97.40)	Acc@5  98.44 ( 99.15)
Epoch: [120][ 90/109]	Time  0.707 ( 0.877)	Data  0.000 ( 0.069)	Loss 0.1657411307096481 (0.1072944356742632)	Acc@1  95.31 ( 97.34)	Acc@5  98.44 ( 99.12)
Epoch: [120][100/109]	Time  0.538 ( 0.897)	Data  0.000 ( 0.062)	Loss 0.1853534430265427 (0.1062029587510641)	Acc@1  92.19 ( 97.35)	Acc@5  98.44 ( 99.10)
epoch: 120, Avg_Loss 0.10527853269574292
Test: [ 0/28]	Time  4.763 ( 4.763)	Loss 9.5767e-01 (9.5767e-01)	Acc@1  76.56 ( 76.56)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.172 ( 0.777)	Loss 9.5761e-01 (1.0513e+00)	Acc@1  73.44 ( 75.85)	Acc@5  92.19 ( 90.20)
Test: [20/28]	Time  0.130 ( 0.473)	Loss 1.1339e+00 (1.0771e+00)	Acc@1  73.44 ( 75.60)	Acc@5  87.50 ( 88.99)
 * Acc@1 75.914 Acc@5 89.139
lr 1.0000000000000003e-05
Epoch: [121][  0/109]	Time  8.100 ( 8.100)	Data  7.397 ( 7.397)	Loss 0.1613014638423920 (0.1613014638423920)	Acc@1  96.88 ( 96.88)	Acc@5  96.88 ( 96.88)
Epoch: [121][ 10/109]	Time  0.674 ( 1.251)	Data  0.002 ( 0.673)	Loss 0.2092842459678650 (0.1193565307185054)	Acc@1  96.88 ( 97.44)	Acc@5  96.88 ( 98.44)
Epoch: [121][ 20/109]	Time  0.683 ( 0.966)	Data  0.000 ( 0.353)	Loss 0.0100788380950689 (0.1167845857285318)	Acc@1 100.00 ( 97.32)	Acc@5 100.00 ( 98.88)
Epoch: [121][ 30/109]	Time  0.630 ( 1.123)	Data  0.000 ( 0.239)	Loss 0.1044246256351471 (0.1000911535755281)	Acc@1  98.44 ( 97.68)	Acc@5 100.00 ( 99.24)
Epoch: [121][ 40/109]	Time  1.047 ( 1.074)	Data  0.007 ( 0.181)	Loss 0.1043003946542740 (0.0964498530119294)	Acc@1  98.44 ( 97.68)	Acc@5 100.00 ( 99.24)
Epoch: [121][ 50/109]	Time  0.624 ( 1.021)	Data  0.000 ( 0.146)	Loss 0.1005251035094261 (0.0972153817431307)	Acc@1  96.88 ( 97.58)	Acc@5 100.00 ( 99.30)
Epoch: [121][ 60/109]	Time  0.847 ( 0.965)	Data  0.000 ( 0.122)	Loss 0.1463143527507782 (0.0972691671617451)	Acc@1  96.88 ( 97.54)	Acc@5  98.44 ( 99.28)
Epoch: [121][ 70/109]	Time  0.753 ( 0.919)	Data  0.000 ( 0.105)	Loss 0.0383061207830906 (0.0972579947843308)	Acc@1 100.00 ( 97.58)	Acc@5 100.00 ( 99.27)
Epoch: [121][ 80/109]	Time  0.501 ( 0.898)	Data  0.000 ( 0.092)	Loss 0.1194877699017525 (0.0958902450324393)	Acc@1  96.88 ( 97.59)	Acc@5  98.44 ( 99.31)
Epoch: [121][ 90/109]	Time  0.501 ( 0.855)	Data  0.000 ( 0.082)	Loss 0.1489802896976471 (0.0922652367082844)	Acc@1  96.88 ( 97.70)	Acc@5  96.88 ( 99.33)
Epoch: [121][100/109]	Time  0.703 ( 0.825)	Data  0.000 ( 0.074)	Loss 0.1522344946861267 (0.0929469524993386)	Acc@1  93.75 ( 97.68)	Acc@5 100.00 ( 99.33)
epoch: 121, Avg_Loss 0.09511020322919848
Test: [ 0/28]	Time  4.450 ( 4.450)	Loss 1.6271e+00 (1.6271e+00)	Acc@1  64.06 ( 64.06)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.168 ( 0.708)	Loss 1.4616e+00 (1.1487e+00)	Acc@1  67.19 ( 72.44)	Acc@5  85.94 ( 88.49)
Test: [20/28]	Time  0.158 ( 0.454)	Loss 9.5295e-01 (1.1190e+00)	Acc@1  76.56 ( 73.88)	Acc@5  87.50 ( 88.91)
 * Acc@1 74.226 Acc@5 88.576
lr 1.0000000000000003e-05
Epoch: [122][  0/109]	Time  6.853 ( 6.853)	Data  6.051 ( 6.051)	Loss 0.0981316640973091 (0.0981316640973091)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [122][ 10/109]	Time  1.339 ( 1.528)	Data  0.002 ( 0.551)	Loss 0.0630987212061882 (0.0919682085514069)	Acc@1  98.44 ( 97.44)	Acc@5 100.00 ( 99.15)
Epoch: [122][ 20/109]	Time  0.485 ( 1.253)	Data  0.000 ( 0.290)	Loss 0.0353269763290882 (0.0868667193821498)	Acc@1  98.44 ( 97.92)	Acc@5 100.00 ( 99.11)
Epoch: [122][ 30/109]	Time  1.099 ( 1.059)	Data  0.000 ( 0.196)	Loss 0.0329807586967945 (0.0935371026036239)	Acc@1  98.44 ( 97.88)	Acc@5 100.00 ( 99.04)
Epoch: [122][ 40/109]	Time  0.593 ( 1.040)	Data  0.000 ( 0.149)	Loss 0.0853794515132904 (0.0958801636517775)	Acc@1  98.44 ( 97.75)	Acc@5  98.44 ( 99.01)
Epoch: [122][ 50/109]	Time  0.574 ( 0.955)	Data  0.000 ( 0.119)	Loss 0.1062600985169411 (0.0987895091301670)	Acc@1  96.88 ( 97.52)	Acc@5  98.44 ( 99.08)
Epoch: [122][ 60/109]	Time  0.582 ( 0.887)	Data  0.000 ( 0.100)	Loss 0.1292207092046738 (0.0989832421917407)	Acc@1  95.31 ( 97.52)	Acc@5  98.44 ( 99.05)
Epoch: [122][ 70/109]	Time  1.192 ( 0.912)	Data  0.000 ( 0.086)	Loss 0.0210900735110044 (0.0983818754763670)	Acc@1 100.00 ( 97.49)	Acc@5 100.00 ( 99.12)
Epoch: [122][ 80/109]	Time  0.500 ( 0.907)	Data  0.000 ( 0.075)	Loss 0.0478257536888123 (0.0951393489254478)	Acc@1 100.00 ( 97.61)	Acc@5 100.00 ( 99.19)
Epoch: [122][ 90/109]	Time  0.609 ( 0.873)	Data  0.000 ( 0.067)	Loss 0.0179770272225142 (0.0926769436797598)	Acc@1 100.00 ( 97.63)	Acc@5 100.00 ( 99.21)
Epoch: [122][100/109]	Time  0.667 ( 0.875)	Data  0.000 ( 0.061)	Loss 0.0754295289516449 (0.0913417583220814)	Acc@1  98.44 ( 97.66)	Acc@5 100.00 ( 99.27)
epoch: 122, Avg_Loss 0.09297589032372477
Test: [ 0/28]	Time  7.095 ( 7.095)	Loss 1.4128e+00 (1.4128e+00)	Acc@1  73.44 ( 73.44)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.135 ( 0.935)	Loss 8.9208e-01 (1.1605e+00)	Acc@1  82.81 ( 73.44)	Acc@5  92.19 ( 88.49)
Test: [20/28]	Time  0.123 ( 0.561)	Loss 1.0685e+00 (1.2023e+00)	Acc@1  79.69 ( 72.84)	Acc@5  87.50 ( 88.39)
 * Acc@1 73.213 Acc@5 88.801
lr 1.0000000000000003e-05
Epoch: [123][  0/109]	Time  4.340 ( 4.340)	Data  3.649 ( 3.649)	Loss 0.0390706397593021 (0.0390706397593021)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [123][ 10/109]	Time  1.599 ( 1.162)	Data  0.006 ( 0.348)	Loss 0.1077786982059479 (0.0758373158221895)	Acc@1  98.44 ( 98.30)	Acc@5  98.44 ( 99.43)
Epoch: [123][ 20/109]	Time  0.834 ( 1.196)	Data  0.003 ( 0.183)	Loss 0.1082687377929688 (0.1019371201594671)	Acc@1  96.88 ( 97.62)	Acc@5  98.44 ( 98.74)
Epoch: [123][ 30/109]	Time  1.030 ( 1.066)	Data  0.000 ( 0.124)	Loss 0.0987163633108139 (0.0891965626318368)	Acc@1  98.44 ( 97.98)	Acc@5 100.00 ( 99.09)
Epoch: [123][ 40/109]	Time  1.011 ( 1.209)	Data  0.001 ( 0.094)	Loss 0.0235762540251017 (0.0893944507669203)	Acc@1 100.00 ( 97.90)	Acc@5 100.00 ( 99.16)
Epoch: [123][ 50/109]	Time  0.743 ( 1.135)	Data  0.000 ( 0.076)	Loss 0.0054404069669545 (0.0901375989265302)	Acc@1 100.00 ( 97.89)	Acc@5 100.00 ( 99.14)
Epoch: [123][ 60/109]	Time  0.513 ( 1.045)	Data  0.000 ( 0.063)	Loss 0.0223966091871262 (0.0867506844281662)	Acc@1 100.00 ( 97.98)	Acc@5 100.00 ( 99.23)
Epoch: [123][ 70/109]	Time  0.578 ( 0.975)	Data  0.000 ( 0.054)	Loss 0.2486220300197601 (0.0887612956248119)	Acc@1  95.31 ( 97.98)	Acc@5  98.44 ( 99.21)
Epoch: [123][ 80/109]	Time  0.570 ( 0.937)	Data  0.000 ( 0.048)	Loss 0.1289262324571609 (0.0869138280826586)	Acc@1  96.88 ( 98.01)	Acc@5  98.44 ( 99.27)
Epoch: [123][ 90/109]	Time  0.585 ( 0.897)	Data  0.000 ( 0.042)	Loss 0.0455299466848373 (0.0859180876555351)	Acc@1  98.44 ( 98.03)	Acc@5 100.00 ( 99.31)
Epoch: [123][100/109]	Time  0.787 ( 0.877)	Data  0.000 ( 0.038)	Loss 0.1595290303230286 (0.0877205171797535)	Acc@1  98.44 ( 98.00)	Acc@5  98.44 ( 99.29)
epoch: 123, Avg_Loss 0.08795572306379812
Test: [ 0/28]	Time  7.744 ( 7.744)	Loss 1.0472e+00 (1.0472e+00)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.126 ( 0.886)	Loss 8.7300e-01 (1.0564e+00)	Acc@1  78.12 ( 75.57)	Acc@5  92.19 ( 90.62)
Test: [20/28]	Time  0.136 ( 0.552)	Loss 1.3208e+00 (1.0542e+00)	Acc@1  75.00 ( 74.85)	Acc@5  87.50 ( 90.62)
 * Acc@1 75.127 Acc@5 90.771
lr 1.0000000000000003e-05
Epoch: [124][  0/109]	Time  4.457 ( 4.457)	Data  3.796 ( 3.796)	Loss 0.0647265687584877 (0.0647265687584877)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [124][ 10/109]	Time  0.559 ( 0.945)	Data  0.001 ( 0.357)	Loss 0.0390549674630165 (0.0712400871244344)	Acc@1 100.00 ( 98.72)	Acc@5 100.00 ( 99.57)
Epoch: [124][ 20/109]	Time  0.910 ( 1.028)	Data  0.000 ( 0.188)	Loss 0.0552801638841629 (0.0784725970810368)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.48)
Epoch: [124][ 30/109]	Time  0.763 ( 1.054)	Data  0.000 ( 0.127)	Loss 0.0127926766872406 (0.0759562395152546)	Acc@1 100.00 ( 98.39)	Acc@5 100.00 ( 99.40)
Epoch: [124][ 40/109]	Time  0.784 ( 1.012)	Data  0.000 ( 0.096)	Loss 0.0702560469508171 (0.0843031195151370)	Acc@1  98.44 ( 98.02)	Acc@5 100.00 ( 99.24)
Epoch: [124][ 50/109]	Time  1.146 ( 1.029)	Data  0.000 ( 0.078)	Loss 0.0295009687542915 (0.0896675489550712)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 99.17)
Epoch: [124][ 60/109]	Time  0.716 ( 0.981)	Data  0.000 ( 0.065)	Loss 0.0692456960678101 (0.0908976569161063)	Acc@1  98.44 ( 97.95)	Acc@5  98.44 ( 99.10)
Epoch: [124][ 70/109]	Time  0.600 ( 0.929)	Data  0.000 ( 0.056)	Loss 0.0889946296811104 (0.0900313600268162)	Acc@1  96.88 ( 97.95)	Acc@5  98.44 ( 99.10)
Epoch: [124][ 80/109]	Time  0.526 ( 0.878)	Data  0.000 ( 0.049)	Loss 0.0535500198602676 (0.0880456899442239)	Acc@1 100.00 ( 97.97)	Acc@5 100.00 ( 99.13)
Epoch: [124][ 90/109]	Time  0.762 ( 0.842)	Data  0.000 ( 0.044)	Loss 0.0516544878482819 (0.0869280484986010)	Acc@1  98.44 ( 97.94)	Acc@5 100.00 ( 99.21)
Epoch: [124][100/109]	Time  0.873 ( 0.838)	Data  0.000 ( 0.039)	Loss 0.0154799036681652 (0.0840037429041349)	Acc@1 100.00 ( 98.05)	Acc@5 100.00 ( 99.27)
epoch: 124, Avg_Loss 0.08729913529145335
Test: [ 0/28]	Time  4.403 ( 4.403)	Loss 1.3924e+00 (1.3924e+00)	Acc@1  73.44 ( 73.44)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.129 ( 0.726)	Loss 1.3822e+00 (1.1179e+00)	Acc@1  67.19 ( 75.57)	Acc@5  85.94 ( 88.78)
Test: [20/28]	Time  0.120 ( 0.441)	Loss 9.4276e-01 (1.0751e+00)	Acc@1  78.12 ( 75.67)	Acc@5  90.62 ( 89.43)
 * Acc@1 75.295 Acc@5 89.364
lr 1.0000000000000003e-05
Epoch: [125][  0/109]	Time  6.937 ( 6.937)	Data  6.334 ( 6.334)	Loss 0.0691256597638130 (0.0691256597638130)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [125][ 10/109]	Time  0.498 ( 1.130)	Data  0.001 ( 0.576)	Loss 0.1610369533300400 (0.0916203860701485)	Acc@1  96.88 ( 98.15)	Acc@5  98.44 ( 98.86)
Epoch: [125][ 20/109]	Time  0.696 ( 0.855)	Data  0.000 ( 0.302)	Loss 0.0405622869729996 (0.0903387508754219)	Acc@1  98.44 ( 97.92)	Acc@5 100.00 ( 99.11)
Epoch: [125][ 30/109]	Time  1.125 ( 0.885)	Data  0.000 ( 0.212)	Loss 0.0234589762985706 (0.0884108652150439)	Acc@1  98.44 ( 97.98)	Acc@5 100.00 ( 99.14)
Epoch: [125][ 40/109]	Time  0.784 ( 0.905)	Data  0.002 ( 0.161)	Loss 0.0655900761485100 (0.0899518895894289)	Acc@1  98.44 ( 97.87)	Acc@5  98.44 ( 99.16)
Epoch: [125][ 50/109]	Time  0.581 ( 0.887)	Data  0.000 ( 0.129)	Loss 0.1256637871265411 (0.0870983739767004)	Acc@1  96.88 ( 98.04)	Acc@5  98.44 ( 99.20)
Epoch: [125][ 60/109]	Time  0.640 ( 0.841)	Data  0.000 ( 0.108)	Loss 0.0646264404058456 (0.0848874313543077)	Acc@1  98.44 ( 98.08)	Acc@5 100.00 ( 99.23)
Epoch: [125][ 70/109]	Time  0.639 ( 0.803)	Data  0.000 ( 0.093)	Loss 0.0088546164333820 (0.0848250977275237)	Acc@1 100.00 ( 97.98)	Acc@5 100.00 ( 99.25)
Epoch: [125][ 80/109]	Time  0.543 ( 0.785)	Data  0.000 ( 0.082)	Loss 0.0358432531356812 (0.0862125772292967)	Acc@1 100.00 ( 97.94)	Acc@5 100.00 ( 99.25)
Epoch: [125][ 90/109]	Time  0.571 ( 0.768)	Data  0.000 ( 0.073)	Loss 0.0430694371461868 (0.0850054814203919)	Acc@1  98.44 ( 97.97)	Acc@5 100.00 ( 99.23)
Epoch: [125][100/109]	Time  0.643 ( 0.753)	Data  0.000 ( 0.066)	Loss 0.0094042355194688 (0.0842837409743357)	Acc@1 100.00 ( 97.97)	Acc@5 100.00 ( 99.24)
epoch: 125, Avg_Loss 0.08664451882567838
Test: [ 0/28]	Time  5.525 ( 5.525)	Loss 1.3695e+00 (1.3695e+00)	Acc@1  67.19 ( 67.19)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.196 ( 0.699)	Loss 1.0928e+00 (1.1531e+00)	Acc@1  79.69 ( 74.29)	Acc@5  87.50 ( 88.35)
Test: [20/28]	Time  0.140 ( 0.443)	Loss 1.6368e+00 (1.1801e+00)	Acc@1  64.06 ( 73.21)	Acc@5  81.25 ( 88.17)
 * Acc@1 73.720 Acc@5 88.464
lr 1.0000000000000003e-05
Epoch: [126][  0/109]	Time  7.081 ( 7.081)	Data  6.322 ( 6.322)	Loss 0.0096061555668712 (0.0096061555668712)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [126][ 10/109]	Time  0.583 ( 1.166)	Data  0.001 ( 0.575)	Loss 0.0163081716746092 (0.0706216795369983)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.43)
Epoch: [126][ 20/109]	Time  0.590 ( 0.924)	Data  0.000 ( 0.301)	Loss 0.0208950936794281 (0.0971367105043360)	Acc@1 100.00 ( 97.62)	Acc@5 100.00 ( 99.26)
Epoch: [126][ 30/109]	Time  1.389 ( 1.071)	Data  0.001 ( 0.204)	Loss 0.0336911864578724 (0.0931744656916107)	Acc@1 100.00 ( 97.73)	Acc@5 100.00 ( 99.19)
Epoch: [126][ 40/109]	Time  0.653 ( 0.999)	Data  0.000 ( 0.155)	Loss 0.1562801301479340 (0.0947797205526291)	Acc@1  95.31 ( 97.64)	Acc@5  96.88 ( 99.12)
Epoch: [126][ 50/109]	Time  0.748 ( 0.944)	Data  0.000 ( 0.124)	Loss 0.0344178304076195 (0.0943628668821618)	Acc@1  98.44 ( 97.61)	Acc@5 100.00 ( 99.08)
Epoch: [126][ 60/109]	Time  0.569 ( 0.900)	Data  0.000 ( 0.104)	Loss 0.1275843977928162 (0.0980156135333122)	Acc@1  96.88 ( 97.59)	Acc@5  98.44 ( 99.05)
Epoch: [126][ 70/109]	Time  0.503 ( 0.848)	Data  0.000 ( 0.089)	Loss 0.1096594631671906 (0.0986206417929539)	Acc@1  96.88 ( 97.56)	Acc@5 100.00 ( 99.10)
Epoch: [126][ 80/109]	Time  0.743 ( 0.817)	Data  0.000 ( 0.078)	Loss 0.1307300031185150 (0.0988799185250644)	Acc@1  96.88 ( 97.49)	Acc@5  98.44 ( 99.09)
Epoch: [126][ 90/109]	Time  0.628 ( 0.815)	Data  0.001 ( 0.070)	Loss 0.1763034909963608 (0.0990823623980140)	Acc@1  92.19 ( 97.46)	Acc@5  98.44 ( 99.09)
Epoch: [126][100/109]	Time  0.880 ( 0.835)	Data  0.000 ( 0.063)	Loss 0.0091759478673339 (0.0948259366565559)	Acc@1 100.00 ( 97.56)	Acc@5 100.00 ( 99.15)
epoch: 126, Avg_Loss 0.09670228658910465
Test: [ 0/28]	Time  5.639 ( 5.639)	Loss 1.8274e+00 (1.8274e+00)	Acc@1  64.06 ( 64.06)	Acc@5  81.25 ( 81.25)
Test: [10/28]	Time  0.142 ( 0.722)	Loss 1.2174e+00 (1.2392e+00)	Acc@1  75.00 ( 72.59)	Acc@5  87.50 ( 88.07)
Test: [20/28]	Time  0.119 ( 0.440)	Loss 8.8230e-01 (1.1628e+00)	Acc@1  78.12 ( 74.40)	Acc@5  90.62 ( 88.10)
 * Acc@1 75.014 Acc@5 88.801
lr 1.0000000000000003e-05
Epoch: [127][  0/109]	Time  4.910 ( 4.910)	Data  4.266 ( 4.266)	Loss 0.0544771328568459 (0.0544771328568459)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [127][ 10/109]	Time  0.914 ( 1.247)	Data  0.002 ( 0.416)	Loss 0.0816338285803795 (0.0704780229451981)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.57)
Epoch: [127][ 20/109]	Time  0.859 ( 1.373)	Data  0.000 ( 0.218)	Loss 0.0512114316225052 (0.0621768967026756)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.70)
Epoch: [127][ 30/109]	Time  0.648 ( 1.164)	Data  0.001 ( 0.148)	Loss 0.1424777805805206 (0.0686939334076258)	Acc@1  95.31 ( 98.39)	Acc@5  98.44 ( 99.65)
Epoch: [127][ 40/109]	Time  0.588 ( 1.031)	Data  0.000 ( 0.112)	Loss 0.1484457105398178 (0.0712033380731577)	Acc@1  96.88 ( 98.40)	Acc@5  98.44 ( 99.50)
Epoch: [127][ 50/109]	Time  1.327 ( 1.035)	Data  0.001 ( 0.090)	Loss 0.0824175328016281 (0.0721336395717135)	Acc@1  96.88 ( 98.35)	Acc@5 100.00 ( 99.51)
Epoch: [127][ 60/109]	Time  0.807 ( 1.002)	Data  0.014 ( 0.076)	Loss 0.1222368031740189 (0.0759006633316396)	Acc@1  96.88 ( 98.28)	Acc@5  98.44 ( 99.46)
Epoch: [127][ 70/109]	Time  0.587 ( 0.961)	Data  0.000 ( 0.065)	Loss 0.0782867968082428 (0.0776606537926365)	Acc@1  96.88 ( 98.17)	Acc@5 100.00 ( 99.45)
Epoch: [127][ 80/109]	Time  0.568 ( 0.935)	Data  0.000 ( 0.057)	Loss 0.0896939858794212 (0.0787814000138530)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.42)
Epoch: [127][ 90/109]	Time  0.496 ( 0.931)	Data  0.000 ( 0.051)	Loss 0.0999837666749954 (0.0793346386034410)	Acc@1  96.88 ( 98.13)	Acc@5 100.00 ( 99.40)
Epoch: [127][100/109]	Time  1.345 ( 0.914)	Data  0.000 ( 0.046)	Loss 0.0182576011866331 (0.0813255650775120)	Acc@1  98.44 ( 98.04)	Acc@5 100.00 ( 99.33)
epoch: 127, Avg_Loss 0.08035240949498951
Test: [ 0/28]	Time  4.643 ( 4.643)	Loss 1.4136e+00 (1.4136e+00)	Acc@1  70.31 ( 70.31)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.145 ( 0.606)	Loss 9.1829e-01 (1.1933e+00)	Acc@1  79.69 ( 73.30)	Acc@5  89.06 ( 88.35)
Test: [20/28]	Time  0.119 ( 0.390)	Loss 1.1426e+00 (1.1290e+00)	Acc@1  70.31 ( 74.11)	Acc@5  95.31 ( 89.51)
 * Acc@1 74.339 Acc@5 90.039
lr 1.0000000000000003e-05
Epoch: [128][  0/109]	Time  6.258 ( 6.258)	Data  5.550 ( 5.550)	Loss 0.0968704819679260 (0.0968704819679260)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [128][ 10/109]	Time  0.570 ( 1.108)	Data  0.001 ( 0.505)	Loss 0.0065735164098442 (0.0570532404817641)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.72)
Epoch: [128][ 20/109]	Time  0.665 ( 0.878)	Data  0.000 ( 0.267)	Loss 0.0698440372943878 (0.0665854633164902)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 ( 99.70)
Epoch: [128][ 30/109]	Time  0.709 ( 0.858)	Data  0.000 ( 0.181)	Loss 0.1934624612331390 (0.0776368162534650)	Acc@1  95.31 ( 98.08)	Acc@5  96.88 ( 99.40)
Epoch: [128][ 40/109]	Time  0.856 ( 0.821)	Data  0.001 ( 0.137)	Loss 0.0645618364214897 (0.0784292531018032)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.39)
Epoch: [128][ 50/109]	Time  0.737 ( 0.810)	Data  0.000 ( 0.110)	Loss 0.0065661328844726 (0.0791190539066698)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 99.36)
Epoch: [128][ 60/109]	Time  0.582 ( 0.776)	Data  0.000 ( 0.092)	Loss 0.0714386999607086 (0.0804032474206608)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.31)
Epoch: [128][ 70/109]	Time  0.514 ( 0.743)	Data  0.000 ( 0.079)	Loss 0.0553542599081993 (0.0804326255267984)	Acc@1  96.88 ( 97.89)	Acc@5 100.00 ( 99.36)
Epoch: [128][ 80/109]	Time  0.485 ( 0.716)	Data  0.000 ( 0.069)	Loss 0.1021642684936523 (0.0834655618800977)	Acc@1  98.44 ( 97.84)	Acc@5  98.44 ( 99.34)
Epoch: [128][ 90/109]	Time  0.520 ( 0.693)	Data  0.000 ( 0.062)	Loss 0.1965532153844833 (0.0843334455186358)	Acc@1  95.31 ( 97.84)	Acc@5  98.44 ( 99.36)
Epoch: [128][100/109]	Time  0.504 ( 0.673)	Data  0.000 ( 0.056)	Loss 0.1478428244590759 (0.0853413502031034)	Acc@1  98.44 ( 97.79)	Acc@5  98.44 ( 99.33)
epoch: 128, Avg_Loss 0.08533114779296272
Test: [ 0/28]	Time  4.325 ( 4.325)	Loss 8.4230e-01 (8.4230e-01)	Acc@1  79.69 ( 79.69)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.193 ( 0.629)	Loss 1.5827e+00 (1.0745e+00)	Acc@1  65.62 ( 75.57)	Acc@5  84.38 ( 88.49)
Test: [20/28]	Time  0.137 ( 0.401)	Loss 1.0554e+00 (1.0827e+00)	Acc@1  73.44 ( 75.07)	Acc@5  85.94 ( 88.39)
 * Acc@1 75.577 Acc@5 88.745
lr 1.0000000000000003e-05
Epoch: [129][  0/109]	Time  6.521 ( 6.521)	Data  5.830 ( 5.830)	Loss 0.0500152707099915 (0.0500152707099915)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [129][ 10/109]	Time  0.602 ( 1.096)	Data  0.001 ( 0.530)	Loss 0.0737183764576912 (0.0765193856575272)	Acc@1  98.44 ( 98.15)	Acc@5  98.44 ( 99.01)
Epoch: [129][ 20/109]	Time  0.507 ( 0.830)	Data  0.000 ( 0.278)	Loss 0.0127596044912934 (0.0830833249769750)	Acc@1 100.00 ( 97.99)	Acc@5 100.00 ( 99.03)
Epoch: [129][ 30/109]	Time  0.560 ( 0.736)	Data  0.000 ( 0.190)	Loss 0.1258530318737030 (0.0849011963263394)	Acc@1  95.31 ( 97.98)	Acc@5  98.44 ( 99.04)
Epoch: [129][ 40/109]	Time  0.605 ( 0.688)	Data  0.000 ( 0.144)	Loss 0.1828858852386475 (0.0874543228504680)	Acc@1  95.31 ( 97.87)	Acc@5  96.88 ( 99.05)
Epoch: [129][ 50/109]	Time  0.583 ( 0.677)	Data  0.000 ( 0.116)	Loss 0.1037670671939850 (0.0991923533946130)	Acc@1  95.31 ( 97.49)	Acc@5 100.00 ( 98.93)
Epoch: [129][ 60/109]	Time  0.597 ( 0.657)	Data  0.000 ( 0.097)	Loss 0.1317172199487686 (0.0968983445667708)	Acc@1  95.31 ( 97.49)	Acc@5 100.00 ( 98.98)
Epoch: [129][ 70/109]	Time  0.538 ( 0.642)	Data  0.000 ( 0.083)	Loss 0.0641442760825157 (0.0930676365494203)	Acc@1  96.88 ( 97.62)	Acc@5 100.00 ( 99.03)
Epoch: [129][ 80/109]	Time  0.503 ( 0.627)	Data  0.000 ( 0.073)	Loss 0.0280311368405819 (0.0901436038763711)	Acc@1 100.00 ( 97.70)	Acc@5 100.00 ( 99.05)
Epoch: [129][ 90/109]	Time  0.479 ( 0.613)	Data  0.000 ( 0.065)	Loss 0.1126399561762810 (0.0890537459700072)	Acc@1  96.88 ( 97.79)	Acc@5  98.44 ( 99.09)
Epoch: [129][100/109]	Time  0.487 ( 0.602)	Data  0.000 ( 0.059)	Loss 0.2687284946441650 (0.0905248661673084)	Acc@1  95.31 ( 97.73)	Acc@5  95.31 ( 99.06)
epoch: 129, Avg_Loss 0.08982924420232756
Test: [ 0/28]	Time  3.869 ( 3.869)	Loss 7.0002e-01 (7.0002e-01)	Acc@1  84.38 ( 84.38)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.141 ( 0.648)	Loss 1.1632e+00 (1.0570e+00)	Acc@1  75.00 ( 75.57)	Acc@5  87.50 ( 89.63)
Test: [20/28]	Time  0.119 ( 0.404)	Loss 1.0944e+00 (1.0445e+00)	Acc@1  73.44 ( 75.45)	Acc@5  90.62 ( 89.73)
 * Acc@1 75.127 Acc@5 89.420
lr 1.0000000000000003e-05
Epoch: [130][  0/109]	Time  7.190 ( 7.190)	Data  6.617 ( 6.617)	Loss 0.0351502671837807 (0.0351502671837807)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [130][ 10/109]	Time  0.523 ( 1.150)	Data  0.001 ( 0.602)	Loss 0.0334356166422367 (0.0700384498658505)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 ( 99.15)
Epoch: [130][ 20/109]	Time  0.539 ( 0.860)	Data  0.000 ( 0.315)	Loss 0.0633999854326248 (0.0676245699148803)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 ( 99.48)
Epoch: [130][ 30/109]	Time  0.518 ( 0.763)	Data  0.000 ( 0.214)	Loss 0.1130873709917068 (0.0729030567792154)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.50)
Epoch: [130][ 40/109]	Time  0.689 ( 0.719)	Data  0.000 ( 0.162)	Loss 0.1364258229732513 (0.0757308465133353)	Acc@1  98.44 ( 98.29)	Acc@5  98.44 ( 99.58)
Epoch: [130][ 50/109]	Time  0.570 ( 0.691)	Data  0.000 ( 0.130)	Loss 0.0620367415249348 (0.0764736239524449)	Acc@1  98.44 ( 98.31)	Acc@5 100.00 ( 99.54)
Epoch: [130][ 60/109]	Time  0.770 ( 0.686)	Data  0.000 ( 0.109)	Loss 0.0345003791153431 (0.0727716470442590)	Acc@1 100.00 ( 98.41)	Acc@5 100.00 ( 99.59)
Epoch: [130][ 70/109]	Time  0.689 ( 0.688)	Data  0.000 ( 0.094)	Loss 0.0697866305708885 (0.0718143978090563)	Acc@1  98.44 ( 98.35)	Acc@5 100.00 ( 99.60)
Epoch: [130][ 80/109]	Time  0.493 ( 0.675)	Data  0.000 ( 0.082)	Loss 0.0861932709813118 (0.0770097054242168)	Acc@1  98.44 ( 98.23)	Acc@5 100.00 ( 99.52)
Epoch: [130][ 90/109]	Time  0.478 ( 0.657)	Data  0.000 ( 0.073)	Loss 0.0917462855577469 (0.0766332341194317)	Acc@1  96.88 ( 98.23)	Acc@5 100.00 ( 99.50)
Epoch: [130][100/109]	Time  0.536 ( 0.644)	Data  0.000 ( 0.066)	Loss 0.0548721924424171 (0.0776514207833622)	Acc@1  98.44 ( 98.17)	Acc@5 100.00 ( 99.50)
epoch: 130, Avg_Loss 0.07544130814013951
Test: [ 0/28]	Time  3.845 ( 3.845)	Loss 8.9449e-01 (8.9449e-01)	Acc@1  73.44 ( 73.44)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.136 ( 0.607)	Loss 1.0511e+00 (1.1217e+00)	Acc@1  71.88 ( 73.58)	Acc@5  90.62 ( 88.64)
Test: [20/28]	Time  0.122 ( 0.396)	Loss 1.2392e+00 (1.1042e+00)	Acc@1  73.44 ( 74.40)	Acc@5  89.06 ( 89.43)
 * Acc@1 74.451 Acc@5 89.252
lr 1.0000000000000003e-05
Epoch: [131][  0/109]	Time  5.197 ( 5.197)	Data  4.487 ( 4.487)	Loss 0.0281119905412197 (0.0281119905412197)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [131][ 10/109]	Time  0.771 ( 1.089)	Data  0.001 ( 0.408)	Loss 0.1989267915487289 (0.1053937158801339)	Acc@1  95.31 ( 97.44)	Acc@5  96.88 ( 98.86)
Epoch: [131][ 20/109]	Time  0.702 ( 0.992)	Data  0.000 ( 0.214)	Loss 0.0464015267789364 (0.0962183027572575)	Acc@1  98.44 ( 97.62)	Acc@5 100.00 ( 98.96)
Epoch: [131][ 30/109]	Time  0.514 ( 0.859)	Data  0.000 ( 0.145)	Loss 0.1670191735029221 (0.0988257874644572)	Acc@1  96.88 ( 97.63)	Acc@5  98.44 ( 99.04)
Epoch: [131][ 40/109]	Time  0.699 ( 0.795)	Data  0.001 ( 0.110)	Loss 0.1657125353813171 (0.0978737236568477)	Acc@1  96.88 ( 97.68)	Acc@5  98.44 ( 99.05)
Epoch: [131][ 50/109]	Time  0.776 ( 0.765)	Data  0.001 ( 0.088)	Loss 0.1186914592981339 (0.0969323423307608)	Acc@1  96.88 ( 97.64)	Acc@5  98.44 ( 99.05)
Epoch: [131][ 60/109]	Time  0.726 ( 0.745)	Data  0.000 ( 0.074)	Loss 0.1293358057737350 (0.0932966840346573)	Acc@1  96.88 ( 97.69)	Acc@5  98.44 ( 99.10)
Epoch: [131][ 70/109]	Time  1.094 ( 0.777)	Data  0.000 ( 0.064)	Loss 0.1121753156185150 (0.0896745030571457)	Acc@1  96.88 ( 97.82)	Acc@5  98.44 ( 99.14)
Epoch: [131][ 80/109]	Time  0.607 ( 0.783)	Data  0.000 ( 0.056)	Loss 0.0593257136642933 (0.0844272887161760)	Acc@1 100.00 ( 97.94)	Acc@5 100.00 ( 99.21)
Epoch: [131][ 90/109]	Time  0.542 ( 0.756)	Data  0.000 ( 0.050)	Loss 0.0285841878503561 (0.0881596363538487)	Acc@1 100.00 ( 97.91)	Acc@5 100.00 ( 99.11)
Epoch: [131][100/109]	Time  0.483 ( 0.731)	Data  0.000 ( 0.045)	Loss 0.0214564539492130 (0.0902536557849017)	Acc@1 100.00 ( 97.83)	Acc@5 100.00 ( 99.12)
epoch: 131, Avg_Loss 0.0914747895066276
Test: [ 0/28]	Time  4.848 ( 4.848)	Loss 1.2998e+00 (1.2998e+00)	Acc@1  71.88 ( 71.88)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.182 ( 0.819)	Loss 6.7317e-01 (1.0692e+00)	Acc@1  78.12 ( 74.86)	Acc@5  95.31 ( 90.06)
Test: [20/28]	Time  0.142 ( 0.502)	Loss 1.5593e+00 (1.0738e+00)	Acc@1  73.44 ( 75.30)	Acc@5  82.81 ( 89.21)
 * Acc@1 74.789 Acc@5 89.195
lr 1.0000000000000003e-05
Epoch: [132][  0/109]	Time  6.848 ( 6.848)	Data  6.247 ( 6.247)	Loss 0.0362130552530289 (0.0362130552530289)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [132][ 10/109]	Time  0.689 ( 1.202)	Data  0.003 ( 0.568)	Loss 0.0988361239433289 (0.0728186573833227)	Acc@1  98.44 ( 98.30)	Acc@5  98.44 ( 99.29)
Epoch: [132][ 20/109]	Time  0.638 ( 0.949)	Data  0.000 ( 0.298)	Loss 0.2228368669748306 (0.0885053934263332)	Acc@1  95.31 ( 97.77)	Acc@5  96.88 ( 99.18)
Epoch: [132][ 30/109]	Time  0.576 ( 0.876)	Data  0.000 ( 0.202)	Loss 0.0767008066177368 (0.0809681663409837)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.24)
Epoch: [132][ 40/109]	Time  0.655 ( 0.802)	Data  0.000 ( 0.153)	Loss 0.0145131666213274 (0.0816684939285241)	Acc@1 100.00 ( 97.90)	Acc@5 100.00 ( 99.28)
Epoch: [132][ 50/109]	Time  0.601 ( 0.838)	Data  0.000 ( 0.123)	Loss 0.0174949951469898 (0.0757448565324440)	Acc@1 100.00 ( 98.13)	Acc@5 100.00 ( 99.39)
Epoch: [132][ 60/109]	Time  0.483 ( 0.785)	Data  0.000 ( 0.103)	Loss 0.0772833228111267 (0.0740777055931384)	Acc@1  98.44 ( 98.16)	Acc@5  98.44 ( 99.41)
Epoch: [132][ 70/109]	Time  0.502 ( 0.748)	Data  0.000 ( 0.088)	Loss 0.0780593529343605 (0.0718920590801978)	Acc@1  98.44 ( 98.22)	Acc@5 100.00 ( 99.45)
Epoch: [132][ 80/109]	Time  0.936 ( 0.748)	Data  0.000 ( 0.078)	Loss 0.0244116485118866 (0.0697619532131487)	Acc@1 100.00 ( 98.28)	Acc@5 100.00 ( 99.48)
Epoch: [132][ 90/109]	Time  0.489 ( 0.735)	Data  0.000 ( 0.069)	Loss 0.0839503780007362 (0.0713589595078112)	Acc@1  98.44 ( 98.25)	Acc@5  98.44 ( 99.47)
Epoch: [132][100/109]	Time  0.509 ( 0.711)	Data  0.000 ( 0.062)	Loss 0.0323936417698860 (0.0723554699285196)	Acc@1 100.00 ( 98.19)	Acc@5 100.00 ( 99.47)
epoch: 132, Avg_Loss 0.07256271370575515
Test: [ 0/28]	Time  4.915 ( 4.915)	Loss 1.2114e+00 (1.2114e+00)	Acc@1  73.44 ( 73.44)	Acc@5  82.81 ( 82.81)
Test: [10/28]	Time  0.159 ( 0.728)	Loss 1.0016e+00 (1.1815e+00)	Acc@1  73.44 ( 72.30)	Acc@5  92.19 ( 87.36)
Test: [20/28]	Time  0.136 ( 0.461)	Loss 1.0490e+00 (1.1526e+00)	Acc@1  75.00 ( 72.77)	Acc@5  85.94 ( 88.17)
 * Acc@1 73.157 Acc@5 88.858
lr 1.0000000000000003e-05
Epoch: [133][  0/109]	Time  6.466 ( 6.466)	Data  5.822 ( 5.822)	Loss 0.2426211535930634 (0.2426211535930634)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [133][ 10/109]	Time  1.848 ( 1.775)	Data  0.001 ( 0.530)	Loss 0.0826069563627243 (0.0764782564206557)	Acc@1  96.88 ( 97.73)	Acc@5 100.00 ( 99.57)
Epoch: [133][ 20/109]	Time  0.848 ( 1.289)	Data  0.000 ( 0.278)	Loss 0.0181768462061882 (0.0771275874049891)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.48)
Epoch: [133][ 30/109]	Time  1.047 ( 1.120)	Data  0.000 ( 0.188)	Loss 0.0330151282250881 (0.0760992958000110)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.45)
Epoch: [133][ 40/109]	Time  0.631 ( 1.086)	Data  0.000 ( 0.143)	Loss 0.1925215572118759 (0.0855460632138136)	Acc@1  95.31 ( 97.68)	Acc@5  98.44 ( 99.43)
Epoch: [133][ 50/109]	Time  0.804 ( 0.997)	Data  0.000 ( 0.115)	Loss 0.0747116580605507 (0.0843615499051178)	Acc@1  98.44 ( 97.76)	Acc@5  98.44 ( 99.39)
Epoch: [133][ 60/109]	Time  0.583 ( 0.949)	Data  0.000 ( 0.096)	Loss 0.1375866383314133 (0.0865064749845349)	Acc@1  96.88 ( 97.72)	Acc@5  98.44 ( 99.33)
Epoch: [133][ 70/109]	Time  0.600 ( 0.892)	Data  0.000 ( 0.082)	Loss 0.0842410027980804 (0.0850724711502627)	Acc@1  98.44 ( 97.71)	Acc@5  98.44 ( 99.34)
Epoch: [133][ 80/109]	Time  0.942 ( 0.856)	Data  0.000 ( 0.072)	Loss 0.0761999115347862 (0.0815031903818894)	Acc@1  96.88 ( 97.88)	Acc@5 100.00 ( 99.36)
Epoch: [133][ 90/109]	Time  0.597 ( 0.846)	Data  0.000 ( 0.064)	Loss 0.0171850323677063 (0.0790168892152116)	Acc@1 100.00 ( 97.94)	Acc@5 100.00 ( 99.42)
Epoch: [133][100/109]	Time  0.599 ( 0.830)	Data  0.000 ( 0.058)	Loss 0.0249571055173874 (0.0782066551405973)	Acc@1 100.00 ( 97.97)	Acc@5 100.00 ( 99.43)
epoch: 133, Avg_Loss 0.08052399797672662
Test: [ 0/28]	Time  7.026 ( 7.026)	Loss 6.3457e-01 (6.3457e-01)	Acc@1  82.81 ( 82.81)	Acc@5  96.88 ( 96.88)
Test: [10/28]	Time  0.180 ( 0.766)	Loss 1.1703e+00 (1.0219e+00)	Acc@1  79.69 ( 75.43)	Acc@5  85.94 ( 90.77)
Test: [20/28]	Time  0.119 ( 0.461)	Loss 1.1210e+00 (1.0526e+00)	Acc@1  76.56 ( 75.60)	Acc@5  89.06 ( 89.96)
 * Acc@1 75.014 Acc@5 89.364
lr 1.0000000000000003e-05
Epoch: [134][  0/109]	Time  5.478 ( 5.478)	Data  4.789 ( 4.789)	Loss 0.0221346467733383 (0.0221346467733383)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [134][ 10/109]	Time  0.506 ( 1.057)	Data  0.001 ( 0.436)	Loss 0.0763064399361610 (0.0798156384209340)	Acc@1  96.88 ( 97.87)	Acc@5 100.00 ( 99.86)
Epoch: [134][ 20/109]	Time  0.828 ( 0.931)	Data  0.000 ( 0.228)	Loss 0.0579413920640945 (0.0822569216557202)	Acc@1  98.44 ( 97.92)	Acc@5 100.00 ( 99.55)
Epoch: [134][ 30/109]	Time  0.657 ( 0.824)	Data  0.000 ( 0.155)	Loss 0.0769117698073387 (0.0819451008292456)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.40)
Epoch: [134][ 40/109]	Time  0.560 ( 0.768)	Data  0.000 ( 0.117)	Loss 0.0339418947696686 (0.0758613058502173)	Acc@1 100.00 ( 98.17)	Acc@5 100.00 ( 99.50)
Epoch: [134][ 50/109]	Time  0.669 ( 0.729)	Data  0.000 ( 0.094)	Loss 0.0501589737832546 (0.0770211657235289)	Acc@1  98.44 ( 98.10)	Acc@5 100.00 ( 99.48)
Epoch: [134][ 60/109]	Time  0.656 ( 0.721)	Data  0.000 ( 0.079)	Loss 0.1544303596019745 (0.0767301119421227)	Acc@1  95.31 ( 98.16)	Acc@5 100.00 ( 99.46)
Epoch: [134][ 70/109]	Time  0.906 ( 0.719)	Data  0.000 ( 0.068)	Loss 0.0343491658568382 (0.0827154344879091)	Acc@1 100.00 ( 98.00)	Acc@5 100.00 ( 99.41)
Epoch: [134][ 80/109]	Time  0.486 ( 0.768)	Data  0.000 ( 0.060)	Loss 0.0828092396259308 (0.0831763138707129)	Acc@1  96.88 ( 97.96)	Acc@5 100.00 ( 99.40)
Epoch: [134][ 90/109]	Time  0.670 ( 0.743)	Data  0.000 ( 0.053)	Loss 0.1629755496978760 (0.0845240562959769)	Acc@1  96.88 ( 97.91)	Acc@5  98.44 ( 99.36)
Epoch: [134][100/109]	Time  0.523 ( 0.730)	Data  0.000 ( 0.048)	Loss 0.1302329599857330 (0.0842026656189251)	Acc@1  95.31 ( 97.88)	Acc@5 100.00 ( 99.38)
epoch: 134, Avg_Loss 0.08229177823256052
Test: [ 0/28]	Time  7.737 ( 7.737)	Loss 1.0306e+00 (1.0306e+00)	Acc@1  82.81 ( 82.81)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.187 ( 0.826)	Loss 1.3481e+00 (1.0222e+00)	Acc@1  68.75 ( 75.57)	Acc@5  89.06 ( 90.20)
Test: [20/28]	Time  0.144 ( 0.495)	Loss 9.3877e-01 (1.0180e+00)	Acc@1  78.12 ( 76.12)	Acc@5  89.06 ( 90.18)
 * Acc@1 74.564 Acc@5 90.208
lr 1.0000000000000003e-05
Epoch: [135][  0/109]	Time  7.796 ( 7.796)	Data  7.124 ( 7.124)	Loss 0.0337082594633102 (0.0337082594633102)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [135][ 10/109]	Time  0.533 ( 1.210)	Data  0.001 ( 0.648)	Loss 0.0486791133880615 (0.0817008208144795)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.29)
Epoch: [135][ 20/109]	Time  0.663 ( 0.897)	Data  0.000 ( 0.339)	Loss 0.0167464520782232 (0.0684186580723950)	Acc@1 100.00 ( 98.29)	Acc@5 100.00 ( 99.48)
Epoch: [135][ 30/109]	Time  0.957 ( 0.913)	Data  0.001 ( 0.230)	Loss 0.1070830672979355 (0.0754018756110341)	Acc@1  96.88 ( 98.08)	Acc@5  98.44 ( 99.34)
Epoch: [135][ 40/109]	Time  0.657 ( 0.913)	Data  0.000 ( 0.174)	Loss 0.0899044275283813 (0.0729189311585775)	Acc@1  98.44 ( 98.13)	Acc@5 100.00 ( 99.43)
Epoch: [135][ 50/109]	Time  0.768 ( 0.905)	Data  0.001 ( 0.140)	Loss 0.0979990065097809 (0.0739957054748255)	Acc@1  96.88 ( 98.04)	Acc@5 100.00 ( 99.45)
Epoch: [135][ 60/109]	Time  0.890 ( 0.871)	Data  0.000 ( 0.117)	Loss 0.1156622469425201 (0.0812121298255735)	Acc@1  96.88 ( 97.98)	Acc@5  98.44 ( 99.36)
Epoch: [135][ 70/109]	Time  0.585 ( 0.845)	Data  0.000 ( 0.101)	Loss 0.0145083069801331 (0.0850919825746350)	Acc@1 100.00 ( 97.82)	Acc@5 100.00 ( 99.32)
Epoch: [135][ 80/109]	Time  0.599 ( 0.808)	Data  0.000 ( 0.088)	Loss 0.0689443126320839 (0.0823610511803885)	Acc@1  98.44 ( 97.88)	Acc@5 100.00 ( 99.36)
Epoch: [135][ 90/109]	Time  1.231 ( 0.790)	Data  0.001 ( 0.079)	Loss 0.1315732151269913 (0.0831299148766058)	Acc@1  96.88 ( 97.91)	Acc@5  98.44 ( 99.30)
Epoch: [135][100/109]	Time  0.601 ( 0.804)	Data  0.000 ( 0.071)	Loss 0.0151160126551986 (0.0800518361980667)	Acc@1 100.00 ( 98.02)	Acc@5 100.00 ( 99.33)
epoch: 135, Avg_Loss 0.07983339302788633
Test: [ 0/28]	Time  5.963 ( 5.963)	Loss 1.0767e+00 (1.0767e+00)	Acc@1  71.88 ( 71.88)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.131 ( 0.675)	Loss 1.0542e+00 (1.1062e+00)	Acc@1  78.12 ( 74.72)	Acc@5  89.06 ( 89.06)
Test: [20/28]	Time  0.163 ( 0.430)	Loss 1.2413e+00 (1.0926e+00)	Acc@1  71.88 ( 74.70)	Acc@5  84.38 ( 89.66)
 * Acc@1 74.283 Acc@5 89.026
lr 1.0000000000000003e-05
Epoch: [136][  0/109]	Time  7.771 ( 7.771)	Data  6.846 ( 6.846)	Loss 0.0871528312563896 (0.0871528312563896)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [136][ 10/109]	Time  0.515 ( 1.264)	Data  0.001 ( 0.623)	Loss 0.1449135541915894 (0.0945672964338552)	Acc@1  95.31 ( 97.87)	Acc@5  98.44 ( 98.72)
Epoch: [136][ 20/109]	Time  0.634 ( 0.945)	Data  0.000 ( 0.326)	Loss 0.0293104909360409 (0.0922615807946949)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 98.96)
Epoch: [136][ 30/109]	Time  2.253 ( 0.929)	Data  0.000 ( 0.221)	Loss 0.0064022927545011 (0.0861637454870487)	Acc@1 100.00 ( 98.03)	Acc@5 100.00 ( 99.09)
Epoch: [136][ 40/109]	Time  0.817 ( 0.985)	Data  0.001 ( 0.168)	Loss 0.1182915493845940 (0.0804279876259587)	Acc@1  95.31 ( 98.06)	Acc@5 100.00 ( 99.16)
Epoch: [136][ 50/109]	Time  0.583 ( 0.922)	Data  0.000 ( 0.135)	Loss 0.2220722734928131 (0.0872286827230424)	Acc@1  96.88 ( 97.89)	Acc@5  96.88 ( 99.05)
Epoch: [136][ 60/109]	Time  1.202 ( 0.930)	Data  0.001 ( 0.113)	Loss 0.0184813812375069 (0.0815511098299481)	Acc@1 100.00 ( 98.08)	Acc@5 100.00 ( 99.10)
Epoch: [136][ 70/109]	Time  0.853 ( 0.928)	Data  0.000 ( 0.097)	Loss 0.0499266199767590 (0.0781211074323616)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.19)
Epoch: [136][ 80/109]	Time  0.514 ( 0.895)	Data  0.000 ( 0.085)	Loss 0.0892798453569412 (0.0769042030701207)	Acc@1  98.44 ( 98.17)	Acc@5 100.00 ( 99.27)
Epoch: [136][ 90/109]	Time  0.498 ( 0.852)	Data  0.000 ( 0.076)	Loss 0.0380266718566418 (0.0766091937618842)	Acc@1  98.44 ( 98.16)	Acc@5 100.00 ( 99.28)
Epoch: [136][100/109]	Time  0.578 ( 0.830)	Data  0.000 ( 0.068)	Loss 0.2972797453403473 (0.0797647923129694)	Acc@1  92.19 ( 98.10)	Acc@5  98.44 ( 99.23)
epoch: 136, Avg_Loss 0.08050557427586766
Test: [ 0/28]	Time  4.358 ( 4.358)	Loss 1.2192e+00 (1.2192e+00)	Acc@1  71.88 ( 71.88)	Acc@5  85.94 ( 85.94)
Test: [10/28]	Time  0.303 ( 0.663)	Loss 8.6385e-01 (1.0410e+00)	Acc@1  78.12 ( 76.56)	Acc@5  95.31 ( 91.34)
Test: [20/28]	Time  0.119 ( 0.429)	Loss 1.2128e+00 (1.0848e+00)	Acc@1  75.00 ( 75.97)	Acc@5  87.50 ( 89.81)
 * Acc@1 76.646 Acc@5 90.208
lr 1.0000000000000003e-05
Epoch: [137][  0/109]	Time  8.218 ( 8.218)	Data  7.618 ( 7.618)	Loss 0.0531640909612179 (0.0531640909612179)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [137][ 10/109]	Time  0.642 ( 1.296)	Data  0.001 ( 0.693)	Loss 0.1380175501108170 (0.0707173749635165)	Acc@1  96.88 ( 98.30)	Acc@5  98.44 ( 99.57)
Epoch: [137][ 20/109]	Time  1.145 ( 1.004)	Data  0.001 ( 0.363)	Loss 0.0085653271526098 (0.0750469489998761)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.33)
Epoch: [137][ 30/109]	Time  0.534 ( 0.970)	Data  0.000 ( 0.246)	Loss 0.0793314203619957 (0.0771782620239162)	Acc@1  98.44 ( 98.08)	Acc@5 100.00 ( 99.29)
Epoch: [137][ 40/109]	Time  0.626 ( 0.882)	Data  0.000 ( 0.186)	Loss 0.1059007272124290 (0.0785321168964956)	Acc@1  95.31 ( 98.13)	Acc@5 100.00 ( 99.28)
Epoch: [137][ 50/109]	Time  0.671 ( 0.853)	Data  0.001 ( 0.150)	Loss 0.0175940468907356 (0.0819574991588061)	Acc@1 100.00 ( 98.16)	Acc@5 100.00 ( 99.23)
Epoch: [137][ 60/109]	Time  0.979 ( 0.839)	Data  0.000 ( 0.125)	Loss 0.1766491979360580 (0.0808713088712854)	Acc@1  95.31 ( 98.21)	Acc@5  96.88 ( 99.23)
Epoch: [137][ 70/109]	Time  1.013 ( 0.837)	Data  0.001 ( 0.108)	Loss 0.1687106788158417 (0.0824456591303395)	Acc@1  95.31 ( 98.15)	Acc@5  96.88 ( 99.19)
Epoch: [137][ 80/109]	Time  0.588 ( 0.840)	Data  0.000 ( 0.095)	Loss 0.0916285291314125 (0.0788268352697753)	Acc@1  96.88 ( 98.24)	Acc@5 100.00 ( 99.23)
Epoch: [137][ 90/109]	Time  0.993 ( 0.830)	Data  0.001 ( 0.084)	Loss 0.0139937316998839 (0.0766097507746583)	Acc@1 100.00 ( 98.27)	Acc@5 100.00 ( 99.28)
Epoch: [137][100/109]	Time  0.687 ( 0.828)	Data  0.000 ( 0.076)	Loss 0.0110557544976473 (0.0735172944669012)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 ( 99.33)
epoch: 137, Avg_Loss 0.07373286115962567
Test: [ 0/28]	Time  7.025 ( 7.025)	Loss 5.8915e-01 (5.8915e-01)	Acc@1  81.25 ( 81.25)	Acc@5  96.88 ( 96.88)
Test: [10/28]	Time  0.192 ( 0.795)	Loss 7.5682e-01 (1.0232e+00)	Acc@1  84.38 ( 75.57)	Acc@5  95.31 ( 89.77)
Test: [20/28]	Time  0.131 ( 0.492)	Loss 1.3686e+00 (1.0556e+00)	Acc@1  73.44 ( 74.70)	Acc@5  89.06 ( 89.58)
 * Acc@1 74.170 Acc@5 89.702
lr 1.0000000000000003e-05
Epoch: [138][  0/109]	Time  6.737 ( 6.737)	Data  6.147 ( 6.147)	Loss 0.0645359382033348 (0.0645359382033348)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [138][ 10/109]	Time  1.190 ( 1.608)	Data  0.003 ( 0.616)	Loss 0.0083179855719209 (0.0567954195324670)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.43)
Epoch: [138][ 20/109]	Time  0.659 ( 1.145)	Data  0.000 ( 0.323)	Loss 0.1363450735807419 (0.0750261239618773)	Acc@1  93.75 ( 97.62)	Acc@5 100.00 ( 99.40)
Epoch: [138][ 30/109]	Time  0.851 ( 1.002)	Data  0.001 ( 0.219)	Loss 0.1533732265233994 (0.0897856024844993)	Acc@1  96.88 ( 97.38)	Acc@5  96.88 ( 99.09)
Epoch: [138][ 40/109]	Time  1.046 ( 1.044)	Data  0.001 ( 0.166)	Loss 0.1431428343057632 (0.0850573645722939)	Acc@1  96.88 ( 97.60)	Acc@5  96.88 ( 99.12)
Epoch: [138][ 50/109]	Time  0.787 ( 1.052)	Data  0.000 ( 0.133)	Loss 0.1146817356348038 (0.0816844002909812)	Acc@1  96.88 ( 97.76)	Acc@5 100.00 ( 99.20)
Epoch: [138][ 60/109]	Time  0.985 ( 1.063)	Data  0.000 ( 0.112)	Loss 0.1236104518175125 (0.0839956946151911)	Acc@1  95.31 ( 97.72)	Acc@5 100.00 ( 99.18)
Epoch: [138][ 70/109]	Time  0.798 ( 1.019)	Data  0.000 ( 0.096)	Loss 0.0191131196916103 (0.0814322072514136)	Acc@1  98.44 ( 97.82)	Acc@5 100.00 ( 99.25)
Epoch: [138][ 80/109]	Time  0.473 ( 0.971)	Data  0.000 ( 0.084)	Loss 0.0438234955072403 (0.0870244420351989)	Acc@1 100.00 ( 97.67)	Acc@5 100.00 ( 99.23)
Epoch: [138][ 90/109]	Time  0.517 ( 0.919)	Data  0.000 ( 0.075)	Loss 0.1275046765804291 (0.0876243250690155)	Acc@1  95.31 ( 97.65)	Acc@5 100.00 ( 99.24)
Epoch: [138][100/109]	Time  0.512 ( 0.877)	Data  0.000 ( 0.067)	Loss 0.2337967157363892 (0.0866372929517143)	Acc@1  95.31 ( 97.76)	Acc@5  98.44 ( 99.29)
epoch: 138, Avg_Loss 0.0853322675930114
Test: [ 0/28]	Time  9.470 ( 9.470)	Loss 9.8720e-01 (9.8720e-01)	Acc@1  79.69 ( 79.69)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.347 ( 1.203)	Loss 1.7643e+00 (1.0019e+00)	Acc@1  57.81 ( 77.41)	Acc@5  82.81 ( 90.34)
Test: [20/28]	Time  0.392 ( 0.776)	Loss 1.7832e+00 (1.0426e+00)	Acc@1  67.19 ( 76.49)	Acc@5  79.69 ( 89.96)
 * Acc@1 75.352 Acc@5 89.420
lr 1.0000000000000003e-05
Epoch: [139][  0/109]	Time  7.422 ( 7.422)	Data  6.793 ( 6.793)	Loss 0.1039352044463158 (0.1039352044463158)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [139][ 10/109]	Time  0.574 ( 1.161)	Data  0.001 ( 0.618)	Loss 0.0572531931102276 (0.0784109441394156)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.15)
Epoch: [139][ 20/109]	Time  0.636 ( 0.867)	Data  0.000 ( 0.324)	Loss 0.0169073380529881 (0.0689299075553815)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.40)
Epoch: [139][ 30/109]	Time  0.474 ( 0.843)	Data  0.000 ( 0.219)	Loss 0.0234918836504221 (0.0668001666725163)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.45)
Epoch: [139][ 40/109]	Time  0.884 ( 0.810)	Data  0.000 ( 0.166)	Loss 0.0334128141403198 (0.0678731271906233)	Acc@1 100.00 ( 98.48)	Acc@5 100.00 ( 99.39)
Epoch: [139][ 50/109]	Time  0.563 ( 0.805)	Data  0.000 ( 0.134)	Loss 0.0463524945080280 (0.0703601487090482)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 ( 99.36)
Epoch: [139][ 60/109]	Time  0.769 ( 0.802)	Data  0.000 ( 0.112)	Loss 0.1688464283943176 (0.0755507688144924)	Acc@1  95.31 ( 98.26)	Acc@5  98.44 ( 99.26)
Epoch: [139][ 70/109]	Time  0.696 ( 0.810)	Data  0.000 ( 0.096)	Loss 0.1888201236724854 (0.0764916438714299)	Acc@1  93.75 ( 98.22)	Acc@5  98.44 ( 99.23)
Epoch: [139][ 80/109]	Time  0.637 ( 0.801)	Data  0.000 ( 0.084)	Loss 0.1091727092862129 (0.0820252738065190)	Acc@1  96.88 ( 98.09)	Acc@5 100.00 ( 99.21)
Epoch: [139][ 90/109]	Time  0.575 ( 0.798)	Data  0.000 ( 0.075)	Loss 0.0716082453727722 (0.0822886602830265)	Acc@1  96.88 ( 98.06)	Acc@5 100.00 ( 99.19)
Epoch: [139][100/109]	Time  0.547 ( 0.774)	Data  0.000 ( 0.068)	Loss 0.0664580464363098 (0.0811095769876743)	Acc@1  98.44 ( 98.13)	Acc@5 100.00 ( 99.24)
epoch: 139, Avg_Loss 0.08212830755996321
Test: [ 0/28]	Time  8.939 ( 8.939)	Loss 1.2055e+00 (1.2055e+00)	Acc@1  75.00 ( 75.00)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.315 ( 1.129)	Loss 9.9261e-01 (1.0605e+00)	Acc@1  76.56 ( 74.72)	Acc@5  89.06 ( 90.20)
Test: [20/28]	Time  0.164 ( 0.725)	Loss 1.0381e+00 (1.0654e+00)	Acc@1  78.12 ( 75.22)	Acc@5  89.06 ( 90.25)
 * Acc@1 74.789 Acc@5 89.871
lr 1.0000000000000003e-05
Epoch: [140][  0/109]	Time  7.828 ( 7.828)	Data  6.489 ( 6.489)	Loss 0.0245912261307240 (0.0245912261307240)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [140][ 10/109]	Time  0.628 ( 1.395)	Data  0.000 ( 0.771)	Loss 0.0196010414510965 (0.1012676891616800)	Acc@1 100.00 ( 97.44)	Acc@5 100.00 ( 99.01)
Epoch: [140][ 20/109]	Time  0.481 ( 0.974)	Data  0.000 ( 0.404)	Loss 0.0630730390548706 (0.0899299054096142)	Acc@1  98.44 ( 97.69)	Acc@5 100.00 ( 99.33)
Epoch: [140][ 30/109]	Time  1.617 ( 0.982)	Data  0.002 ( 0.274)	Loss 0.2483038604259491 (0.0883929608690162)	Acc@1  93.75 ( 97.73)	Acc@5  96.88 ( 99.34)
Epoch: [140][ 40/109]	Time  0.478 ( 0.878)	Data  0.000 ( 0.207)	Loss 0.0836725533008575 (0.0863728107112210)	Acc@1  98.44 ( 97.87)	Acc@5  98.44 ( 99.35)
Epoch: [140][ 50/109]	Time  0.809 ( 0.846)	Data  0.001 ( 0.167)	Loss 0.0542082451283932 (0.0793901575254459)	Acc@1  98.44 ( 97.95)	Acc@5 100.00 ( 99.48)
Epoch: [140][ 60/109]	Time  0.685 ( 0.941)	Data  0.000 ( 0.139)	Loss 0.1303900480270386 (0.0772274798851033)	Acc@1  96.88 ( 97.98)	Acc@5  96.88 ( 99.46)
Epoch: [140][ 70/109]	Time  1.740 ( 0.951)	Data  0.000 ( 0.120)	Loss 0.0375560186803341 (0.0731208592548337)	Acc@1  98.44 ( 98.02)	Acc@5 100.00 ( 99.54)
Epoch: [140][ 80/109]	Time  0.475 ( 0.907)	Data  0.000 ( 0.105)	Loss 0.1237414255738258 (0.0714694005034772)	Acc@1  96.88 ( 98.07)	Acc@5  98.44 ( 99.52)
Epoch: [140][ 90/109]	Time  0.477 ( 0.861)	Data  0.000 ( 0.094)	Loss 0.0440593436360359 (0.0720982721976035)	Acc@1  98.44 ( 98.09)	Acc@5 100.00 ( 99.50)
Epoch: [140][100/109]	Time  0.500 ( 0.824)	Data  0.000 ( 0.084)	Loss 0.0426114760339260 (0.0756408449280823)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.46)
epoch: 140, Avg_Loss 0.07900786581833702
Test: [ 0/28]	Time 10.973 (10.973)	Loss 6.8326e-01 (6.8326e-01)	Acc@1  82.81 ( 82.81)	Acc@5  93.75 ( 93.75)
Test: [10/28]	Time  0.165 ( 1.346)	Loss 1.3075e+00 (1.0317e+00)	Acc@1  73.44 ( 75.71)	Acc@5  89.06 ( 89.77)
Test: [20/28]	Time  0.127 ( 0.780)	Loss 1.1124e+00 (1.0197e+00)	Acc@1  71.88 ( 75.60)	Acc@5  92.19 ( 89.81)
 * Acc@1 75.521 Acc@5 90.039
lr 1.0000000000000003e-05
Epoch: [141][  0/109]	Time  6.606 ( 6.606)	Data  5.890 ( 5.890)	Loss 0.1325611621141434 (0.1325611621141434)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [141][ 10/109]	Time  0.789 ( 1.451)	Data  0.001 ( 0.536)	Loss 0.1043056324124336 (0.1162043427201835)	Acc@1  96.88 ( 97.02)	Acc@5  98.44 ( 99.01)
Epoch: [141][ 20/109]	Time  0.535 ( 1.200)	Data  0.000 ( 0.281)	Loss 0.1461240202188492 (0.0995809281510966)	Acc@1  96.88 ( 97.69)	Acc@5  98.44 ( 99.11)
Epoch: [141][ 30/109]	Time  0.944 ( 1.036)	Data  0.000 ( 0.191)	Loss 0.0153230726718903 (0.1008434921743408)	Acc@1 100.00 ( 97.68)	Acc@5 100.00 ( 99.04)
Epoch: [141][ 40/109]	Time  0.670 ( 0.952)	Data  0.000 ( 0.144)	Loss 0.0402220301330090 (0.0853249122979256)	Acc@1  98.44 ( 98.02)	Acc@5 100.00 ( 99.24)
Epoch: [141][ 50/109]	Time  0.785 ( 1.010)	Data  0.001 ( 0.116)	Loss 0.0219311509281397 (0.0820390746709617)	Acc@1 100.00 ( 98.16)	Acc@5 100.00 ( 99.26)
Epoch: [141][ 60/109]	Time  0.476 ( 0.948)	Data  0.000 ( 0.097)	Loss 0.0783010125160217 (0.0812214298677615)	Acc@1  98.44 ( 98.23)	Acc@5  98.44 ( 99.31)
Epoch: [141][ 70/109]	Time  0.529 ( 0.885)	Data  0.000 ( 0.084)	Loss 0.0216905288398266 (0.0825104496546719)	Acc@1 100.00 ( 98.20)	Acc@5 100.00 ( 99.25)
Epoch: [141][ 80/109]	Time  2.502 ( 0.935)	Data  0.001 ( 0.073)	Loss 0.1140301823616028 (0.0835500713955197)	Acc@1  95.31 ( 98.19)	Acc@5 100.00 ( 99.23)
Epoch: [141][ 90/109]	Time  0.494 ( 0.912)	Data  0.000 ( 0.065)	Loss 0.0507226251065731 (0.0845297390421095)	Acc@1 100.00 ( 98.20)	Acc@5 100.00 ( 99.23)
Epoch: [141][100/109]	Time  0.569 ( 0.874)	Data  0.000 ( 0.059)	Loss 0.0842598453164101 (0.0817213034266514)	Acc@1  98.44 ( 98.28)	Acc@5 100.00 ( 99.27)
epoch: 141, Avg_Loss 0.0792405002776089
Test: [ 0/28]	Time  6.031 ( 6.031)	Loss 1.2749e+00 (1.2749e+00)	Acc@1  73.44 ( 73.44)	Acc@5  84.38 ( 84.38)
Test: [10/28]	Time  0.127 ( 0.837)	Loss 1.6285e+00 (1.2081e+00)	Acc@1  70.31 ( 73.01)	Acc@5  85.94 ( 88.07)
Test: [20/28]	Time  0.117 ( 0.496)	Loss 1.2118e+00 (1.0999e+00)	Acc@1  71.88 ( 74.70)	Acc@5  87.50 ( 88.99)
 * Acc@1 75.295 Acc@5 89.195
lr 1.0000000000000003e-05
Epoch: [142][  0/109]	Time  6.473 ( 6.473)	Data  5.690 ( 5.690)	Loss 0.0519449263811111 (0.0519449263811111)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [142][ 10/109]	Time  0.755 ( 1.565)	Data  0.001 ( 0.559)	Loss 0.1145558655261993 (0.0814213161780076)	Acc@1  95.31 ( 97.73)	Acc@5 100.00 ( 99.29)
Epoch: [142][ 20/109]	Time  0.630 ( 1.161)	Data  0.000 ( 0.293)	Loss 0.0116709126159549 (0.0786195992093001)	Acc@1 100.00 ( 97.92)	Acc@5 100.00 ( 99.40)
Epoch: [142][ 30/109]	Time  0.766 ( 1.018)	Data  0.000 ( 0.199)	Loss 0.0483904480934143 (0.0703735482848940)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 ( 99.55)
Epoch: [142][ 40/109]	Time  1.057 ( 1.027)	Data  0.001 ( 0.150)	Loss 0.0333498604595661 (0.0758730750303806)	Acc@1  98.44 ( 98.13)	Acc@5 100.00 ( 99.39)
Epoch: [142][ 50/109]	Time  2.104 ( 1.056)	Data  0.000 ( 0.121)	Loss 0.0521690845489502 (0.0754326554015279)	Acc@1  98.44 ( 98.16)	Acc@5 100.00 ( 99.42)
Epoch: [142][ 60/109]	Time  0.793 ( 1.176)	Data  0.000 ( 0.101)	Loss 0.0812246054410934 (0.0701759583851109)	Acc@1  96.88 ( 98.31)	Acc@5  98.44 ( 99.44)
Epoch: [142][ 70/109]	Time  0.598 ( 1.095)	Data  0.000 ( 0.087)	Loss 0.0535239093005657 (0.0759181751095703)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.38)
Epoch: [142][ 80/109]	Time  0.486 ( 1.022)	Data  0.000 ( 0.076)	Loss 0.0876276716589928 (0.0816049885671632)	Acc@1  96.88 ( 97.94)	Acc@5 100.00 ( 99.31)
Epoch: [142][ 90/109]	Time  0.743 ( 0.966)	Data  0.000 ( 0.068)	Loss 0.1639691591262817 (0.0816344473572387)	Acc@1  95.31 ( 97.97)	Acc@5  98.44 ( 99.30)
Epoch: [142][100/109]	Time  0.477 ( 0.960)	Data  0.000 ( 0.061)	Loss 0.0138495899736881 (0.0784869804369784)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.35)
epoch: 142, Avg_Loss 0.07902841440000392
Test: [ 0/28]	Time  4.978 ( 4.978)	Loss 6.3182e-01 (6.3182e-01)	Acc@1  82.81 ( 82.81)	Acc@5  96.88 ( 96.88)
Test: [10/28]	Time  0.182 ( 0.662)	Loss 1.1727e+00 (9.6901e-01)	Acc@1  73.44 ( 77.56)	Acc@5  85.94 ( 90.91)
Test: [20/28]	Time  0.119 ( 0.411)	Loss 8.2661e-01 (1.0650e+00)	Acc@1  84.38 ( 76.19)	Acc@5  95.31 ( 90.03)
 * Acc@1 76.083 Acc@5 89.702
lr 1.0000000000000003e-05
Epoch: [143][  0/109]	Time  6.888 ( 6.888)	Data  6.057 ( 6.057)	Loss 0.2074391245841980 (0.2074391245841980)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [143][ 10/109]	Time  0.484 ( 1.128)	Data  0.001 ( 0.551)	Loss 0.1800951361656189 (0.0776595627381043)	Acc@1  95.31 ( 97.87)	Acc@5  96.88 ( 99.15)
Epoch: [143][ 20/109]	Time  0.638 ( 0.849)	Data  0.000 ( 0.289)	Loss 0.0846032649278641 (0.0803853535492505)	Acc@1  98.44 ( 97.77)	Acc@5  98.44 ( 99.11)
Epoch: [143][ 30/109]	Time  0.518 ( 0.885)	Data  0.000 ( 0.196)	Loss 0.0400760844349861 (0.0827412263400132)	Acc@1  98.44 ( 97.73)	Acc@5 100.00 ( 99.09)
Epoch: [143][ 40/109]	Time  0.522 ( 0.797)	Data  0.001 ( 0.148)	Loss 0.0121382242068648 (0.0834369806163922)	Acc@1 100.00 ( 97.75)	Acc@5 100.00 ( 99.09)
Epoch: [143][ 50/109]	Time  0.590 ( 0.764)	Data  0.000 ( 0.119)	Loss 0.0154118621721864 (0.0755837167266245)	Acc@1 100.00 ( 98.01)	Acc@5 100.00 ( 99.17)
Epoch: [143][ 60/109]	Time  0.649 ( 0.771)	Data  0.001 ( 0.100)	Loss 0.0874677374958992 (0.0756485002329115)	Acc@1  98.44 ( 98.03)	Acc@5  98.44 ( 99.15)
Epoch: [143][ 70/109]	Time  0.598 ( 0.744)	Data  0.000 ( 0.086)	Loss 0.0673214346170425 (0.0809340340833009)	Acc@1  98.44 ( 97.98)	Acc@5  98.44 ( 99.08)
Epoch: [143][ 80/109]	Time  0.533 ( 0.724)	Data  0.000 ( 0.075)	Loss 0.1361853927373886 (0.0851099010051033)	Acc@1  96.88 ( 97.86)	Acc@5  96.88 ( 99.05)
Epoch: [143][ 90/109]	Time  0.915 ( 0.762)	Data  0.000 ( 0.067)	Loss 0.0507091097533703 (0.0837102668503156)	Acc@1  96.88 ( 97.92)	Acc@5 100.00 ( 99.09)
Epoch: [143][100/109]	Time  0.475 ( 0.743)	Data  0.000 ( 0.060)	Loss 0.1656764447689056 (0.0845412552116973)	Acc@1  95.31 ( 97.93)	Acc@5  96.88 ( 99.06)
epoch: 143, Avg_Loss 0.08448898266795851
Test: [ 0/28]	Time  4.969 ( 4.969)	Loss 1.3314e+00 (1.3314e+00)	Acc@1  68.75 ( 68.75)	Acc@5  90.62 ( 90.62)
Test: [10/28]	Time  0.481 ( 1.119)	Loss 1.0411e+00 (1.0971e+00)	Acc@1  71.88 ( 74.01)	Acc@5  90.62 ( 89.63)
Test: [20/28]	Time  0.225 ( 0.724)	Loss 8.7197e-01 (1.1026e+00)	Acc@1  76.56 ( 74.40)	Acc@5  90.62 ( 89.81)
 * Acc@1 74.114 Acc@5 89.533
lr 1.0000000000000003e-05
Epoch: [144][  0/109]	Time  9.531 ( 9.531)	Data  8.917 ( 8.917)	Loss 0.1020011603832245 (0.1020011603832245)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [144][ 10/109]	Time  2.462 ( 2.020)	Data  0.003 ( 0.811)	Loss 0.1680693477392197 (0.1281230022961443)	Acc@1  96.88 ( 96.02)	Acc@5  96.88 ( 98.44)
Epoch: [144][ 20/109]	Time  0.916 ( 1.594)	Data  0.000 ( 0.425)	Loss 0.0896137505769730 (0.0986304251654517)	Acc@1  96.88 ( 97.17)	Acc@5 100.00 ( 98.96)
Epoch: [144][ 30/109]	Time  0.900 ( 1.341)	Data  0.000 ( 0.288)	Loss 0.0100037399679422 (0.0949537101231756)	Acc@1 100.00 ( 97.48)	Acc@5 100.00 ( 99.09)
Epoch: [144][ 40/109]	Time  0.784 ( 1.274)	Data  0.000 ( 0.218)	Loss 0.0356326550245285 (0.0862510141394124)	Acc@1 100.00 ( 97.83)	Acc@5 100.00 ( 99.20)
Epoch: [144][ 50/109]	Time  0.906 ( 1.197)	Data  0.000 ( 0.175)	Loss 0.0602224767208099 (0.0878735177365004)	Acc@1  98.44 ( 97.82)	Acc@5 100.00 ( 99.17)
Epoch: [144][ 60/109]	Time  0.581 ( 1.125)	Data  0.000 ( 0.147)	Loss 0.1344907581806183 (0.0875733253836143)	Acc@1  93.75 ( 97.75)	Acc@5 100.00 ( 99.23)
Epoch: [144][ 70/109]	Time  0.616 ( 1.054)	Data  0.000 ( 0.127)	Loss 0.0326183550059795 (0.0928513176188293)	Acc@1  98.44 ( 97.56)	Acc@5 100.00 ( 99.21)
Epoch: [144][ 80/109]	Time  0.852 ( 1.033)	Data  0.000 ( 0.111)	Loss 0.0280441660434008 (0.0889529305866655)	Acc@1 100.00 ( 97.67)	Acc@5 100.00 ( 99.29)
Epoch: [144][ 90/109]	Time  0.524 ( 0.981)	Data  0.000 ( 0.099)	Loss 0.0176533795893192 (0.0875299088759245)	Acc@1 100.00 ( 97.72)	Acc@5 100.00 ( 99.28)
Epoch: [144][100/109]	Time  1.858 ( 0.957)	Data  0.000 ( 0.089)	Loss 0.0738353207707405 (0.0852110853123635)	Acc@1  98.44 ( 97.77)	Acc@5  98.44 ( 99.32)
epoch: 144, Avg_Loss 0.08502326751503786
Test: [ 0/28]	Time  5.362 ( 5.362)	Loss 1.0545e+00 (1.0545e+00)	Acc@1  79.69 ( 79.69)	Acc@5  92.19 ( 92.19)
Test: [10/28]	Time  0.298 ( 0.702)	Loss 1.1809e+00 (1.0766e+00)	Acc@1  76.56 ( 77.27)	Acc@5  87.50 ( 89.63)
Test: [20/28]	Time  0.160 ( 0.450)	Loss 1.3088e+00 (1.1242e+00)	Acc@1  70.31 ( 75.45)	Acc@5  81.25 ( 89.21)
 * Acc@1 75.802 Acc@5 89.308
lr 1.0000000000000003e-05
Epoch: [145][  0/109]	Time  5.518 ( 5.518)	Data  4.903 ( 4.903)	Loss 0.0465574376285076 (0.0465574376285076)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [145][ 10/109]	Time  0.476 ( 1.014)	Data  0.001 ( 0.446)	Loss 0.0433297194540501 (0.0618619952689518)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 ( 99.57)
Epoch: [145][ 20/109]	Time  0.554 ( 0.788)	Data  0.000 ( 0.235)	Loss 0.0329137295484543 (0.0612078052723692)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 ( 99.63)
Epoch: [145][ 30/109]	Time  0.710 ( 0.770)	Data  0.000 ( 0.160)	Loss 0.0907747820019722 (0.0616726406639622)	Acc@1  95.31 ( 98.34)	Acc@5 100.00 ( 99.60)
Epoch: [145][ 40/109]	Time  2.868 ( 0.915)	Data  0.002 ( 0.121)	Loss 0.0423546433448792 (0.0608910188169741)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 ( 99.58)
Epoch: [145][ 50/109]	Time  0.553 ( 0.889)	Data  0.000 ( 0.098)	Loss 0.0665073096752167 (0.0577103586173525)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.66)
Epoch: [145][ 60/109]	Time  0.483 ( 0.827)	Data  0.000 ( 0.082)	Loss 0.0410194359719753 (0.0583185811878228)	Acc@1 100.00 ( 98.46)	Acc@5 100.00 ( 99.59)
Epoch: [145][ 70/109]	Time  0.574 ( 0.787)	Data  0.000 ( 0.070)	Loss 0.0174854695796967 (0.0590237565863300)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.56)
Epoch: [145][ 80/109]	Time  0.504 ( 0.790)	Data  0.000 ( 0.062)	Loss 0.0201968383044004 (0.0564720924357297)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.58)
Epoch: [145][ 90/109]	Time  1.611 ( 0.826)	Data  0.000 ( 0.055)	Loss 0.0877448320388794 (0.0582020681525407)	Acc@1  98.44 ( 98.51)	Acc@5  98.44 ( 99.61)
Epoch: [145][100/109]	Time  0.752 ( 0.822)	Data  0.000 ( 0.049)	Loss 0.0935730040073395 (0.0613003095455173)	Acc@1  96.88 ( 98.44)	Acc@5  98.44 ( 99.52)
epoch: 145, Avg_Loss 0.0611699788677378
Test: [ 0/28]	Time  5.020 ( 5.020)	Loss 1.7262e+00 (1.7262e+00)	Acc@1  64.06 ( 64.06)	Acc@5  79.69 ( 79.69)
Test: [10/28]	Time  0.118 ( 0.679)	Loss 8.8564e-01 (1.1201e+00)	Acc@1  79.69 ( 74.29)	Acc@5  96.88 ( 88.64)
Test: [20/28]	Time  0.127 ( 0.419)	Loss 8.2234e-01 (1.1116e+00)	Acc@1  81.25 ( 74.11)	Acc@5  93.75 ( 89.36)
 * Acc@1 73.945 Acc@5 89.758
lr 1.0000000000000003e-05
Epoch: [146][  0/109]	Time  5.433 ( 5.433)	Data  4.638 ( 4.638)	Loss 0.0417905189096928 (0.0417905189096928)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [146][ 10/109]	Time  0.999 ( 1.130)	Data  0.001 ( 0.422)	Loss 0.0892521142959595 (0.0547776081683961)	Acc@1  98.44 ( 98.72)	Acc@5  98.44 ( 99.72)
Epoch: [146][ 20/109]	Time  0.875 ( 0.969)	Data  0.000 ( 0.221)	Loss 0.1868766993284225 (0.0795598783131157)	Acc@1  95.31 ( 98.21)	Acc@5  96.88 ( 99.33)
Epoch: [146][ 30/109]	Time  0.768 ( 0.898)	Data  0.000 ( 0.150)	Loss 0.0089081227779388 (0.0666578919776986)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.40)
Epoch: [146][ 40/109]	Time  0.492 ( 0.868)	Data  0.000 ( 0.114)	Loss 0.0723097547888756 (0.0713234433858860)	Acc@1  95.31 ( 98.21)	Acc@5 100.00 ( 99.43)
Epoch: [146][ 50/109]	Time  0.713 ( 0.816)	Data  0.000 ( 0.091)	Loss 0.1228446364402771 (0.0733150281194671)	Acc@1  96.88 ( 98.25)	Acc@5  96.88 ( 99.39)
Epoch: [146][ 60/109]	Time  0.494 ( 0.768)	Data  0.000 ( 0.076)	Loss 0.0534411370754242 (0.0732635391845566)	Acc@1  98.44 ( 98.26)	Acc@5 100.00 ( 99.44)
Epoch: [146][ 70/109]	Time  0.701 ( 0.740)	Data  0.000 ( 0.066)	Loss 0.0830336585640907 (0.0723484607387177)	Acc@1  98.44 ( 98.31)	Acc@5  98.44 ( 99.41)
Epoch: [146][ 80/109]	Time  2.335 ( 0.784)	Data  0.001 ( 0.058)	Loss 0.1030037179589272 (0.0747459623962641)	Acc@1  96.88 ( 98.23)	Acc@5 100.00 ( 99.38)
Epoch: [146][ 90/109]	Time  0.480 ( 0.779)	Data  0.000 ( 0.051)	Loss 0.0987771600484848 (0.0743056685960555)	Acc@1  98.44 ( 98.18)	Acc@5 100.00 ( 99.42)
Epoch: [146][100/109]	Time  0.480 ( 0.749)	Data  0.000 ( 0.046)	Loss 0.1783360242843628 (0.0776266168323484)	Acc@1  95.31 ( 98.10)	Acc@5  95.31 ( 99.33)
epoch: 146, Avg_Loss 0.07824267935725528
Test: [ 0/28]	Time  7.071 ( 7.071)	Loss 8.9538e-01 (8.9538e-01)	Acc@1  82.81 ( 82.81)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.133 ( 0.909)	Loss 1.6764e+00 (1.1612e+00)	Acc@1  65.62 ( 75.00)	Acc@5  85.94 ( 88.35)
Test: [20/28]	Time  0.129 ( 0.539)	Loss 1.3101e+00 (1.0895e+00)	Acc@1  71.88 ( 75.82)	Acc@5  85.94 ( 88.99)
 * Acc@1 74.789 Acc@5 88.351
lr 1.0000000000000003e-05
Epoch: [147][  0/109]	Time  5.585 ( 5.585)	Data  4.914 ( 4.914)	Loss 0.1088520735502243 (0.1088520735502243)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [147][ 10/109]	Time  0.940 ( 1.118)	Data  0.002 ( 0.447)	Loss 0.0167677085846663 (0.0561025110496716)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.72)
Epoch: [147][ 20/109]	Time  0.795 ( 1.119)	Data  0.001 ( 0.235)	Loss 0.0261142980307341 (0.0626285676622675)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.63)
Epoch: [147][ 30/109]	Time  0.594 ( 0.962)	Data  0.000 ( 0.159)	Loss 0.1201272457838058 (0.0637563489858181)	Acc@1  96.88 ( 98.49)	Acc@5  98.44 ( 99.60)
Epoch: [147][ 40/109]	Time  0.633 ( 0.873)	Data  0.000 ( 0.120)	Loss 0.1186871528625488 (0.0656729653568529)	Acc@1  98.44 ( 98.51)	Acc@5  98.44 ( 99.54)
Epoch: [147][ 50/109]	Time  0.861 ( 0.847)	Data  0.000 ( 0.097)	Loss 0.0927267223596573 (0.0674225885932352)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 99.48)
Epoch: [147][ 60/109]	Time  0.698 ( 0.859)	Data  0.000 ( 0.081)	Loss 0.0138707226142287 (0.0671576850696421)	Acc@1 100.00 ( 98.41)	Acc@5 100.00 ( 99.46)
Epoch: [147][ 70/109]	Time  0.873 ( 0.835)	Data  0.000 ( 0.070)	Loss 0.0452783703804016 (0.0668363164664364)	Acc@1 100.00 ( 98.46)	Acc@5 100.00 ( 99.45)
Epoch: [147][ 80/109]	Time  0.516 ( 0.810)	Data  0.000 ( 0.061)	Loss 0.0655642151832581 (0.0645147301946525)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.48)
Epoch: [147][ 90/109]	Time  0.696 ( 0.786)	Data  0.000 ( 0.054)	Loss 0.0932626202702522 (0.0672132523914615)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.42)
Epoch: [147][100/109]	Time  0.534 ( 0.763)	Data  0.000 ( 0.049)	Loss 0.0740951672196388 (0.0701672437388708)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.40)
epoch: 147, Avg_Loss 0.07051315064618893
Test: [ 0/28]	Time  5.587 ( 5.587)	Loss 8.1755e-01 (8.1755e-01)	Acc@1  76.56 ( 76.56)	Acc@5  95.31 ( 95.31)
Test: [10/28]	Time  0.159 ( 0.699)	Loss 9.7999e-01 (1.0628e+00)	Acc@1  75.00 ( 75.57)	Acc@5  95.31 ( 91.05)
Test: [20/28]	Time  0.118 ( 0.426)	Loss 1.0728e+00 (1.1077e+00)	Acc@1  75.00 ( 75.67)	Acc@5  90.62 ( 89.66)
 * Acc@1 75.239 Acc@5 89.533
lr 1.0000000000000003e-05
Epoch: [148][  0/109]	Time  5.703 ( 5.703)	Data  5.030 ( 5.030)	Loss 0.0642579346895218 (0.0642579346895218)	Acc@1  98.44 ( 98.44)	Acc@5  98.44 ( 98.44)
Epoch: [148][ 10/109]	Time  0.550 ( 1.190)	Data  0.001 ( 0.501)	Loss 0.0266571268439293 (0.0670230287042531)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.43)
Epoch: [148][ 20/109]	Time  0.814 ( 0.956)	Data  0.000 ( 0.263)	Loss 0.0599109195172787 (0.0770233593703736)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.33)
Epoch: [148][ 30/109]	Time  0.645 ( 0.987)	Data  0.000 ( 0.178)	Loss 0.1495070755481720 (0.0840590898127806)	Acc@1  96.88 ( 98.39)	Acc@5  98.44 ( 99.29)
Epoch: [148][ 40/109]	Time  0.666 ( 0.939)	Data  0.000 ( 0.135)	Loss 0.0387630574405193 (0.0775384174932430)	Acc@1  98.44 ( 98.40)	Acc@5 100.00 ( 99.43)
Epoch: [148][ 50/109]	Time  1.556 ( 0.940)	Data  0.004 ( 0.109)	Loss 0.0786938816308975 (0.0810946581300859)	Acc@1  98.44 ( 98.16)	Acc@5 100.00 ( 99.42)
Epoch: [148][ 60/109]	Time  0.539 ( 0.968)	Data  0.001 ( 0.091)	Loss 0.1028457283973694 (0.0755182476714253)	Acc@1  98.44 ( 98.26)	Acc@5  98.44 ( 99.44)
Epoch: [148][ 70/109]	Time  0.484 ( 0.910)	Data  0.000 ( 0.078)	Loss 0.0171061102300882 (0.0735390117706757)	Acc@1 100.00 ( 98.31)	Acc@5 100.00 ( 99.45)
Epoch: [148][ 80/109]	Time  1.170 ( 0.874)	Data  0.000 ( 0.068)	Loss 0.0213727876543999 (0.0754476326552254)	Acc@1 100.00 ( 98.28)	Acc@5 100.00 ( 99.38)
Epoch: [148][ 90/109]	Time  0.538 ( 0.848)	Data  0.000 ( 0.061)	Loss 0.1517948061227798 (0.0754185706520310)	Acc@1  96.88 ( 98.30)	Acc@5 100.00 ( 99.42)
Epoch: [148][100/109]	Time  0.816 ( 0.835)	Data  0.000 ( 0.055)	Loss 0.1069100201129913 (0.0764375355481954)	Acc@1  96.88 ( 98.25)	Acc@5  98.44 ( 99.43)
epoch: 148, Avg_Loss 0.07482939097312612
Test: [ 0/28]	Time  6.803 ( 6.803)	Loss 1.0793e+00 (1.0793e+00)	Acc@1  67.19 ( 67.19)	Acc@5  87.50 ( 87.50)
Test: [10/28]	Time  0.167 ( 0.870)	Loss 1.3185e+00 (1.1744e+00)	Acc@1  76.56 ( 73.86)	Acc@5  85.94 ( 88.49)
Test: [20/28]	Time  0.117 ( 0.523)	Loss 1.0780e+00 (1.1413e+00)	Acc@1  73.44 ( 74.33)	Acc@5  90.62 ( 88.84)
 * Acc@1 75.352 Acc@5 89.195
lr 1.0000000000000003e-05
Epoch: [149][  0/109]	Time  4.838 ( 4.838)	Data  4.250 ( 4.250)	Loss 0.1448514759540558 (0.1448514759540558)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [149][ 10/109]	Time  2.133 ( 1.545)	Data  0.003 ( 0.506)	Loss 0.0688825249671936 (0.0659578339281407)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.57)
Epoch: [149][ 20/109]	Time  1.066 ( 1.489)	Data  0.001 ( 0.266)	Loss 0.0169807337224483 (0.0638824913295962)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.40)
Epoch: [149][ 30/109]	Time  0.516 ( 1.219)	Data  0.000 ( 0.180)	Loss 0.0408102087676525 (0.0729019259132685)	Acc@1  98.44 ( 98.14)	Acc@5 100.00 ( 99.40)
Epoch: [149][ 40/109]	Time  0.573 ( 1.072)	Data  0.001 ( 0.136)	Loss 0.0387640148401260 (0.0697872398830042)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 ( 99.43)
Epoch: [149][ 50/109]	Time  0.918 ( 0.985)	Data  0.000 ( 0.110)	Loss 0.0362215265631676 (0.0716635185092980)	Acc@1  98.44 ( 98.22)	Acc@5 100.00 ( 99.36)
Epoch: [149][ 60/109]	Time  1.676 ( 0.968)	Data  0.000 ( 0.092)	Loss 0.1099323481321335 (0.0708291649161914)	Acc@1  98.44 ( 98.23)	Acc@5  98.44 ( 99.41)
Epoch: [149][ 70/109]	Time  0.565 ( 1.023)	Data  0.000 ( 0.079)	Loss 0.0318663008511066 (0.0749633051520607)	Acc@1 100.00 ( 98.17)	Acc@5 100.00 ( 99.34)
Epoch: [149][ 80/109]	Time  0.543 ( 0.980)	Data  0.000 ( 0.069)	Loss 0.0713717564940453 (0.0789341905476226)	Acc@1  98.44 ( 98.05)	Acc@5  98.44 ( 99.29)
Epoch: [149][ 90/109]	Time  0.712 ( 0.933)	Data  0.000 ( 0.062)	Loss 0.0253428760915995 (0.0789935667180344)	Acc@1 100.00 ( 98.08)	Acc@5 100.00 ( 99.28)
Epoch: [149][100/109]	Time  0.489 ( 0.947)	Data  0.000 ( 0.056)	Loss 0.0756299570202827 (0.0809018712002083)	Acc@1  98.44 ( 98.00)	Acc@5  98.44 ( 99.27)
epoch: 149, Avg_Loss 0.0831112275711782
Test: [ 0/28]	Time  6.442 ( 6.442)	Loss 1.2160e+00 (1.2160e+00)	Acc@1  78.12 ( 78.12)	Acc@5  89.06 ( 89.06)
Test: [10/28]	Time  0.645 ( 0.884)	Loss 1.2593e+00 (1.1336e+00)	Acc@1  73.44 ( 74.86)	Acc@5  81.25 ( 87.50)
Test: [20/28]	Time  0.546 ( 0.574)	Loss 9.2481e-01 (1.1740e+00)	Acc@1  78.12 ( 73.59)	Acc@5  93.75 ( 88.02)
 * Acc@1 74.902 Acc@5 89.195
best_acc1: tensor(76.6460, device='cuda:4')
