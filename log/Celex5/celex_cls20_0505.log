nohup: ignoring input
main.py:110: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
n_per_node: 8
gpu 4
Use GPU: 4 for training
create model mf508
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
block: 12544, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 24, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 40, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 40, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 40, token: 192
block: 3136, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 40, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 72, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 72, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 72, token: 192
block: 784, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 72, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 128, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 128, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 176, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 176, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 176, token: 192
block: 196, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 176, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 240, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
block: 49, cnn-drop 0.0000, mlp-drop 0.0000
L2G: 2 heads, inp: 240, token: 192
G2G: 4 heads
use ffn
G2L: 2 heads, inp: 240, token: 192
L2G: 2 heads, inp: 240, token: 192
MobileFormer(
  (tokens): Embedding(6, 192)
  (stem): Sequential(
    (0): Conv3d(3, 24, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
    (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (resnet18_feature_extractor): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
  (features): Sequential(
    (0): DnaBlock3(
      (conv): Sequential(
        (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Sequential()
        (4): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(24, 144, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=24, bias=False)
        (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=288, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(40, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=40, bias=False)
        (1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=320, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(160, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=24, bias=True)
        (proj): Linear(in_features=24, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=24, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=192, out_features=40, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
    )
    (2): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(40, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=240, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(120, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=120, bias=False)
        (1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=240, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(120, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=40, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=192, out_features=40, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
    )
    (3): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(40, 240, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=40, bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=480, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(240, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(72, 288, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=72, bias=False)
        (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=576, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(288, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=40, bias=True)
        (proj): Linear(in_features=40, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=40, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=192, out_features=72, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
    )
    (4): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(72, 216, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=432, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=216, bias=False)
        (1): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=432, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(216, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=72, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=192, out_features=72, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
    )
    (5): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(72, 432, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=72, bias=False)
        (1): BatchNorm3d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=864, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(432, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(128, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=72, bias=True)
        (proj): Linear(in_features=72, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=72, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
    )
    (6): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)
        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1024, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=192, out_features=128, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
    )
    (7): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(128, 768, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=768, bias=False)
        (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1536, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(768, 176, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=128, bias=True)
        (proj): Linear(in_features=128, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=128, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=192, out_features=176, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
    )
    (8): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(176, 1056, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1056, 1056, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1056, bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1056, 176, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=176, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=192, out_features=176, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
    )
    (9): DnaBlock3(
      (conv1): Sequential(
        (0): Conv3d(176, 1056, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=176, bias=False)
        (1): BatchNorm3d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2112, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1056, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (conv3): Sequential(
        (0): Conv3d(240, 960, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=240, bias=False)
        (1): BatchNorm3d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=1920, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv4): Sequential(
        (0): Conv3d(960, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act4): DyReLU(
        (act): Sequential()
      )
      (hyper4): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=176, bias=True)
        (proj): Linear(in_features=176, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=176, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
    (10): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1440, 1440, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1440, bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1440, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=240, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
    (11): DnaBlock(
      (conv1): Sequential(
        (0): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act1): DyReLU(
        (act): Sequential()
      )
      (hyper1): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv2): Sequential(
        (0): Conv3d(1440, 1440, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1440, bias=False)
        (1): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (act2): DyReLU(
        (act): Sequential()
      )
      (hyper2): HyperFunc(
        (hyper): Sequential(
          (0): Linear(in_features=192, out_features=48, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=48, out_features=2880, bias=True)
          (3): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (conv3): Sequential(
        (0): Conv3d(1440, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm3d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Sequential()
      )
      (act3): DyReLU(
        (act): Sequential()
      )
      (hyper3): Sequential()
      (drop_path): DropPath(drop_prob=0.000)
      (local_global): Local2Global(
        (alpha): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
        (q): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=240, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
      (global_block): GlobalBlock(
        (ffn): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=True)
          (1): GELU()
          (2): Linear(in_features=384, out_features=192, bias=True)
        )
        (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (q): Linear(in_features=192, out_features=192, bias=True)
        (channel_mlp): Linear(in_features=192, out_features=192, bias=True)
        (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(drop_prob=0.000)
      )
      (global_local): Global2Local(
        (k): Linear(in_features=192, out_features=240, bias=True)
        (proj): Linear(in_features=192, out_features=240, bias=True)
        (drop_path): DropPath(drop_prob=0.000)
        (fc_cnn): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_u): Linear(in_features=192, out_features=1, bias=True)
        (fc_kv_std): Linear(in_features=192, out_features=1, bias=True)
        (emd): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
          (1): ReLU(inplace=True)
        )
        (var): Sequential(
          (0): Linear(in_features=192, out_features=240, bias=True)
        )
      )
    )
  )
  (local_global): Local2Global(
    (alpha): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
      (1): h_sigmoid(
        (relu): ReLU6(inplace=True)
      )
    )
    (q): Linear(in_features=192, out_features=240, bias=True)
    (proj): Linear(in_features=240, out_features=192, bias=True)
    (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (drop_path): DropPath(drop_prob=0.000)
    (fc_q_u): Linear(in_features=192, out_features=1, bias=True)
    (fc_q_std): Linear(in_features=192, out_features=1, bias=True)
    (emd): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
      (1): ReLU(inplace=True)
    )
    (var): Sequential(
      (0): Linear(in_features=192, out_features=240, bias=True)
    )
  )
  (classifier): MergeClassifier(
    (conv): Sequential(
      (0): Sequential()
      (1): Conv3d(240, 1440, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (2): BatchNorm3d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (act): DyReLU(
      (act): ReLU6(inplace=True)
    )
    (hyper): Sequential()
    (avgpool): Sequential(
      (0): AdaptiveAvgPool3d(output_size=(1, 1, 1))
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (fc): Sequential(
      (0): Linear(in_features=2592, out_features=1920, bias=True)
      (1): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=1920, out_features=20, bias=True)
    )
  )
)
############################### Dataset loading ###############################
/home/amax/anaconda3/envs/yuan/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
###############################  Dataset loaded  ##############################
Epoch: [0][  0/203]	Time 42.052 (42.052)	Data 34.019 (34.019)	Loss 3.0632948875427246 (3.0632948875427246)	Acc@1   1.56 (  1.56)	Acc@5  17.19 ( 17.19)
Epoch: [0][ 10/203]	Time  0.586 ( 4.420)	Data  0.000 ( 3.093)	Loss 2.9606411457061768 (3.0708371075716885)	Acc@1  12.50 (  7.39)	Acc@5  35.94 ( 33.38)
Epoch: [0][ 20/203]	Time  0.683 ( 3.461)	Data  0.000 ( 2.496)	Loss 2.8961610794067383 (3.0194110643296015)	Acc@1  12.50 (  9.00)	Acc@5  40.62 ( 36.09)
Epoch: [0][ 30/203]	Time  0.531 ( 2.529)	Data  0.000 ( 1.691)	Loss 2.7189986705780029 (2.9993923479510891)	Acc@1   9.38 (  8.97)	Acc@5  46.88 ( 37.20)
Epoch: [0][ 40/203]	Time  0.520 ( 2.618)	Data  0.000 ( 1.852)	Loss 3.0557456016540527 (2.9789945672198042)	Acc@1   7.81 (  9.49)	Acc@5  29.69 ( 38.45)
Epoch: [0][ 50/203]	Time  0.588 ( 2.581)	Data  0.001 ( 1.859)	Loss 3.0762519836425781 (2.9607205718171361)	Acc@1   9.38 ( 10.05)	Acc@5  32.81 ( 39.12)
Epoch: [0][ 60/203]	Time  0.486 ( 2.255)	Data  0.000 ( 1.564)	Loss 2.6818151473999023 (2.9304178034672970)	Acc@1  18.75 ( 10.48)	Acc@5  48.44 ( 40.80)
Epoch: [0][ 70/203]	Time  0.538 ( 2.381)	Data  0.000 ( 1.709)	Loss 2.6487064361572266 (2.9065422105117582)	Acc@1  21.88 ( 10.89)	Acc@5  59.38 ( 41.73)
Epoch: [0][ 80/203]	Time 24.300 ( 2.451)	Data 23.734 ( 1.791)	Loss 2.7984223365783691 (2.8936071395874023)	Acc@1  20.31 ( 11.19)	Acc@5  50.00 ( 42.46)
Epoch: [0][ 90/203]	Time  0.541 ( 2.308)	Data  0.000 ( 1.661)	Loss 2.8425774574279785 (2.8805423359294515)	Acc@1  12.50 ( 11.69)	Acc@5  37.50 ( 43.48)
Epoch: [0][100/203]	Time  2.049 ( 2.374)	Data  1.469 ( 1.739)	Loss 2.9941954612731934 (2.8724274635314941)	Acc@1   3.12 ( 11.77)	Acc@5  37.50 ( 44.18)
Epoch: [0][110/203]	Time  0.520 ( 2.217)	Data  0.000 ( 1.590)	Loss 2.5825295448303223 (2.8587531442040794)	Acc@1  15.62 ( 12.22)	Acc@5  50.00 ( 44.75)
Epoch: [0][120/203]	Time  0.512 ( 2.305)	Data  0.000 ( 1.685)	Loss 2.6920654773712158 (2.8411887677247858)	Acc@1  15.62 ( 12.85)	Acc@5  62.50 ( 45.60)
Epoch: [0][130/203]	Time  1.271 ( 2.357)	Data  0.725 ( 1.743)	Loss 2.6259834766387939 (2.8280963024110286)	Acc@1  15.62 ( 13.19)	Acc@5  57.81 ( 46.17)
Epoch: [0][140/203]	Time  0.596 ( 2.272)	Data  0.000 ( 1.659)	Loss 2.4362688064575195 (2.8056171887309840)	Acc@1  17.19 ( 13.66)	Acc@5  65.62 ( 47.15)
Epoch: [0][150/203]	Time  0.562 ( 2.341)	Data  0.000 ( 1.731)	Loss 2.5389032363891602 (2.7846590935789197)	Acc@1  15.62 ( 13.94)	Acc@5  64.06 ( 48.10)
Epoch: [0][160/203]	Time 18.968 ( 2.347)	Data 18.382 ( 1.738)	Loss 2.6792449951171875 (2.7728402525741860)	Acc@1  20.31 ( 14.05)	Acc@5  51.56 ( 48.91)
Epoch: [0][170/203]	Time  0.645 ( 2.286)	Data  0.001 ( 1.678)	Loss 2.2193357944488525 (2.7505842049916587)	Acc@1  29.69 ( 14.67)	Acc@5  70.31 ( 49.79)
Epoch: [0][180/203]	Time  1.689 ( 2.330)	Data  1.108 ( 1.726)	Loss 2.4660894870758057 (2.7335354794454836)	Acc@1  20.31 ( 14.95)	Acc@5  62.50 ( 50.60)
Epoch: [0][190/203]	Time  0.610 ( 2.238)	Data  0.000 ( 1.636)	Loss 2.4305810928344727 (2.7186142524499544)	Acc@1  20.31 ( 15.36)	Acc@5  70.31 ( 51.34)
Epoch: [0][200/203]	Time  0.577 ( 2.276)	Data  0.000 ( 1.674)	Loss 2.5101292133331299 (2.7054611758806217)	Acc@1  25.00 ( 15.80)	Acc@5  65.62 ( 51.85)
epoch: 0, Avg_Loss 2.7047114736340903
Test: [ 0/51]	Time 34.325 (34.325)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  20.31 ( 20.31)	Acc@5  67.19 ( 67.19)
Test: [10/51]	Time  0.120 ( 3.254)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  15.62 ( 20.74)	Acc@5  42.19 ( 55.97)
Test: [20/51]	Time  1.002 ( 3.169)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  35.94 ( 20.98)	Acc@5  60.94 ( 55.65)
Test: [30/51]	Time  0.125 ( 2.248)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  21.88 ( 20.82)	Acc@5  62.50 ( 55.65)
Test: [40/51]	Time  0.128 ( 2.526)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  29.69 ( 20.39)	Acc@5  54.69 ( 55.95)
Test: [50/51]	Time  2.539 ( 2.655)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  18.18 ( 20.65)	Acc@5  58.18 ( 55.70)
 * Acc@1 20.645 Acc@5 55.699
Epoch: [1][  0/203]	Time 41.505 (41.505)	Data 40.065 (40.065)	Loss 2.4001426696777344 (2.4001426696777344)	Acc@1  20.31 ( 20.31)	Acc@5  60.94 ( 60.94)
Epoch: [1][ 10/203]	Time  0.905 ( 4.437)	Data  0.001 ( 3.643)	Loss 2.0703322887420654 (2.3363793763247402)	Acc@1  32.81 ( 25.85)	Acc@5  81.25 ( 66.34)
Epoch: [1][ 20/203]	Time  0.510 ( 3.894)	Data  0.000 ( 3.179)	Loss 2.0504770278930664 (2.3293943859281994)	Acc@1  32.81 ( 25.97)	Acc@5  73.44 ( 66.29)
Epoch: [1][ 30/203]	Time  0.567 ( 2.811)	Data  0.000 ( 2.154)	Loss 2.5405099391937256 (2.3514697782454954)	Acc@1  25.00 ( 26.11)	Acc@5  51.56 ( 65.47)
Epoch: [1][ 40/203]	Time  0.828 ( 2.968)	Data  0.001 ( 2.232)	Loss 2.2058136463165283 (2.3372433301879139)	Acc@1  25.00 ( 26.22)	Acc@5  68.75 ( 66.35)
Epoch: [1][ 50/203]	Time  0.783 ( 2.921)	Data  0.100 ( 2.215)	Loss 2.2308206558227539 (2.3241225691402660)	Acc@1  28.12 ( 26.56)	Acc@5  68.75 ( 66.97)
Epoch: [1][ 60/203]	Time  0.719 ( 2.554)	Data  0.001 ( 1.857)	Loss 2.4672994613647461 (2.3211335158738935)	Acc@1  17.19 ( 26.84)	Acc@5  62.50 ( 67.55)
Epoch: [1][ 70/203]	Time  0.597 ( 2.673)	Data  0.000 ( 1.982)	Loss 2.4225082397460938 (2.3064998724091219)	Acc@1  23.44 ( 27.31)	Acc@5  71.88 ( 68.24)
Epoch: [1][ 80/203]	Time 21.965 ( 2.675)	Data 21.249 ( 2.000)	Loss 2.1236979961395264 (2.2946996144306513)	Acc@1  32.81 ( 27.64)	Acc@5  70.31 ( 68.63)
Epoch: [1][ 90/203]	Time  0.575 ( 2.481)	Data  0.000 ( 1.818)	Loss 2.1448101997375488 (2.2846028608280222)	Acc@1  29.69 ( 27.76)	Acc@5  70.31 ( 68.94)
Epoch: [1][100/203]	Time  0.533 ( 2.521)	Data  0.000 ( 1.866)	Loss 1.9914301633834839 (2.2696666434259698)	Acc@1  32.81 ( 28.33)	Acc@5  75.00 ( 69.43)
Epoch: [1][110/203]	Time  0.564 ( 2.342)	Data  0.000 ( 1.698)	Loss 2.0807442665100098 (2.2478155359491572)	Acc@1  39.06 ( 28.87)	Acc@5  73.44 ( 69.90)
Epoch: [1][120/203]	Time  0.681 ( 2.415)	Data  0.000 ( 1.773)	Loss 1.9319859743118286 (2.2391132470990014)	Acc@1  40.62 ( 29.04)	Acc@5  75.00 ( 70.08)
Epoch: [1][130/203]	Time  0.691 ( 2.459)	Data  0.000 ( 1.824)	Loss 1.9444887638092041 (2.2279620916788816)	Acc@1  43.75 ( 29.47)	Acc@5  71.88 ( 70.29)
Epoch: [1][140/203]	Time  0.907 ( 2.356)	Data  0.000 ( 1.716)	Loss 1.8073092699050903 (2.2179423393087183)	Acc@1  39.06 ( 29.77)	Acc@5  84.38 ( 70.61)
Epoch: [1][150/203]	Time  0.513 ( 2.401)	Data  0.000 ( 1.763)	Loss 1.8136879205703735 (2.2066237563329025)	Acc@1  45.31 ( 30.10)	Acc@5  84.38 ( 71.10)
Epoch: [1][160/203]	Time 24.718 ( 2.436)	Data 24.046 ( 1.803)	Loss 1.9137883186340332 (2.1997836561676878)	Acc@1  39.06 ( 30.29)	Acc@5  85.94 ( 71.38)
Epoch: [1][170/203]	Time  0.603 ( 2.332)	Data  0.001 ( 1.702)	Loss 1.9311902523040771 (2.1838925289131743)	Acc@1  37.50 ( 30.74)	Acc@5  76.56 ( 71.68)
Epoch: [1][180/203]	Time  0.704 ( 2.377)	Data  0.000 ( 1.751)	Loss 1.9166586399078369 (2.1769538413095213)	Acc@1  35.94 ( 30.89)	Acc@5  76.56 ( 71.92)
Epoch: [1][190/203]	Time  0.587 ( 2.281)	Data  0.000 ( 1.659)	Loss 1.9446469545364380 (2.1736783020159338)	Acc@1  35.94 ( 30.97)	Acc@5  79.69 ( 72.14)
Epoch: [1][200/203]	Time  0.805 ( 2.318)	Data  0.000 ( 1.693)	Loss 1.9416872262954712 (2.1703461224759990)	Acc@1  29.69 ( 31.01)	Acc@5  81.25 ( 72.33)
epoch: 1, Avg_Loss 2.1715727380931082
Test: [ 0/51]	Time 30.389 (30.389)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  32.81 ( 32.81)	Acc@5  73.44 ( 73.44)
Test: [10/51]	Time  0.136 ( 3.211)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  20.31 ( 23.58)	Acc@5  51.56 ( 61.65)
Test: [20/51]	Time  3.538 ( 3.306)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  23.44 ( 24.48)	Acc@5  71.88 ( 64.43)
Test: [30/51]	Time  0.154 ( 2.286)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  31.25 ( 24.50)	Acc@5  71.88 ( 64.36)
Test: [40/51]	Time  0.164 ( 2.489)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.00 ( 23.25)	Acc@5  64.06 ( 64.33)
Test: [50/51]	Time  0.156 ( 2.455)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.45 ( 23.20)	Acc@5  80.00 ( 64.52)
 * Acc@1 23.195 Acc@5 64.516
Epoch: [2][  0/203]	Time 39.126 (39.126)	Data 38.530 (38.530)	Loss 2.0303685665130615 (2.0303685665130615)	Acc@1  35.94 ( 35.94)	Acc@5  75.00 ( 75.00)
Epoch: [2][ 10/203]	Time  0.595 ( 4.046)	Data  0.001 ( 3.503)	Loss 2.3284075260162354 (2.2788783420215952)	Acc@1  20.31 ( 28.27)	Acc@5  67.19 ( 70.88)
Epoch: [2][ 20/203]	Time  0.562 ( 3.694)	Data  0.000 ( 3.145)	Loss 2.0804061889648438 (2.2251731441134499)	Acc@1  25.00 ( 29.09)	Acc@5  76.56 ( 71.06)
Epoch: [2][ 30/203]	Time  0.617 ( 2.732)	Data  0.000 ( 2.131)	Loss 2.1747877597808838 (2.1792184614366099)	Acc@1  21.88 ( 29.94)	Acc@5  70.31 ( 71.52)
Epoch: [2][ 40/203]	Time  0.504 ( 2.707)	Data  0.000 ( 2.108)	Loss 1.8776910305023193 (2.0957071868384758)	Acc@1  43.75 ( 32.85)	Acc@5  78.12 ( 73.02)
Epoch: [2][ 50/203]	Time  0.857 ( 2.720)	Data  0.000 ( 2.120)	Loss 2.0991330146789551 (2.0687849778755036)	Acc@1  29.69 ( 33.92)	Acc@5  75.00 ( 73.99)
Epoch: [2][ 60/203]	Time  0.482 ( 2.360)	Data  0.000 ( 1.772)	Loss 1.5966166257858276 (2.0369443053104836)	Acc@1  43.75 ( 35.25)	Acc@5  87.50 ( 74.97)
Epoch: [2][ 70/203]	Time  0.908 ( 2.464)	Data  0.000 ( 1.869)	Loss 1.8264249563217163 (2.0147514880543023)	Acc@1  46.88 ( 35.72)	Acc@5  85.94 ( 75.75)
Epoch: [2][ 80/203]	Time 21.797 ( 2.502)	Data 21.231 ( 1.900)	Loss 2.0315353870391846 (1.9958443759400168)	Acc@1  39.06 ( 35.76)	Acc@5  71.88 ( 76.10)
Epoch: [2][ 90/203]	Time  0.736 ( 2.287)	Data  0.000 ( 1.691)	Loss 1.9602662324905396 (1.9767680600449280)	Acc@1  37.50 ( 36.32)	Acc@5  75.00 ( 76.63)
Epoch: [2][100/203]	Time  0.964 ( 2.362)	Data  0.001 ( 1.759)	Loss 1.8799657821655273 (1.9722057994049373)	Acc@1  34.38 ( 36.49)	Acc@5  78.12 ( 76.81)
Epoch: [2][110/203]	Time  0.556 ( 2.207)	Data  0.000 ( 1.601)	Loss 2.0228800773620605 (1.9546686486080960)	Acc@1  39.06 ( 37.08)	Acc@5  78.12 ( 77.27)
Epoch: [2][120/203]	Time  0.625 ( 2.252)	Data  0.000 ( 1.647)	Loss 1.7392388582229614 (1.9459436195941011)	Acc@1  40.62 ( 37.32)	Acc@5  81.25 ( 77.63)
Epoch: [2][130/203]	Time  0.615 ( 2.316)	Data  0.000 ( 1.712)	Loss 1.8084151744842529 (1.9374877360030895)	Acc@1  42.19 ( 37.62)	Acc@5  81.25 ( 77.89)
Epoch: [2][140/203]	Time  0.493 ( 2.188)	Data  0.000 ( 1.590)	Loss 1.6610358953475952 (1.9277516045468919)	Acc@1  42.19 ( 37.84)	Acc@5  84.38 ( 78.12)
Epoch: [2][150/203]	Time  0.612 ( 2.265)	Data  0.000 ( 1.670)	Loss 2.3515527248382568 (1.9185723871584759)	Acc@1  29.69 ( 38.17)	Acc@5  68.75 ( 78.33)
Epoch: [2][160/203]	Time 23.212 ( 2.301)	Data 22.611 ( 1.707)	Loss 1.6075600385665894 (1.9155887269085239)	Acc@1  42.19 ( 38.24)	Acc@5  89.06 ( 78.52)
Epoch: [2][170/203]	Time  0.687 ( 2.218)	Data  0.002 ( 1.611)	Loss 1.7552379369735718 (1.9039438147293894)	Acc@1  42.19 ( 38.75)	Acc@5  82.81 ( 78.75)
Epoch: [2][180/203]	Time  0.609 ( 2.243)	Data  0.000 ( 1.638)	Loss 1.7590221166610718 (1.8959743008429175)	Acc@1  51.56 ( 38.93)	Acc@5  85.94 ( 78.96)
Epoch: [2][190/203]	Time  0.506 ( 2.155)	Data  0.000 ( 1.552)	Loss 1.8543379306793213 (1.8844070035125573)	Acc@1  35.94 ( 39.36)	Acc@5  85.94 ( 79.20)
Epoch: [2][200/203]	Time  0.660 ( 2.195)	Data  0.000 ( 1.591)	Loss 1.5814828872680664 (1.8728977335033132)	Acc@1  51.56 ( 39.68)	Acc@5  87.50 ( 79.45)
epoch: 2, Avg_Loss 1.8697472816617617
Test: [ 0/51]	Time 29.468 (29.468)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  37.50 ( 37.50)	Acc@5  79.69 ( 79.69)
Test: [10/51]	Time  0.131 ( 2.973)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.88 ( 36.51)	Acc@5  76.56 ( 72.44)
Test: [20/51]	Time  0.138 ( 2.937)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  26.56 ( 36.76)	Acc@5  67.19 ( 71.65)
Test: [30/51]	Time  0.140 ( 2.043)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 35.64)	Acc@5  76.56 ( 71.22)
Test: [40/51]	Time  0.142 ( 2.200)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.06 ( 35.67)	Acc@5  73.44 ( 71.07)
Test: [50/51]	Time  0.161 ( 2.207)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  34.55 ( 35.51)	Acc@5  69.09 ( 71.21)
 * Acc@1 35.515 Acc@5 71.214
Epoch: [3][  0/203]	Time 38.574 (38.574)	Data 37.926 (37.926)	Loss 1.9218344688415527 (1.9218344688415527)	Acc@1  35.94 ( 35.94)	Acc@5  79.69 ( 79.69)
Epoch: [3][ 10/203]	Time  0.625 ( 4.130)	Data  0.001 ( 3.448)	Loss 1.7449345588684082 (1.6238154064525256)	Acc@1  42.19 ( 47.73)	Acc@5  87.50 ( 85.09)
Epoch: [3][ 20/203]	Time  0.516 ( 3.419)	Data  0.000 ( 2.777)	Loss 1.5093326568603516 (1.5632242361704509)	Acc@1  51.56 ( 49.18)	Acc@5  85.94 ( 86.46)
Epoch: [3][ 30/203]	Time  0.690 ( 2.502)	Data  0.000 ( 1.882)	Loss 1.7035918235778809 (1.5821989851613198)	Acc@1  40.62 ( 49.04)	Acc@5  87.50 ( 86.24)
Epoch: [3][ 40/203]	Time  0.617 ( 2.679)	Data  0.000 ( 2.039)	Loss 1.5996719598770142 (1.5941365462977712)	Acc@1  43.75 ( 48.70)	Acc@5  89.06 ( 86.20)
Epoch: [3][ 50/203]	Time  0.651 ( 2.729)	Data  0.000 ( 2.103)	Loss 1.7416715621948242 (1.6162732114978866)	Acc@1  46.88 ( 48.10)	Acc@5  82.81 ( 85.97)
Epoch: [3][ 60/203]	Time  0.772 ( 2.383)	Data  0.001 ( 1.758)	Loss 1.5182052850723267 (1.6282171225938640)	Acc@1  51.56 ( 47.54)	Acc@5  92.19 ( 85.86)
Epoch: [3][ 70/203]	Time  0.565 ( 2.413)	Data  0.000 ( 1.784)	Loss 1.3370494842529297 (1.6147061149838944)	Acc@1  50.00 ( 48.00)	Acc@5  95.31 ( 86.00)
Epoch: [3][ 80/203]	Time 30.542 ( 2.569)	Data 29.967 ( 1.934)	Loss 1.3238641023635864 (1.6038559689933871)	Acc@1  51.56 ( 48.15)	Acc@5  95.31 ( 86.27)
Epoch: [3][ 90/203]	Time  0.677 ( 2.362)	Data  0.000 ( 1.722)	Loss 1.5771070718765259 (1.5979647073116932)	Acc@1  50.00 ( 48.25)	Acc@5  87.50 ( 86.38)
Epoch: [3][100/203]	Time  0.510 ( 2.408)	Data  0.000 ( 1.776)	Loss 1.3362605571746826 (1.5954610534233622)	Acc@1  53.12 ( 48.10)	Acc@5  93.75 ( 86.34)
Epoch: [3][110/203]	Time  0.521 ( 2.242)	Data  0.000 ( 1.616)	Loss 1.6731301546096802 (1.5956299734545183)	Acc@1  42.19 ( 48.04)	Acc@5  81.25 ( 86.32)
Epoch: [3][120/203]	Time  0.569 ( 2.420)	Data  0.000 ( 1.799)	Loss 1.6668384075164795 (1.5981944050670656)	Acc@1  53.12 ( 48.04)	Acc@5  82.81 ( 86.32)
Epoch: [3][130/203]	Time  0.678 ( 2.502)	Data  0.000 ( 1.884)	Loss 1.4894665479660034 (1.5978216160344714)	Acc@1  43.75 ( 48.12)	Acc@5  89.06 ( 86.21)
Epoch: [3][140/203]	Time  0.544 ( 2.364)	Data  0.000 ( 1.750)	Loss 1.7044124603271484 (1.5934735012392627)	Acc@1  50.00 ( 48.20)	Acc@5  85.94 ( 86.29)
Epoch: [3][150/203]	Time  0.553 ( 2.401)	Data  0.000 ( 1.789)	Loss 1.4847842454910278 (1.5933632921698868)	Acc@1  43.75 ( 48.22)	Acc@5  90.62 ( 86.21)
Epoch: [3][160/203]	Time 23.587 ( 2.428)	Data 23.037 ( 1.821)	Loss 1.7354612350463867 (1.5845422974284391)	Acc@1  42.19 ( 48.48)	Acc@5  85.94 ( 86.40)
Epoch: [3][170/203]	Time  0.560 ( 2.328)	Data  0.001 ( 1.714)	Loss 1.4670790433883667 (1.5777387221654255)	Acc@1  54.69 ( 48.68)	Acc@5  89.06 ( 86.49)
Epoch: [3][180/203]	Time  0.600 ( 2.350)	Data  0.000 ( 1.732)	Loss 1.3673187494277954 (1.5702930096104659)	Acc@1  53.12 ( 48.96)	Acc@5  89.06 ( 86.62)
Epoch: [3][190/203]	Time  0.582 ( 2.260)	Data  0.000 ( 1.642)	Loss 1.4603668451309204 (1.5614801239592866)	Acc@1  51.56 ( 49.21)	Acc@5  92.19 ( 86.72)
Epoch: [3][200/203]	Time  0.539 ( 2.286)	Data  0.000 ( 1.672)	Loss 1.8538448810577393 (1.5573433287701204)	Acc@1  46.88 ( 49.49)	Acc@5  75.00 ( 86.73)
epoch: 3, Avg_Loss 1.5583822568649142
Test: [ 0/51]	Time 30.171 (30.171)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  43.75 ( 43.75)	Acc@5  76.56 ( 76.56)
Test: [10/51]	Time  0.145 ( 2.866)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  26.56 ( 38.49)	Acc@5  73.44 ( 74.72)
Test: [20/51]	Time  0.138 ( 2.726)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.06 ( 36.90)	Acc@5  76.56 ( 74.85)
Test: [30/51]	Time  0.129 ( 1.893)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  35.94 ( 35.94)	Acc@5  81.25 ( 75.81)
Test: [40/51]	Time  0.121 ( 2.084)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  29.69 ( 34.41)	Acc@5  82.81 ( 76.22)
Test: [50/51]	Time  0.116 ( 2.131)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  34.55 ( 34.35)	Acc@5  81.82 ( 76.25)
 * Acc@1 34.347 Acc@5 76.252
Epoch: [4][  0/203]	Time 31.751 (31.751)	Data 31.070 (31.070)	Loss 1.4047857522964478 (1.4047857522964478)	Acc@1  51.56 ( 51.56)	Acc@5  85.94 ( 85.94)
Epoch: [4][ 10/203]	Time  0.597 ( 3.714)	Data  0.001 ( 3.129)	Loss 1.5193005800247192 (1.4305916049263694)	Acc@1  50.00 ( 54.40)	Acc@5  79.69 ( 86.36)
Epoch: [4][ 20/203]	Time  0.740 ( 3.421)	Data  0.000 ( 2.784)	Loss 1.4461921453475952 (1.4318106288001651)	Acc@1  50.00 ( 53.35)	Acc@5  84.38 ( 87.35)
Epoch: [4][ 30/203]	Time  0.554 ( 2.497)	Data  0.001 ( 1.886)	Loss 1.3615223169326782 (1.4001657078343053)	Acc@1  64.06 ( 54.79)	Acc@5  85.94 ( 88.21)
Epoch: [4][ 40/203]	Time  0.508 ( 2.921)	Data  0.000 ( 2.317)	Loss 1.3465331792831421 (1.4180937423938658)	Acc@1  59.38 ( 54.23)	Acc@5  89.06 ( 87.92)
Epoch: [4][ 50/203]	Time 10.507 ( 3.115)	Data  9.991 ( 2.521)	Loss 1.5253596305847168 (1.4261211180219464)	Acc@1  53.12 ( 54.11)	Acc@5  84.38 ( 87.87)
Epoch: [4][ 60/203]	Time  0.554 ( 2.700)	Data  0.000 ( 2.108)	Loss 1.2716542482376099 (1.4052846842124813)	Acc@1  59.38 ( 54.89)	Acc@5  89.06 ( 88.11)
Epoch: [4][ 70/203]	Time  0.561 ( 3.146)	Data  0.001 ( 2.557)	Loss 1.1612139940261841 (1.3989151531541850)	Acc@1  60.94 ( 54.93)	Acc@5  98.44 ( 88.58)
Epoch: [4][ 80/203]	Time 18.675 ( 3.058)	Data 18.002 ( 2.464)	Loss 1.4299191236495972 (1.3980237083670535)	Acc@1  48.44 ( 54.88)	Acc@5  92.19 ( 88.85)
Epoch: [4][ 90/203]	Time  0.565 ( 2.937)	Data  0.000 ( 2.339)	Loss 1.2272135019302368 (1.3981162702644265)	Acc@1  59.38 ( 54.81)	Acc@5  89.06 ( 88.89)
Epoch: [4][100/203]	Time  0.657 ( 2.989)	Data  0.000 ( 2.391)	Loss 1.5388536453247070 (1.3964228441219519)	Acc@1  54.69 ( 54.87)	Acc@5  84.38 ( 88.91)
Epoch: [4][110/203]	Time  0.556 ( 2.775)	Data  0.000 ( 2.176)	Loss 1.4528654813766479 (1.3852831264873882)	Acc@1  53.12 ( 55.12)	Acc@5  85.94 ( 89.12)
Epoch: [4][120/203]	Time  0.524 ( 2.787)	Data  0.000 ( 2.192)	Loss 1.2602369785308838 (1.3758537552573464)	Acc@1  57.81 ( 55.36)	Acc@5  90.62 ( 89.29)
Epoch: [4][130/203]	Time  6.850 ( 2.801)	Data  6.304 ( 2.210)	Loss 1.2290782928466797 (1.3639097873491186)	Acc@1  65.62 ( 55.90)	Acc@5  92.19 ( 89.41)
Epoch: [4][140/203]	Time  0.546 ( 2.651)	Data  0.000 ( 2.054)	Loss 1.3941545486450195 (1.3651237694929677)	Acc@1  53.12 ( 55.80)	Acc@5  87.50 ( 89.32)
Epoch: [4][150/203]	Time  0.545 ( 2.669)	Data  0.000 ( 2.071)	Loss 0.9744852185249329 (1.3632511176810360)	Acc@1  70.31 ( 55.95)	Acc@5  93.75 ( 89.35)
Epoch: [4][160/203]	Time 18.448 ( 2.649)	Data 17.819 ( 2.053)	Loss 1.4322993755340576 (1.3592889427398303)	Acc@1  43.75 ( 55.95)	Acc@5  89.06 ( 89.38)
Epoch: [4][170/203]	Time  0.644 ( 2.563)	Data  0.002 ( 1.967)	Loss 1.6320759057998657 (1.3584755937955533)	Acc@1  56.25 ( 56.03)	Acc@5  85.94 ( 89.36)
Epoch: [4][180/203]	Time  0.695 ( 2.585)	Data  0.000 ( 1.980)	Loss 1.2362456321716309 (1.3507508092163676)	Acc@1  56.25 ( 56.28)	Acc@5  93.75 ( 89.44)
Epoch: [4][190/203]	Time  0.529 ( 2.482)	Data  0.000 ( 1.876)	Loss 1.5522904396057129 (1.3485840212612252)	Acc@1  50.00 ( 56.30)	Acc@5  84.38 ( 89.55)
Epoch: [4][200/203]	Time  0.614 ( 2.500)	Data  0.000 ( 1.894)	Loss 1.2561436891555786 (1.3455140243715316)	Acc@1  57.81 ( 56.34)	Acc@5  92.19 ( 89.57)
epoch: 4, Avg_Loss 1.3471252739135855
Test: [ 0/51]	Time 29.411 (29.411)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.00 ( 25.00)	Acc@5  68.75 ( 68.75)
Test: [10/51]	Time  0.131 ( 3.221)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  32.81 ( 29.12)	Acc@5  81.25 ( 71.16)
Test: [20/51]	Time  0.136 ( 3.153)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.00 ( 30.36)	Acc@5  64.06 ( 70.76)
Test: [30/51]	Time  0.234 ( 2.273)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.00 ( 29.74)	Acc@5  70.31 ( 70.06)
Test: [40/51]	Time  0.144 ( 2.328)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  34.38 ( 30.49)	Acc@5  71.88 ( 70.05)
Test: [50/51]	Time  0.114 ( 2.407)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.45 ( 31.15)	Acc@5  70.91 ( 70.51)
 * Acc@1 31.152 Acc@5 70.507
Epoch: [5][  0/203]	Time 40.028 (40.028)	Data 39.440 (39.440)	Loss 1.1790044307708740 (1.1790044307708740)	Acc@1  67.19 ( 67.19)	Acc@5  93.75 ( 93.75)
Epoch: [5][ 10/203]	Time  1.088 ( 4.379)	Data  0.002 ( 3.669)	Loss 1.1654648780822754 (1.1771587946198203)	Acc@1  60.94 ( 62.50)	Acc@5  92.19 ( 91.05)
Epoch: [5][ 20/203]	Time  0.548 ( 3.642)	Data  0.000 ( 3.011)	Loss 1.6579567193984985 (1.2331879025413877)	Acc@1  50.00 ( 61.09)	Acc@5  84.38 ( 90.70)
Epoch: [5][ 30/203]	Time  0.529 ( 2.644)	Data  0.000 ( 2.040)	Loss 1.0438315868377686 (1.1864449843283622)	Acc@1  64.06 ( 62.05)	Acc@5  92.19 ( 91.78)
Epoch: [5][ 40/203]	Time  0.905 ( 2.698)	Data  0.000 ( 2.078)	Loss 0.9169421792030334 (1.1872879790096749)	Acc@1  73.44 ( 62.00)	Acc@5  93.75 ( 92.00)
Epoch: [5][ 50/203]	Time  0.571 ( 2.667)	Data  0.000 ( 2.056)	Loss 1.0724732875823975 (1.1880050219741523)	Acc@1  68.75 ( 61.49)	Acc@5  95.31 ( 92.13)
Epoch: [5][ 60/203]	Time  0.591 ( 2.334)	Data  0.000 ( 1.719)	Loss 1.5041950941085815 (1.1959814145916798)	Acc@1  45.31 ( 60.91)	Acc@5  90.62 ( 91.98)
Epoch: [5][ 70/203]	Time  0.531 ( 2.316)	Data  0.000 ( 1.706)	Loss 1.2070769071578979 (1.1997852493339860)	Acc@1  60.94 ( 60.81)	Acc@5  92.19 ( 91.79)
Epoch: [5][ 80/203]	Time 19.354 ( 2.337)	Data 18.736 ( 1.727)	Loss 1.0416294336318970 (1.1931994800214414)	Acc@1  59.38 ( 61.00)	Acc@5  96.88 ( 91.90)
Epoch: [5][ 90/203]	Time  0.559 ( 2.182)	Data  0.000 ( 1.573)	Loss 0.9583852887153625 (1.1841312129418928)	Acc@1  70.31 ( 61.28)	Acc@5  89.06 ( 91.93)
Epoch: [5][100/203]	Time  0.610 ( 2.247)	Data  0.000 ( 1.639)	Loss 1.1415380239486694 (1.1755456918537026)	Acc@1  68.75 ( 61.71)	Acc@5  93.75 ( 91.94)
Epoch: [5][110/203]	Time  0.643 ( 2.105)	Data  0.000 ( 1.492)	Loss 1.1968691349029541 (1.1764452113761559)	Acc@1  62.50 ( 61.80)	Acc@5  85.94 ( 91.88)
Epoch: [5][120/203]	Time  0.515 ( 2.202)	Data  0.000 ( 1.594)	Loss 1.1466996669769287 (1.1715198681374226)	Acc@1  62.50 ( 61.96)	Acc@5  92.19 ( 91.92)
Epoch: [5][130/203]	Time  0.958 ( 2.373)	Data  0.001 ( 1.766)	Loss 1.1177233457565308 (1.1715215681163409)	Acc@1  62.50 ( 61.93)	Acc@5  95.31 ( 91.95)
Epoch: [5][140/203]	Time  0.672 ( 2.249)	Data  0.000 ( 1.641)	Loss 1.1595155000686646 (1.1655293060532699)	Acc@1  60.94 ( 62.02)	Acc@5  95.31 ( 92.14)
Epoch: [5][150/203]	Time  0.532 ( 2.286)	Data  0.000 ( 1.678)	Loss 1.0904029607772827 (1.1616457440205756)	Acc@1  59.38 ( 62.00)	Acc@5  93.75 ( 92.29)
Epoch: [5][160/203]	Time 23.470 ( 2.322)	Data 22.828 ( 1.716)	Loss 1.0977512598037720 (1.1603424811955565)	Acc@1  62.50 ( 61.96)	Acc@5  93.75 ( 92.27)
Epoch: [5][170/203]	Time  0.617 ( 2.223)	Data  0.001 ( 1.615)	Loss 1.0828107595443726 (1.1548919503451789)	Acc@1  62.50 ( 62.13)	Acc@5  92.19 ( 92.31)
Epoch: [5][180/203]	Time  0.595 ( 2.251)	Data  0.000 ( 1.646)	Loss 1.2360874414443970 (1.1498179732106668)	Acc@1  57.81 ( 62.27)	Acc@5  95.31 ( 92.35)
Epoch: [5][190/203]	Time  0.582 ( 2.164)	Data  0.000 ( 1.560)	Loss 1.0880109071731567 (1.1487488191165225)	Acc@1  62.50 ( 62.24)	Acc@5  95.31 ( 92.42)
Epoch: [5][200/203]	Time  0.609 ( 2.233)	Data  0.000 ( 1.627)	Loss 0.7950028181076050 (1.1471976276060836)	Acc@1  70.31 ( 62.27)	Acc@5  96.88 ( 92.48)
epoch: 5, Avg_Loss 1.1476513587782535
Test: [ 0/51]	Time 32.945 (32.945)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.31 ( 45.31)	Acc@5  75.00 ( 75.00)
Test: [10/51]	Time  0.124 ( 3.261)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  53.12 ( 48.72)	Acc@5  85.94 ( 82.10)
Test: [20/51]	Time  0.127 ( 3.382)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  39.06 ( 47.77)	Acc@5  81.25 ( 81.32)
Test: [30/51]	Time  0.137 ( 2.334)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  50.00 ( 47.83)	Acc@5  78.12 ( 81.40)
Test: [40/51]	Time  1.029 ( 2.428)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  48.44 ( 48.59)	Acc@5  81.25 ( 81.33)
Test: [50/51]	Time  0.171 ( 2.443)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  50.91 ( 47.96)	Acc@5  83.64 ( 81.14)
 * Acc@1 47.957 Acc@5 81.137
Epoch: [6][  0/203]	Time 29.936 (29.936)	Data 29.225 (29.225)	Loss 1.1618942022323608 (1.1618942022323608)	Acc@1  71.88 ( 71.88)	Acc@5  92.19 ( 92.19)
Epoch: [6][ 10/203]	Time  0.526 ( 3.479)	Data  0.001 ( 2.918)	Loss 0.7589695453643799 (1.0956415046345105)	Acc@1  73.44 ( 64.49)	Acc@5  96.88 ( 93.47)
Epoch: [6][ 20/203]	Time  0.745 ( 3.165)	Data  0.000 ( 2.587)	Loss 1.0847058296203613 (1.1234585415749323)	Acc@1  70.31 ( 63.24)	Acc@5  92.19 ( 93.53)
Epoch: [6][ 30/203]	Time  0.571 ( 2.318)	Data  0.000 ( 1.752)	Loss 1.1075280904769897 (1.0932083379837774)	Acc@1  60.94 ( 64.01)	Acc@5  96.88 ( 93.75)
Epoch: [6][ 40/203]	Time  0.575 ( 2.420)	Data  0.000 ( 1.847)	Loss 0.9009236097335815 (1.0794583631724846)	Acc@1  70.31 ( 64.37)	Acc@5  98.44 ( 94.25)
Epoch: [6][ 50/203]	Time  0.645 ( 2.452)	Data  0.000 ( 1.863)	Loss 0.9310564398765564 (1.0585864723897447)	Acc@1  70.31 ( 64.68)	Acc@5  95.31 ( 94.49)
Epoch: [6][ 60/203]	Time  0.547 ( 2.179)	Data  0.000 ( 1.592)	Loss 0.9699041247367859 (1.0451941851709710)	Acc@1  73.44 ( 65.22)	Acc@5  95.31 ( 94.44)
Epoch: [6][ 70/203]	Time  0.609 ( 2.283)	Data  0.000 ( 1.696)	Loss 0.9844625592231750 (1.0430270005279862)	Acc@1  68.75 ( 65.80)	Acc@5  92.19 ( 94.28)
Epoch: [6][ 80/203]	Time 12.022 ( 2.224)	Data 11.496 ( 1.629)	Loss 0.9944797754287720 (1.0556914158809332)	Acc@1  60.94 ( 65.28)	Acc@5  98.44 ( 94.16)
Epoch: [6][ 90/203]	Time  0.557 ( 2.165)	Data  0.000 ( 1.569)	Loss 0.7988671064376831 (1.0548270292334505)	Acc@1  68.75 ( 65.28)	Acc@5  98.44 ( 94.06)
Epoch: [6][100/203]	Time  0.615 ( 2.189)	Data  0.000 ( 1.596)	Loss 0.7913229465484619 (1.0433441843136702)	Acc@1  71.88 ( 65.47)	Acc@5 100.00 ( 94.21)
Epoch: [6][110/203]	Time  0.572 ( 2.085)	Data  0.000 ( 1.495)	Loss 1.3862656354904175 (1.0420348542230624)	Acc@1  53.12 ( 65.65)	Acc@5  93.75 ( 94.17)
Epoch: [6][120/203]	Time  0.546 ( 2.147)	Data  0.000 ( 1.553)	Loss 1.0953842401504517 (1.0323998637435849)	Acc@1  67.19 ( 65.97)	Acc@5  89.06 ( 94.25)
Epoch: [6][130/203]	Time  0.831 ( 2.144)	Data  0.201 ( 1.551)	Loss 1.1586964130401611 (1.0397106964169567)	Acc@1  62.50 ( 65.91)	Acc@5  90.62 ( 94.10)
Epoch: [6][140/203]	Time  0.566 ( 2.065)	Data  0.000 ( 1.470)	Loss 0.6513018608093262 (1.0274075020289590)	Acc@1  79.69 ( 66.27)	Acc@5  96.88 ( 94.22)
Epoch: [6][150/203]	Time  0.547 ( 2.123)	Data  0.000 ( 1.529)	Loss 0.8385743498802185 (1.0214923497856847)	Acc@1  68.75 ( 66.38)	Acc@5 100.00 ( 94.27)
Epoch: [6][160/203]	Time 17.173 ( 2.132)	Data 16.624 ( 1.538)	Loss 0.9320442676544189 (1.0148831228291766)	Acc@1  68.75 ( 66.57)	Acc@5  96.88 ( 94.30)
Epoch: [6][170/203]	Time  0.671 ( 2.063)	Data  0.001 ( 1.467)	Loss 0.9174692034721375 (1.0100355134372823)	Acc@1  70.31 ( 66.85)	Acc@5  95.31 ( 94.31)
Epoch: [6][180/203]	Time  0.715 ( 2.111)	Data  0.000 ( 1.512)	Loss 1.0445977449417114 (1.0047939228748091)	Acc@1  62.50 ( 66.95)	Acc@5  90.62 ( 94.36)
Epoch: [6][190/203]	Time  0.545 ( 2.058)	Data  0.000 ( 1.462)	Loss 1.0890697240829468 (0.9998971354898982)	Acc@1  59.38 ( 66.99)	Acc@5  93.75 ( 94.45)
Epoch: [6][200/203]	Time  0.769 ( 2.087)	Data  0.000 ( 1.489)	Loss 0.7062213420867920 (0.9970424626004043)	Acc@1  75.00 ( 67.03)	Acc@5  96.88 ( 94.47)
epoch: 6, Avg_Loss 0.9947974764067551
Test: [ 0/51]	Time 29.462 (29.462)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.31 ( 45.31)	Acc@5  73.44 ( 73.44)
Test: [10/51]	Time  0.138 ( 2.945)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  35.94 ( 42.19)	Acc@5  71.88 ( 75.00)
Test: [20/51]	Time  0.256 ( 2.865)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  37.50 ( 41.59)	Acc@5  59.38 ( 72.92)
Test: [30/51]	Time  0.157 ( 2.004)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  42.19 ( 41.99)	Acc@5  67.19 ( 72.48)
Test: [40/51]	Time  0.279 ( 2.152)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 41.96)	Acc@5  81.25 ( 72.48)
Test: [50/51]	Time  1.154 ( 2.107)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  50.91 ( 42.33)	Acc@5  76.36 ( 73.00)
 * Acc@1 42.335 Acc@5 72.995
Epoch: [7][  0/203]	Time 36.612 (36.612)	Data 35.916 (35.916)	Loss 0.8042075634002686 (0.8042075634002686)	Acc@1  75.00 ( 75.00)	Acc@5  96.88 ( 96.88)
Epoch: [7][ 10/203]	Time  0.535 ( 3.843)	Data  0.001 ( 3.265)	Loss 0.9479073882102966 (0.9253223592584784)	Acc@1  65.62 ( 70.45)	Acc@5  90.62 ( 94.74)
Epoch: [7][ 20/203]	Time  0.499 ( 3.383)	Data  0.000 ( 2.803)	Loss 1.0950381755828857 (0.9125976789565313)	Acc@1  60.94 ( 70.01)	Acc@5  90.62 ( 94.72)
Epoch: [7][ 30/203]	Time  0.523 ( 2.474)	Data  0.000 ( 1.899)	Loss 1.0392446517944336 (0.9193417699106278)	Acc@1  68.75 ( 69.46)	Acc@5  93.75 ( 94.81)
Epoch: [7][ 40/203]	Time  0.575 ( 2.767)	Data  0.000 ( 2.180)	Loss 0.8894494771957397 (0.9199824391341791)	Acc@1  67.19 ( 69.09)	Acc@5  95.31 ( 95.05)
Epoch: [7][ 50/203]	Time  0.542 ( 2.768)	Data  0.000 ( 2.182)	Loss 0.9538758397102356 (0.9101735376844219)	Acc@1  71.88 ( 69.45)	Acc@5  95.31 ( 94.98)
Epoch: [7][ 60/203]	Time  0.750 ( 2.435)	Data  0.000 ( 1.824)	Loss 0.7752441763877869 (0.9016976200166296)	Acc@1  81.25 ( 69.88)	Acc@5  95.31 ( 95.13)
Epoch: [7][ 70/203]	Time  0.506 ( 2.547)	Data  0.000 ( 1.934)	Loss 0.9117087125778198 (0.9051728013535620)	Acc@1  67.19 ( 69.89)	Acc@5  95.31 ( 95.16)
Epoch: [7][ 80/203]	Time 21.728 ( 2.566)	Data 21.180 ( 1.956)	Loss 0.7341364026069641 (0.9053712891943660)	Acc@1  71.88 ( 70.06)	Acc@5  92.19 ( 94.97)
Epoch: [7][ 90/203]	Time  0.503 ( 2.376)	Data  0.000 ( 1.775)	Loss 0.9759315252304077 (0.8957996794155666)	Acc@1  71.88 ( 70.50)	Acc@5  95.31 ( 95.05)
Epoch: [7][100/203]	Time  0.686 ( 2.414)	Data  0.000 ( 1.814)	Loss 1.0694309473037720 (0.8982340286273768)	Acc@1  65.62 ( 70.59)	Acc@5  92.19 ( 95.05)
Epoch: [7][110/203]	Time  0.537 ( 2.247)	Data  0.000 ( 1.650)	Loss 0.8278098702430725 (0.8885901414596282)	Acc@1  71.88 ( 70.95)	Acc@5  93.75 ( 95.12)
Epoch: [7][120/203]	Time  0.580 ( 2.294)	Data  0.000 ( 1.698)	Loss 0.8822479844093323 (0.8939875359377585)	Acc@1  76.56 ( 70.89)	Acc@5  98.44 ( 95.04)
Epoch: [7][130/203]	Time  0.575 ( 2.336)	Data  0.000 ( 1.743)	Loss 1.0013977289199829 (0.8929726217539256)	Acc@1  70.31 ( 71.04)	Acc@5  90.62 ( 94.93)
Epoch: [7][140/203]	Time  0.524 ( 2.216)	Data  0.000 ( 1.619)	Loss 1.1266505718231201 (0.8908629979647643)	Acc@1  68.75 ( 71.12)	Acc@5  90.62 ( 94.95)
Epoch: [7][150/203]	Time  0.543 ( 2.260)	Data  0.000 ( 1.666)	Loss 0.7959679365158081 (0.8862023262788128)	Acc@1  76.56 ( 71.35)	Acc@5  96.88 ( 95.08)
Epoch: [7][160/203]	Time 21.662 ( 2.292)	Data 21.026 ( 1.697)	Loss 1.0628184080123901 (0.8881429071011750)	Acc@1  65.62 ( 71.23)	Acc@5  93.75 ( 95.10)
Epoch: [7][170/203]	Time  0.578 ( 2.197)	Data  0.001 ( 1.603)	Loss 0.7421959638595581 (0.8835117294077288)	Acc@1  78.12 ( 71.27)	Acc@5  95.31 ( 95.19)
Epoch: [7][180/203]	Time  0.607 ( 2.235)	Data  0.000 ( 1.641)	Loss 0.6542536616325378 (0.8808669253607482)	Acc@1  75.00 ( 71.39)	Acc@5  98.44 ( 95.25)
Epoch: [7][190/203]	Time  0.578 ( 2.147)	Data  0.000 ( 1.555)	Loss 0.7317920327186584 (0.8780186578865451)	Acc@1  75.00 ( 71.42)	Acc@5  95.31 ( 95.32)
Epoch: [7][200/203]	Time  0.778 ( 2.183)	Data  0.000 ( 1.584)	Loss 0.9670486450195312 (0.8758992959017777)	Acc@1  65.62 ( 71.42)	Acc@5  95.31 ( 95.35)
epoch: 7, Avg_Loss 0.8730444843545923
Test: [ 0/51]	Time 25.668 (25.668)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  57.81 ( 57.81)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.143 ( 2.667)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  40.62 ( 53.84)	Acc@5  81.25 ( 82.81)
Test: [20/51]	Time  0.123 ( 2.519)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 53.87)	Acc@5  85.94 ( 82.89)
Test: [30/51]	Time  0.132 ( 1.803)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.31 ( 52.77)	Acc@5  78.12 ( 82.21)
Test: [40/51]	Time  0.138 ( 1.899)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  50.00 ( 51.64)	Acc@5  82.81 ( 81.67)
Test: [50/51]	Time  0.115 ( 1.931)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.55 ( 51.58)	Acc@5  78.18 ( 81.26)
 * Acc@1 51.582 Acc@5 81.260
Epoch: [8][  0/203]	Time 34.138 (34.138)	Data 33.582 (33.582)	Loss 0.7334320545196533 (0.7334320545196533)	Acc@1  78.12 ( 78.12)	Acc@5  96.88 ( 96.88)
Epoch: [8][ 10/203]	Time  0.968 ( 3.869)	Data  0.002 ( 3.235)	Loss 0.9812114238739014 (0.8168542439287360)	Acc@1  68.75 ( 74.57)	Acc@5  95.31 ( 95.88)
Epoch: [8][ 20/203]	Time  0.654 ( 3.388)	Data  0.000 ( 2.726)	Loss 0.8530893921852112 (0.8076905012130737)	Acc@1  75.00 ( 74.85)	Acc@5  95.31 ( 95.46)
Epoch: [8][ 30/203]	Time  0.529 ( 2.525)	Data  0.000 ( 1.847)	Loss 0.7148979306221008 (0.8081201834063376)	Acc@1  75.00 ( 74.34)	Acc@5  95.31 ( 95.16)
Epoch: [8][ 40/203]	Time  0.550 ( 2.546)	Data  0.000 ( 1.890)	Loss 0.9243964552879333 (0.7995254629995765)	Acc@1  73.44 ( 74.28)	Acc@5  95.31 ( 95.39)
Epoch: [8][ 50/203]	Time  0.521 ( 2.581)	Data  0.000 ( 1.942)	Loss 0.7109945416450500 (0.7790797580690945)	Acc@1  78.12 ( 75.12)	Acc@5  95.31 ( 95.68)
Epoch: [8][ 60/203]	Time  0.509 ( 2.256)	Data  0.000 ( 1.636)	Loss 1.0366054773330688 (0.7818311496836240)	Acc@1  68.75 ( 74.77)	Acc@5  93.75 ( 95.82)
Epoch: [8][ 70/203]	Time  0.587 ( 2.344)	Data  0.000 ( 1.725)	Loss 0.8816388845443726 (0.7688903317485057)	Acc@1  76.56 ( 75.18)	Acc@5  95.31 ( 96.02)
Epoch: [8][ 80/203]	Time 21.076 ( 2.395)	Data 20.382 ( 1.767)	Loss 0.7097851634025574 (0.7696167072396219)	Acc@1  76.56 ( 75.12)	Acc@5  98.44 ( 96.03)
Epoch: [8][ 90/203]	Time  0.756 ( 2.235)	Data  0.000 ( 1.607)	Loss 1.0030609369277954 (0.7779310093476222)	Acc@1  68.75 ( 74.74)	Acc@5  92.19 ( 96.03)
Epoch: [8][100/203]	Time  0.634 ( 2.295)	Data  0.000 ( 1.656)	Loss 0.9028131961822510 (0.7808438046733932)	Acc@1  65.62 ( 74.68)	Acc@5  95.31 ( 95.99)
Epoch: [8][110/203]	Time  0.568 ( 2.188)	Data  0.000 ( 1.554)	Loss 0.9229602217674255 (0.7820461029941971)	Acc@1  75.00 ( 74.63)	Acc@5  90.62 ( 96.06)
Epoch: [8][120/203]	Time  0.567 ( 2.255)	Data  0.000 ( 1.625)	Loss 0.8393841981887817 (0.7840483422614326)	Acc@1  78.12 ( 74.43)	Acc@5  95.31 ( 96.00)
Epoch: [8][130/203]	Time  0.996 ( 2.314)	Data  0.000 ( 1.680)	Loss 0.6959105134010315 (0.7823765871634010)	Acc@1  78.12 ( 74.45)	Acc@5 100.00 ( 96.04)
Epoch: [8][140/203]	Time  0.520 ( 2.206)	Data  0.000 ( 1.572)	Loss 0.8209074139595032 (0.7782339400856207)	Acc@1  75.00 ( 74.60)	Acc@5  96.88 ( 96.11)
Epoch: [8][150/203]	Time  0.605 ( 2.239)	Data  0.000 ( 1.606)	Loss 0.6766156554222107 (0.7751336593106882)	Acc@1  73.44 ( 74.70)	Acc@5  98.44 ( 96.17)
Epoch: [8][160/203]	Time 26.590 ( 2.313)	Data 25.829 ( 1.684)	Loss 0.7603240013122559 (0.7719585351322008)	Acc@1  73.44 ( 74.95)	Acc@5  95.31 ( 96.14)
Epoch: [8][170/203]	Time  0.515 ( 2.327)	Data  0.001 ( 1.703)	Loss 0.7633692026138306 (0.7711968906441627)	Acc@1  73.44 ( 74.90)	Acc@5  96.88 ( 96.20)
Epoch: [8][180/203]	Time  0.557 ( 2.377)	Data  0.000 ( 1.755)	Loss 0.7601413726806641 (0.7697437692083706)	Acc@1  76.56 ( 74.89)	Acc@5  92.19 ( 96.23)
Epoch: [8][190/203]	Time  0.752 ( 2.328)	Data  0.000 ( 1.707)	Loss 0.9214007258415222 (0.7701852384037996)	Acc@1  71.88 ( 74.91)	Acc@5  95.31 ( 96.23)
Epoch: [8][200/203]	Time  0.667 ( 2.318)	Data  0.000 ( 1.695)	Loss 0.5593345165252686 (0.7683493239962640)	Acc@1  84.38 ( 75.01)	Acc@5  98.44 ( 96.28)
epoch: 8, Avg_Loss 0.7660234752546977
Test: [ 0/51]	Time 27.275 (27.275)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.88 ( 46.88)	Acc@5  78.12 ( 78.12)
Test: [10/51]	Time  0.144 ( 2.694)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 57.39)	Acc@5  82.81 ( 79.83)
Test: [20/51]	Time  3.375 ( 2.652)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 56.85)	Acc@5  82.81 ( 80.06)
Test: [30/51]	Time  0.128 ( 1.839)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  57.81 ( 56.25)	Acc@5  82.81 ( 79.79)
Test: [40/51]	Time  0.132 ( 1.949)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 57.47)	Acc@5  87.50 ( 80.18)
Test: [50/51]	Time  0.129 ( 1.997)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  60.00 ( 57.73)	Acc@5  87.27 ( 80.18)
 * Acc@1 57.727 Acc@5 80.184
Epoch: [9][  0/203]	Time 34.135 (34.135)	Data 33.581 (33.581)	Loss 0.7928292751312256 (0.7928292751312256)	Acc@1  75.00 ( 75.00)	Acc@5  93.75 ( 93.75)
Epoch: [9][ 10/203]	Time  0.631 ( 3.714)	Data  0.001 ( 3.053)	Loss 0.6803508400917053 (0.7511970427903262)	Acc@1  76.56 ( 76.42)	Acc@5  95.31 ( 96.45)
Epoch: [9][ 20/203]	Time  0.553 ( 3.395)	Data  0.000 ( 2.746)	Loss 0.8109641075134277 (0.7249301416533334)	Acc@1  75.00 ( 76.49)	Acc@5  92.19 ( 96.21)
Epoch: [9][ 30/203]	Time  0.583 ( 2.493)	Data  0.000 ( 1.861)	Loss 0.8015707135200500 (0.7219902526947760)	Acc@1  70.31 ( 76.36)	Acc@5  95.31 ( 96.12)
Epoch: [9][ 40/203]	Time  0.518 ( 2.807)	Data  0.000 ( 2.187)	Loss 0.6549590826034546 (0.7151398556988414)	Acc@1  76.56 ( 76.60)	Acc@5  96.88 ( 96.27)
Epoch: [9][ 50/203]	Time  0.627 ( 2.970)	Data  0.000 ( 2.357)	Loss 0.6977754235267639 (0.7118568560656380)	Acc@1  75.00 ( 76.78)	Acc@5  98.44 ( 96.45)
Epoch: [9][ 60/203]	Time  0.593 ( 2.601)	Data  0.000 ( 1.988)	Loss 0.7043950557708740 (0.7139442191749322)	Acc@1  78.12 ( 76.84)	Acc@5  96.88 ( 96.44)
Epoch: [9][ 70/203]	Time  0.598 ( 2.663)	Data  0.000 ( 2.057)	Loss 0.6853591203689575 (0.7168272431467620)	Acc@1  73.44 ( 76.54)	Acc@5  96.88 ( 96.43)
Epoch: [9][ 80/203]	Time 21.168 ( 2.665)	Data 20.491 ( 2.056)	Loss 0.7690200209617615 (0.7095692216614147)	Acc@1  73.44 ( 76.93)	Acc@5  96.88 ( 96.47)
Epoch: [9][ 90/203]	Time  0.612 ( 2.478)	Data  0.000 ( 1.868)	Loss 0.8416367173194885 (0.7052238681814172)	Acc@1  73.44 ( 77.15)	Acc@5  93.75 ( 96.53)
Epoch: [9][100/203]	Time  0.555 ( 2.526)	Data  0.000 ( 1.916)	Loss 0.6242525577545166 (0.6997786302967827)	Acc@1  85.94 ( 77.35)	Acc@5  95.31 ( 96.50)
Epoch: [9][110/203]	Time  0.552 ( 2.348)	Data  0.000 ( 1.743)	Loss 0.7028596997261047 (0.7034612322175825)	Acc@1  79.69 ( 77.24)	Acc@5  98.44 ( 96.51)
Epoch: [9][120/203]	Time  0.546 ( 2.378)	Data  0.000 ( 1.773)	Loss 0.5206045508384705 (0.7009784840355234)	Acc@1  84.38 ( 77.34)	Acc@5  95.31 ( 96.49)
Epoch: [9][130/203]	Time  0.561 ( 2.402)	Data  0.000 ( 1.796)	Loss 0.6561751961708069 (0.7010405102303920)	Acc@1  78.12 ( 77.24)	Acc@5  95.31 ( 96.49)
Epoch: [9][140/203]	Time  0.572 ( 2.272)	Data  0.000 ( 1.670)	Loss 0.5029720664024353 (0.7020077614496786)	Acc@1  85.94 ( 77.24)	Acc@5 100.00 ( 96.46)
Epoch: [9][150/203]	Time  0.648 ( 2.320)	Data  0.000 ( 1.714)	Loss 0.4795869886875153 (0.6966495853386178)	Acc@1  85.94 ( 77.27)	Acc@5  96.88 ( 96.53)
Epoch: [9][160/203]	Time  6.990 ( 2.276)	Data  6.427 ( 1.648)	Loss 0.7940651178359985 (0.6981841825550388)	Acc@1  75.00 ( 77.36)	Acc@5  90.62 ( 96.53)
Epoch: [9][170/203]	Time  0.573 ( 2.248)	Data  0.002 ( 1.621)	Loss 0.7014732360839844 (0.6974254229612518)	Acc@1  73.44 ( 77.36)	Acc@5  95.31 ( 96.55)
Epoch: [9][180/203]	Time  0.607 ( 2.273)	Data  0.000 ( 1.645)	Loss 0.6035354137420654 (0.6949693707142087)	Acc@1  76.56 ( 77.42)	Acc@5 100.00 ( 96.62)
Epoch: [9][190/203]	Time  0.579 ( 2.185)	Data  0.000 ( 1.562)	Loss 0.5513221621513367 (0.6943880332077985)	Acc@1  85.94 ( 77.45)	Acc@5  96.88 ( 96.63)
Epoch: [9][200/203]	Time  0.622 ( 2.202)	Data  0.000 ( 1.580)	Loss 0.4697155058383942 (0.6934164123452125)	Acc@1  82.81 ( 77.50)	Acc@5 100.00 ( 96.64)
epoch: 9, Avg_Loss 0.691569286614216
Test: [ 0/51]	Time 24.820 (24.820)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  45.31 ( 45.31)	Acc@5  60.94 ( 60.94)
Test: [10/51]	Time  0.153 ( 2.448)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  53.12 ( 56.53)	Acc@5  75.00 ( 77.98)
Test: [20/51]	Time  0.157 ( 2.393)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  62.50 ( 56.77)	Acc@5  81.25 ( 78.42)
Test: [30/51]	Time  0.133 ( 1.674)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  53.12 ( 55.59)	Acc@5  64.06 ( 77.22)
Test: [40/51]	Time  0.153 ( 1.854)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  56.25 ( 55.91)	Acc@5  81.25 ( 77.40)
Test: [50/51]	Time  0.119 ( 1.849)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.27 ( 55.58)	Acc@5  83.64 ( 77.05)
 * Acc@1 55.576 Acc@5 77.051
Epoch: [10][  0/203]	Time 31.302 (31.302)	Data 30.619 (30.619)	Loss 0.7373839616775513 (0.7373839616775513)	Acc@1  82.81 ( 82.81)	Acc@5  95.31 ( 95.31)
Epoch: [10][ 10/203]	Time  0.538 ( 3.472)	Data  0.001 ( 2.925)	Loss 0.7386729717254639 (0.6816352416168560)	Acc@1  73.44 ( 78.98)	Acc@5  98.44 ( 96.02)
Epoch: [10][ 20/203]	Time  0.602 ( 3.075)	Data  0.000 ( 2.516)	Loss 0.6163278222084045 (0.6679346050534930)	Acc@1  84.38 ( 78.87)	Acc@5  96.88 ( 96.50)
Epoch: [10][ 30/203]	Time  0.511 ( 2.279)	Data  0.001 ( 1.705)	Loss 0.5578905344009399 (0.6670911321716924)	Acc@1  84.38 ( 78.12)	Acc@5 100.00 ( 96.67)
Epoch: [10][ 40/203]	Time  0.541 ( 2.389)	Data  0.000 ( 1.797)	Loss 0.3580857217311859 (0.6630933066693748)	Acc@1  87.50 ( 78.28)	Acc@5 100.00 ( 96.80)
Epoch: [10][ 50/203]	Time  0.822 ( 2.430)	Data  0.000 ( 1.835)	Loss 0.7176439166069031 (0.6541500418793922)	Acc@1  78.12 ( 78.58)	Acc@5  92.19 ( 96.84)
Epoch: [10][ 60/203]	Time  0.629 ( 2.133)	Data  0.000 ( 1.534)	Loss 0.7520101070404053 (0.6507163551010069)	Acc@1  71.88 ( 78.59)	Acc@5  95.31 ( 96.95)
Epoch: [10][ 70/203]	Time  0.638 ( 2.231)	Data  0.000 ( 1.625)	Loss 0.2968152761459351 (0.6492172022100905)	Acc@1  90.62 ( 78.63)	Acc@5 100.00 ( 97.01)
Epoch: [10][ 80/203]	Time 20.466 ( 2.270)	Data 19.703 ( 1.668)	Loss 0.6346856951713562 (0.6432043597286130)	Acc@1  82.81 ( 78.94)	Acc@5  96.88 ( 97.07)
Epoch: [10][ 90/203]	Time  0.510 ( 2.097)	Data  0.000 ( 1.484)	Loss 0.7269152402877808 (0.6405424727843358)	Acc@1  71.88 ( 78.98)	Acc@5  98.44 ( 97.22)
Epoch: [10][100/203]	Time  0.522 ( 2.160)	Data  0.000 ( 1.548)	Loss 0.6000020503997803 (0.6355448875686910)	Acc@1  78.12 ( 79.18)	Acc@5  98.44 ( 97.28)
Epoch: [10][110/203]	Time  0.744 ( 2.019)	Data  0.000 ( 1.409)	Loss 0.6321330666542053 (0.6314677684693724)	Acc@1  76.56 ( 79.27)	Acc@5 100.00 ( 97.34)
Epoch: [10][120/203]	Time  0.532 ( 2.081)	Data  0.000 ( 1.474)	Loss 0.7061015963554382 (0.6239851944702716)	Acc@1  75.00 ( 79.49)	Acc@5 100.00 ( 97.47)
Epoch: [10][130/203]	Time  0.520 ( 2.138)	Data  0.000 ( 1.536)	Loss 0.6238518357276917 (0.6228600135286346)	Acc@1  78.12 ( 79.53)	Acc@5 100.00 ( 97.52)
Epoch: [10][140/203]	Time  0.522 ( 2.057)	Data  0.000 ( 1.458)	Loss 0.4374202787876129 (0.6205258969719528)	Acc@1  90.62 ( 79.55)	Acc@5 100.00 ( 97.52)
Epoch: [10][150/203]	Time  0.570 ( 2.093)	Data  0.001 ( 1.492)	Loss 0.7570407390594482 (0.6256257927180916)	Acc@1  70.31 ( 79.36)	Acc@5 100.00 ( 97.50)
Epoch: [10][160/203]	Time 22.557 ( 2.133)	Data 21.367 ( 1.533)	Loss 0.5189853310585022 (0.6252206580609269)	Acc@1  87.50 ( 79.41)	Acc@5  96.88 ( 97.46)
Epoch: [10][170/203]	Time  0.524 ( 2.051)	Data  0.002 ( 1.445)	Loss 0.5220959782600403 (0.6234596793414556)	Acc@1  79.69 ( 79.38)	Acc@5  98.44 ( 97.46)
Epoch: [10][180/203]	Time  4.925 ( 2.100)	Data  4.237 ( 1.495)	Loss 0.4820240139961243 (0.6206518785400286)	Acc@1  82.81 ( 79.46)	Acc@5  98.44 ( 97.48)
Epoch: [10][190/203]	Time  0.789 ( 2.026)	Data  0.000 ( 1.417)	Loss 0.6273062825202942 (0.6189952729884243)	Acc@1  71.88 ( 79.54)	Acc@5  96.88 ( 97.49)
Epoch: [10][200/203]	Time  0.569 ( 2.053)	Data  0.000 ( 1.443)	Loss 0.8717935681343079 (0.6183991329883461)	Acc@1  73.44 ( 79.62)	Acc@5  93.75 ( 97.47)
epoch: 10, Avg_Loss 0.6160705681211256
Test: [ 0/51]	Time 25.659 (25.659)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  28.12 ( 28.12)	Acc@5  70.31 ( 70.31)
Test: [10/51]	Time  0.128 ( 2.532)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  31.25 ( 33.38)	Acc@5  71.88 ( 75.00)
Test: [20/51]	Time  0.122 ( 2.437)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  25.00 ( 32.51)	Acc@5  68.75 ( 75.82)
Test: [30/51]	Time  0.171 ( 1.720)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  35.94 ( 32.36)	Acc@5  73.44 ( 75.55)
Test: [40/51]	Time  0.152 ( 1.793)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  32.81 ( 31.44)	Acc@5  79.69 ( 75.23)
Test: [50/51]	Time  0.340 ( 1.891)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  32.73 ( 32.26)	Acc@5  87.27 ( 75.91)
 * Acc@1 32.258 Acc@5 75.914
Epoch: [11][  0/203]	Time 34.148 (34.148)	Data 33.486 (33.486)	Loss 0.7867721319198608 (0.7867721319198608)	Acc@1  70.31 ( 70.31)	Acc@5  95.31 ( 95.31)
Epoch: [11][ 10/203]	Time  0.514 ( 3.560)	Data  0.001 ( 3.044)	Loss 0.4808608889579773 (0.6006955612789501)	Acc@1  82.81 ( 81.11)	Acc@5  96.88 ( 96.88)
Epoch: [11][ 20/203]	Time  0.605 ( 3.198)	Data  0.000 ( 2.636)	Loss 0.6810845136642456 (0.5745643292154584)	Acc@1  79.69 ( 81.32)	Acc@5  95.31 ( 97.47)
Epoch: [11][ 30/203]	Time  0.573 ( 2.352)	Data  0.000 ( 1.786)	Loss 0.4781455397605896 (0.5703799032395885)	Acc@1  84.38 ( 81.35)	Acc@5 100.00 ( 97.68)
Epoch: [11][ 40/203]	Time  0.572 ( 2.364)	Data  0.000 ( 1.780)	Loss 0.5284667611122131 (0.5687944372979606)	Acc@1  87.50 ( 81.36)	Acc@5 100.00 ( 97.75)
Epoch: [11][ 50/203]	Time  0.551 ( 2.479)	Data  0.000 ( 1.884)	Loss 0.6151081919670105 (0.5675243600910785)	Acc@1  79.69 ( 81.25)	Acc@5 100.00 ( 97.98)
Epoch: [11][ 60/203]	Time  0.576 ( 2.160)	Data  0.000 ( 1.575)	Loss 0.8246728777885437 (0.5753996807043670)	Acc@1  75.00 ( 81.05)	Acc@5  95.31 ( 97.87)
Epoch: [11][ 70/203]	Time  0.659 ( 2.238)	Data  0.000 ( 1.643)	Loss 0.6295025944709778 (0.5837268988851091)	Acc@1  82.81 ( 80.88)	Acc@5 100.00 ( 97.87)
Epoch: [11][ 80/203]	Time 16.836 ( 2.237)	Data 16.128 ( 1.640)	Loss 0.4440491795539856 (0.5847610099080168)	Acc@1  85.94 ( 81.06)	Acc@5 100.00 ( 97.70)
Epoch: [11][ 90/203]	Time  0.573 ( 2.071)	Data  0.000 ( 1.474)	Loss 0.5915215015411377 (0.5957427067416055)	Acc@1  78.12 ( 80.55)	Acc@5  96.88 ( 97.61)
Epoch: [11][100/203]	Time  0.650 ( 2.144)	Data  0.000 ( 1.541)	Loss 0.6837811470031738 (0.5974639627603021)	Acc@1  78.12 ( 80.51)	Acc@5  98.44 ( 97.65)
Epoch: [11][110/203]	Time  0.559 ( 2.008)	Data  0.000 ( 1.405)	Loss 0.4547235965728760 (0.5985406119007248)	Acc@1  81.25 ( 80.43)	Acc@5 100.00 ( 97.65)
Epoch: [11][120/203]	Time  0.520 ( 2.092)	Data  0.000 ( 1.484)	Loss 0.6644331812858582 (0.5986859478241155)	Acc@1  81.25 ( 80.46)	Acc@5  95.31 ( 97.62)
Epoch: [11][130/203]	Time  3.410 ( 2.140)	Data  2.808 ( 1.535)	Loss 0.6226149201393127 (0.5991278925469814)	Acc@1  84.38 ( 80.40)	Acc@5  96.88 ( 97.53)
Epoch: [11][140/203]	Time  0.563 ( 2.032)	Data  0.000 ( 1.431)	Loss 0.7438557147979736 (0.5941872491058728)	Acc@1  76.56 ( 80.53)	Acc@5  96.88 ( 97.60)
Epoch: [11][150/203]	Time  1.888 ( 2.091)	Data  1.201 ( 1.492)	Loss 0.6768082380294800 (0.5932949406421737)	Acc@1  78.12 ( 80.67)	Acc@5  98.44 ( 97.58)
Epoch: [11][160/203]	Time 18.634 ( 2.120)	Data 18.114 ( 1.512)	Loss 0.6937672495841980 (0.5964439707513182)	Acc@1  73.44 ( 80.60)	Acc@5  98.44 ( 97.57)
Epoch: [11][170/203]	Time  0.524 ( 2.053)	Data  0.001 ( 1.445)	Loss 0.4450742602348328 (0.5974564006802632)	Acc@1  84.38 ( 80.58)	Acc@5 100.00 ( 97.57)
Epoch: [11][180/203]	Time  0.718 ( 2.104)	Data  0.000 ( 1.495)	Loss 0.5139808654785156 (0.6000296779759022)	Acc@1  84.38 ( 80.62)	Acc@5 100.00 ( 97.54)
Epoch: [11][190/203]	Time  0.501 ( 2.025)	Data  0.000 ( 1.416)	Loss 0.4168561995029449 (0.5945835920216526)	Acc@1  84.38 ( 80.73)	Acc@5 100.00 ( 97.59)
Epoch: [11][200/203]	Time  0.694 ( 2.079)	Data  0.000 ( 1.462)	Loss 0.4937535524368286 (0.5931013001138298)	Acc@1  82.81 ( 80.83)	Acc@5  98.44 ( 97.57)
epoch: 11, Avg_Loss 0.5909517065351233
Test: [ 0/51]	Time 25.189 (25.189)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 70.31)	Acc@5  79.69 ( 79.69)
Test: [10/51]	Time  0.135 ( 2.619)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 69.74)	Acc@5  87.50 ( 86.51)
Test: [20/51]	Time  0.133 ( 2.587)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 68.60)	Acc@5  92.19 ( 86.53)
Test: [30/51]	Time  0.141 ( 1.796)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 67.69)	Acc@5  87.50 ( 86.04)
Test: [40/51]	Time  0.117 ( 1.941)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  65.62 ( 67.72)	Acc@5  82.81 ( 85.79)
Test: [50/51]	Time  0.129 ( 1.960)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  63.64 ( 68.39)	Acc@5  85.45 ( 85.84)
 * Acc@1 68.387 Acc@5 85.837
Epoch: [12][  0/203]	Time 29.656 (29.656)	Data 28.997 (28.997)	Loss 0.5931919813156128 (0.5931919813156128)	Acc@1  78.12 ( 78.12)	Acc@5  96.88 ( 96.88)
Epoch: [12][ 10/203]	Time  0.509 ( 3.470)	Data  0.000 ( 2.936)	Loss 0.3050899207592010 (0.4999620833180167)	Acc@1  92.19 ( 83.38)	Acc@5 100.00 ( 98.15)
Epoch: [12][ 20/203]	Time  0.583 ( 3.115)	Data  0.000 ( 2.535)	Loss 0.5611451864242554 (0.5109806898094359)	Acc@1  79.69 ( 83.11)	Acc@5  98.44 ( 97.92)
Epoch: [12][ 30/203]	Time  0.523 ( 2.325)	Data  0.000 ( 1.717)	Loss 0.4950364232063293 (0.5062564967140075)	Acc@1  85.94 ( 83.67)	Acc@5  98.44 ( 97.93)
Epoch: [12][ 40/203]	Time  0.632 ( 2.350)	Data  0.000 ( 1.747)	Loss 0.2991791367530823 (0.4933083609836857)	Acc@1  90.62 ( 84.07)	Acc@5 100.00 ( 98.17)
Epoch: [12][ 50/203]	Time  1.014 ( 2.447)	Data  0.000 ( 1.829)	Loss 0.6309019327163696 (0.5188964231341493)	Acc@1  78.12 ( 83.18)	Acc@5  96.88 ( 97.89)
Epoch: [12][ 60/203]	Time  0.689 ( 2.195)	Data  0.000 ( 1.556)	Loss 0.6650024056434631 (0.5195120074709908)	Acc@1  78.12 ( 83.12)	Acc@5  98.44 ( 97.90)
Epoch: [12][ 70/203]	Time  0.641 ( 2.264)	Data  0.135 ( 1.632)	Loss 0.6726749539375305 (0.5198631097733135)	Acc@1  81.25 ( 83.03)	Acc@5  95.31 ( 97.98)
Epoch: [12][ 80/203]	Time 24.106 ( 2.344)	Data 23.498 ( 1.721)	Loss 0.3509137034416199 (0.5172690859547368)	Acc@1  89.06 ( 83.18)	Acc@5 100.00 ( 98.01)
Epoch: [12][ 90/203]	Time  0.664 ( 2.171)	Data  0.002 ( 1.544)	Loss 0.4947019517421722 (0.5148833423525423)	Acc@1  84.38 ( 83.26)	Acc@5  98.44 ( 98.04)
Epoch: [12][100/203]	Time  0.566 ( 2.286)	Data  0.000 ( 1.654)	Loss 0.5412642359733582 (0.5047465580524785)	Acc@1  82.81 ( 83.62)	Acc@5  96.88 ( 98.10)
Epoch: [12][110/203]	Time  0.601 ( 2.133)	Data  0.001 ( 1.505)	Loss 0.4077188968658447 (0.4997247799828246)	Acc@1  85.94 ( 83.73)	Acc@5 100.00 ( 98.10)
Epoch: [12][120/203]	Time  0.597 ( 2.234)	Data  0.000 ( 1.595)	Loss 0.5904602408409119 (0.5017148269848390)	Acc@1  81.25 ( 83.70)	Acc@5 100.00 ( 98.09)
Epoch: [12][130/203]	Time  0.703 ( 2.238)	Data  0.000 ( 1.597)	Loss 0.3436108529567719 (0.5025253738383301)	Acc@1  87.50 ( 83.55)	Acc@5 100.00 ( 98.20)
Epoch: [12][140/203]	Time  0.503 ( 2.167)	Data  0.000 ( 1.523)	Loss 0.4745181202888489 (0.5001625715629429)	Acc@1  82.81 ( 83.57)	Acc@5 100.00 ( 98.26)
Epoch: [12][150/203]	Time  0.513 ( 2.208)	Data  0.000 ( 1.572)	Loss 0.8589766025543213 (0.5023587262196256)	Acc@1  70.31 ( 83.52)	Acc@5  93.75 ( 98.27)
Epoch: [12][160/203]	Time 29.323 ( 2.288)	Data 28.752 ( 1.653)	Loss 0.4349501729011536 (0.5027914968151483)	Acc@1  81.25 ( 83.49)	Acc@5 100.00 ( 98.30)
Epoch: [12][170/203]	Time  0.541 ( 2.259)	Data  0.001 ( 1.627)	Loss 0.6214998960494995 (0.5031286046693200)	Acc@1  81.25 ( 83.52)	Acc@5  95.31 ( 98.29)
Epoch: [12][180/203]	Time  0.735 ( 2.297)	Data  0.000 ( 1.666)	Loss 0.4525213241577148 (0.5000272310076498)	Acc@1  84.38 ( 83.68)	Acc@5 100.00 ( 98.31)
Epoch: [12][190/203]	Time  0.611 ( 2.208)	Data  0.000 ( 1.579)	Loss 0.3779933750629425 (0.5005951647827138)	Acc@1  85.94 ( 83.58)	Acc@5  98.44 ( 98.32)
Epoch: [12][200/203]	Time  0.579 ( 2.232)	Data  0.000 ( 1.605)	Loss 0.6414495706558228 (0.5011275860652402)	Acc@1  81.25 ( 83.58)	Acc@5  98.44 ( 98.31)
epoch: 12, Avg_Loss 0.50127707597951
Test: [ 0/51]	Time 27.628 (27.628)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.44)	Acc@5  92.19 ( 92.19)
Test: [10/51]	Time  0.158 ( 2.799)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 61.79)	Acc@5  79.69 ( 87.93)
Test: [20/51]	Time  0.177 ( 2.722)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  51.56 ( 61.24)	Acc@5  82.81 ( 87.43)
Test: [30/51]	Time  0.143 ( 1.895)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  62.50 ( 62.70)	Acc@5  89.06 ( 87.75)
Test: [40/51]	Time  0.218 ( 2.079)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 62.73)	Acc@5  89.06 ( 87.80)
Test: [50/51]	Time  0.133 ( 2.018)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  63.64 ( 63.35)	Acc@5  89.09 ( 87.93)
 * Acc@1 63.349 Acc@5 87.926
Epoch: [13][  0/203]	Time 43.521 (43.521)	Data 42.735 (42.735)	Loss 0.5774782299995422 (0.5774782299995422)	Acc@1  84.38 ( 84.38)	Acc@5  95.31 ( 95.31)
Epoch: [13][ 10/203]	Time  0.680 ( 4.531)	Data  0.001 ( 3.886)	Loss 0.4872300028800964 (0.5185048227960413)	Acc@1  89.06 ( 83.10)	Acc@5  95.31 ( 97.44)
Epoch: [13][ 20/203]	Time  0.709 ( 3.948)	Data  0.001 ( 3.272)	Loss 0.4832908809185028 (0.5095638079302651)	Acc@1  85.94 ( 83.33)	Acc@5 100.00 ( 97.84)
Epoch: [13][ 30/203]	Time  0.641 ( 2.874)	Data  0.000 ( 2.216)	Loss 0.5942154526710510 (0.5109436406243232)	Acc@1  82.81 ( 83.47)	Acc@5  96.88 ( 97.63)
Epoch: [13][ 40/203]	Time  0.500 ( 2.793)	Data  0.000 ( 2.155)	Loss 0.3565062880516052 (0.5012520646176687)	Acc@1  82.81 ( 83.38)	Acc@5 100.00 ( 97.75)
Epoch: [13][ 50/203]	Time  0.508 ( 2.852)	Data  0.000 ( 2.227)	Loss 0.4825214147567749 (0.4944089084279303)	Acc@1  81.25 ( 83.52)	Acc@5  98.44 ( 97.89)
Epoch: [13][ 60/203]	Time  0.517 ( 2.534)	Data  0.000 ( 1.912)	Loss 0.5011179447174072 (0.4805334352078985)	Acc@1  81.25 ( 83.97)	Acc@5  98.44 ( 98.00)
Epoch: [13][ 70/203]	Time  0.531 ( 2.565)	Data  0.000 ( 1.954)	Loss 0.3668407201766968 (0.4762431471280649)	Acc@1  93.75 ( 84.11)	Acc@5  96.88 ( 98.06)
Epoch: [13][ 80/203]	Time 16.232 ( 2.521)	Data 15.615 ( 1.905)	Loss 0.5144130587577820 (0.4774020531295258)	Acc@1  85.94 ( 84.18)	Acc@5  96.88 ( 98.11)
Epoch: [13][ 90/203]	Time  0.632 ( 2.369)	Data  0.029 ( 1.758)	Loss 0.4939486682415009 (0.4787045749989185)	Acc@1  87.50 ( 84.08)	Acc@5  96.88 ( 98.08)
Epoch: [13][100/203]	Time  4.557 ( 2.417)	Data  3.945 ( 1.803)	Loss 0.5970115661621094 (0.4809392065104872)	Acc@1  79.69 ( 84.11)	Acc@5  95.31 ( 98.00)
Epoch: [13][110/203]	Time  0.577 ( 2.256)	Data  0.000 ( 1.640)	Loss 0.3515509665012360 (0.4793657920919023)	Acc@1  85.94 ( 84.14)	Acc@5 100.00 ( 98.03)
Epoch: [13][120/203]	Time  0.530 ( 2.302)	Data  0.000 ( 1.689)	Loss 0.3605051040649414 (0.4779394421695678)	Acc@1  87.50 ( 84.26)	Acc@5  98.44 ( 98.08)
Epoch: [13][130/203]	Time  0.564 ( 2.279)	Data  0.000 ( 1.671)	Loss 0.6460310220718384 (0.4767718640447573)	Acc@1  76.56 ( 84.23)	Acc@5  95.31 ( 98.07)
Epoch: [13][140/203]	Time  0.608 ( 2.226)	Data  0.000 ( 1.620)	Loss 0.3987349271774292 (0.4747117064523358)	Acc@1  84.38 ( 84.36)	Acc@5 100.00 ( 98.11)
Epoch: [13][150/203]	Time  0.544 ( 2.370)	Data  0.000 ( 1.766)	Loss 0.4799040257930756 (0.4769598180489824)	Acc@1  84.38 ( 84.29)	Acc@5  98.44 ( 98.14)
Epoch: [13][160/203]	Time 16.717 ( 2.360)	Data 16.115 ( 1.756)	Loss 0.5506100654602051 (0.4784746094149833)	Acc@1  82.81 ( 84.24)	Acc@5  98.44 ( 98.13)
Epoch: [13][170/203]	Time  0.498 ( 2.298)	Data  0.001 ( 1.697)	Loss 0.3321470916271210 (0.4739330160861824)	Acc@1  87.50 ( 84.38)	Acc@5 100.00 ( 98.15)
Epoch: [13][180/203]	Time  4.659 ( 2.322)	Data  4.003 ( 1.723)	Loss 0.5664565563201904 (0.4771373445651808)	Acc@1  79.69 ( 84.35)	Acc@5  98.44 ( 98.12)
Epoch: [13][190/203]	Time  0.566 ( 2.252)	Data  0.000 ( 1.654)	Loss 0.4586538672447205 (0.4768327801483464)	Acc@1  87.50 ( 84.35)	Acc@5 100.00 ( 98.12)
Epoch: [13][200/203]	Time  0.576 ( 2.267)	Data  0.000 ( 1.666)	Loss 0.4375794231891632 (0.4766424714184519)	Acc@1  87.50 ( 84.43)	Acc@5  98.44 ( 98.10)
epoch: 13, Avg_Loss 0.47629275000447713
Test: [ 0/51]	Time 21.045 (21.045)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  65.62 ( 65.62)	Acc@5  84.38 ( 84.38)
Test: [10/51]	Time  0.128 ( 2.378)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 66.19)	Acc@5  87.50 ( 80.97)
Test: [20/51]	Time  0.139 ( 2.387)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 66.82)	Acc@5  90.62 ( 82.29)
Test: [30/51]	Time  0.400 ( 1.672)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  53.12 ( 66.13)	Acc@5  76.56 ( 82.41)
Test: [40/51]	Time  1.068 ( 1.806)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 66.27)	Acc@5  84.38 ( 82.09)
Test: [50/51]	Time  0.161 ( 1.813)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  65.45 ( 66.24)	Acc@5  85.45 ( 82.43)
 * Acc@1 66.237 Acc@5 82.427
Epoch: [14][  0/203]	Time 27.707 (27.707)	Data 27.094 (27.094)	Loss 0.3588642776012421 (0.3588642776012421)	Acc@1  84.38 ( 84.38)	Acc@5 100.00 (100.00)
Epoch: [14][ 10/203]	Time  0.547 ( 3.368)	Data  0.005 ( 2.795)	Loss 0.3718318641185760 (0.5042800984599374)	Acc@1  90.62 ( 84.09)	Acc@5  98.44 ( 98.72)
Epoch: [14][ 20/203]	Time  0.842 ( 3.126)	Data  0.000 ( 2.529)	Loss 0.3844458162784576 (0.4746119614158358)	Acc@1  89.06 ( 85.34)	Acc@5 100.00 ( 98.36)
Epoch: [14][ 30/203]	Time  0.518 ( 2.306)	Data  0.000 ( 1.713)	Loss 0.3387380242347717 (0.4674384223838006)	Acc@1  87.50 ( 85.53)	Acc@5 100.00 ( 98.08)
Epoch: [14][ 40/203]	Time  0.521 ( 2.288)	Data  0.000 ( 1.703)	Loss 0.3495171070098877 (0.4445083461156705)	Acc@1  85.94 ( 85.90)	Acc@5 100.00 ( 98.36)
Epoch: [14][ 50/203]	Time  2.902 ( 2.369)	Data  2.096 ( 1.770)	Loss 0.4784860014915466 (0.4685561580985200)	Acc@1  89.06 ( 85.26)	Acc@5  95.31 ( 98.01)
Epoch: [14][ 60/203]	Time  0.678 ( 2.129)	Data  0.000 ( 1.534)	Loss 0.4136705994606018 (0.4684449390309756)	Acc@1  84.38 ( 85.19)	Acc@5 100.00 ( 98.10)
Epoch: [14][ 70/203]	Time  3.257 ( 2.193)	Data  2.518 ( 1.592)	Loss 0.5547305941581726 (0.4772594117782485)	Acc@1  82.81 ( 84.97)	Acc@5  96.88 ( 98.11)
Epoch: [14][ 80/203]	Time 16.905 ( 2.193)	Data 16.316 ( 1.597)	Loss 0.4853984415531158 (0.4728520354371012)	Acc@1  82.81 ( 84.97)	Acc@5  98.44 ( 98.13)
Epoch: [14][ 90/203]	Time  0.512 ( 2.070)	Data  0.000 ( 1.467)	Loss 0.4043286144733429 (0.4682876811577724)	Acc@1  84.38 ( 85.01)	Acc@5 100.00 ( 98.23)
Epoch: [14][100/203]	Time  0.546 ( 2.128)	Data  0.000 ( 1.524)	Loss 0.4602903723716736 (0.4630963604639072)	Acc@1  81.25 ( 85.09)	Acc@5 100.00 ( 98.30)
Epoch: [14][110/203]	Time  0.576 ( 2.011)	Data  0.000 ( 1.403)	Loss 0.4656290411949158 (0.4575758106536693)	Acc@1  84.38 ( 85.30)	Acc@5 100.00 ( 98.37)
Epoch: [14][120/203]	Time  0.500 ( 2.052)	Data  0.000 ( 1.439)	Loss 0.3744336962699890 (0.4530614043070265)	Acc@1  89.06 ( 85.41)	Acc@5  96.88 ( 98.40)
Epoch: [14][130/203]	Time  1.588 ( 2.107)	Data  0.866 ( 1.493)	Loss 0.3717001676559448 (0.4516340605630220)	Acc@1  89.06 ( 85.47)	Acc@5 100.00 ( 98.39)
Epoch: [14][140/203]	Time  0.700 ( 2.009)	Data  0.000 ( 1.391)	Loss 0.7001064419746399 (0.4533875330965570)	Acc@1  79.69 ( 85.39)	Acc@5  95.31 ( 98.39)
Epoch: [14][150/203]	Time  0.630 ( 2.068)	Data  0.000 ( 1.452)	Loss 0.4733246266841888 (0.4542555787310695)	Acc@1  79.69 ( 85.30)	Acc@5 100.00 ( 98.45)
Epoch: [14][160/203]	Time 18.277 ( 2.084)	Data 17.688 ( 1.472)	Loss 0.5251222252845764 (0.4540272319909208)	Acc@1  78.12 ( 85.30)	Acc@5  98.44 ( 98.47)
Epoch: [14][170/203]	Time  0.766 ( 2.033)	Data  0.001 ( 1.421)	Loss 0.5530334115028381 (0.4533654897533662)	Acc@1  84.38 ( 85.30)	Acc@5  93.75 ( 98.46)
Epoch: [14][180/203]	Time  1.189 ( 2.076)	Data  0.685 ( 1.466)	Loss 0.3881474137306213 (0.4559257213252684)	Acc@1  84.38 ( 85.15)	Acc@5 100.00 ( 98.47)
Epoch: [14][190/203]	Time  0.608 ( 2.001)	Data  0.000 ( 1.389)	Loss 0.4144641458988190 (0.4549171564154600)	Acc@1  89.06 ( 85.15)	Acc@5  98.44 ( 98.49)
Epoch: [14][200/203]	Time  0.528 ( 2.035)	Data  0.000 ( 1.424)	Loss 0.5455287694931030 (0.4562779289128175)	Acc@1  79.69 ( 85.07)	Acc@5  93.75 ( 98.46)
epoch: 14, Avg_Loss 0.4547985999895434
Test: [ 0/51]	Time 24.485 (24.485)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.44)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.174 ( 2.865)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  60.94 ( 68.61)	Acc@5  71.88 ( 80.97)
Test: [20/51]	Time  0.152 ( 2.720)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 66.96)	Acc@5  85.94 ( 81.18)
Test: [30/51]	Time  0.135 ( 1.887)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 66.33)	Acc@5  81.25 ( 80.95)
Test: [40/51]	Time  0.126 ( 2.004)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 66.96)	Acc@5  90.62 ( 81.59)
Test: [50/51]	Time  0.197 ( 2.002)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.55 ( 66.48)	Acc@5  72.73 ( 81.84)
 * Acc@1 66.482 Acc@5 81.843
Epoch: [15][  0/203]	Time 34.478 (34.478)	Data 33.742 (33.742)	Loss 0.4744869470596313 (0.4744869470596313)	Acc@1  84.38 ( 84.38)	Acc@5  98.44 ( 98.44)
Epoch: [15][ 10/203]	Time  0.678 ( 3.734)	Data  0.001 ( 3.097)	Loss 0.3907910585403442 (0.4896618317474019)	Acc@1  90.62 ( 84.38)	Acc@5  96.88 ( 98.01)
Epoch: [15][ 20/203]	Time  0.637 ( 3.089)	Data  0.000 ( 2.439)	Loss 0.4795995354652405 (0.4571508339473179)	Acc@1  79.69 ( 85.04)	Acc@5 100.00 ( 98.21)
Epoch: [15][ 30/203]	Time  0.522 ( 2.276)	Data  0.000 ( 1.652)	Loss 0.4073241353034973 (0.4249392315264671)	Acc@1  92.19 ( 86.39)	Acc@5 100.00 ( 98.54)
Epoch: [15][ 40/203]	Time  0.526 ( 2.394)	Data  0.000 ( 1.763)	Loss 0.4163136780261993 (0.4359602757343432)	Acc@1  84.38 ( 86.24)	Acc@5 100.00 ( 98.21)
Epoch: [15][ 50/203]	Time  1.408 ( 2.473)	Data  0.548 ( 1.837)	Loss 0.3807069063186646 (0.4288276705671759)	Acc@1  89.06 ( 86.58)	Acc@5  98.44 ( 98.19)
Epoch: [15][ 60/203]	Time  0.508 ( 2.193)	Data  0.000 ( 1.543)	Loss 0.5737397670745850 (0.4318702931775422)	Acc@1  76.56 ( 86.30)	Acc@5  98.44 ( 98.10)
Epoch: [15][ 70/203]	Time  0.614 ( 2.528)	Data  0.000 ( 1.885)	Loss 0.3802635669708252 (0.4284724444150925)	Acc@1  85.94 ( 86.55)	Acc@5 100.00 ( 98.11)
Epoch: [15][ 80/203]	Time 19.849 ( 2.530)	Data 19.037 ( 1.887)	Loss 0.3856949806213379 (0.4296467872681441)	Acc@1  89.06 ( 86.52)	Acc@5  98.44 ( 98.19)
Epoch: [15][ 90/203]	Time  0.558 ( 2.319)	Data  0.000 ( 1.680)	Loss 0.3346517980098724 (0.4228442794346547)	Acc@1  92.19 ( 86.69)	Acc@5  98.44 ( 98.33)
Epoch: [15][100/203]	Time  0.690 ( 2.361)	Data  0.000 ( 1.725)	Loss 0.3764665424823761 (0.4210645109415054)	Acc@1  87.50 ( 86.77)	Acc@5  98.44 ( 98.36)
Epoch: [15][110/203]	Time  0.606 ( 2.217)	Data  0.000 ( 1.583)	Loss 0.2712591290473938 (0.4188451472971890)	Acc@1  90.62 ( 86.80)	Acc@5 100.00 ( 98.40)
Epoch: [15][120/203]	Time  0.558 ( 2.265)	Data  0.000 ( 1.637)	Loss 0.4540890753269196 (0.4147490678001041)	Acc@1  87.50 ( 86.93)	Acc@5  96.88 ( 98.41)
Epoch: [15][130/203]	Time  2.387 ( 2.289)	Data  1.640 ( 1.662)	Loss 0.3388498723506927 (0.4095166797628840)	Acc@1  89.06 ( 87.08)	Acc@5  98.44 ( 98.43)
Epoch: [15][140/203]	Time  0.638 ( 2.198)	Data  0.000 ( 1.575)	Loss 0.3372689187526703 (0.4058667742614205)	Acc@1  90.62 ( 87.25)	Acc@5  98.44 ( 98.48)
Epoch: [15][150/203]	Time  0.526 ( 2.242)	Data  0.000 ( 1.617)	Loss 0.4414846003055573 (0.4058093566768217)	Acc@1  87.50 ( 87.20)	Acc@5 100.00 ( 98.53)
Epoch: [15][160/203]	Time 14.981 ( 2.231)	Data 14.406 ( 1.611)	Loss 0.3511871397495270 (0.4064595275413916)	Acc@1  92.19 ( 87.18)	Acc@5  96.88 ( 98.49)
Epoch: [15][170/203]	Time  0.561 ( 2.185)	Data  0.001 ( 1.566)	Loss 0.4209857881069183 (0.4085804075874083)	Acc@1  89.06 ( 87.06)	Acc@5 100.00 ( 98.52)
Epoch: [15][180/203]	Time  0.595 ( 2.209)	Data  0.000 ( 1.593)	Loss 0.5232300162315369 (0.4092557191519448)	Acc@1  85.94 ( 87.02)	Acc@5  96.88 ( 98.52)
Epoch: [15][190/203]	Time  0.567 ( 2.140)	Data  0.000 ( 1.527)	Loss 0.4209240674972534 (0.4085688697105927)	Acc@1  89.06 ( 86.99)	Acc@5  98.44 ( 98.54)
Epoch: [15][200/203]	Time  0.640 ( 2.157)	Data  0.000 ( 1.541)	Loss 0.4464463591575623 (0.4109152387920303)	Acc@1  87.50 ( 86.89)	Acc@5  96.88 ( 98.53)
epoch: 15, Avg_Loss 0.4118572554271209
Test: [ 0/51]	Time 28.037 (28.037)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  53.12 ( 53.12)	Acc@5  81.25 ( 81.25)
Test: [10/51]	Time  0.139 ( 2.817)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 53.27)	Acc@5  65.62 ( 75.71)
Test: [20/51]	Time  0.192 ( 2.495)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  54.69 ( 52.16)	Acc@5  76.56 ( 75.82)
Test: [30/51]	Time  0.160 ( 1.738)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  57.81 ( 52.17)	Acc@5  71.88 ( 76.16)
Test: [40/51]	Time  0.141 ( 1.838)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  46.88 ( 51.68)	Acc@5  75.00 ( 75.69)
Test: [50/51]	Time  0.118 ( 1.887)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  58.18 ( 51.52)	Acc@5  80.00 ( 76.28)
 * Acc@1 51.521 Acc@5 76.283
Epoch: [16][  0/203]	Time 31.477 (31.477)	Data 30.786 (30.786)	Loss 0.3551652729511261 (0.3551652729511261)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [16][ 10/203]	Time  0.557 ( 3.367)	Data  0.001 ( 2.799)	Loss 0.3545214831829071 (0.3744149763475765)	Acc@1  90.62 ( 88.64)	Acc@5 100.00 ( 98.72)
Epoch: [16][ 20/203]	Time  0.626 ( 3.045)	Data  0.000 ( 2.474)	Loss 0.5464195013046265 (0.3777653780721483)	Acc@1  85.94 ( 88.47)	Acc@5  93.75 ( 98.66)
Epoch: [16][ 30/203]	Time  1.691 ( 2.359)	Data  0.001 ( 1.676)	Loss 0.2961374819278717 (0.3718742766687947)	Acc@1  90.62 ( 88.36)	Acc@5 100.00 ( 98.69)
Epoch: [16][ 40/203]	Time  0.763 ( 2.383)	Data  0.000 ( 1.652)	Loss 0.6559187173843384 (0.3937777836875218)	Acc@1  78.12 ( 87.73)	Acc@5 100.00 ( 98.51)
Epoch: [16][ 50/203]	Time  4.857 ( 2.425)	Data  4.149 ( 1.715)	Loss 0.3852815330028534 (0.4040034562349319)	Acc@1  87.50 ( 87.32)	Acc@5 100.00 ( 98.47)
Epoch: [16][ 60/203]	Time  0.850 ( 2.134)	Data  0.000 ( 1.434)	Loss 0.5036994218826294 (0.3997181077472499)	Acc@1  84.38 ( 87.32)	Acc@5  98.44 ( 98.51)
Epoch: [16][ 70/203]	Time  0.607 ( 2.198)	Data  0.000 ( 1.508)	Loss 0.5317559242248535 (0.4005955604600235)	Acc@1  82.81 ( 87.26)	Acc@5  98.44 ( 98.44)
Epoch: [16][ 80/203]	Time 17.346 ( 2.203)	Data 16.403 ( 1.524)	Loss 0.2771220803260803 (0.3949208539209248)	Acc@1  89.06 ( 87.38)	Acc@5 100.00 ( 98.53)
Epoch: [16][ 90/203]	Time  0.578 ( 2.067)	Data  0.000 ( 1.389)	Loss 0.2646679878234863 (0.3911070044224079)	Acc@1  92.19 ( 87.48)	Acc@5 100.00 ( 98.59)
Epoch: [16][100/203]	Time  0.580 ( 2.132)	Data  0.000 ( 1.465)	Loss 0.2794429063796997 (0.3847071743837678)	Acc@1  89.06 ( 87.73)	Acc@5 100.00 ( 98.59)
Epoch: [16][110/203]	Time  0.698 ( 2.000)	Data  0.001 ( 1.333)	Loss 0.4926841557025909 (0.3837041593081242)	Acc@1  84.38 ( 87.67)	Acc@5  96.88 ( 98.59)
Epoch: [16][120/203]	Time  0.597 ( 2.049)	Data  0.000 ( 1.381)	Loss 0.3498646914958954 (0.3815448210259114)	Acc@1  87.50 ( 87.65)	Acc@5 100.00 ( 98.64)
Epoch: [16][130/203]	Time  1.305 ( 2.087)	Data  0.717 ( 1.429)	Loss 0.4592725634574890 (0.3806328263901572)	Acc@1  85.94 ( 87.79)	Acc@5 100.00 ( 98.66)
Epoch: [16][140/203]	Time  0.568 ( 2.009)	Data  0.000 ( 1.354)	Loss 0.3924630284309387 (0.3798919948914372)	Acc@1  84.38 ( 87.92)	Acc@5 100.00 ( 98.66)
Epoch: [16][150/203]	Time  0.566 ( 2.066)	Data  0.000 ( 1.416)	Loss 0.3723449110984802 (0.3784206662549088)	Acc@1  89.06 ( 87.93)	Acc@5 100.00 ( 98.72)
Epoch: [16][160/203]	Time 18.183 ( 2.081)	Data 17.450 ( 1.436)	Loss 0.2672844529151917 (0.3788287296243336)	Acc@1  90.62 ( 87.89)	Acc@5  98.44 ( 98.74)
Epoch: [16][170/203]	Time  0.512 ( 2.023)	Data  0.001 ( 1.385)	Loss 0.4961215853691101 (0.3788666726030104)	Acc@1  85.94 ( 87.85)	Acc@5  98.44 ( 98.77)
Epoch: [16][180/203]	Time  4.619 ( 2.075)	Data  3.986 ( 1.441)	Loss 0.3682870864868164 (0.3778589375275933)	Acc@1  85.94 ( 87.85)	Acc@5 100.00 ( 98.78)
Epoch: [16][190/203]	Time  0.620 ( 1.998)	Data  0.000 ( 1.366)	Loss 0.4465849101543427 (0.3790650907611348)	Acc@1  87.50 ( 87.83)	Acc@5  98.44 ( 98.76)
Epoch: [16][200/203]	Time  0.546 ( 2.059)	Data  0.000 ( 1.427)	Loss 0.3576511144638062 (0.3786716639847305)	Acc@1  89.06 ( 87.79)	Acc@5  98.44 ( 98.78)
epoch: 16, Avg_Loss 0.37733815514982627
Test: [ 0/51]	Time 19.705 (19.705)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 71.88)	Acc@5  84.38 ( 84.38)
Test: [10/51]	Time  0.150 ( 2.270)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 74.29)	Acc@5  92.19 ( 88.35)
Test: [20/51]	Time  2.270 ( 2.118)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 73.88)	Acc@5  85.94 ( 89.66)
Test: [30/51]	Time  0.127 ( 1.481)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 73.19)	Acc@5  84.38 ( 88.96)
Test: [40/51]	Time  0.136 ( 1.714)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 73.48)	Acc@5  85.94 ( 89.44)
Test: [50/51]	Time  0.693 ( 1.613)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  74.55 ( 73.46)	Acc@5  90.91 ( 89.49)
 * Acc@1 73.456 Acc@5 89.493
Epoch: [17][  0/203]	Time 31.141 (31.141)	Data 30.410 (30.410)	Loss 0.3921014964580536 (0.3921014964580536)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Epoch: [17][ 10/203]	Time  0.519 ( 3.498)	Data  0.001 ( 2.902)	Loss 0.5065932869911194 (0.3488710454919122)	Acc@1  84.38 ( 89.35)	Acc@5  95.31 ( 98.86)
Epoch: [17][ 20/203]	Time  0.610 ( 3.323)	Data  0.000 ( 2.715)	Loss 0.3290771842002869 (0.3407368106501443)	Acc@1  87.50 ( 89.58)	Acc@5 100.00 ( 98.96)
Epoch: [17][ 30/203]	Time  0.820 ( 2.719)	Data  0.000 ( 2.101)	Loss 0.4782952666282654 (0.3498853493121363)	Acc@1  79.69 ( 89.01)	Acc@5  98.44 ( 98.99)
Epoch: [17][ 40/203]	Time  0.612 ( 3.219)	Data  0.000 ( 2.592)	Loss 0.2601054012775421 (0.3436352145381090)	Acc@1  93.75 ( 89.18)	Acc@5  98.44 ( 98.93)
Epoch: [17][ 50/203]	Time  0.517 ( 3.167)	Data  0.000 ( 2.550)	Loss 0.6599587798118591 (0.3531318245565190)	Acc@1  81.25 ( 88.76)	Acc@5  96.88 ( 98.87)
Epoch: [17][ 60/203]	Time  0.602 ( 2.846)	Data  0.000 ( 2.210)	Loss 0.3611043691635132 (0.3576429894224542)	Acc@1  87.50 ( 88.58)	Acc@5  98.44 ( 98.85)
Epoch: [17][ 70/203]	Time  1.770 ( 2.789)	Data  1.047 ( 2.135)	Loss 0.3652535974979401 (0.3518691824775347)	Acc@1  89.06 ( 88.93)	Acc@5  98.44 ( 98.81)
Epoch: [17][ 80/203]	Time 18.209 ( 2.785)	Data 17.619 ( 2.133)	Loss 0.3822298049926758 (0.3510978262365600)	Acc@1  85.94 ( 88.79)	Acc@5 100.00 ( 98.86)
Epoch: [17][ 90/203]	Time  0.574 ( 2.594)	Data  0.001 ( 1.947)	Loss 0.2397172451019287 (0.3427554226511128)	Acc@1  93.75 ( 89.17)	Acc@5 100.00 ( 98.88)
Epoch: [17][100/203]	Time  0.527 ( 2.581)	Data  0.000 ( 1.939)	Loss 0.6412059068679810 (0.3459503950163870)	Acc@1  85.94 ( 89.09)	Acc@5  96.88 ( 98.86)
Epoch: [17][110/203]	Time  0.573 ( 2.475)	Data  0.000 ( 1.839)	Loss 0.4268704354763031 (0.3504369789147162)	Acc@1  85.94 ( 88.98)	Acc@5  98.44 ( 98.83)
Epoch: [17][120/203]	Time  0.530 ( 2.655)	Data  0.000 ( 2.026)	Loss 0.2423826754093170 (0.3498070268345273)	Acc@1  93.75 ( 89.04)	Acc@5  98.44 ( 98.85)
Epoch: [17][130/203]	Time  0.605 ( 2.782)	Data  0.000 ( 2.155)	Loss 0.4106201827526093 (0.3530751351864284)	Acc@1  84.38 ( 88.84)	Acc@5 100.00 ( 98.91)
Epoch: [17][140/203]	Time  0.525 ( 2.665)	Data  0.000 ( 2.043)	Loss 0.2107509225606918 (0.3506462456698113)	Acc@1  92.19 ( 88.92)	Acc@5 100.00 ( 98.95)
Epoch: [17][150/203]	Time  0.651 ( 2.803)	Data  0.000 ( 2.181)	Loss 0.4127921760082245 (0.3505556095909599)	Acc@1  89.06 ( 88.89)	Acc@5  96.88 ( 98.93)
Epoch: [17][160/203]	Time  9.347 ( 2.727)	Data  8.695 ( 2.108)	Loss 0.4255626499652863 (0.3488962120891358)	Acc@1  90.62 ( 88.92)	Acc@5  93.75 ( 98.93)
Epoch: [17][170/203]	Time  0.538 ( 2.682)	Data  0.001 ( 2.065)	Loss 0.3337779641151428 (0.3509040052256389)	Acc@1  87.50 ( 88.78)	Acc@5 100.00 ( 98.92)
Epoch: [17][180/203]	Time  0.574 ( 2.702)	Data  0.000 ( 2.087)	Loss 0.2168324887752533 (0.3490186071856904)	Acc@1  93.75 ( 88.86)	Acc@5 100.00 ( 98.94)
Epoch: [17][190/203]	Time  1.028 ( 2.593)	Data  0.502 ( 1.981)	Loss 0.2636885941028595 (0.3502856077948166)	Acc@1  92.19 ( 88.83)	Acc@5 100.00 ( 98.94)
Epoch: [17][200/203]	Time  0.612 ( 2.592)	Data  0.000 ( 1.977)	Loss 0.3262856006622314 (0.3492716563429998)	Acc@1  92.19 ( 88.83)	Acc@5  98.44 ( 98.93)
epoch: 17, Avg_Loss 0.34964023310269043
Test: [ 0/51]	Time 23.254 (23.254)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 64.06)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.151 ( 2.361)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 64.20)	Acc@5  82.81 ( 83.52)
Test: [20/51]	Time  0.141 ( 2.338)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 66.37)	Acc@5  82.81 ( 84.30)
Test: [30/51]	Time  0.139 ( 1.628)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 67.19)	Acc@5  81.25 ( 84.63)
Test: [40/51]	Time  0.130 ( 1.746)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 67.26)	Acc@5  85.94 ( 84.87)
Test: [50/51]	Time  0.160 ( 1.803)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.27 ( 67.00)	Acc@5  81.82 ( 85.10)
 * Acc@1 67.005 Acc@5 85.100
Epoch: [18][  0/203]	Time 49.858 (49.858)	Data 49.244 (49.244)	Loss 0.2332862913608551 (0.2332862913608551)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [18][ 10/203]	Time  0.641 ( 5.325)	Data  0.001 ( 4.716)	Loss 0.3378754854202271 (0.3274915706027638)	Acc@1  89.06 ( 88.35)	Acc@5  98.44 ( 99.29)
Epoch: [18][ 20/203]	Time  2.221 ( 4.094)	Data  1.626 ( 3.490)	Loss 0.4995178878307343 (0.3377878389188221)	Acc@1  84.38 ( 88.91)	Acc@5  96.88 ( 99.26)
Epoch: [18][ 30/203]	Time  0.714 ( 2.982)	Data  0.000 ( 2.364)	Loss 0.2060621976852417 (0.3433037568484583)	Acc@1  95.31 ( 88.91)	Acc@5 100.00 ( 99.04)
Epoch: [18][ 40/203]	Time  0.565 ( 2.903)	Data  0.000 ( 2.291)	Loss 0.2328640222549438 (0.3350590133085484)	Acc@1  93.75 ( 89.37)	Acc@5  98.44 ( 99.05)
Epoch: [18][ 50/203]	Time  0.739 ( 2.827)	Data  0.000 ( 2.216)	Loss 0.4347406625747681 (0.3360236450737598)	Acc@1  90.62 ( 89.52)	Acc@5  96.88 ( 98.87)
Epoch: [18][ 60/203]	Time  0.625 ( 2.469)	Data  0.000 ( 1.853)	Loss 0.4167610704898834 (0.3343570757596219)	Acc@1  89.06 ( 89.45)	Acc@5 100.00 ( 99.00)
Epoch: [18][ 70/203]	Time  0.545 ( 2.504)	Data  0.000 ( 1.893)	Loss 0.3601483404636383 (0.3347500822913479)	Acc@1  87.50 ( 89.41)	Acc@5 100.00 ( 99.03)
Epoch: [18][ 80/203]	Time 18.305 ( 2.484)	Data 17.770 ( 1.879)	Loss 0.4043464064598083 (0.3474015260552182)	Acc@1  90.62 ( 88.91)	Acc@5 100.00 ( 98.98)
Epoch: [18][ 90/203]	Time  0.515 ( 2.319)	Data  0.000 ( 1.723)	Loss 0.1619394868612289 (0.3449242142858086)	Acc@1  93.75 ( 88.96)	Acc@5 100.00 ( 99.00)
Epoch: [18][100/203]	Time  0.764 ( 2.367)	Data  0.000 ( 1.768)	Loss 0.4614329338073730 (0.3491453330705662)	Acc@1  84.38 ( 88.63)	Acc@5  96.88 ( 98.98)
Epoch: [18][110/203]	Time  0.504 ( 2.207)	Data  0.000 ( 1.609)	Loss 0.2357689738273621 (0.3493339258271295)	Acc@1  92.19 ( 88.64)	Acc@5 100.00 ( 98.96)
Epoch: [18][120/203]	Time  0.540 ( 2.244)	Data  0.000 ( 1.646)	Loss 0.4490249752998352 (0.3549006961840243)	Acc@1  82.81 ( 88.46)	Acc@5 100.00 ( 98.95)
Epoch: [18][130/203]	Time  0.601 ( 2.288)	Data  0.000 ( 1.691)	Loss 0.3144890964031219 (0.3545779328764850)	Acc@1  90.62 ( 88.50)	Acc@5 100.00 ( 98.96)
Epoch: [18][140/203]	Time  0.618 ( 2.169)	Data  0.000 ( 1.571)	Loss 0.5026530027389526 (0.3542369198291860)	Acc@1  85.94 ( 88.52)	Acc@5  96.88 ( 98.95)
Epoch: [18][150/203]	Time  0.556 ( 2.201)	Data  0.000 ( 1.599)	Loss 0.4498488306999207 (0.3536753109748790)	Acc@1  84.38 ( 88.47)	Acc@5  96.88 ( 98.99)
Epoch: [18][160/203]	Time 22.850 ( 2.237)	Data 22.101 ( 1.637)	Loss 0.2556200027465820 (0.3526833211968404)	Acc@1  93.75 ( 88.54)	Acc@5  98.44 ( 98.94)
Epoch: [18][170/203]	Time  0.530 ( 2.140)	Data  0.001 ( 1.541)	Loss 0.3251663148403168 (0.3534968139832480)	Acc@1  90.62 ( 88.54)	Acc@5  98.44 ( 98.91)
Epoch: [18][180/203]	Time  0.631 ( 2.176)	Data  0.000 ( 1.574)	Loss 0.3705176115036011 (0.3555608880783313)	Acc@1  87.50 ( 88.45)	Acc@5 100.00 ( 98.94)
Epoch: [18][190/203]	Time  0.538 ( 2.092)	Data  0.000 ( 1.492)	Loss 0.3461970388889313 (0.3543756552703717)	Acc@1  89.06 ( 88.50)	Acc@5  98.44 ( 98.94)
Epoch: [18][200/203]	Time  0.709 ( 2.148)	Data  0.000 ( 1.542)	Loss 0.2462014555931091 (0.3523244371461631)	Acc@1  93.75 ( 88.55)	Acc@5  98.44 ( 98.95)
epoch: 18, Avg_Loss 0.3517175533354576
Test: [ 0/51]	Time 26.176 (26.176)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.44)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.134 ( 2.627)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 70.45)	Acc@5  89.06 ( 84.66)
Test: [20/51]	Time  0.127 ( 2.471)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 70.01)	Acc@5  89.06 ( 83.71)
Test: [30/51]	Time  0.138 ( 1.823)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 70.36)	Acc@5  85.94 ( 83.57)
Test: [40/51]	Time  0.142 ( 1.970)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 70.66)	Acc@5  89.06 ( 83.77)
Test: [50/51]	Time  0.118 ( 1.932)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  69.09 ( 70.97)	Acc@5  85.45 ( 84.52)
 * Acc@1 70.968 Acc@5 84.516
Epoch: [19][  0/203]	Time 31.119 (31.119)	Data 30.414 (30.414)	Loss 0.1951969563961029 (0.1951969563961029)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [19][ 10/203]	Time  0.576 ( 3.418)	Data  0.001 ( 2.876)	Loss 0.3021683096885681 (0.3217824860052629)	Acc@1  90.62 ( 88.92)	Acc@5  98.44 ( 99.01)
Epoch: [19][ 20/203]	Time  0.542 ( 3.119)	Data  0.000 ( 2.535)	Loss 0.2210860252380371 (0.3117534135069166)	Acc@1  95.31 ( 89.66)	Acc@5  98.44 ( 99.11)
Epoch: [19][ 30/203]	Time  0.542 ( 2.305)	Data  0.001 ( 1.717)	Loss 0.3405974805355072 (0.3082335360588566)	Acc@1  87.50 ( 90.02)	Acc@5  98.44 ( 99.24)
Epoch: [19][ 40/203]	Time  0.543 ( 2.413)	Data  0.000 ( 1.821)	Loss 0.2447792291641235 (0.3028408739624954)	Acc@1  90.62 ( 90.05)	Acc@5 100.00 ( 99.24)
Epoch: [19][ 50/203]	Time  0.674 ( 2.883)	Data  0.000 ( 2.298)	Loss 0.3353433012962341 (0.3181527890995437)	Acc@1  85.94 ( 89.77)	Acc@5 100.00 ( 99.11)
Epoch: [19][ 60/203]	Time  0.496 ( 2.507)	Data  0.000 ( 1.922)	Loss 0.4517059326171875 (0.3271072890426292)	Acc@1  85.94 ( 89.47)	Acc@5 100.00 ( 99.15)
Epoch: [19][ 70/203]	Time  0.503 ( 2.921)	Data  0.000 ( 2.340)	Loss 0.2927626669406891 (0.3309509227393378)	Acc@1  85.94 ( 89.26)	Acc@5 100.00 ( 99.19)
Epoch: [19][ 80/203]	Time  5.152 ( 2.686)	Data  4.588 ( 2.109)	Loss 0.3186205625534058 (0.3364102904811317)	Acc@1  85.94 ( 89.10)	Acc@5  98.44 ( 99.17)
Epoch: [19][ 90/203]	Time  0.538 ( 2.670)	Data  0.000 ( 2.095)	Loss 0.3060248494148254 (0.3427120276859829)	Acc@1  92.19 ( 88.89)	Acc@5  98.44 ( 99.11)
Epoch: [19][100/203]	Time  0.579 ( 2.714)	Data  0.001 ( 2.133)	Loss 0.3211838304996490 (0.3458643126310689)	Acc@1  87.50 ( 88.71)	Acc@5 100.00 ( 99.03)
Epoch: [19][110/203]	Time  0.517 ( 2.527)	Data  0.000 ( 1.941)	Loss 0.1815019845962524 (0.3465089391212205)	Acc@1  93.75 ( 88.70)	Acc@5  98.44 ( 98.94)
Epoch: [19][120/203]	Time  0.542 ( 2.537)	Data  0.000 ( 1.955)	Loss 0.3127470612525940 (0.3406230260517972)	Acc@1  89.06 ( 88.95)	Acc@5 100.00 ( 98.99)
Epoch: [19][130/203]	Time  0.707 ( 2.584)	Data  0.000 ( 1.997)	Loss 0.2941286861896515 (0.3372600565429862)	Acc@1  90.62 ( 88.97)	Acc@5  98.44 ( 99.03)
Epoch: [19][140/203]	Time  0.580 ( 2.441)	Data  0.000 ( 1.855)	Loss 0.2831770777702332 (0.3403712339857791)	Acc@1  92.19 ( 88.81)	Acc@5 100.00 ( 99.02)
Epoch: [19][150/203]	Time  0.598 ( 2.466)	Data  0.001 ( 1.879)	Loss 0.3912063241004944 (0.3408808117078629)	Acc@1  84.38 ( 88.82)	Acc@5 100.00 ( 98.98)
Epoch: [19][160/203]	Time  0.544 ( 2.348)	Data  0.000 ( 1.762)	Loss 0.4498606026172638 (0.3384495563573719)	Acc@1  87.50 ( 88.94)	Acc@5  98.44 ( 98.98)
Epoch: [19][170/203]	Time  0.607 ( 2.385)	Data  0.001 ( 1.798)	Loss 0.2091255336999893 (0.3351458060114007)	Acc@1  92.19 ( 89.00)	Acc@5 100.00 ( 99.01)
Epoch: [19][180/203]	Time  0.561 ( 2.393)	Data  0.000 ( 1.803)	Loss 0.3387151658535004 (0.3342554613289254)	Acc@1  85.94 ( 89.01)	Acc@5 100.00 ( 99.02)
Epoch: [19][190/203]	Time  0.540 ( 2.297)	Data  0.000 ( 1.708)	Loss 0.3467644751071930 (0.3365176306423092)	Acc@1  87.50 ( 88.95)	Acc@5  98.44 ( 98.99)
Epoch: [19][200/203]	Time  0.647 ( 2.312)	Data  0.000 ( 1.725)	Loss 0.4532414674758911 (0.3376584188336164)	Acc@1  84.38 ( 88.91)	Acc@5 100.00 ( 98.98)
epoch: 19, Avg_Loss 0.33788703745368664
Test: [ 0/51]	Time 25.652 (25.652)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 70.31)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.129 ( 2.472)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 65.06)	Acc@5  87.50 ( 83.81)
Test: [20/51]	Time  0.128 ( 2.385)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 64.29)	Acc@5  78.12 ( 82.14)
Test: [30/51]	Time  0.125 ( 1.767)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 64.36)	Acc@5  87.50 ( 82.31)
Test: [40/51]	Time  1.766 ( 1.901)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 64.44)	Acc@5  81.25 ( 82.66)
Test: [50/51]	Time  0.132 ( 1.870)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.91 ( 64.45)	Acc@5  89.09 ( 82.67)
 * Acc@1 64.455 Acc@5 82.673
Epoch: [20][  0/203]	Time 33.153 (33.153)	Data 32.356 (32.356)	Loss 0.6754027009010315 (0.6754027009010315)	Acc@1  78.12 ( 78.12)	Acc@5  98.44 ( 98.44)
Epoch: [20][ 10/203]	Time  0.579 ( 3.525)	Data  0.001 ( 2.942)	Loss 0.3437332212924957 (0.3959916748783805)	Acc@1  89.06 ( 87.50)	Acc@5  98.44 ( 99.15)
Epoch: [20][ 20/203]	Time  0.549 ( 3.286)	Data  0.000 ( 2.711)	Loss 0.3058834969997406 (0.3704479634761810)	Acc@1  92.19 ( 88.69)	Acc@5  98.44 ( 99.03)
Epoch: [20][ 30/203]	Time  0.625 ( 2.413)	Data  0.000 ( 1.836)	Loss 0.3439047932624817 (0.3494845926761627)	Acc@1  87.50 ( 89.47)	Acc@5  98.44 ( 98.99)
Epoch: [20][ 40/203]	Time  0.514 ( 2.535)	Data  0.000 ( 1.952)	Loss 0.2841711938381195 (0.3317282330699083)	Acc@1  89.06 ( 89.63)	Acc@5 100.00 ( 99.16)
Epoch: [20][ 50/203]	Time  0.911 ( 2.626)	Data  0.000 ( 2.030)	Loss 0.3790799677371979 (0.3308272005296221)	Acc@1  84.38 ( 89.61)	Acc@5  98.44 ( 99.08)
Epoch: [20][ 60/203]	Time  0.670 ( 2.312)	Data  0.000 ( 1.697)	Loss 0.3342360854148865 (0.3191970867700264)	Acc@1  89.06 ( 89.88)	Acc@5  96.88 ( 99.15)
Epoch: [20][ 70/203]	Time  0.602 ( 2.409)	Data  0.000 ( 1.774)	Loss 0.4286399483680725 (0.3161282203566860)	Acc@1  85.94 ( 89.99)	Acc@5 100.00 ( 99.08)
Epoch: [20][ 80/203]	Time 38.963 ( 2.663)	Data 38.387 ( 2.029)	Loss 0.5134000182151794 (0.3237665177863321)	Acc@1  79.69 ( 89.70)	Acc@5  98.44 ( 99.00)
Epoch: [20][ 90/203]	Time  0.545 ( 2.489)	Data  0.000 ( 1.866)	Loss 0.4082375168800354 (0.3250219764617773)	Acc@1  90.62 ( 89.70)	Acc@5 100.00 ( 98.99)
Epoch: [20][100/203]	Time  0.541 ( 2.574)	Data  0.000 ( 1.957)	Loss 0.2564232349395752 (0.3194109801903809)	Acc@1  90.62 ( 89.87)	Acc@5 100.00 ( 99.03)
Epoch: [20][110/203]	Time  0.563 ( 2.398)	Data  0.000 ( 1.785)	Loss 0.3761920928955078 (0.3203204373518626)	Acc@1  90.62 ( 89.77)	Acc@5  98.44 ( 99.01)
Epoch: [20][120/203]	Time  0.648 ( 2.447)	Data  0.000 ( 1.825)	Loss 0.3255211710929871 (0.3160505904392762)	Acc@1  87.50 ( 89.89)	Acc@5 100.00 ( 99.04)
Epoch: [20][130/203]	Time  0.696 ( 2.507)	Data  0.000 ( 1.872)	Loss 0.2713755965232849 (0.3181893098672838)	Acc@1  90.62 ( 89.79)	Acc@5 100.00 ( 99.02)
Epoch: [20][140/203]	Time  0.589 ( 2.374)	Data  0.000 ( 1.739)	Loss 0.2361813485622406 (0.3163673673749816)	Acc@1  89.06 ( 89.86)	Acc@5 100.00 ( 99.00)
Epoch: [20][150/203]	Time  0.633 ( 2.477)	Data  0.001 ( 1.841)	Loss 0.4434189200401306 (0.3179950031223676)	Acc@1  87.50 ( 89.85)	Acc@5  98.44 ( 99.03)
Epoch: [20][160/203]	Time 27.798 ( 2.529)	Data 27.182 ( 1.895)	Loss 0.2633415162563324 (0.3148484993610323)	Acc@1  90.62 ( 89.89)	Acc@5 100.00 ( 99.05)
Epoch: [20][170/203]	Time  0.564 ( 2.413)	Data  0.001 ( 1.785)	Loss 0.3435214459896088 (0.3137937493578732)	Acc@1  87.50 ( 89.92)	Acc@5 100.00 ( 99.08)
Epoch: [20][180/203]	Time  0.563 ( 2.450)	Data  0.000 ( 1.824)	Loss 0.3028275370597839 (0.3156343820756970)	Acc@1  90.62 ( 89.89)	Acc@5 100.00 ( 99.05)
Epoch: [20][190/203]	Time  0.585 ( 2.354)	Data  0.000 ( 1.729)	Loss 0.3396148979663849 (0.3155678614817989)	Acc@1  84.38 ( 89.86)	Acc@5  98.44 ( 99.07)
Epoch: [20][200/203]	Time  0.554 ( 2.386)	Data  0.000 ( 1.761)	Loss 0.4363620579242706 (0.3140969227869712)	Acc@1  89.06 ( 89.96)	Acc@5 100.00 ( 99.07)
epoch: 20, Avg_Loss 0.3134686852543812
Test: [ 0/51]	Time 25.495 (25.495)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  59.38 ( 59.38)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.141 ( 2.862)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 65.06)	Acc@5  82.81 ( 82.81)
Test: [20/51]	Time  0.124 ( 2.547)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 67.19)	Acc@5  84.38 ( 84.90)
Test: [30/51]	Time  0.146 ( 1.839)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  60.94 ( 66.28)	Acc@5  79.69 ( 84.58)
Test: [40/51]	Time  0.140 ( 2.011)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  59.38 ( 65.82)	Acc@5  82.81 ( 84.03)
Test: [50/51]	Time  0.108 ( 2.105)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  69.09 ( 65.93)	Acc@5  90.91 ( 84.09)
 * Acc@1 65.929 Acc@5 84.086
Epoch: [21][  0/203]	Time 38.743 (38.743)	Data 38.082 (38.082)	Loss 0.2661333680152893 (0.2661333680152893)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [21][ 10/203]	Time  0.687 ( 4.070)	Data  0.002 ( 3.462)	Loss 0.2744019627571106 (0.2951221262866801)	Acc@1  92.19 ( 90.20)	Acc@5  98.44 ( 99.43)
Epoch: [21][ 20/203]	Time  0.712 ( 3.366)	Data  0.001 ( 2.690)	Loss 0.1573651134967804 (0.2569175508050692)	Acc@1  95.31 ( 91.89)	Acc@5 100.00 ( 99.40)
Epoch: [21][ 30/203]	Time  0.540 ( 2.477)	Data  0.000 ( 1.822)	Loss 0.2308925837278366 (0.2670114787836229)	Acc@1  96.88 ( 91.78)	Acc@5  98.44 ( 99.29)
Epoch: [21][ 40/203]	Time  0.589 ( 2.533)	Data  0.000 ( 1.882)	Loss 0.3735727369785309 (0.2836072821079231)	Acc@1  93.75 ( 91.35)	Acc@5  96.88 ( 99.16)
Epoch: [21][ 50/203]	Time  0.597 ( 2.553)	Data  0.000 ( 1.905)	Loss 0.3950186967849731 (0.2784464650002180)	Acc@1  84.38 ( 91.39)	Acc@5 100.00 ( 99.26)
Epoch: [21][ 60/203]	Time  0.796 ( 2.295)	Data  0.000 ( 1.611)	Loss 0.4017592370510101 (0.2784788618322279)	Acc@1  89.06 ( 91.39)	Acc@5 100.00 ( 99.31)
Epoch: [21][ 70/203]	Time  0.544 ( 2.429)	Data  0.000 ( 1.758)	Loss 0.2665327787399292 (0.2768836598580992)	Acc@1  90.62 ( 91.40)	Acc@5  98.44 ( 99.32)
Epoch: [21][ 80/203]	Time 31.791 ( 2.582)	Data 31.168 ( 1.926)	Loss 0.1980475485324860 (0.2734740111562941)	Acc@1  92.19 ( 91.45)	Acc@5 100.00 ( 99.29)
Epoch: [21][ 90/203]	Time  0.541 ( 2.358)	Data  0.000 ( 1.714)	Loss 0.3044058680534363 (0.2767775296182423)	Acc@1  92.19 ( 91.29)	Acc@5  98.44 ( 99.31)
Epoch: [21][100/203]	Time  0.629 ( 2.595)	Data  0.000 ( 1.959)	Loss 0.1585235744714737 (0.2751290811465518)	Acc@1  96.88 ( 91.31)	Acc@5 100.00 ( 99.30)
Epoch: [21][110/203]	Time  0.516 ( 2.414)	Data  0.000 ( 1.783)	Loss 0.2848873436450958 (0.2759028385888349)	Acc@1  89.06 ( 91.23)	Acc@5  98.44 ( 99.27)
Epoch: [21][120/203]	Time  0.573 ( 2.433)	Data  0.000 ( 1.806)	Loss 0.3101791143417358 (0.2774451696429371)	Acc@1  87.50 ( 91.06)	Acc@5 100.00 ( 99.29)
Epoch: [21][130/203]	Time  0.624 ( 2.488)	Data  0.000 ( 1.864)	Loss 0.1894270330667496 (0.2786880061599135)	Acc@1  96.88 ( 90.99)	Acc@5 100.00 ( 99.32)
Epoch: [21][140/203]	Time  0.540 ( 2.351)	Data  0.000 ( 1.732)	Loss 0.2735986411571503 (0.2805396620686172)	Acc@1  90.62 ( 90.88)	Acc@5 100.00 ( 99.34)
Epoch: [21][150/203]	Time  0.649 ( 2.478)	Data  0.000 ( 1.860)	Loss 0.2190466523170471 (0.2804778880433531)	Acc@1  92.19 ( 90.86)	Acc@5 100.00 ( 99.34)
Epoch: [21][160/203]	Time 35.562 ( 2.579)	Data 35.029 ( 1.962)	Loss 0.3150244355201721 (0.2800971594471369)	Acc@1  87.50 ( 90.87)	Acc@5 100.00 ( 99.33)
Epoch: [21][170/203]	Time  0.540 ( 2.460)	Data  0.001 ( 1.847)	Loss 0.3224303126335144 (0.2802255633804533)	Acc@1  92.19 ( 90.86)	Acc@5 100.00 ( 99.32)
Epoch: [21][180/203]	Time  0.606 ( 2.468)	Data  0.000 ( 1.856)	Loss 0.2647719979286194 (0.2817389967527179)	Acc@1  90.62 ( 90.77)	Acc@5  98.44 ( 99.33)
Epoch: [21][190/203]	Time  0.533 ( 2.373)	Data  0.000 ( 1.759)	Loss 0.3536607027053833 (0.2813824288820097)	Acc@1  89.06 ( 90.82)	Acc@5 100.00 ( 99.30)
Epoch: [21][200/203]	Time  0.617 ( 2.405)	Data  0.000 ( 1.790)	Loss 0.2357508391141891 (0.2820489242747055)	Acc@1  90.62 ( 90.79)	Acc@5 100.00 ( 99.32)
epoch: 21, Avg_Loss 0.28342419532425883
Test: [ 0/51]	Time 26.617 (26.617)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.44)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.124 ( 2.578)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 78.41)	Acc@5  92.19 ( 90.48)
Test: [20/51]	Time  0.131 ( 2.562)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 77.68)	Acc@5  84.38 ( 90.10)
Test: [30/51]	Time  0.152 ( 1.817)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 77.72)	Acc@5  89.06 ( 89.67)
Test: [40/51]	Time  0.132 ( 1.933)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 77.74)	Acc@5  90.62 ( 89.56)
Test: [50/51]	Time  0.131 ( 1.928)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  63.64 ( 77.54)	Acc@5  81.82 ( 89.31)
 * Acc@1 77.542 Acc@5 89.309
Epoch: [22][  0/203]	Time 30.812 (30.812)	Data 29.991 (29.991)	Loss 0.2116551548242569 (0.2116551548242569)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [22][ 10/203]	Time  0.573 ( 3.419)	Data  0.000 ( 2.757)	Loss 0.2344571053981781 (0.2600375847382979)	Acc@1  92.19 ( 91.05)	Acc@5  98.44 ( 99.72)
Epoch: [22][ 20/203]	Time  0.626 ( 3.191)	Data  0.000 ( 2.538)	Loss 0.2969724535942078 (0.2535570327724729)	Acc@1  85.94 ( 91.37)	Acc@5 100.00 ( 99.70)
Epoch: [22][ 30/203]	Time  0.640 ( 2.351)	Data  0.000 ( 1.719)	Loss 0.4390617907047272 (0.2572829877176592)	Acc@1  84.38 ( 91.48)	Acc@5  98.44 ( 99.55)
Epoch: [22][ 40/203]	Time  0.629 ( 2.718)	Data  0.000 ( 2.069)	Loss 0.3687930405139923 (0.2684208121968479)	Acc@1  82.81 ( 91.08)	Acc@5  98.44 ( 99.39)
Epoch: [22][ 50/203]	Time  2.026 ( 2.731)	Data  1.502 ( 2.096)	Loss 0.2289748936891556 (0.2679117324889875)	Acc@1  92.19 ( 90.99)	Acc@5 100.00 ( 99.33)
Epoch: [22][ 60/203]	Time  0.542 ( 2.387)	Data  0.000 ( 1.763)	Loss 0.3439028561115265 (0.2688416086259435)	Acc@1  92.19 ( 91.03)	Acc@5  95.31 ( 99.33)
Epoch: [22][ 70/203]	Time  0.546 ( 2.485)	Data  0.000 ( 1.868)	Loss 0.1958863139152527 (0.2694798399445037)	Acc@1  93.75 ( 91.15)	Acc@5 100.00 ( 99.41)
Epoch: [22][ 80/203]	Time 15.481 ( 2.433)	Data 14.910 ( 1.821)	Loss 0.2701507210731506 (0.2772427147921221)	Acc@1  95.31 ( 90.99)	Acc@5  98.44 ( 99.36)
Epoch: [22][ 90/203]	Time  0.570 ( 2.302)	Data  0.000 ( 1.685)	Loss 0.3252602815628052 (0.2776367383507582)	Acc@1  90.62 ( 91.00)	Acc@5  98.44 ( 99.36)
Epoch: [22][100/203]	Time  0.598 ( 2.333)	Data  0.000 ( 1.720)	Loss 0.1953991800546646 (0.2793488609466222)	Acc@1  90.62 ( 90.83)	Acc@5  98.44 ( 99.33)
Epoch: [22][110/203]	Time  0.617 ( 2.195)	Data  0.000 ( 1.584)	Loss 0.3789555728435516 (0.2793048977986112)	Acc@1  92.19 ( 90.82)	Acc@5  96.88 ( 99.34)
Epoch: [22][120/203]	Time  0.540 ( 2.265)	Data  0.000 ( 1.655)	Loss 0.3335380852222443 (0.2824386494341961)	Acc@1  89.06 ( 90.74)	Acc@5  96.88 ( 99.30)
Epoch: [22][130/203]	Time  7.438 ( 2.295)	Data  6.868 ( 1.688)	Loss 0.1817586272954941 (0.2828379586793994)	Acc@1  93.75 ( 90.71)	Acc@5 100.00 ( 99.32)
Epoch: [22][140/203]	Time  0.537 ( 2.189)	Data  0.000 ( 1.579)	Loss 0.2174538373947144 (0.2806669509051539)	Acc@1  95.31 ( 90.82)	Acc@5 100.00 ( 99.31)
Epoch: [22][150/203]	Time  3.812 ( 2.233)	Data  3.041 ( 1.626)	Loss 0.2371665686368942 (0.2771229328994719)	Acc@1  92.19 ( 91.00)	Acc@5 100.00 ( 99.32)
Epoch: [22][160/203]	Time 12.807 ( 2.210)	Data 12.212 ( 1.601)	Loss 0.4883774518966675 (0.2789174769976124)	Acc@1  81.25 ( 90.90)	Acc@5 100.00 ( 99.31)
Epoch: [22][170/203]	Time  0.517 ( 2.170)	Data  0.001 ( 1.562)	Loss 0.4152018129825592 (0.2786974153149198)	Acc@1  87.50 ( 90.96)	Acc@5  95.31 ( 99.26)
Epoch: [22][180/203]	Time  0.506 ( 2.191)	Data  0.000 ( 1.583)	Loss 0.3222942948341370 (0.2782979849623053)	Acc@1  87.50 ( 91.03)	Acc@5  98.44 ( 99.26)
Epoch: [22][190/203]	Time  0.555 ( 2.118)	Data  0.000 ( 1.511)	Loss 0.1627794206142426 (0.2789292666690512)	Acc@1  96.88 ( 91.02)	Acc@5 100.00 ( 99.25)
Epoch: [22][200/203]	Time  0.686 ( 2.137)	Data  0.000 ( 1.530)	Loss 0.2664318978786469 (0.2786604107834806)	Acc@1  92.19 ( 91.00)	Acc@5  98.44 ( 99.25)
epoch: 22, Avg_Loss 0.2782323277128741
Test: [ 0/51]	Time 24.412 (24.412)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 70.31)	Acc@5  84.38 ( 84.38)
Test: [10/51]	Time  0.220 ( 2.450)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 73.15)	Acc@5  84.38 ( 84.23)
Test: [20/51]	Time  0.123 ( 2.378)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 75.97)	Acc@5  85.94 ( 86.38)
Test: [30/51]	Time  0.133 ( 1.679)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 75.86)	Acc@5  84.38 ( 86.24)
Test: [40/51]	Time  1.237 ( 1.822)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 74.77)	Acc@5  81.25 ( 85.37)
Test: [50/51]	Time  0.130 ( 1.858)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  69.09 ( 74.47)	Acc@5  80.00 ( 85.75)
 * Acc@1 74.470 Acc@5 85.745
Epoch: [23][  0/203]	Time 44.582 (44.582)	Data 43.982 (43.982)	Loss 0.2762176692485809 (0.2762176692485809)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Epoch: [23][ 10/203]	Time  0.748 ( 4.857)	Data  0.001 ( 4.111)	Loss 0.0925774276256561 (0.2719076993790540)	Acc@1  98.44 ( 90.34)	Acc@5 100.00 ( 99.29)
Epoch: [23][ 20/203]	Time  0.708 ( 3.663)	Data  0.000 ( 2.980)	Loss 0.4971691370010376 (0.2645630318494070)	Acc@1  82.81 ( 91.15)	Acc@5 100.00 ( 99.18)
Epoch: [23][ 30/203]	Time  0.498 ( 2.652)	Data  0.000 ( 2.019)	Loss 0.3122600317001343 (0.2676625751679944)	Acc@1  90.62 ( 91.08)	Acc@5 100.00 ( 99.29)
Epoch: [23][ 40/203]	Time  0.680 ( 2.672)	Data  0.000 ( 2.040)	Loss 0.3072364926338196 (0.2593594662299970)	Acc@1  87.50 ( 91.31)	Acc@5 100.00 ( 99.35)
Epoch: [23][ 50/203]	Time  0.610 ( 2.629)	Data  0.000 ( 1.996)	Loss 0.2163969427347183 (0.2518244692507912)	Acc@1  95.31 ( 91.70)	Acc@5  98.44 ( 99.33)
Epoch: [23][ 60/203]	Time  0.679 ( 2.292)	Data  0.000 ( 1.669)	Loss 0.2463940978050232 (0.2529188546000934)	Acc@1  89.06 ( 91.57)	Acc@5 100.00 ( 99.33)
Epoch: [23][ 70/203]	Time  0.546 ( 2.368)	Data  0.000 ( 1.754)	Loss 0.3090380132198334 (0.2564859482604013)	Acc@1  85.94 ( 91.44)	Acc@5 100.00 ( 99.36)
Epoch: [23][ 80/203]	Time 20.043 ( 2.387)	Data 19.356 ( 1.776)	Loss 0.2529287636280060 (0.2540449341874064)	Acc@1  93.75 ( 91.57)	Acc@5 100.00 ( 99.38)
Epoch: [23][ 90/203]	Time  0.569 ( 2.186)	Data  0.000 ( 1.581)	Loss 0.1433320641517639 (0.2540030808566691)	Acc@1  95.31 ( 91.55)	Acc@5 100.00 ( 99.36)
Epoch: [23][100/203]	Time  0.587 ( 2.263)	Data  0.000 ( 1.655)	Loss 0.2816684246063232 (0.2544373781374185)	Acc@1  90.62 ( 91.52)	Acc@5  98.44 ( 99.35)
Epoch: [23][110/203]	Time  0.582 ( 2.111)	Data  0.000 ( 1.506)	Loss 0.1964432001113892 (0.2561712232124698)	Acc@1  95.31 ( 91.55)	Acc@5 100.00 ( 99.37)
Epoch: [23][120/203]	Time  0.607 ( 2.304)	Data  0.000 ( 1.702)	Loss 0.2414205670356750 (0.2560046704963219)	Acc@1  92.19 ( 91.55)	Acc@5 100.00 ( 99.37)
Epoch: [23][130/203]	Time  0.653 ( 2.461)	Data  0.000 ( 1.855)	Loss 0.2827636003494263 (0.2572536258638360)	Acc@1  85.94 ( 91.42)	Acc@5 100.00 ( 99.38)
Epoch: [23][140/203]	Time  0.702 ( 2.333)	Data  0.000 ( 1.723)	Loss 0.3355047702789307 (0.2612615178557152)	Acc@1  84.38 ( 91.30)	Acc@5  98.44 ( 99.35)
Epoch: [23][150/203]	Time  0.544 ( 2.369)	Data  0.000 ( 1.761)	Loss 0.2213262766599655 (0.2609307599186108)	Acc@1  89.06 ( 91.35)	Acc@5  98.44 ( 99.36)
Epoch: [23][160/203]	Time 29.736 ( 2.440)	Data 29.011 ( 1.832)	Loss 0.3271900117397308 (0.2624813970756827)	Acc@1  92.19 ( 91.31)	Acc@5  96.88 ( 99.31)
Epoch: [23][170/203]	Time  0.529 ( 2.332)	Data  0.001 ( 1.725)	Loss 0.3020520508289337 (0.2640978862144794)	Acc@1  90.62 ( 91.27)	Acc@5 100.00 ( 99.30)
Epoch: [23][180/203]	Time  0.620 ( 2.419)	Data  0.000 ( 1.812)	Loss 0.1788907200098038 (0.2658232499058075)	Acc@1  93.75 ( 91.26)	Acc@5 100.00 ( 99.27)
Epoch: [23][190/203]	Time  0.516 ( 2.319)	Data  0.000 ( 1.717)	Loss 0.2119814306497574 (0.2651815502587413)	Acc@1  92.19 ( 91.26)	Acc@5 100.00 ( 99.30)
Epoch: [23][200/203]	Time  0.568 ( 2.373)	Data  0.000 ( 1.773)	Loss 0.2204258888959885 (0.2639703239077952)	Acc@1  90.62 ( 91.29)	Acc@5 100.00 ( 99.31)
epoch: 23, Avg_Loss 0.2635047349142911
Test: [ 0/51]	Time 25.232 (25.232)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 68.75)	Acc@5  93.75 ( 93.75)
Test: [10/51]	Time  0.136 ( 2.664)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.30)	Acc@5  95.31 ( 91.62)
Test: [20/51]	Time  0.260 ( 2.710)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 72.54)	Acc@5  87.50 ( 90.85)
Test: [30/51]	Time  0.149 ( 1.886)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 72.88)	Acc@5  93.75 ( 90.73)
Test: [40/51]	Time  0.132 ( 2.045)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 72.94)	Acc@5  92.19 ( 90.59)
Test: [50/51]	Time  1.182 ( 2.051)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 73.21)	Acc@5  94.55 ( 90.51)
 * Acc@1 73.210 Acc@5 90.507
Epoch: [24][  0/203]	Time 36.174 (36.174)	Data 35.439 (35.439)	Loss 0.2963655591011047 (0.2963655591011047)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [24][ 10/203]	Time  0.556 ( 3.870)	Data  0.001 ( 3.222)	Loss 0.3649449646472931 (0.2253569770943035)	Acc@1  90.62 ( 92.19)	Acc@5  98.44 ( 99.57)
Epoch: [24][ 20/203]	Time  0.605 ( 3.399)	Data  0.000 ( 2.776)	Loss 0.2194921076297760 (0.2244440299414453)	Acc@1  90.62 ( 91.89)	Acc@5 100.00 ( 99.70)
Epoch: [24][ 30/203]	Time  0.552 ( 2.483)	Data  0.000 ( 1.881)	Loss 0.1628814637660980 (0.2173569144741181)	Acc@1  95.31 ( 92.34)	Acc@5 100.00 ( 99.70)
Epoch: [24][ 40/203]	Time  0.612 ( 2.508)	Data  0.000 ( 1.910)	Loss 0.3330170810222626 (0.2365483434461966)	Acc@1  89.06 ( 92.07)	Acc@5  98.44 ( 99.43)
Epoch: [24][ 50/203]	Time  0.597 ( 2.472)	Data  0.000 ( 1.864)	Loss 0.2306369245052338 (0.2349943001480664)	Acc@1  93.75 ( 92.25)	Acc@5 100.00 ( 99.42)
Epoch: [24][ 60/203]	Time  0.583 ( 2.168)	Data  0.000 ( 1.558)	Loss 0.2062320560216904 (0.2330963584731837)	Acc@1  92.19 ( 92.29)	Acc@5 100.00 ( 99.44)
Epoch: [24][ 70/203]	Time  0.602 ( 2.305)	Data  0.000 ( 1.683)	Loss 0.2947965264320374 (0.2374695249846284)	Acc@1  89.06 ( 92.21)	Acc@5  98.44 ( 99.38)
Epoch: [24][ 80/203]	Time 17.744 ( 2.326)	Data 17.213 ( 1.688)	Loss 0.1249925792217255 (0.2391556865639157)	Acc@1  96.88 ( 92.26)	Acc@5 100.00 ( 99.40)
Epoch: [24][ 90/203]	Time  0.519 ( 2.130)	Data  0.000 ( 1.502)	Loss 0.3071113228797913 (0.2419553574297454)	Acc@1  87.50 ( 91.98)	Acc@5  98.44 ( 99.42)
Epoch: [24][100/203]	Time  0.531 ( 2.211)	Data  0.000 ( 1.591)	Loss 0.2668991982936859 (0.2445879000248295)	Acc@1  90.62 ( 91.92)	Acc@5  98.44 ( 99.38)
Epoch: [24][110/203]	Time  0.517 ( 2.071)	Data  0.000 ( 1.448)	Loss 0.3375656008720398 (0.2459464810184530)	Acc@1  87.50 ( 91.85)	Acc@5  98.44 ( 99.38)
Epoch: [24][120/203]	Time  0.513 ( 2.138)	Data  0.000 ( 1.520)	Loss 0.1821214705705643 (0.2420118693724151)	Acc@1  96.88 ( 91.97)	Acc@5 100.00 ( 99.41)
Epoch: [24][130/203]	Time  0.672 ( 2.213)	Data  0.000 ( 1.587)	Loss 0.2400462925434113 (0.2399549624733343)	Acc@1  90.62 ( 92.13)	Acc@5 100.00 ( 99.39)
Epoch: [24][140/203]	Time  0.684 ( 2.102)	Data  0.001 ( 1.475)	Loss 0.4328964650630951 (0.2410521581768990)	Acc@1  89.06 ( 92.17)	Acc@5  95.31 ( 99.35)
Epoch: [24][150/203]	Time  0.617 ( 2.166)	Data  0.000 ( 1.538)	Loss 0.5362116098403931 (0.2445519164401964)	Acc@1  85.94 ( 92.10)	Acc@5  98.44 ( 99.36)
Epoch: [24][160/203]	Time 24.326 ( 2.220)	Data 23.670 ( 1.589)	Loss 0.2396904081106186 (0.2464049784755855)	Acc@1  93.75 ( 92.01)	Acc@5 100.00 ( 99.37)
Epoch: [24][170/203]	Time  0.554 ( 2.130)	Data  0.001 ( 1.504)	Loss 0.1817265897989273 (0.2460813251765151)	Acc@1  95.31 ( 92.06)	Acc@5 100.00 ( 99.38)
Epoch: [24][180/203]	Time  0.504 ( 2.171)	Data  0.000 ( 1.549)	Loss 0.4948169589042664 (0.2493683655041357)	Acc@1  85.94 ( 91.96)	Acc@5  98.44 ( 99.38)
Epoch: [24][190/203]	Time  0.602 ( 2.087)	Data  0.000 ( 1.468)	Loss 0.2298319190740585 (0.2464663178040719)	Acc@1  92.19 ( 92.05)	Acc@5 100.00 ( 99.39)
Epoch: [24][200/203]	Time  0.702 ( 2.145)	Data  0.000 ( 1.515)	Loss 0.2425292283296585 (0.2450727629127787)	Acc@1  90.62 ( 92.06)	Acc@5 100.00 ( 99.42)
epoch: 24, Avg_Loss 0.24461675115994044
Test: [ 0/51]	Time 30.143 (30.143)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 71.88)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.125 ( 3.376)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 75.14)	Acc@5  92.19 ( 86.36)
Test: [20/51]	Time  0.162 ( 3.172)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 76.26)	Acc@5  90.62 ( 87.05)
Test: [30/51]	Time  0.129 ( 2.489)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 74.40)	Acc@5  87.50 ( 85.28)
Test: [40/51]	Time  3.591 ( 2.548)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 73.97)	Acc@5  90.62 ( 85.48)
Test: [50/51]	Time  0.119 ( 2.286)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.27 ( 74.50)	Acc@5  92.73 ( 86.11)
 * Acc@1 74.501 Acc@5 86.114
Epoch: [25][  0/203]	Time 35.214 (35.214)	Data 34.469 (34.469)	Loss 0.2631187140941620 (0.2631187140941620)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [25][ 10/203]	Time  0.506 ( 3.759)	Data  0.001 ( 3.178)	Loss 0.2655467987060547 (0.2464508034966209)	Acc@1  90.62 ( 92.33)	Acc@5 100.00 ( 99.29)
Epoch: [25][ 20/203]	Time  0.603 ( 3.576)	Data  0.001 ( 2.977)	Loss 0.1780427843332291 (0.2207344050208727)	Acc@1  93.75 ( 93.38)	Acc@5 100.00 ( 99.40)
Epoch: [25][ 30/203]	Time  0.541 ( 2.622)	Data  0.000 ( 2.017)	Loss 0.2673207521438599 (0.2267329012674670)	Acc@1  89.06 ( 93.09)	Acc@5  98.44 ( 99.34)
Epoch: [25][ 40/203]	Time  0.553 ( 2.682)	Data  0.000 ( 2.084)	Loss 0.2647608220577240 (0.2267403440867982)	Acc@1  90.62 ( 92.99)	Acc@5 100.00 ( 99.35)
Epoch: [25][ 50/203]	Time  0.583 ( 2.632)	Data  0.000 ( 2.033)	Loss 0.2043904066085815 (0.2238838701855903)	Acc@1  90.62 ( 92.98)	Acc@5 100.00 ( 99.36)
Epoch: [25][ 60/203]	Time  0.703 ( 2.406)	Data  0.001 ( 1.765)	Loss 0.1157610714435577 (0.2240237664492404)	Acc@1  98.44 ( 92.98)	Acc@5 100.00 ( 99.33)
Epoch: [25][ 70/203]	Time  0.627 ( 2.511)	Data  0.000 ( 1.871)	Loss 0.1905635595321655 (0.2192721073318955)	Acc@1  93.75 ( 93.02)	Acc@5 100.00 ( 99.38)
Epoch: [25][ 80/203]	Time 18.371 ( 2.502)	Data 17.727 ( 1.859)	Loss 0.2937490344047546 (0.2196050545913570)	Acc@1  90.62 ( 92.92)	Acc@5  98.44 ( 99.36)
Epoch: [25][ 90/203]	Time  0.731 ( 2.357)	Data  0.000 ( 1.714)	Loss 0.2968308031558990 (0.2195509497976893)	Acc@1  89.06 ( 92.94)	Acc@5 100.00 ( 99.36)
Epoch: [25][100/203]	Time  0.507 ( 2.407)	Data  0.000 ( 1.770)	Loss 0.1316721290349960 (0.2206500484838639)	Acc@1  95.31 ( 92.87)	Acc@5 100.00 ( 99.38)
Epoch: [25][110/203]	Time  0.513 ( 2.237)	Data  0.000 ( 1.611)	Loss 0.2196270525455475 (0.2197711661223087)	Acc@1  93.75 ( 92.89)	Acc@5 100.00 ( 99.38)
Epoch: [25][120/203]	Time  0.696 ( 2.336)	Data  0.000 ( 1.709)	Loss 0.2644180059432983 (0.2219269894032685)	Acc@1  93.75 ( 92.85)	Acc@5 100.00 ( 99.38)
Epoch: [25][130/203]	Time  0.561 ( 2.418)	Data  0.000 ( 1.792)	Loss 0.2299827337265015 (0.2245639289181879)	Acc@1  92.19 ( 92.72)	Acc@5  98.44 ( 99.36)
Epoch: [25][140/203]	Time  0.528 ( 2.347)	Data  0.000 ( 1.725)	Loss 0.2317852228879929 (0.2274044840497539)	Acc@1  92.19 ( 92.61)	Acc@5  98.44 ( 99.35)
Epoch: [25][150/203]	Time  0.576 ( 2.377)	Data  0.000 ( 1.759)	Loss 0.1996935158967972 (0.2262031168164994)	Acc@1  93.75 ( 92.62)	Acc@5 100.00 ( 99.38)
Epoch: [25][160/203]	Time 14.731 ( 2.351)	Data 13.990 ( 1.736)	Loss 0.3306989073753357 (0.2277498050529209)	Acc@1  90.62 ( 92.54)	Acc@5  98.44 ( 99.39)
Epoch: [25][170/203]	Time  0.533 ( 2.290)	Data  0.001 ( 1.679)	Loss 0.2788214087486267 (0.2284806284138508)	Acc@1  89.06 ( 92.52)	Acc@5 100.00 ( 99.39)
Epoch: [25][180/203]	Time  0.540 ( 2.315)	Data  0.000 ( 1.699)	Loss 0.2825146615505219 (0.2297874310913172)	Acc@1  92.19 ( 92.49)	Acc@5 100.00 ( 99.40)
Epoch: [25][190/203]	Time  0.586 ( 2.224)	Data  0.000 ( 1.610)	Loss 0.1689883768558502 (0.2307990354178620)	Acc@1  92.19 ( 92.46)	Acc@5 100.00 ( 99.41)
Epoch: [25][200/203]	Time  0.970 ( 2.256)	Data  0.000 ( 1.634)	Loss 0.2261565327644348 (0.2321164334535747)	Acc@1  92.19 ( 92.43)	Acc@5  98.44 ( 99.41)
epoch: 25, Avg_Loss 0.23157502836524854
Test: [ 0/51]	Time 26.270 (26.270)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 87.50)	Acc@5  98.44 ( 98.44)
Test: [10/51]	Time  0.169 ( 2.652)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 75.57)	Acc@5  85.94 ( 90.62)
Test: [20/51]	Time  0.126 ( 2.338)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 73.88)	Acc@5  89.06 ( 89.81)
Test: [30/51]	Time  0.139 ( 1.627)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  68.75 ( 73.89)	Acc@5  89.06 ( 90.27)
Test: [40/51]	Time  0.168 ( 1.750)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 74.43)	Acc@5  89.06 ( 90.32)
Test: [50/51]	Time  0.122 ( 1.794)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.36 ( 75.02)	Acc@5  90.91 ( 90.63)
 * Acc@1 75.023 Acc@5 90.630
Epoch: [26][  0/203]	Time 35.639 (35.639)	Data 34.863 (34.863)	Loss 0.2325692921876907 (0.2325692921876907)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [26][ 10/203]	Time  0.551 ( 3.753)	Data  0.001 ( 3.170)	Loss 0.2179861366748810 (0.2470743344588713)	Acc@1  92.19 ( 91.62)	Acc@5 100.00 ( 99.86)
Epoch: [26][ 20/203]	Time  1.104 ( 3.513)	Data  0.001 ( 2.721)	Loss 0.1030563563108444 (0.2520568385010674)	Acc@1  98.44 ( 91.59)	Acc@5 100.00 ( 99.63)
Epoch: [26][ 30/203]	Time  0.774 ( 2.601)	Data  0.000 ( 1.844)	Loss 0.2773818075656891 (0.2418656019914535)	Acc@1  90.62 ( 92.14)	Acc@5  98.44 ( 99.45)
Epoch: [26][ 40/203]	Time  0.800 ( 2.512)	Data  0.000 ( 1.763)	Loss 0.4269766509532928 (0.2313306725970129)	Acc@1  89.06 ( 92.61)	Acc@5  98.44 ( 99.50)
Epoch: [26][ 50/203]	Time  3.844 ( 2.571)	Data  3.172 ( 1.838)	Loss 0.1941830813884735 (0.2364901422577746)	Acc@1  93.75 ( 92.31)	Acc@5 100.00 ( 99.51)
Epoch: [26][ 60/203]	Time  0.556 ( 2.242)	Data  0.000 ( 1.537)	Loss 0.1900245100259781 (0.2256038971855992)	Acc@1  90.62 ( 92.67)	Acc@5 100.00 ( 99.54)
Epoch: [26][ 70/203]	Time  0.560 ( 2.344)	Data  0.000 ( 1.658)	Loss 0.2343822270631790 (0.2185870023890280)	Acc@1  90.62 ( 92.78)	Acc@5 100.00 ( 99.56)
Epoch: [26][ 80/203]	Time 16.182 ( 2.316)	Data 15.242 ( 1.642)	Loss 0.1353583633899689 (0.2157623440395167)	Acc@1  93.75 ( 92.79)	Acc@5 100.00 ( 99.58)
Epoch: [26][ 90/203]	Time  0.525 ( 2.182)	Data  0.000 ( 1.523)	Loss 0.1258106082677841 (0.2158575835791263)	Acc@1  95.31 ( 92.87)	Acc@5 100.00 ( 99.59)
Epoch: [26][100/203]	Time  2.742 ( 2.235)	Data  2.103 ( 1.583)	Loss 0.1235986351966858 (0.2129444979352526)	Acc@1  96.88 ( 93.07)	Acc@5 100.00 ( 99.63)
Epoch: [26][110/203]	Time  0.750 ( 2.085)	Data  0.000 ( 1.441)	Loss 0.1776955872774124 (0.2095387927717991)	Acc@1  93.75 ( 93.19)	Acc@5 100.00 ( 99.65)
Epoch: [26][120/203]	Time  0.533 ( 2.162)	Data  0.000 ( 1.517)	Loss 0.1745348572731018 (0.2098401688224028)	Acc@1  95.31 ( 93.14)	Acc@5  98.44 ( 99.64)
Epoch: [26][130/203]	Time  3.883 ( 2.201)	Data  3.173 ( 1.561)	Loss 0.1294328868389130 (0.2102293220298891)	Acc@1  95.31 ( 93.08)	Acc@5  98.44 ( 99.63)
Epoch: [26][140/203]	Time  0.522 ( 2.106)	Data  0.000 ( 1.466)	Loss 0.1835693567991257 (0.2100213740205934)	Acc@1  90.62 ( 93.06)	Acc@5 100.00 ( 99.65)
Epoch: [26][150/203]	Time  0.548 ( 2.160)	Data  0.000 ( 1.524)	Loss 0.2222923934459686 (0.2084563067614637)	Acc@1  92.19 ( 93.13)	Acc@5 100.00 ( 99.65)
Epoch: [26][160/203]	Time 18.881 ( 2.175)	Data 17.802 ( 1.540)	Loss 0.3899995684623718 (0.2097974465407940)	Acc@1  90.62 ( 93.13)	Acc@5  98.44 ( 99.64)
Epoch: [26][170/203]	Time  0.516 ( 2.114)	Data  0.001 ( 1.481)	Loss 0.0722839906811714 (0.2088403232526361)	Acc@1 100.00 ( 93.12)	Acc@5 100.00 ( 99.65)
Epoch: [26][180/203]	Time  3.512 ( 2.172)	Data  2.802 ( 1.539)	Loss 0.2879326641559601 (0.2110084330261742)	Acc@1  89.06 ( 93.06)	Acc@5 100.00 ( 99.65)
Epoch: [26][190/203]	Time  0.551 ( 2.088)	Data  0.000 ( 1.459)	Loss 0.2038625031709671 (0.2119562245944408)	Acc@1  92.19 ( 93.01)	Acc@5  98.44 ( 99.65)
Epoch: [26][200/203]	Time  0.551 ( 2.108)	Data  0.000 ( 1.481)	Loss 0.1905308812856674 (0.2110561170981298)	Acc@1  95.31 ( 93.02)	Acc@5 100.00 ( 99.64)
epoch: 26, Avg_Loss 0.21101490588023744
Test: [ 0/51]	Time 27.490 (27.490)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.56)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.936 ( 2.962)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 79.83)	Acc@5  82.81 ( 88.35)
Test: [20/51]	Time  0.145 ( 2.738)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 80.13)	Acc@5  90.62 ( 88.69)
Test: [30/51]	Time  0.156 ( 1.972)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 80.44)	Acc@5  84.38 ( 89.06)
Test: [40/51]	Time  0.120 ( 2.034)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 79.95)	Acc@5  90.62 ( 88.45)
Test: [50/51]	Time  0.137 ( 2.019)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  80.00 ( 79.78)	Acc@5  85.45 ( 88.73)
 * Acc@1 79.785 Acc@5 88.725
Epoch: [27][  0/203]	Time 39.346 (39.346)	Data 38.623 (38.623)	Loss 0.1323093473911285 (0.1323093473911285)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [27][ 10/203]	Time  0.572 ( 4.117)	Data  0.001 ( 3.511)	Loss 0.1121704652905464 (0.1826440305872397)	Acc@1  96.88 ( 93.61)	Acc@5 100.00 ( 99.86)
Epoch: [27][ 20/203]	Time  0.598 ( 3.464)	Data  0.000 ( 2.857)	Loss 0.2718568444252014 (0.2099454924464226)	Acc@1  90.62 ( 92.93)	Acc@5  98.44 ( 99.40)
Epoch: [27][ 30/203]	Time  0.568 ( 2.529)	Data  0.000 ( 1.935)	Loss 0.1514052301645279 (0.2090809027994833)	Acc@1  95.31 ( 93.15)	Acc@5 100.00 ( 99.45)
Epoch: [27][ 40/203]	Time  0.528 ( 2.665)	Data  0.000 ( 2.070)	Loss 0.1875370591878891 (0.2192466546122621)	Acc@1  90.62 ( 92.68)	Acc@5 100.00 ( 99.31)
Epoch: [27][ 50/203]	Time  0.819 ( 2.820)	Data  0.000 ( 2.224)	Loss 0.2905592024326324 (0.2129067518547469)	Acc@1  93.75 ( 93.05)	Acc@5  98.44 ( 99.39)
Epoch: [27][ 60/203]	Time  0.573 ( 2.457)	Data  0.000 ( 1.860)	Loss 0.1182521879673004 (0.2150548403380347)	Acc@1  98.44 ( 93.14)	Acc@5 100.00 ( 99.44)
Epoch: [27][ 70/203]	Time  0.595 ( 2.510)	Data  0.000 ( 1.896)	Loss 0.2495050579309464 (0.2111185470097502)	Acc@1  93.75 ( 93.09)	Acc@5  96.88 ( 99.47)
Epoch: [27][ 80/203]	Time 40.417 ( 2.760)	Data 39.825 ( 2.153)	Loss 0.1242689490318298 (0.2065804143562729)	Acc@1  96.88 ( 93.42)	Acc@5 100.00 ( 99.50)
Epoch: [27][ 90/203]	Time  0.571 ( 2.525)	Data  0.000 ( 1.922)	Loss 0.2013780325651169 (0.2045269610135110)	Acc@1  93.75 ( 93.41)	Acc@5 100.00 ( 99.52)
Epoch: [27][100/203]	Time  0.822 ( 2.562)	Data  0.000 ( 1.943)	Loss 0.1756044775247574 (0.2011506285997901)	Acc@1  93.75 ( 93.47)	Acc@5 100.00 ( 99.54)
Epoch: [27][110/203]	Time  0.832 ( 2.396)	Data  0.000 ( 1.768)	Loss 0.1172095760703087 (0.2012239050892022)	Acc@1  96.88 ( 93.44)	Acc@5 100.00 ( 99.55)
Epoch: [27][120/203]	Time  0.604 ( 2.410)	Data  0.000 ( 1.785)	Loss 0.3450424075126648 (0.1998259630823924)	Acc@1  92.19 ( 93.54)	Acc@5  98.44 ( 99.56)
Epoch: [27][130/203]	Time  0.546 ( 2.464)	Data  0.000 ( 1.843)	Loss 0.1353490650653839 (0.1962824570199916)	Acc@1  98.44 ( 93.75)	Acc@5 100.00 ( 99.56)
Epoch: [27][140/203]	Time  0.639 ( 2.401)	Data  0.000 ( 1.778)	Loss 0.2072103023529053 (0.1978917456370719)	Acc@1  92.19 ( 93.66)	Acc@5 100.00 ( 99.57)
Epoch: [27][150/203]	Time  0.683 ( 2.542)	Data  0.000 ( 1.916)	Loss 0.3677280247211456 (0.2015679020755338)	Acc@1  90.62 ( 93.55)	Acc@5  98.44 ( 99.58)
Epoch: [27][160/203]	Time 23.685 ( 2.568)	Data 23.070 ( 1.941)	Loss 0.1750666797161102 (0.1992174037587569)	Acc@1  96.88 ( 93.67)	Acc@5 100.00 ( 99.55)
Epoch: [27][170/203]	Time  0.541 ( 2.501)	Data  0.001 ( 1.876)	Loss 0.2357100099325180 (0.1991959320522888)	Acc@1  93.75 ( 93.72)	Acc@5 100.00 ( 99.52)
Epoch: [27][180/203]	Time  0.562 ( 2.515)	Data  0.000 ( 1.894)	Loss 0.2419916838407516 (0.2010438332735504)	Acc@1  96.88 ( 93.70)	Acc@5  98.44 ( 99.49)
Epoch: [27][190/203]	Time  0.589 ( 2.414)	Data  0.000 ( 1.795)	Loss 0.2047663629055023 (0.2004730885175510)	Acc@1  90.62 ( 93.65)	Acc@5 100.00 ( 99.52)
Epoch: [27][200/203]	Time  0.653 ( 2.432)	Data  0.000 ( 1.810)	Loss 0.1372001469135284 (0.1993288247294687)	Acc@1  96.88 ( 93.70)	Acc@5 100.00 ( 99.53)
epoch: 27, Avg_Loss 0.20088892998953758
Test: [ 0/51]	Time 30.739 (30.739)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 81.25)	Acc@5  90.62 ( 90.62)
Test: [10/51]	Time  0.213 ( 3.312)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 79.40)	Acc@5  85.94 ( 87.50)
Test: [20/51]	Time  0.209 ( 3.412)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 78.50)	Acc@5  84.38 ( 87.35)
Test: [30/51]	Time  0.144 ( 2.435)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 78.93)	Acc@5  90.62 ( 88.16)
Test: [40/51]	Time  0.153 ( 2.506)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 78.89)	Acc@5  89.06 ( 88.49)
Test: [50/51]	Time  0.125 ( 2.444)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.18 ( 78.89)	Acc@5  87.27 ( 88.48)
 * Acc@1 78.894 Acc@5 88.479
Epoch: [28][  0/203]	Time 30.210 (30.210)	Data 29.661 (29.661)	Loss 0.2264527976512909 (0.2264527976512909)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [28][ 10/203]	Time  0.627 ( 3.700)	Data  0.001 ( 3.058)	Loss 0.2004856169223785 (0.2422733604907990)	Acc@1  93.75 ( 92.90)	Acc@5 100.00 ( 99.15)
Epoch: [28][ 20/203]	Time  0.993 ( 3.100)	Data  0.195 ( 2.463)	Loss 0.2557908594608307 (0.2221217762146677)	Acc@1  90.62 ( 92.86)	Acc@5 100.00 ( 99.40)
Epoch: [28][ 30/203]	Time  0.542 ( 2.289)	Data  0.001 ( 1.679)	Loss 0.2550995647907257 (0.2221368507992837)	Acc@1  95.31 ( 93.04)	Acc@5  98.44 ( 99.14)
Epoch: [28][ 40/203]	Time  0.758 ( 2.551)	Data  0.000 ( 1.930)	Loss 0.2720569968223572 (0.2288204189844248)	Acc@1  92.19 ( 92.72)	Acc@5 100.00 ( 99.20)
Epoch: [28][ 50/203]	Time  0.568 ( 2.541)	Data  0.000 ( 1.921)	Loss 0.1388325542211533 (0.2168767206809100)	Acc@1  98.44 ( 93.14)	Acc@5 100.00 ( 99.36)
Epoch: [28][ 60/203]	Time  0.531 ( 2.274)	Data  0.000 ( 1.663)	Loss 0.2515127360820770 (0.2178853312965299)	Acc@1  89.06 ( 93.14)	Acc@5 100.00 ( 99.39)
Epoch: [28][ 70/203]	Time  0.621 ( 2.405)	Data  0.000 ( 1.790)	Loss 0.1504419296979904 (0.2196079373989307)	Acc@1  96.88 ( 93.05)	Acc@5  98.44 ( 99.36)
Epoch: [28][ 80/203]	Time 21.201 ( 2.440)	Data 20.571 ( 1.823)	Loss 0.2151605039834976 (0.2243852691701901)	Acc@1  93.75 ( 92.88)	Acc@5  98.44 ( 99.31)
Epoch: [28][ 90/203]	Time  0.682 ( 2.343)	Data  0.000 ( 1.707)	Loss 0.1469631940126419 (0.2262754321589575)	Acc@1  95.31 ( 92.87)	Acc@5 100.00 ( 99.31)
Epoch: [28][100/203]	Time  0.488 ( 2.466)	Data  0.000 ( 1.827)	Loss 0.1184193715453148 (0.2182226329304204)	Acc@1  92.19 ( 92.98)	Acc@5 100.00 ( 99.38)
Epoch: [28][110/203]	Time  0.563 ( 2.294)	Data  0.000 ( 1.663)	Loss 0.1555332839488983 (0.2197784982823037)	Acc@1  95.31 ( 92.93)	Acc@5  98.44 ( 99.38)
Epoch: [28][120/203]	Time  0.527 ( 2.622)	Data  0.000 ( 1.994)	Loss 0.2019778490066528 (0.2175868419576282)	Acc@1  90.62 ( 93.03)	Acc@5 100.00 ( 99.37)
Epoch: [28][130/203]	Time 10.482 ( 2.656)	Data  9.899 ( 2.033)	Loss 0.1644616425037384 (0.2167415489791004)	Acc@1  92.19 ( 93.02)	Acc@5 100.00 ( 99.36)
Epoch: [28][140/203]	Time  0.606 ( 2.611)	Data  0.000 ( 1.993)	Loss 0.0730665773153305 (0.2145364430356533)	Acc@1  98.44 ( 93.09)	Acc@5 100.00 ( 99.38)
Epoch: [28][150/203]	Time  0.627 ( 2.670)	Data  0.000 ( 2.055)	Loss 0.3306472003459930 (0.2174516715948155)	Acc@1  84.38 ( 92.95)	Acc@5  98.44 ( 99.34)
Epoch: [28][160/203]	Time  6.310 ( 2.578)	Data  5.795 ( 1.964)	Loss 0.1962746232748032 (0.2165207806396188)	Acc@1  93.75 ( 92.96)	Acc@5 100.00 ( 99.36)
Epoch: [28][170/203]	Time  0.578 ( 2.605)	Data  0.001 ( 1.994)	Loss 0.1180452331900597 (0.2188471341777963)	Acc@1  95.31 ( 92.82)	Acc@5 100.00 ( 99.36)
Epoch: [28][180/203]	Time  0.491 ( 2.703)	Data  0.000 ( 2.090)	Loss 0.1583946496248245 (0.2158572537546658)	Acc@1  95.31 ( 92.94)	Acc@5 100.00 ( 99.40)
Epoch: [28][190/203]	Time  0.736 ( 2.597)	Data  0.000 ( 1.980)	Loss 0.1643555313348770 (0.2142855855416877)	Acc@1  93.75 ( 92.98)	Acc@5 100.00 ( 99.41)
Epoch: [28][200/203]	Time  0.607 ( 2.607)	Data  0.000 ( 1.988)	Loss 0.3948706090450287 (0.2138605797616997)	Acc@1  89.06 ( 93.03)	Acc@5  98.44 ( 99.43)
epoch: 28, Avg_Loss 0.2141382504126121
Test: [ 0/51]	Time 31.402 (31.402)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.56)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.193 ( 2.994)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 69.46)	Acc@5  81.25 ( 84.80)
Test: [20/51]	Time  0.210 ( 3.027)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 70.54)	Acc@5  82.81 ( 84.67)
Test: [30/51]	Time  0.122 ( 2.096)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  64.06 ( 69.61)	Acc@5  85.94 ( 84.32)
Test: [40/51]	Time  0.148 ( 2.274)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 70.24)	Acc@5  89.06 ( 84.98)
Test: [50/51]	Time  0.125 ( 2.327)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  74.55 ( 70.57)	Acc@5  81.82 ( 84.92)
 * Acc@1 70.568 Acc@5 84.916
Epoch: [29][  0/203]	Time 33.771 (33.771)	Data 33.087 (33.087)	Loss 0.1542423367500305 (0.1542423367500305)	Acc@1  95.31 ( 95.31)	Acc@5  98.44 ( 98.44)
Epoch: [29][ 10/203]	Time  0.551 ( 3.664)	Data  0.001 ( 3.059)	Loss 0.1348367333412170 (0.1864415210756389)	Acc@1  95.31 ( 94.18)	Acc@5 100.00 ( 99.57)
Epoch: [29][ 20/203]	Time  0.696 ( 3.188)	Data  0.000 ( 2.573)	Loss 0.0658820420503616 (0.1760539950004646)	Acc@1  98.44 ( 94.64)	Acc@5 100.00 ( 99.63)
Epoch: [29][ 30/203]	Time  0.776 ( 2.359)	Data  0.001 ( 1.743)	Loss 0.1638145744800568 (0.1737609201621625)	Acc@1  93.75 ( 94.61)	Acc@5 100.00 ( 99.65)
Epoch: [29][ 40/203]	Time  0.520 ( 2.415)	Data  0.000 ( 1.797)	Loss 0.1450079232454300 (0.1741576306521893)	Acc@1  96.88 ( 94.25)	Acc@5 100.00 ( 99.73)
Epoch: [29][ 50/203]	Time  0.639 ( 2.385)	Data  0.000 ( 1.768)	Loss 0.1921554952859879 (0.1716299887527438)	Acc@1  90.62 ( 94.21)	Acc@5  98.44 ( 99.63)
Epoch: [29][ 60/203]	Time  0.569 ( 2.216)	Data  0.000 ( 1.608)	Loss 0.1398908197879791 (0.1769649799852098)	Acc@1  95.31 ( 94.06)	Acc@5 100.00 ( 99.62)
Epoch: [29][ 70/203]	Time  2.548 ( 2.489)	Data  1.968 ( 1.889)	Loss 0.2398010343313217 (0.1779585222018437)	Acc@1  90.62 ( 94.01)	Acc@5 100.00 ( 99.63)
Epoch: [29][ 80/203]	Time 18.617 ( 2.478)	Data 18.062 ( 1.879)	Loss 0.2611390650272369 (0.1818943703892054)	Acc@1  95.31 ( 93.96)	Acc@5 100.00 ( 99.58)
Epoch: [29][ 90/203]	Time  0.538 ( 2.294)	Data  0.000 ( 1.697)	Loss 0.1398070305585861 (0.1852948658659563)	Acc@1  96.88 ( 93.92)	Acc@5 100.00 ( 99.54)
Epoch: [29][100/203]	Time  1.520 ( 2.347)	Data  0.992 ( 1.745)	Loss 0.1935081183910370 (0.1820916150982427)	Acc@1  90.62 ( 94.00)	Acc@5 100.00 ( 99.58)
Epoch: [29][110/203]	Time  0.542 ( 2.189)	Data  0.000 ( 1.588)	Loss 0.1356498301029205 (0.1836109967851961)	Acc@1  95.31 ( 93.92)	Acc@5 100.00 ( 99.56)
Epoch: [29][120/203]	Time  0.715 ( 2.278)	Data  0.000 ( 1.668)	Loss 0.1629976034164429 (0.1832196391995781)	Acc@1  93.75 ( 93.93)	Acc@5 100.00 ( 99.57)
Epoch: [29][130/203]	Time  2.085 ( 2.291)	Data  1.561 ( 1.683)	Loss 0.1569295078516006 (0.1839403311885495)	Acc@1  95.31 ( 93.88)	Acc@5  98.44 ( 99.57)
Epoch: [29][140/203]	Time  0.577 ( 2.190)	Data  0.000 ( 1.588)	Loss 0.1640846878290176 (0.1847272685709152)	Acc@1  93.75 ( 93.86)	Acc@5 100.00 ( 99.58)
Epoch: [29][150/203]	Time  0.577 ( 2.245)	Data  0.000 ( 1.643)	Loss 0.1817969381809235 (0.1834447733465804)	Acc@1  93.75 ( 93.89)	Acc@5 100.00 ( 99.58)
Epoch: [29][160/203]	Time 29.896 ( 2.324)	Data 29.285 ( 1.723)	Loss 0.1225759834051132 (0.1868654081586355)	Acc@1  93.75 ( 93.80)	Acc@5 100.00 ( 99.57)
Epoch: [29][170/203]	Time  0.524 ( 2.251)	Data  0.001 ( 1.652)	Loss 0.4009030163288116 (0.1885850759582561)	Acc@1  89.06 ( 93.78)	Acc@5  98.44 ( 99.58)
Epoch: [29][180/203]	Time  0.778 ( 2.398)	Data  0.000 ( 1.798)	Loss 0.1675204485654831 (0.1895946255005196)	Acc@1  95.31 ( 93.76)	Acc@5 100.00 ( 99.59)
Epoch: [29][190/203]	Time  0.552 ( 2.302)	Data  0.000 ( 1.704)	Loss 0.1152355000376701 (0.1892300023653432)	Acc@1  95.31 ( 93.77)	Acc@5 100.00 ( 99.59)
Epoch: [29][200/203]	Time  0.515 ( 2.313)	Data  0.000 ( 1.716)	Loss 0.1467989385128021 (0.1921790671622872)	Acc@1  95.31 ( 93.68)	Acc@5 100.00 ( 99.56)
epoch: 29, Avg_Loss 0.19134929510099546
Test: [ 0/51]	Time 25.717 (25.717)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 81.25)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.141 ( 2.651)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  65.62 ( 75.14)	Acc@5  82.81 ( 86.36)
Test: [20/51]	Time  0.148 ( 2.638)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 74.85)	Acc@5  93.75 ( 86.68)
Test: [30/51]	Time  0.234 ( 1.876)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 76.66)	Acc@5  82.81 ( 87.45)
Test: [40/51]	Time  0.124 ( 2.105)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.18)	Acc@5  89.06 ( 87.16)
Test: [50/51]	Time  0.138 ( 2.148)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.36 ( 76.25)	Acc@5  81.82 ( 86.88)
 * Acc@1 76.252 Acc@5 86.882
Epoch: [30][  0/203]	Time 32.835 (32.835)	Data 32.280 (32.280)	Loss 0.1671594828367233 (0.1671594828367233)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 98.44)
Epoch: [30][ 10/203]	Time  0.640 ( 3.491)	Data  0.001 ( 2.935)	Loss 0.1109401881694794 (0.1764185841787945)	Acc@1  95.31 ( 94.46)	Acc@5 100.00 ( 99.29)
Epoch: [30][ 20/203]	Time  0.736 ( 3.096)	Data  0.000 ( 2.449)	Loss 0.0978427901864052 (0.1667179688811302)	Acc@1  96.88 ( 94.42)	Acc@5 100.00 ( 99.63)
Epoch: [30][ 30/203]	Time  0.691 ( 2.346)	Data  0.001 ( 1.659)	Loss 0.1670040935277939 (0.1508088812472359)	Acc@1  96.88 ( 95.06)	Acc@5  98.44 ( 99.70)
Epoch: [30][ 40/203]	Time  0.879 ( 2.354)	Data  0.000 ( 1.632)	Loss 0.0859316810965538 (0.1534752737639881)	Acc@1  98.44 ( 95.08)	Acc@5 100.00 ( 99.70)
Epoch: [30][ 50/203]	Time  0.757 ( 2.340)	Data  0.000 ( 1.524)	Loss 0.1666634529829025 (0.1516272351876193)	Acc@1  95.31 ( 95.19)	Acc@5 100.00 ( 99.72)
Epoch: [30][ 60/203]	Time  0.663 ( 2.064)	Data  0.000 ( 1.274)	Loss 0.3165416717529297 (0.1559948649440633)	Acc@1  89.06 ( 95.01)	Acc@5  96.88 ( 99.67)
Epoch: [30][ 70/203]	Time  0.945 ( 2.377)	Data  0.000 ( 1.586)	Loss 0.1972197443246841 (0.1563396770244753)	Acc@1  92.19 ( 94.98)	Acc@5 100.00 ( 99.71)
Epoch: [30][ 80/203]	Time 15.661 ( 2.352)	Data 15.070 ( 1.576)	Loss 0.0916610956192017 (0.1534326174928818)	Acc@1  98.44 ( 95.16)	Acc@5 100.00 ( 99.75)
Epoch: [30][ 90/203]	Time  0.578 ( 2.175)	Data  0.000 ( 1.421)	Loss 0.1346846967935562 (0.1590140328466237)	Acc@1  93.75 ( 94.97)	Acc@5 100.00 ( 99.74)
Epoch: [30][100/203]	Time  0.586 ( 2.217)	Data  0.000 ( 1.474)	Loss 0.1597962826490402 (0.1607659830905423)	Acc@1  92.19 ( 94.85)	Acc@5 100.00 ( 99.75)
Epoch: [30][110/203]	Time  0.679 ( 2.073)	Data  0.000 ( 1.341)	Loss 0.1953008025884628 (0.1623986218426679)	Acc@1  93.75 ( 94.78)	Acc@5 100.00 ( 99.77)
Epoch: [30][120/203]	Time  0.539 ( 2.106)	Data  0.000 ( 1.386)	Loss 0.1261863559484482 (0.1656596077498326)	Acc@1  95.31 ( 94.63)	Acc@5 100.00 ( 99.73)
Epoch: [30][130/203]	Time  0.515 ( 2.153)	Data  0.000 ( 1.446)	Loss 0.3045827746391296 (0.1665012353590427)	Acc@1  90.62 ( 94.64)	Acc@5  98.44 ( 99.70)
Epoch: [30][140/203]	Time  0.671 ( 2.040)	Data  0.000 ( 1.344)	Loss 0.1048473864793777 (0.1675562016296049)	Acc@1  96.88 ( 94.65)	Acc@5 100.00 ( 99.69)
Epoch: [30][150/203]	Time  0.550 ( 2.090)	Data  0.000 ( 1.400)	Loss 0.0893924459815025 (0.1697370269341974)	Acc@1  96.88 ( 94.59)	Acc@5 100.00 ( 99.68)
Epoch: [30][160/203]	Time 23.547 ( 2.140)	Data 22.954 ( 1.455)	Loss 0.1568224430084229 (0.1702543023672904)	Acc@1  93.75 ( 94.56)	Acc@5 100.00 ( 99.68)
Epoch: [30][170/203]	Time  0.542 ( 2.049)	Data  0.001 ( 1.370)	Loss 0.2151063233613968 (0.1708263773144337)	Acc@1  92.19 ( 94.51)	Acc@5 100.00 ( 99.68)
Epoch: [30][180/203]	Time  0.515 ( 2.079)	Data  0.000 ( 1.405)	Loss 0.1626001894474030 (0.1703202726514959)	Acc@1  95.31 ( 94.55)	Acc@5  98.44 ( 99.66)
Epoch: [30][190/203]	Time  0.621 ( 2.000)	Data  0.000 ( 1.332)	Loss 0.1726058721542358 (0.1704226875024316)	Acc@1  92.19 ( 94.54)	Acc@5 100.00 ( 99.68)
Epoch: [30][200/203]	Time  0.548 ( 2.047)	Data  0.000 ( 1.384)	Loss 0.0969381481409073 (0.1703672333069109)	Acc@1  96.88 ( 94.57)	Acc@5 100.00 ( 99.68)
epoch: 30, Avg_Loss 0.17021160844364777
Test: [ 0/51]	Time 21.257 (21.257)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 71.88)	Acc@5  89.06 ( 89.06)
Test: [10/51]	Time  0.139 ( 2.307)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 78.12)	Acc@5  90.62 ( 92.76)
Test: [20/51]	Time  0.223 ( 2.233)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 80.51)	Acc@5  90.62 ( 93.30)
Test: [30/51]	Time  0.131 ( 1.559)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 80.24)	Acc@5  93.75 ( 93.09)
Test: [40/51]	Time  0.127 ( 1.757)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 80.11)	Acc@5  95.31 ( 92.68)
Test: [50/51]	Time  0.119 ( 1.833)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  80.00 ( 79.60)	Acc@5  92.73 ( 92.32)
 * Acc@1 79.601 Acc@5 92.320
Epoch: [31][  0/203]	Time 28.437 (28.437)	Data 27.666 (27.666)	Loss 0.1108546182513237 (0.1108546182513237)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [31][ 10/203]	Time  0.591 ( 3.288)	Data  0.001 ( 2.661)	Loss 0.1068637222051620 (0.1385178234089505)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [31][ 20/203]	Time  0.634 ( 2.944)	Data  0.000 ( 2.310)	Loss 0.3111116290092468 (0.1938064783101990)	Acc@1  90.62 ( 93.53)	Acc@5 100.00 ( 99.78)
Epoch: [31][ 30/203]	Time  0.679 ( 2.212)	Data  0.000 ( 1.565)	Loss 0.1848265826702118 (0.1892187490818962)	Acc@1  95.31 ( 93.75)	Acc@5  98.44 ( 99.70)
Epoch: [31][ 40/203]	Time  0.602 ( 2.238)	Data  0.000 ( 1.610)	Loss 0.1599843800067902 (0.1900920792505509)	Acc@1  95.31 ( 93.90)	Acc@5 100.00 ( 99.73)
Epoch: [31][ 50/203]	Time  0.754 ( 2.287)	Data  0.000 ( 1.656)	Loss 0.1658208668231964 (0.1845174993516183)	Acc@1  93.75 ( 94.00)	Acc@5 100.00 ( 99.66)
Epoch: [31][ 60/203]	Time  0.595 ( 2.014)	Data  0.000 ( 1.384)	Loss 0.1473384648561478 (0.1826989106589653)	Acc@1  95.31 ( 94.11)	Acc@5  98.44 ( 99.62)
Epoch: [31][ 70/203]	Time  0.547 ( 2.094)	Data  0.000 ( 1.466)	Loss 0.1216533407568932 (0.1788977875151265)	Acc@1  96.88 ( 94.23)	Acc@5 100.00 ( 99.63)
Epoch: [31][ 80/203]	Time 14.844 ( 2.084)	Data 14.217 ( 1.461)	Loss 0.2105786353349686 (0.1772343193031388)	Acc@1  89.06 ( 94.21)	Acc@5  98.44 ( 99.59)
Epoch: [31][ 90/203]	Time  0.592 ( 1.970)	Data  0.000 ( 1.341)	Loss 0.0820197463035583 (0.1770449216467339)	Acc@1  98.44 ( 94.21)	Acc@5 100.00 ( 99.62)
Epoch: [31][100/203]	Time  0.558 ( 2.022)	Data  0.000 ( 1.398)	Loss 0.1681320518255234 (0.1733377118143115)	Acc@1  92.19 ( 94.28)	Acc@5 100.00 ( 99.66)
Epoch: [31][110/203]	Time  0.658 ( 1.892)	Data  0.000 ( 1.272)	Loss 0.0641239881515503 (0.1737704243141789)	Acc@1  98.44 ( 94.28)	Acc@5 100.00 ( 99.68)
Epoch: [31][120/203]	Time  0.503 ( 1.925)	Data  0.000 ( 1.313)	Loss 0.1249659508466721 (0.1718715450857297)	Acc@1  95.31 ( 94.37)	Acc@5 100.00 ( 99.68)
Epoch: [31][130/203]	Time  0.556 ( 1.977)	Data  0.000 ( 1.366)	Loss 0.1529361456632614 (0.1708316470830495)	Acc@1  96.88 ( 94.41)	Acc@5 100.00 ( 99.69)
Epoch: [31][140/203]	Time  0.553 ( 1.897)	Data  0.000 ( 1.289)	Loss 0.2569762766361237 (0.1720628373007825)	Acc@1  92.19 ( 94.43)	Acc@5 100.00 ( 99.68)
Epoch: [31][150/203]	Time  0.500 ( 1.942)	Data  0.000 ( 1.335)	Loss 0.1309212297201157 (0.1716002200464934)	Acc@1  95.31 ( 94.43)	Acc@5 100.00 ( 99.68)
Epoch: [31][160/203]	Time 11.839 ( 1.951)	Data 11.293 ( 1.345)	Loss 0.1809986233711243 (0.1721818436237966)	Acc@1  93.75 ( 94.41)	Acc@5 100.00 ( 99.67)
Epoch: [31][170/203]	Time  6.166 ( 1.925)	Data  5.653 ( 1.322)	Loss 0.2354371547698975 (0.1755880689281121)	Acc@1  92.19 ( 94.28)	Acc@5 100.00 ( 99.63)
Epoch: [31][180/203]	Time  2.860 ( 1.946)	Data  2.259 ( 1.345)	Loss 0.2138226926326752 (0.1764666269126847)	Acc@1  95.31 ( 94.28)	Acc@5 100.00 ( 99.64)
Epoch: [31][190/203]	Time  0.621 ( 1.897)	Data  0.000 ( 1.295)	Loss 0.2528941929340363 (0.1775906090063886)	Acc@1  90.62 ( 94.25)	Acc@5  98.44 ( 99.62)
Epoch: [31][200/203]	Time  0.523 ( 1.907)	Data  0.000 ( 1.308)	Loss 0.1805648803710938 (0.1788389171793390)	Acc@1  96.88 ( 94.20)	Acc@5 100.00 ( 99.62)
epoch: 31, Avg_Loss 0.17847592620353395
Test: [ 0/51]	Time 24.350 (24.350)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.56)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.140 ( 2.355)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 74.29)	Acc@5  85.94 ( 85.09)
Test: [20/51]	Time  0.137 ( 2.284)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 74.85)	Acc@5  92.19 ( 85.94)
Test: [30/51]	Time  0.129 ( 1.593)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 74.60)	Acc@5  84.38 ( 86.24)
Test: [40/51]	Time  0.134 ( 1.741)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 74.85)	Acc@5  82.81 ( 86.28)
Test: [50/51]	Time  0.121 ( 1.769)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  83.64 ( 74.90)	Acc@5  94.55 ( 86.54)
 * Acc@1 74.900 Acc@5 86.544
Epoch: [32][  0/203]	Time 29.908 (29.908)	Data 29.146 (29.146)	Loss 0.2198117375373840 (0.2198117375373840)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [32][ 10/203]	Time  0.505 ( 3.448)	Data  0.001 ( 2.857)	Loss 0.1840143501758575 (0.1776229894974015)	Acc@1  95.31 ( 94.46)	Acc@5 100.00 ( 99.57)
Epoch: [32][ 20/203]	Time  0.519 ( 3.022)	Data  0.000 ( 2.440)	Loss 0.1550898998975754 (0.1636395078329813)	Acc@1  95.31 ( 94.79)	Acc@5 100.00 ( 99.70)
Epoch: [32][ 30/203]	Time  0.479 ( 2.228)	Data  0.000 ( 1.653)	Loss 0.1647720187902451 (0.1619462947691641)	Acc@1  96.88 ( 94.96)	Acc@5 100.00 ( 99.70)
Epoch: [32][ 40/203]	Time  0.473 ( 2.321)	Data  0.000 ( 1.753)	Loss 0.1306071281433105 (0.1616024233219100)	Acc@1  95.31 ( 95.05)	Acc@5 100.00 ( 99.62)
Epoch: [32][ 50/203]	Time  0.527 ( 2.369)	Data  0.000 ( 1.807)	Loss 0.1841962933540344 (0.1586136541091928)	Acc@1  90.62 ( 94.98)	Acc@5 100.00 ( 99.66)
Epoch: [32][ 60/203]	Time  0.558 ( 2.069)	Data  0.000 ( 1.511)	Loss 0.0718326792120934 (0.1597805362133706)	Acc@1  98.44 ( 94.88)	Acc@5 100.00 ( 99.67)
Epoch: [32][ 70/203]	Time  0.599 ( 2.241)	Data  0.000 ( 1.688)	Loss 0.3724985122680664 (0.1678240851722133)	Acc@1  90.62 ( 94.65)	Acc@5  98.44 ( 99.58)
Epoch: [32][ 80/203]	Time 39.348 ( 2.508)	Data 38.813 ( 1.959)	Loss 0.1176898032426834 (0.1618417874438527)	Acc@1  93.75 ( 94.81)	Acc@5 100.00 ( 99.63)
Epoch: [32][ 90/203]	Time  0.589 ( 2.379)	Data  0.001 ( 1.816)	Loss 0.1959650665521622 (0.1630371523673063)	Acc@1  93.75 ( 94.75)	Acc@5 100.00 ( 99.66)
Epoch: [32][100/203]	Time  0.526 ( 2.454)	Data  0.000 ( 1.887)	Loss 0.1421375721693039 (0.1612748413319045)	Acc@1  93.75 ( 94.83)	Acc@5 100.00 ( 99.63)
Epoch: [32][110/203]	Time  0.478 ( 2.285)	Data  0.000 ( 1.717)	Loss 0.0827710703015327 (0.1577750866276187)	Acc@1  95.31 ( 94.88)	Acc@5 100.00 ( 99.63)
Epoch: [32][120/203]	Time  0.560 ( 2.355)	Data  0.000 ( 1.788)	Loss 0.3004991114139557 (0.1582376034853380)	Acc@1  90.62 ( 94.85)	Acc@5  98.44 ( 99.65)
Epoch: [32][130/203]	Time  0.563 ( 2.389)	Data  0.001 ( 1.822)	Loss 0.1676655858755112 (0.1586214921913529)	Acc@1  95.31 ( 94.84)	Acc@5 100.00 ( 99.64)
Epoch: [32][140/203]	Time  0.648 ( 2.275)	Data  0.000 ( 1.705)	Loss 0.1523090004920959 (0.1587559753857183)	Acc@1  95.31 ( 94.77)	Acc@5 100.00 ( 99.63)
Epoch: [32][150/203]	Time  0.521 ( 2.328)	Data  0.000 ( 1.758)	Loss 0.1904842108488083 (0.1592509298776554)	Acc@1  95.31 ( 94.73)	Acc@5  98.44 ( 99.64)
Epoch: [32][160/203]	Time 11.106 ( 2.282)	Data 10.607 ( 1.715)	Loss 0.2104415893554688 (0.1603894848954974)	Acc@1  90.62 ( 94.68)	Acc@5 100.00 ( 99.65)
Epoch: [32][170/203]	Time  0.510 ( 2.270)	Data  0.001 ( 1.699)	Loss 0.0892140492796898 (0.1619868930973853)	Acc@1  98.44 ( 94.71)	Acc@5 100.00 ( 99.64)
Epoch: [32][180/203]	Time  0.562 ( 2.319)	Data  0.000 ( 1.748)	Loss 0.1612168997526169 (0.1599267676925462)	Acc@1  95.31 ( 94.77)	Acc@5  98.44 ( 99.65)
Epoch: [32][190/203]	Time  0.593 ( 2.226)	Data  0.000 ( 1.656)	Loss 0.2526895999908447 (0.1598093109254126)	Acc@1  92.19 ( 94.76)	Acc@5  98.44 ( 99.66)
Epoch: [32][200/203]	Time  0.579 ( 2.254)	Data  0.000 ( 1.683)	Loss 0.2134476602077484 (0.1601481167367887)	Acc@1  92.19 ( 94.76)	Acc@5  98.44 ( 99.67)
epoch: 32, Avg_Loss 0.15978640988652637
Test: [ 0/51]	Time 24.418 (24.418)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.38)	Acc@5  90.62 ( 90.62)
Test: [10/51]	Time  0.127 ( 2.707)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.83)	Acc@5  92.19 ( 91.19)
Test: [20/51]	Time  0.121 ( 2.384)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 80.06)	Acc@5  90.62 ( 90.70)
Test: [30/51]	Time  0.134 ( 1.732)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 79.33)	Acc@5  89.06 ( 89.67)
Test: [40/51]	Time  0.135 ( 1.829)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 79.50)	Acc@5  90.62 ( 90.05)
Test: [50/51]	Time  0.109 ( 1.899)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.36 ( 79.75)	Acc@5  89.09 ( 90.35)
 * Acc@1 79.754 Acc@5 90.353
Epoch: [33][  0/203]	Time 33.204 (33.204)	Data 32.637 (32.637)	Loss 0.0611386075615883 (0.0611386075615883)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [33][ 10/203]	Time  0.605 ( 3.819)	Data  0.001 ( 3.229)	Loss 0.0875864773988724 (0.1598670970309864)	Acc@1  96.88 ( 94.60)	Acc@5 100.00 (100.00)
Epoch: [33][ 20/203]	Time  0.600 ( 3.628)	Data  0.000 ( 3.034)	Loss 0.1523663252592087 (0.1513790977852685)	Acc@1  93.75 ( 94.49)	Acc@5 100.00 (100.00)
Epoch: [33][ 30/203]	Time  0.551 ( 2.631)	Data  0.000 ( 2.056)	Loss 0.3179118037223816 (0.1503198307848746)	Acc@1  93.75 ( 94.81)	Acc@5  98.44 ( 99.95)
Epoch: [33][ 40/203]	Time  0.534 ( 2.956)	Data  0.000 ( 2.387)	Loss 0.1083795130252838 (0.1410362228932904)	Acc@1  96.88 ( 95.05)	Acc@5 100.00 ( 99.96)
Epoch: [33][ 50/203]	Time  0.741 ( 3.093)	Data  0.000 ( 2.520)	Loss 0.1119469925761223 (0.1411232624714281)	Acc@1  98.44 ( 95.04)	Acc@5 100.00 ( 99.94)
Epoch: [33][ 60/203]	Time  0.700 ( 2.690)	Data  0.000 ( 2.107)	Loss 0.0987981259822845 (0.1397896846909015)	Acc@1  96.88 ( 95.16)	Acc@5 100.00 ( 99.90)
Epoch: [33][ 70/203]	Time  0.526 ( 2.782)	Data  0.000 ( 2.202)	Loss 0.1785685122013092 (0.1424464518860192)	Acc@1  95.31 ( 95.14)	Acc@5  98.44 ( 99.87)
Epoch: [33][ 80/203]	Time 21.672 ( 2.764)	Data 21.055 ( 2.190)	Loss 0.1567257791757584 (0.1418267324290894)	Acc@1  95.31 ( 95.18)	Acc@5 100.00 ( 99.86)
Epoch: [33][ 90/203]	Time  0.519 ( 2.773)	Data  0.000 ( 2.203)	Loss 0.1014773473143578 (0.1425180361902976)	Acc@1  96.88 ( 95.16)	Acc@5 100.00 ( 99.85)
Epoch: [33][100/203]	Time  0.497 ( 2.867)	Data  0.000 ( 2.292)	Loss 0.1654715687036514 (0.1459108446125347)	Acc@1  95.31 ( 95.08)	Acc@5 100.00 ( 99.81)
Epoch: [33][110/203]	Time  0.526 ( 2.658)	Data  0.000 ( 2.086)	Loss 0.1619644910097122 (0.1457257802421982)	Acc@1  95.31 ( 95.09)	Acc@5 100.00 ( 99.79)
Epoch: [33][120/203]	Time  0.498 ( 2.694)	Data  0.000 ( 2.125)	Loss 0.1351282596588135 (0.1474358122949758)	Acc@1  90.62 ( 95.05)	Acc@5 100.00 ( 99.75)
Epoch: [33][130/203]	Time  0.529 ( 2.706)	Data  0.000 ( 2.138)	Loss 0.1203225329518318 (0.1466101135575134)	Acc@1  96.88 ( 95.09)	Acc@5  98.44 ( 99.76)
Epoch: [33][140/203]	Time  0.604 ( 2.551)	Data  0.000 ( 1.987)	Loss 0.1091953217983246 (0.1472847558927874)	Acc@1  96.88 ( 95.02)	Acc@5 100.00 ( 99.78)
Epoch: [33][150/203]	Time  0.542 ( 2.557)	Data  0.000 ( 1.995)	Loss 0.0867809206247330 (0.1457989219551450)	Acc@1  96.88 ( 95.08)	Acc@5 100.00 ( 99.78)
Epoch: [33][160/203]	Time  3.445 ( 2.453)	Data  2.914 ( 1.889)	Loss 0.0619732327759266 (0.1448938783188784)	Acc@1  98.44 ( 95.12)	Acc@5 100.00 ( 99.78)
Epoch: [33][170/203]	Time  0.512 ( 2.443)	Data  0.003 ( 1.881)	Loss 0.0871188417077065 (0.1454457415823351)	Acc@1  96.88 ( 95.14)	Acc@5 100.00 ( 99.79)
Epoch: [33][180/203]	Time  0.551 ( 2.464)	Data  0.000 ( 1.903)	Loss 0.1123482584953308 (0.1454448713535103)	Acc@1  95.31 ( 95.16)	Acc@5 100.00 ( 99.76)
Epoch: [33][190/203]	Time  0.617 ( 2.364)	Data  0.000 ( 1.803)	Loss 0.0625943839550018 (0.1446464765056266)	Acc@1  98.44 ( 95.20)	Acc@5 100.00 ( 99.76)
Epoch: [33][200/203]	Time  0.679 ( 2.373)	Data  0.000 ( 1.813)	Loss 0.1824025511741638 (0.1455732033916967)	Acc@1  96.88 ( 95.21)	Acc@5 100.00 ( 99.77)
epoch: 33, Avg_Loss 0.14548253624016427
Test: [ 0/51]	Time 32.644 (32.644)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.38)	Acc@5  90.62 ( 90.62)
Test: [10/51]	Time  0.143 ( 3.115)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 77.56)	Acc@5  95.31 ( 92.61)
Test: [20/51]	Time  0.122 ( 2.788)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 76.64)	Acc@5  92.19 ( 91.59)
Test: [30/51]	Time  0.118 ( 1.929)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 76.92)	Acc@5  85.94 ( 91.03)
Test: [40/51]	Time  0.139 ( 2.212)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  67.19 ( 76.49)	Acc@5  85.94 ( 90.78)
Test: [50/51]	Time  0.153 ( 2.253)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  80.00 ( 77.14)	Acc@5  89.09 ( 90.69)
 * Acc@1 77.143 Acc@5 90.691
Epoch: [34][  0/203]	Time 33.686 (33.686)	Data 33.011 (33.011)	Loss 0.1098028719425201 (0.1098028719425201)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [34][ 10/203]	Time  0.564 ( 3.650)	Data  0.001 ( 3.001)	Loss 0.1361623257398605 (0.1274174042046070)	Acc@1  96.88 ( 96.88)	Acc@5  98.44 ( 99.86)
Epoch: [34][ 20/203]	Time  0.617 ( 3.026)	Data  0.000 ( 2.407)	Loss 0.1031113639473915 (0.1220640101957889)	Acc@1  96.88 ( 96.58)	Acc@5 100.00 ( 99.93)
Epoch: [34][ 30/203]	Time  0.520 ( 2.240)	Data  0.000 ( 1.631)	Loss 0.1793989539146423 (0.1171881777324503)	Acc@1  92.19 ( 96.57)	Acc@5 100.00 ( 99.95)
Epoch: [34][ 40/203]	Time  2.239 ( 2.398)	Data  1.599 ( 1.788)	Loss 0.1037157475948334 (0.1199393342135519)	Acc@1  96.88 ( 96.38)	Acc@5 100.00 ( 99.96)
Epoch: [34][ 50/203]	Time  3.581 ( 2.458)	Data  2.992 ( 1.836)	Loss 0.0783826783299446 (0.1284233935579073)	Acc@1  96.88 ( 96.11)	Acc@5 100.00 ( 99.94)
Epoch: [34][ 60/203]	Time  0.556 ( 2.155)	Data  0.000 ( 1.544)	Loss 0.0856162384152412 (0.1350128255387554)	Acc@1  98.44 ( 96.00)	Acc@5 100.00 ( 99.87)
Epoch: [34][ 70/203]	Time  0.506 ( 2.312)	Data  0.000 ( 1.712)	Loss 0.1754835993051529 (0.1365602509000562)	Acc@1  96.88 ( 95.88)	Acc@5  98.44 ( 99.87)
Epoch: [34][ 80/203]	Time 15.103 ( 2.277)	Data 14.454 ( 1.679)	Loss 0.1601087599992752 (0.1364645713158412)	Acc@1  95.31 ( 95.81)	Acc@5 100.00 ( 99.83)
Epoch: [34][ 90/203]	Time  0.502 ( 2.170)	Data  0.000 ( 1.575)	Loss 0.2582235634326935 (0.1379440673985160)	Acc@1  90.62 ( 95.76)	Acc@5 100.00 ( 99.81)
Epoch: [34][100/203]	Time  0.532 ( 2.258)	Data  0.000 ( 1.667)	Loss 0.1876799911260605 (0.1359823597226255)	Acc@1  93.75 ( 95.79)	Acc@5  98.44 ( 99.81)
Epoch: [34][110/203]	Time  0.551 ( 2.105)	Data  0.000 ( 1.517)	Loss 0.1755645573139191 (0.1344517118607958)	Acc@1  95.31 ( 95.78)	Acc@5 100.00 ( 99.82)
Epoch: [34][120/203]	Time  0.503 ( 2.164)	Data  0.000 ( 1.579)	Loss 0.0945114418864250 (0.1360665197938311)	Acc@1  96.88 ( 95.69)	Acc@5 100.00 ( 99.82)
Epoch: [34][130/203]	Time  8.328 ( 2.196)	Data  7.783 ( 1.616)	Loss 0.1109475567936897 (0.1364124644448170)	Acc@1  95.31 ( 95.61)	Acc@5 100.00 ( 99.83)
Epoch: [34][140/203]	Time  0.600 ( 2.093)	Data  0.000 ( 1.514)	Loss 0.1547569036483765 (0.1343233557814296)	Acc@1  93.75 ( 95.67)	Acc@5 100.00 ( 99.84)
Epoch: [34][150/203]	Time  0.604 ( 2.187)	Data  0.000 ( 1.608)	Loss 0.1269036531448364 (0.1343820763579169)	Acc@1  96.88 ( 95.67)	Acc@5 100.00 ( 99.84)
Epoch: [34][160/203]	Time 23.459 ( 2.226)	Data 22.834 ( 1.650)	Loss 0.0932386666536331 (0.1340361261994850)	Acc@1  98.44 ( 95.70)	Acc@5 100.00 ( 99.84)
Epoch: [34][170/203]	Time  0.511 ( 2.197)	Data  0.001 ( 1.622)	Loss 0.3362033665180206 (0.1347260505603681)	Acc@1  89.06 ( 95.72)	Acc@5 100.00 ( 99.84)
Epoch: [34][180/203]	Time  0.535 ( 2.254)	Data  0.000 ( 1.680)	Loss 0.1395675688982010 (0.1347625304517743)	Acc@1  96.88 ( 95.72)	Acc@5 100.00 ( 99.84)
Epoch: [34][190/203]	Time  0.524 ( 2.204)	Data  0.000 ( 1.631)	Loss 0.1193667501211166 (0.1353422716523262)	Acc@1  95.31 ( 95.67)	Acc@5 100.00 ( 99.84)
Epoch: [34][200/203]	Time  0.516 ( 2.242)	Data  0.000 ( 1.669)	Loss 0.2773110866546631 (0.1370492943363329)	Acc@1  89.06 ( 95.62)	Acc@5 100.00 ( 99.83)
epoch: 34, Avg_Loss 0.13721424601329812
Test: [ 0/51]	Time 29.351 (29.351)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 75.00)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.125 ( 2.985)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 76.56)	Acc@5  81.25 ( 85.94)
Test: [20/51]	Time  0.182 ( 2.796)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 77.01)	Acc@5  85.94 ( 86.01)
Test: [30/51]	Time  0.156 ( 2.061)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 77.87)	Acc@5  89.06 ( 86.29)
Test: [40/51]	Time  0.120 ( 2.208)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 77.55)	Acc@5  89.06 ( 85.98)
Test: [50/51]	Time  0.120 ( 2.214)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.18 ( 77.70)	Acc@5  87.27 ( 85.96)
 * Acc@1 77.696 Acc@5 85.960
Epoch: [35][  0/203]	Time 40.779 (40.779)	Data 40.033 (40.033)	Loss 0.1182521283626556 (0.1182521283626556)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [35][ 10/203]	Time  0.534 ( 4.303)	Data  0.001 ( 3.690)	Loss 0.0844645202159882 (0.1529355184598402)	Acc@1  96.88 ( 95.17)	Acc@5 100.00 ( 99.43)
Epoch: [35][ 20/203]	Time  0.559 ( 3.670)	Data  0.000 ( 3.083)	Loss 0.0843647047877312 (0.1344920402126653)	Acc@1  96.88 ( 95.91)	Acc@5 100.00 ( 99.55)
Epoch: [35][ 30/203]	Time  0.493 ( 2.664)	Data  0.000 ( 2.089)	Loss 0.2852715849876404 (0.1488296142028224)	Acc@1  90.62 ( 95.36)	Acc@5  98.44 ( 99.45)
Epoch: [35][ 40/203]	Time  0.656 ( 2.721)	Data  0.000 ( 2.130)	Loss 0.0542190857231617 (0.1442524015721751)	Acc@1  98.44 ( 95.54)	Acc@5 100.00 ( 99.58)
Epoch: [35][ 50/203]	Time  0.542 ( 2.639)	Data  0.000 ( 2.037)	Loss 0.1090608909726143 (0.1357580302831005)	Acc@1  98.44 ( 95.89)	Acc@5 100.00 ( 99.66)
Epoch: [35][ 60/203]	Time  0.530 ( 2.354)	Data  0.000 ( 1.757)	Loss 0.1145728006958961 (0.1306375535663034)	Acc@1  96.88 ( 96.13)	Acc@5  98.44 ( 99.69)
Epoch: [35][ 70/203]	Time  0.546 ( 2.426)	Data  0.000 ( 1.835)	Loss 0.2049947232007980 (0.1295349015001680)	Acc@1  93.75 ( 96.06)	Acc@5 100.00 ( 99.74)
Epoch: [35][ 80/203]	Time 14.184 ( 2.361)	Data 13.608 ( 1.776)	Loss 0.2022705525159836 (0.1278671755650897)	Acc@1  90.62 ( 95.97)	Acc@5 100.00 ( 99.77)
Epoch: [35][ 90/203]	Time  0.652 ( 2.284)	Data  0.000 ( 1.693)	Loss 0.0910240486264229 (0.1278689943745241)	Acc@1  96.88 ( 96.00)	Acc@5 100.00 ( 99.74)
Epoch: [35][100/203]	Time  0.561 ( 2.320)	Data  0.000 ( 1.726)	Loss 0.1746908426284790 (0.1294490466687349)	Acc@1  93.75 ( 95.93)	Acc@5 100.00 ( 99.74)
Epoch: [35][110/203]	Time  0.500 ( 2.157)	Data  0.000 ( 1.570)	Loss 0.1565744876861572 (0.1275933558406594)	Acc@1  96.88 ( 95.95)	Acc@5 100.00 ( 99.76)
Epoch: [35][120/203]	Time  0.498 ( 2.212)	Data  0.000 ( 1.630)	Loss 0.1801215261220932 (0.1342409506655675)	Acc@1  92.19 ( 95.69)	Acc@5 100.00 ( 99.77)
Epoch: [35][130/203]	Time  0.527 ( 2.332)	Data  0.000 ( 1.753)	Loss 0.0836035460233688 (0.1316014983414011)	Acc@1  95.31 ( 95.77)	Acc@5 100.00 ( 99.77)
Epoch: [35][140/203]	Time  0.660 ( 2.256)	Data  0.000 ( 1.674)	Loss 0.1081249788403511 (0.1310226454511813)	Acc@1  96.88 ( 95.78)	Acc@5 100.00 ( 99.76)
Epoch: [35][150/203]	Time  0.499 ( 2.408)	Data  0.003 ( 1.829)	Loss 0.0836781412363052 (0.1316633038099436)	Acc@1  96.88 ( 95.75)	Acc@5  98.44 ( 99.75)
Epoch: [35][160/203]	Time 25.469 ( 2.447)	Data 24.939 ( 1.871)	Loss 0.1824507564306259 (0.1359494616688223)	Acc@1  93.75 ( 95.63)	Acc@5 100.00 ( 99.73)
Epoch: [35][170/203]	Time  0.548 ( 2.400)	Data  0.001 ( 1.821)	Loss 0.2141820639371872 (0.1372948551975321)	Acc@1  93.75 ( 95.60)	Acc@5 100.00 ( 99.74)
Epoch: [35][180/203]	Time  0.649 ( 2.478)	Data  0.000 ( 1.899)	Loss 0.0937672331929207 (0.1375668176362363)	Acc@1  96.88 ( 95.59)	Acc@5 100.00 ( 99.73)
Epoch: [35][190/203]	Time  0.528 ( 2.378)	Data  0.000 ( 1.800)	Loss 0.1086619794368744 (0.1378082996478099)	Acc@1  98.44 ( 95.58)	Acc@5  98.44 ( 99.74)
Epoch: [35][200/203]	Time  0.559 ( 2.415)	Data  0.000 ( 1.835)	Loss 0.0880536362528801 (0.1365398743018434)	Acc@1  98.44 ( 95.58)	Acc@5 100.00 ( 99.74)
epoch: 35, Avg_Loss 0.13679423677767144
Test: [ 0/51]	Time 22.703 (22.703)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.56)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.150 ( 2.386)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 78.27)	Acc@5  79.69 ( 86.79)
Test: [20/51]	Time  0.153 ( 2.269)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 78.42)	Acc@5  82.81 ( 87.50)
Test: [30/51]	Time  0.126 ( 1.631)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 78.68)	Acc@5  89.06 ( 87.60)
Test: [40/51]	Time  0.131 ( 1.754)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 79.19)	Acc@5  92.19 ( 87.77)
Test: [50/51]	Time  0.128 ( 1.761)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  80.00 ( 79.39)	Acc@5  85.45 ( 87.71)
 * Acc@1 79.386 Acc@5 87.711
Epoch: [36][  0/203]	Time 36.792 (36.792)	Data 35.827 (35.827)	Loss 0.0799102336168289 (0.0799102336168289)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [36][ 10/203]	Time  0.571 ( 3.996)	Data  0.001 ( 3.391)	Loss 0.0621541962027550 (0.1223294541917064)	Acc@1  98.44 ( 96.16)	Acc@5 100.00 ( 99.57)
Epoch: [36][ 20/203]	Time  0.552 ( 3.673)	Data  0.000 ( 3.083)	Loss 0.1640411615371704 (0.1266080790332385)	Acc@1  93.75 ( 96.28)	Acc@5  98.44 ( 99.55)
Epoch: [36][ 30/203]	Time  0.485 ( 2.664)	Data  0.000 ( 2.092)	Loss 0.1184668317437172 (0.1231251171519679)	Acc@1  96.88 ( 96.42)	Acc@5 100.00 ( 99.65)
Epoch: [36][ 40/203]	Time  0.550 ( 2.831)	Data  0.000 ( 2.260)	Loss 0.0884140655398369 (0.1262859587625760)	Acc@1  95.31 ( 96.27)	Acc@5 100.00 ( 99.73)
Epoch: [36][ 50/203]	Time 13.350 ( 3.121)	Data 12.754 ( 2.549)	Loss 0.0746397450566292 (0.1221079895017194)	Acc@1  96.88 ( 96.26)	Acc@5 100.00 ( 99.72)
Epoch: [36][ 60/203]	Time  0.567 ( 2.704)	Data  0.000 ( 2.131)	Loss 0.0786278843879700 (0.1236785912550375)	Acc@1  98.44 ( 96.23)	Acc@5 100.00 ( 99.69)
Epoch: [36][ 70/203]	Time  0.511 ( 2.816)	Data  0.000 ( 2.247)	Loss 0.0959010273218155 (0.1184580900876875)	Acc@1  98.44 ( 96.43)	Acc@5 100.00 ( 99.74)
Epoch: [36][ 80/203]	Time 19.552 ( 2.777)	Data 18.956 ( 2.204)	Loss 0.1492119431495667 (0.1182713113771177)	Acc@1  95.31 ( 96.45)	Acc@5  98.44 ( 99.73)
Epoch: [36][ 90/203]	Time  0.507 ( 2.751)	Data  0.000 ( 2.184)	Loss 0.0781852677464485 (0.1157505346646348)	Acc@1  98.44 ( 96.55)	Acc@5 100.00 ( 99.76)
Epoch: [36][100/203]	Time  0.587 ( 2.775)	Data  0.000 ( 2.208)	Loss 0.3072544038295746 (0.1187916982845210)	Acc@1  84.38 ( 96.47)	Acc@5 100.00 ( 99.75)
Epoch: [36][110/203]	Time  0.503 ( 2.574)	Data  0.000 ( 2.009)	Loss 0.1288823634386063 (0.1186506797030971)	Acc@1  96.88 ( 96.51)	Acc@5 100.00 ( 99.76)
Epoch: [36][120/203]	Time  0.498 ( 2.668)	Data  0.000 ( 2.103)	Loss 0.0792540013790131 (0.1186473947942011)	Acc@1  96.88 ( 96.50)	Acc@5 100.00 ( 99.77)
Epoch: [36][130/203]	Time  3.764 ( 2.718)	Data  3.128 ( 2.155)	Loss 0.1706318259239197 (0.1190269699903162)	Acc@1  92.19 ( 96.42)	Acc@5  98.44 ( 99.76)
Epoch: [36][140/203]	Time  0.524 ( 2.566)	Data  0.000 ( 2.002)	Loss 0.1130438819527626 (0.1179734885507653)	Acc@1  95.31 ( 96.40)	Acc@5 100.00 ( 99.76)
Epoch: [36][150/203]	Time  0.538 ( 2.598)	Data  0.000 ( 2.033)	Loss 0.1236137449741364 (0.1188189998540460)	Acc@1  96.88 ( 96.34)	Acc@5 100.00 ( 99.76)
Epoch: [36][160/203]	Time 18.049 ( 2.582)	Data 17.437 ( 2.015)	Loss 0.1180531978607178 (0.1204255071833082)	Acc@1  95.31 ( 96.25)	Acc@5 100.00 ( 99.76)
Epoch: [36][170/203]	Time  1.079 ( 2.523)	Data  0.002 ( 1.947)	Loss 0.1320502310991287 (0.1196526029631931)	Acc@1  95.31 ( 96.25)	Acc@5 100.00 ( 99.77)
Epoch: [36][180/203]	Time  0.685 ( 2.558)	Data  0.000 ( 1.979)	Loss 0.1371832340955734 (0.1211041379514155)	Acc@1  96.88 ( 96.19)	Acc@5 100.00 ( 99.78)
Epoch: [36][190/203]	Time  0.544 ( 2.454)	Data  0.000 ( 1.876)	Loss 0.1207651495933533 (0.1205759945164644)	Acc@1  95.31 ( 96.20)	Acc@5 100.00 ( 99.78)
Epoch: [36][200/203]	Time  0.571 ( 2.486)	Data  0.000 ( 1.908)	Loss 0.0984405949711800 (0.1204262722135332)	Acc@1  95.31 ( 96.19)	Acc@5 100.00 ( 99.79)
epoch: 36, Avg_Loss 0.12036032193877133
Test: [ 0/51]	Time 27.195 (27.195)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.31 ( 70.31)	Acc@5  81.25 ( 81.25)
Test: [10/51]	Time  0.167 ( 2.849)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 80.54)	Acc@5  92.19 ( 88.35)
Test: [20/51]	Time  0.186 ( 2.704)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 78.87)	Acc@5  87.50 ( 87.43)
Test: [30/51]	Time  0.197 ( 1.886)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 78.68)	Acc@5  90.62 ( 86.64)
Test: [40/51]	Time  0.129 ( 2.019)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 78.93)	Acc@5  95.31 ( 86.74)
Test: [50/51]	Time  0.135 ( 2.111)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 78.77)	Acc@5  90.91 ( 86.88)
 * Acc@1 78.771 Acc@5 86.882
Epoch: [37][  0/203]	Time 36.117 (36.117)	Data 35.331 (35.331)	Loss 0.0992880538105965 (0.0992880538105965)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [37][ 10/203]	Time  0.500 ( 3.782)	Data  0.001 ( 3.212)	Loss 0.0484263077378273 (0.1133445331996137)	Acc@1  98.44 ( 97.02)	Acc@5 100.00 ( 99.72)
Epoch: [37][ 20/203]	Time  0.499 ( 3.827)	Data  0.000 ( 3.276)	Loss 0.1009030044078827 (0.1308605763174239)	Acc@1  96.88 ( 96.21)	Acc@5 100.00 ( 99.63)
Epoch: [37][ 30/203]	Time  0.610 ( 2.760)	Data  0.000 ( 2.219)	Loss 0.0299638677388430 (0.1190324131880076)	Acc@1 100.00 ( 96.47)	Acc@5 100.00 ( 99.65)
Epoch: [37][ 40/203]	Time  4.996 ( 3.437)	Data  4.441 ( 2.881)	Loss 0.0686673671007156 (0.1246087109079448)	Acc@1  98.44 ( 96.38)	Acc@5 100.00 ( 99.70)
Epoch: [37][ 50/203]	Time  0.591 ( 3.339)	Data  0.000 ( 2.782)	Loss 0.1139874383807182 (0.1206215834427698)	Acc@1  95.31 ( 96.42)	Acc@5 100.00 ( 99.69)
Epoch: [37][ 60/203]	Time  0.542 ( 2.888)	Data  0.000 ( 2.326)	Loss 0.1482661813497543 (0.1228564232893166)	Acc@1  95.31 ( 96.36)	Acc@5 100.00 ( 99.69)
Epoch: [37][ 70/203]	Time  0.649 ( 2.951)	Data  0.000 ( 2.378)	Loss 0.0391450673341751 (0.1218045248164677)	Acc@1 100.00 ( 96.35)	Acc@5 100.00 ( 99.67)
Epoch: [37][ 80/203]	Time 20.508 ( 2.907)	Data 19.841 ( 2.329)	Loss 0.2126567214727402 (0.1214066450656564)	Acc@1  93.75 ( 96.24)	Acc@5 100.00 ( 99.67)
Epoch: [37][ 90/203]	Time  0.537 ( 2.656)	Data  0.000 ( 2.078)	Loss 0.1058291867375374 (0.1207241150908745)	Acc@1  96.88 ( 96.31)	Acc@5  98.44 ( 99.66)
Epoch: [37][100/203]	Time  0.755 ( 2.673)	Data  0.000 ( 2.094)	Loss 0.1251554340124130 (0.1204570111551202)	Acc@1  92.19 ( 96.26)	Acc@5 100.00 ( 99.66)
Epoch: [37][110/203]	Time  0.527 ( 2.500)	Data  0.000 ( 1.920)	Loss 0.0399925224483013 (0.1176273135283777)	Acc@1  98.44 ( 96.26)	Acc@5 100.00 ( 99.69)
Epoch: [37][120/203]	Time  2.602 ( 2.529)	Data  2.079 ( 1.951)	Loss 0.0863672867417336 (0.1197829153080863)	Acc@1  96.88 ( 96.23)	Acc@5 100.00 ( 99.65)
Epoch: [37][130/203]	Time  0.767 ( 2.528)	Data  0.086 ( 1.948)	Loss 0.1249619796872139 (0.1171811719545881)	Acc@1  98.44 ( 96.31)	Acc@5 100.00 ( 99.67)
Epoch: [37][140/203]	Time  0.499 ( 2.397)	Data  0.000 ( 1.817)	Loss 0.0807994902133942 (0.1179120447090332)	Acc@1 100.00 ( 96.28)	Acc@5 100.00 ( 99.68)
Epoch: [37][150/203]	Time  0.630 ( 2.435)	Data  0.000 ( 1.854)	Loss 0.0784327983856201 (0.1197167123785082)	Acc@1  98.44 ( 96.27)	Acc@5 100.00 ( 99.69)
Epoch: [37][160/203]	Time 23.440 ( 2.461)	Data 22.802 ( 1.880)	Loss 0.0680077001452446 (0.1200266416120973)	Acc@1  98.44 ( 96.25)	Acc@5 100.00 ( 99.70)
Epoch: [37][170/203]	Time  0.659 ( 2.386)	Data  0.001 ( 1.803)	Loss 0.1600225567817688 (0.1210263949432220)	Acc@1  93.75 ( 96.21)	Acc@5 100.00 ( 99.72)
Epoch: [37][180/203]	Time  0.741 ( 2.397)	Data  0.000 ( 1.812)	Loss 0.1483727395534515 (0.1209812596522642)	Acc@1  95.31 ( 96.23)	Acc@5  98.44 ( 99.70)
Epoch: [37][190/203]	Time  0.592 ( 2.328)	Data  0.000 ( 1.745)	Loss 0.1400709897279739 (0.1219186519336014)	Acc@1  95.31 ( 96.20)	Acc@5  98.44 ( 99.68)
Epoch: [37][200/203]	Time  4.608 ( 2.361)	Data  4.054 ( 1.779)	Loss 0.1201772987842560 (0.1198783827324708)	Acc@1  95.31 ( 96.27)	Acc@5 100.00 ( 99.69)
epoch: 37, Avg_Loss 0.11933259634769021
Test: [ 0/51]	Time 26.667 (26.667)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 71.88)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.146 ( 2.815)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 77.70)	Acc@5  89.06 ( 86.22)
Test: [20/51]	Time  0.139 ( 2.730)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 78.35)	Acc@5  89.06 ( 85.86)
Test: [30/51]	Time  0.149 ( 1.897)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 78.48)	Acc@5  81.25 ( 86.09)
Test: [40/51]	Time  0.152 ( 2.029)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  92.19 ( 79.23)	Acc@5  96.88 ( 86.74)
Test: [50/51]	Time  0.148 ( 2.114)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  80.00 ( 79.29)	Acc@5  90.91 ( 86.85)
 * Acc@1 79.293 Acc@5 86.851
Epoch: [38][  0/203]	Time 34.482 (34.482)	Data 33.807 (33.807)	Loss 0.1571671962738037 (0.1571671962738037)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [38][ 10/203]	Time  0.558 ( 3.633)	Data  0.001 ( 3.074)	Loss 0.0908927693963051 (0.0989833010191267)	Acc@1  98.44 ( 96.59)	Acc@5 100.00 ( 99.86)
Epoch: [38][ 20/203]	Time  0.574 ( 3.228)	Data  0.000 ( 2.663)	Loss 0.0299558509141207 (0.0985209431854032)	Acc@1 100.00 ( 96.80)	Acc@5 100.00 ( 99.93)
Epoch: [38][ 30/203]	Time  0.670 ( 2.387)	Data  0.000 ( 1.804)	Loss 0.1104316785931587 (0.1030553552292047)	Acc@1  96.88 ( 96.77)	Acc@5 100.00 ( 99.90)
Epoch: [38][ 40/203]	Time  0.564 ( 2.478)	Data  0.000 ( 1.897)	Loss 0.0639298185706139 (0.0959771126508713)	Acc@1  98.44 ( 96.99)	Acc@5 100.00 ( 99.92)
Epoch: [38][ 50/203]	Time  0.558 ( 2.550)	Data  0.000 ( 1.974)	Loss 0.2074834704399109 (0.1000066003670879)	Acc@1  93.75 ( 96.78)	Acc@5  98.44 ( 99.88)
Epoch: [38][ 60/203]	Time  0.520 ( 2.226)	Data  0.000 ( 1.651)	Loss 0.0906614363193512 (0.0973474037390752)	Acc@1  98.44 ( 96.82)	Acc@5 100.00 ( 99.87)
Epoch: [38][ 70/203]	Time  0.559 ( 2.298)	Data  0.000 ( 1.718)	Loss 0.0339524596929550 (0.0988407328095235)	Acc@1 100.00 ( 96.83)	Acc@5 100.00 ( 99.87)
Epoch: [38][ 80/203]	Time 22.174 ( 2.355)	Data 21.458 ( 1.771)	Loss 0.1891197115182877 (0.1016907591234755)	Acc@1  95.31 ( 96.74)	Acc@5  98.44 ( 99.86)
Epoch: [38][ 90/203]	Time  0.559 ( 2.214)	Data  0.000 ( 1.628)	Loss 0.0927777364850044 (0.1006415880561530)	Acc@1  96.88 ( 96.82)	Acc@5 100.00 ( 99.85)
Epoch: [38][100/203]	Time  0.529 ( 2.430)	Data  0.000 ( 1.843)	Loss 0.0858154371380806 (0.1028936653222778)	Acc@1  96.88 ( 96.74)	Acc@5 100.00 ( 99.83)
Epoch: [38][110/203]	Time  2.942 ( 2.310)	Data  2.393 ( 1.729)	Loss 0.0904144197702408 (0.1024541173230957)	Acc@1  95.31 ( 96.71)	Acc@5 100.00 ( 99.85)
Epoch: [38][120/203]	Time  0.514 ( 2.455)	Data  0.000 ( 1.868)	Loss 0.1455924808979034 (0.1007666062902321)	Acc@1  95.31 ( 96.73)	Acc@5 100.00 ( 99.86)
Epoch: [38][130/203]	Time  0.537 ( 2.432)	Data  0.000 ( 1.848)	Loss 0.1270418018102646 (0.1002710223738246)	Acc@1  93.75 ( 96.77)	Acc@5 100.00 ( 99.84)
Epoch: [38][140/203]	Time  0.631 ( 2.347)	Data  0.000 ( 1.764)	Loss 0.1141672357916832 (0.1003557916942006)	Acc@1  96.88 ( 96.74)	Acc@5  98.44 ( 99.84)
Epoch: [38][150/203]	Time  3.591 ( 2.394)	Data  3.045 ( 1.811)	Loss 0.1412547230720520 (0.1021587693484019)	Acc@1  96.88 ( 96.67)	Acc@5  98.44 ( 99.84)
Epoch: [38][160/203]	Time 15.487 ( 2.374)	Data 14.791 ( 1.790)	Loss 0.0377005636692047 (0.1020071397749534)	Acc@1 100.00 ( 96.69)	Acc@5 100.00 ( 99.84)
Epoch: [38][170/203]	Time  0.607 ( 2.331)	Data  0.001 ( 1.742)	Loss 0.1453129053115845 (0.1020390693076521)	Acc@1  95.31 ( 96.68)	Acc@5  98.44 ( 99.84)
Epoch: [38][180/203]	Time  0.570 ( 2.317)	Data  0.000 ( 1.726)	Loss 0.1431769877672195 (0.1025201050739591)	Acc@1  95.31 ( 96.65)	Acc@5 100.00 ( 99.84)
Epoch: [38][190/203]	Time  0.494 ( 2.270)	Data  0.000 ( 1.683)	Loss 0.0910369977355003 (0.1022591329720944)	Acc@1  96.88 ( 96.67)	Acc@5  98.44 ( 99.84)
Epoch: [38][200/203]	Time  0.618 ( 2.305)	Data  0.000 ( 1.718)	Loss 0.1498207747936249 (0.1021638669870534)	Acc@1  95.31 ( 96.69)	Acc@5 100.00 ( 99.83)
epoch: 38, Avg_Loss 0.10213038641867672
Test: [ 0/51]	Time 27.890 (27.890)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 81.25)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.123 ( 2.679)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 78.98)	Acc@5  89.06 ( 87.07)
Test: [20/51]	Time  0.166 ( 2.747)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 79.99)	Acc@5  89.06 ( 87.80)
Test: [30/51]	Time  0.148 ( 1.911)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 79.94)	Acc@5  85.94 ( 87.40)
Test: [40/51]	Time  0.137 ( 2.066)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 79.54)	Acc@5  81.25 ( 87.16)
Test: [50/51]	Time  1.537 ( 2.032)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.27 ( 79.69)	Acc@5  98.18 ( 87.50)
 * Acc@1 79.693 Acc@5 87.496
Epoch: [39][  0/203]	Time 36.301 (36.301)	Data 35.471 (35.471)	Loss 0.2012258619070053 (0.2012258619070053)	Acc@1  95.31 ( 95.31)	Acc@5  96.88 ( 96.88)
Epoch: [39][ 10/203]	Time  0.512 ( 3.824)	Data  0.001 ( 3.225)	Loss 0.0388694070279598 (0.1029527106068351)	Acc@1  98.44 ( 97.44)	Acc@5 100.00 ( 99.72)
Epoch: [39][ 20/203]	Time  1.414 ( 3.772)	Data  0.892 ( 3.195)	Loss 0.1089166998863220 (0.1034139210269565)	Acc@1  95.31 ( 97.10)	Acc@5 100.00 ( 99.78)
Epoch: [39][ 30/203]	Time  0.555 ( 2.731)	Data  0.000 ( 2.165)	Loss 0.0259562395513058 (0.1066470576390143)	Acc@1 100.00 ( 96.77)	Acc@5 100.00 ( 99.85)
Epoch: [39][ 40/203]	Time  0.621 ( 3.156)	Data  0.000 ( 2.572)	Loss 0.1007634401321411 (0.1126142414968188)	Acc@1  96.88 ( 96.49)	Acc@5 100.00 ( 99.81)
Epoch: [39][ 50/203]	Time  0.622 ( 3.190)	Data  0.000 ( 2.607)	Loss 0.0853124782443047 (0.1090093682355741)	Acc@1  96.88 ( 96.63)	Acc@5 100.00 ( 99.82)
Epoch: [39][ 60/203]	Time  0.698 ( 2.777)	Data  0.000 ( 2.180)	Loss 0.1952319592237473 (0.1110213464889370)	Acc@1  95.31 ( 96.62)	Acc@5  96.88 ( 99.74)
Epoch: [39][ 70/203]	Time  0.524 ( 2.788)	Data  0.000 ( 2.190)	Loss 0.0312490593641996 (0.1055078443244729)	Acc@1 100.00 ( 96.81)	Acc@5 100.00 ( 99.78)
Epoch: [39][ 80/203]	Time 27.636 ( 2.843)	Data 26.965 ( 2.253)	Loss 0.1224218606948853 (0.1065936258039725)	Acc@1  96.88 ( 96.84)	Acc@5  98.44 ( 99.77)
Epoch: [39][ 90/203]	Time  0.632 ( 2.602)	Data  0.000 ( 2.005)	Loss 0.1843052655458450 (0.1056662818191798)	Acc@1  96.88 ( 96.86)	Acc@5 100.00 ( 99.79)
Epoch: [39][100/203]	Time  0.546 ( 2.620)	Data  0.000 ( 2.021)	Loss 0.1907155960798264 (0.1039445224301060)	Acc@1  92.19 ( 96.86)	Acc@5 100.00 ( 99.81)
Epoch: [39][110/203]	Time  0.607 ( 2.434)	Data  0.000 ( 1.839)	Loss 0.0374184884130955 (0.1044078430009855)	Acc@1  98.44 ( 96.80)	Acc@5 100.00 ( 99.83)
Epoch: [39][120/203]	Time  0.543 ( 2.478)	Data  0.000 ( 1.886)	Loss 0.0342066586017609 (0.1043576235798272)	Acc@1 100.00 ( 96.85)	Acc@5 100.00 ( 99.81)
Epoch: [39][130/203]	Time  0.712 ( 2.509)	Data  0.000 ( 1.918)	Loss 0.1228562444448471 (0.1025705283991139)	Acc@1  98.44 ( 96.90)	Acc@5 100.00 ( 99.81)
Epoch: [39][140/203]	Time  0.550 ( 2.370)	Data  0.000 ( 1.782)	Loss 0.0834400281310081 (0.1023697553678079)	Acc@1  96.88 ( 96.89)	Acc@5  98.44 ( 99.81)
Epoch: [39][150/203]	Time  0.587 ( 2.405)	Data  0.000 ( 1.817)	Loss 0.1755837351083755 (0.1021649880852822)	Acc@1  96.88 ( 96.91)	Acc@5  98.44 ( 99.81)
Epoch: [39][160/203]	Time 25.749 ( 2.448)	Data 25.200 ( 1.861)	Loss 0.0910802632570267 (0.1024573190970728)	Acc@1  96.88 ( 96.92)	Acc@5 100.00 ( 99.81)
Epoch: [39][170/203]	Time  0.863 ( 2.338)	Data  0.210 ( 1.753)	Loss 0.1436057537794113 (0.1033505399095995)	Acc@1  96.88 ( 96.93)	Acc@5 100.00 ( 99.80)
Epoch: [39][180/203]	Time  0.557 ( 2.393)	Data  0.000 ( 1.809)	Loss 0.0632435008883476 (0.1037611137324358)	Acc@1  96.88 ( 96.89)	Acc@5 100.00 ( 99.81)
Epoch: [39][190/203]	Time  0.515 ( 2.323)	Data  0.000 ( 1.740)	Loss 0.0578778684139252 (0.1037348926662228)	Acc@1 100.00 ( 96.88)	Acc@5 100.00 ( 99.81)
Epoch: [39][200/203]	Time  0.539 ( 2.356)	Data  0.000 ( 1.773)	Loss 0.0650817230343819 (0.1023851374757305)	Acc@1  96.88 ( 96.94)	Acc@5 100.00 ( 99.81)
epoch: 39, Avg_Loss 0.10223234004887014
Test: [ 0/51]	Time 34.354 (34.354)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.985 ( 3.356)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 82.39)	Acc@5  87.50 ( 89.91)
Test: [20/51]	Time  0.144 ( 2.787)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 80.58)	Acc@5  82.81 ( 87.35)
Test: [30/51]	Time  1.913 ( 2.024)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 80.49)	Acc@5  84.38 ( 87.45)
Test: [40/51]	Time  0.130 ( 2.048)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 80.60)	Acc@5  92.19 ( 87.50)
Test: [50/51]	Time  0.116 ( 2.089)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.45 ( 80.58)	Acc@5  90.91 ( 87.47)
 * Acc@1 80.584 Acc@5 87.465
Epoch: [40][  0/203]	Time 33.368 (33.368)	Data 32.715 (32.715)	Loss 0.0842030420899391 (0.0842030420899391)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [40][ 10/203]	Time  0.620 ( 4.085)	Data  0.001 ( 3.504)	Loss 0.2217668741941452 (0.0948526578193361)	Acc@1  92.19 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [40][ 20/203]	Time  0.496 ( 3.930)	Data  0.000 ( 3.327)	Loss 0.0242019034922123 (0.0760557901646410)	Acc@1 100.00 ( 97.69)	Acc@5 100.00 (100.00)
Epoch: [40][ 30/203]	Time  0.703 ( 2.857)	Data  0.000 ( 2.254)	Loss 0.1303099840879440 (0.0809819431554887)	Acc@1  96.88 ( 97.53)	Acc@5  98.44 ( 99.95)
Epoch: [40][ 40/203]	Time  0.666 ( 3.404)	Data  0.000 ( 2.799)	Loss 0.0942941457033157 (0.0832681823067549)	Acc@1  93.75 ( 97.41)	Acc@5 100.00 ( 99.96)
Epoch: [40][ 50/203]	Time  2.992 ( 3.434)	Data  2.143 ( 2.829)	Loss 0.1216176003217697 (0.0897246850471871)	Acc@1  96.88 ( 97.09)	Acc@5 100.00 ( 99.94)
Epoch: [40][ 60/203]	Time  0.561 ( 2.964)	Data  0.000 ( 2.365)	Loss 0.0740101635456085 (0.0901168961016858)	Acc@1  98.44 ( 97.16)	Acc@5 100.00 ( 99.87)
Epoch: [40][ 70/203]	Time  0.579 ( 3.006)	Data  0.001 ( 2.411)	Loss 0.0347823053598404 (0.0892938997229220)	Acc@1 100.00 ( 97.14)	Acc@5 100.00 ( 99.87)
Epoch: [40][ 80/203]	Time 22.362 ( 2.973)	Data 21.782 ( 2.382)	Loss 0.1540629565715790 (0.0918812514685186)	Acc@1  93.75 ( 97.03)	Acc@5 100.00 ( 99.88)
Epoch: [40][ 90/203]	Time  0.630 ( 2.756)	Data  0.000 ( 2.168)	Loss 0.0403467938303947 (0.0946128749298853)	Acc@1  98.44 ( 96.89)	Acc@5 100.00 ( 99.88)
Epoch: [40][100/203]	Time  0.563 ( 2.793)	Data  0.000 ( 2.206)	Loss 0.0813396871089935 (0.0947630741624254)	Acc@1  93.75 ( 96.84)	Acc@5 100.00 ( 99.88)
Epoch: [40][110/203]	Time  0.550 ( 2.605)	Data  0.000 ( 2.018)	Loss 0.0992240086197853 (0.0949859584740422)	Acc@1  95.31 ( 96.86)	Acc@5 100.00 ( 99.89)
Epoch: [40][120/203]	Time  0.565 ( 2.657)	Data  0.000 ( 2.069)	Loss 0.1072547212243080 (0.0942865004993914)	Acc@1  95.31 ( 96.84)	Acc@5 100.00 ( 99.90)
Epoch: [40][130/203]	Time  0.558 ( 2.663)	Data  0.000 ( 2.076)	Loss 0.0449890270829201 (0.0940264205924655)	Acc@1  98.44 ( 96.90)	Acc@5 100.00 ( 99.88)
Epoch: [40][140/203]	Time  0.532 ( 2.560)	Data  0.000 ( 1.972)	Loss 0.0597839131951332 (0.0937742560388560)	Acc@1  98.44 ( 96.84)	Acc@5 100.00 ( 99.89)
Epoch: [40][150/203]	Time  0.539 ( 2.595)	Data  0.000 ( 2.008)	Loss 0.0967935472726822 (0.0945726533525235)	Acc@1  96.88 ( 96.83)	Acc@5 100.00 ( 99.88)
Epoch: [40][160/203]	Time 22.838 ( 2.606)	Data 22.278 ( 2.022)	Loss 0.0986406281590462 (0.0964726109335326)	Acc@1  96.88 ( 96.80)	Acc@5 100.00 ( 99.88)
Epoch: [40][170/203]	Time  0.497 ( 2.506)	Data  0.001 ( 1.923)	Loss 0.1466046124696732 (0.0952043942889275)	Acc@1  96.88 ( 96.85)	Acc@5  98.44 ( 99.88)
Epoch: [40][180/203]	Time  3.459 ( 2.530)	Data  2.909 ( 1.948)	Loss 0.1380890458822250 (0.0942577518913792)	Acc@1  96.88 ( 96.93)	Acc@5  98.44 ( 99.88)
Epoch: [40][190/203]	Time  0.587 ( 2.442)	Data  0.000 ( 1.861)	Loss 0.0254742410033941 (0.0931462804196861)	Acc@1 100.00 ( 96.98)	Acc@5 100.00 ( 99.89)
Epoch: [40][200/203]	Time  0.545 ( 2.463)	Data  0.000 ( 1.883)	Loss 0.1067970991134644 (0.0926254764847939)	Acc@1  96.88 ( 97.00)	Acc@5 100.00 ( 99.88)
epoch: 40, Avg_Loss 0.09225489719417589
Test: [ 0/51]	Time 42.434 (42.434)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.38)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.127 ( 4.117)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 79.97)	Acc@5  84.38 ( 86.93)
Test: [20/51]	Time  0.131 ( 3.838)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 79.99)	Acc@5  89.06 ( 85.94)
Test: [30/51]	Time  0.120 ( 2.640)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 80.90)	Acc@5  89.06 ( 86.29)
Test: [40/51]	Time  0.118 ( 2.915)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 80.37)	Acc@5  87.50 ( 85.79)
Test: [50/51]	Time  0.124 ( 2.837)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 80.40)	Acc@5  81.82 ( 85.71)
 * Acc@1 80.399 Acc@5 85.714
Epoch: [41][  0/203]	Time 38.970 (38.970)	Data 38.280 (38.280)	Loss 0.0781364813446999 (0.0781364813446999)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [41][ 10/203]	Time  0.499 ( 4.061)	Data  0.001 ( 3.480)	Loss 0.0230052173137665 (0.0782181134616787)	Acc@1 100.00 ( 97.87)	Acc@5 100.00 ( 99.86)
Epoch: [41][ 20/203]	Time  0.522 ( 3.578)	Data  0.000 ( 2.975)	Loss 0.0948159322142601 (0.0741199751694997)	Acc@1  96.88 ( 97.84)	Acc@5 100.00 ( 99.85)
Epoch: [41][ 30/203]	Time  0.550 ( 2.595)	Data  0.000 ( 2.015)	Loss 0.0433506257832050 (0.0706353433910877)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.90)
Epoch: [41][ 40/203]	Time  0.758 ( 2.642)	Data  0.000 ( 2.054)	Loss 0.1780485957860947 (0.0803607259309146)	Acc@1  92.19 ( 97.56)	Acc@5  98.44 ( 99.89)
Epoch: [41][ 50/203]	Time  3.630 ( 2.599)	Data  3.083 ( 2.017)	Loss 0.0666297003626823 (0.0795883670924049)	Acc@1  98.44 ( 97.55)	Acc@5 100.00 ( 99.88)
Epoch: [41][ 60/203]	Time  0.558 ( 2.308)	Data  0.000 ( 1.730)	Loss 0.0695391297340393 (0.0769978207917731)	Acc@1  96.88 ( 97.59)	Acc@5 100.00 ( 99.90)
Epoch: [41][ 70/203]	Time  0.662 ( 2.424)	Data  0.000 ( 1.851)	Loss 0.1658605039119720 (0.0767649973965657)	Acc@1  95.31 ( 97.69)	Acc@5 100.00 ( 99.91)
Epoch: [41][ 80/203]	Time 12.419 ( 2.345)	Data 11.870 ( 1.769)	Loss 0.0596539191901684 (0.0769642848222528)	Acc@1  96.88 ( 97.65)	Acc@5 100.00 ( 99.92)
Epoch: [41][ 90/203]	Time  0.680 ( 2.222)	Data  0.000 ( 1.638)	Loss 0.0735364034771919 (0.0786276323884562)	Acc@1  98.44 ( 97.56)	Acc@5 100.00 ( 99.93)
Epoch: [41][100/203]	Time  0.562 ( 2.276)	Data  0.000 ( 1.690)	Loss 0.0247265305370092 (0.0812742118769796)	Acc@1 100.00 ( 97.46)	Acc@5 100.00 ( 99.92)
Epoch: [41][110/203]	Time  0.500 ( 2.149)	Data  0.000 ( 1.567)	Loss 0.0884024351835251 (0.0807708406250353)	Acc@1  96.88 ( 97.49)	Acc@5 100.00 ( 99.92)
Epoch: [41][120/203]	Time  0.546 ( 2.184)	Data  0.000 ( 1.602)	Loss 0.0211342666298151 (0.0836346058852293)	Acc@1 100.00 ( 97.42)	Acc@5 100.00 ( 99.91)
Epoch: [41][130/203]	Time  1.915 ( 2.234)	Data  1.307 ( 1.651)	Loss 0.0884395390748978 (0.0827697284078894)	Acc@1  96.88 ( 97.45)	Acc@5 100.00 ( 99.92)
Epoch: [41][140/203]	Time  0.559 ( 2.117)	Data  0.000 ( 1.535)	Loss 0.1138012930750847 (0.0820963348308248)	Acc@1  96.88 ( 97.45)	Acc@5 100.00 ( 99.92)
Epoch: [41][150/203]	Time  0.615 ( 2.160)	Data  0.000 ( 1.578)	Loss 0.1667020618915558 (0.0830314731694116)	Acc@1  95.31 ( 97.49)	Acc@5 100.00 ( 99.92)
Epoch: [41][160/203]	Time 15.460 ( 2.153)	Data 14.942 ( 1.573)	Loss 0.1062895432114601 (0.0833564240496999)	Acc@1  96.88 ( 97.49)	Acc@5 100.00 ( 99.92)
Epoch: [41][170/203]	Time  0.550 ( 2.136)	Data  0.001 ( 1.555)	Loss 0.0430328175425529 (0.0857685728935383)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 ( 99.90)
Epoch: [41][180/203]	Time  0.620 ( 2.159)	Data  0.000 ( 1.577)	Loss 0.0644084662199020 (0.0851755518600015)	Acc@1  96.88 ( 97.42)	Acc@5 100.00 ( 99.91)
Epoch: [41][190/203]	Time  0.640 ( 2.090)	Data  0.000 ( 1.506)	Loss 0.1259546726942062 (0.0860876107627419)	Acc@1  93.75 ( 97.35)	Acc@5 100.00 ( 99.91)
Epoch: [41][200/203]	Time  0.555 ( 2.096)	Data  0.000 ( 1.514)	Loss 0.0590486340224743 (0.0873961686967543)	Acc@1  96.88 ( 97.29)	Acc@5 100.00 ( 99.91)
epoch: 41, Avg_Loss 0.08715552006724286
Test: [ 0/51]	Time 28.182 (28.182)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 71.88)	Acc@5  78.12 ( 78.12)
Test: [10/51]	Time  0.130 ( 2.970)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.14)	Acc@5  87.50 ( 83.66)
Test: [20/51]	Time  0.767 ( 2.819)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 77.60)	Acc@5  90.62 ( 85.12)
Test: [30/51]	Time  0.133 ( 1.952)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 77.77)	Acc@5  90.62 ( 85.08)
Test: [40/51]	Time  0.127 ( 2.190)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 77.97)	Acc@5  90.62 ( 85.21)
Test: [50/51]	Time  0.123 ( 2.210)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  69.09 ( 77.97)	Acc@5  80.00 ( 85.07)
 * Acc@1 77.972 Acc@5 85.069
Epoch: [42][  0/203]	Time 33.299 (33.299)	Data 32.666 (32.666)	Loss 0.1241236850619316 (0.1241236850619316)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [42][ 10/203]	Time  0.709 ( 3.755)	Data  0.001 ( 3.198)	Loss 0.1252394467592239 (0.1218289743092927)	Acc@1  95.31 ( 95.45)	Acc@5 100.00 ( 99.86)
Epoch: [42][ 20/203]	Time  1.093 ( 3.190)	Data  0.464 ( 2.617)	Loss 0.0400856807827950 (0.0984296713556562)	Acc@1  98.44 ( 96.35)	Acc@5 100.00 ( 99.93)
Epoch: [42][ 30/203]	Time  0.590 ( 2.354)	Data  0.000 ( 1.773)	Loss 0.0390658602118492 (0.0906389273342586)	Acc@1  98.44 ( 96.77)	Acc@5 100.00 ( 99.90)
Epoch: [42][ 40/203]	Time  0.594 ( 2.434)	Data  0.000 ( 1.849)	Loss 0.0492716357111931 (0.0911597225406184)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 ( 99.92)
Epoch: [42][ 50/203]	Time  2.414 ( 2.455)	Data  1.774 ( 1.874)	Loss 0.0882121697068214 (0.0892218879661432)	Acc@1  96.88 ( 96.91)	Acc@5 100.00 ( 99.94)
Epoch: [42][ 60/203]	Time  0.571 ( 2.174)	Data  0.000 ( 1.596)	Loss 0.1021883562207222 (0.0872794479040093)	Acc@1  93.75 ( 96.90)	Acc@5 100.00 ( 99.92)
Epoch: [42][ 70/203]	Time  0.605 ( 2.236)	Data  0.000 ( 1.653)	Loss 0.0680458769202232 (0.0867691993529738)	Acc@1  98.44 ( 96.99)	Acc@5 100.00 ( 99.93)
Epoch: [42][ 80/203]	Time 20.354 ( 2.284)	Data 19.458 ( 1.704)	Loss 0.0463617146015167 (0.0850525599455944)	Acc@1  98.44 ( 97.01)	Acc@5 100.00 ( 99.90)
Epoch: [42][ 90/203]	Time  0.565 ( 2.160)	Data  0.000 ( 1.582)	Loss 0.0868317410349846 (0.0866442616967546)	Acc@1  95.31 ( 97.00)	Acc@5 100.00 ( 99.90)
Epoch: [42][100/203]	Time  0.864 ( 2.225)	Data  0.147 ( 1.647)	Loss 0.0462959483265877 (0.0854281424683067)	Acc@1  98.44 ( 97.08)	Acc@5 100.00 ( 99.91)
Epoch: [42][110/203]	Time  0.611 ( 2.078)	Data  0.000 ( 1.499)	Loss 0.1311118304729462 (0.0868364209644832)	Acc@1  96.88 ( 97.13)	Acc@5 100.00 ( 99.92)
Epoch: [42][120/203]	Time  0.487 ( 2.126)	Data  0.000 ( 1.547)	Loss 0.1028464585542679 (0.0859936588051275)	Acc@1  98.44 ( 97.21)	Acc@5 100.00 ( 99.92)
Epoch: [42][130/203]	Time  0.637 ( 2.170)	Data  0.000 ( 1.593)	Loss 0.0952418521046638 (0.0869024446774416)	Acc@1  96.88 ( 97.09)	Acc@5 100.00 ( 99.93)
Epoch: [42][140/203]	Time  0.523 ( 2.057)	Data  0.000 ( 1.480)	Loss 0.0497939288616180 (0.0863022350818447)	Acc@1 100.00 ( 97.09)	Acc@5 100.00 ( 99.93)
Epoch: [42][150/203]	Time  0.510 ( 2.114)	Data  0.000 ( 1.540)	Loss 0.0545408912003040 (0.0859457671901347)	Acc@1 100.00 ( 97.11)	Acc@5 100.00 ( 99.94)
Epoch: [42][160/203]	Time 17.119 ( 2.119)	Data 16.470 ( 1.547)	Loss 0.0871258899569511 (0.0847603066402100)	Acc@1  96.88 ( 97.15)	Acc@5 100.00 ( 99.94)
Epoch: [42][170/203]	Time  0.847 ( 2.065)	Data  0.001 ( 1.490)	Loss 0.1105779856443405 (0.0856243084124916)	Acc@1  96.88 ( 97.09)	Acc@5 100.00 ( 99.95)
Epoch: [42][180/203]	Time  1.443 ( 2.105)	Data  0.796 ( 1.527)	Loss 0.0736326649785042 (0.0848286409105962)	Acc@1  96.88 ( 97.12)	Acc@5 100.00 ( 99.95)
Epoch: [42][190/203]	Time  0.544 ( 2.023)	Data  0.000 ( 1.447)	Loss 0.0129926754161716 (0.0845256795843390)	Acc@1 100.00 ( 97.15)	Acc@5 100.00 ( 99.94)
Epoch: [42][200/203]	Time  0.523 ( 2.057)	Data  0.000 ( 1.483)	Loss 0.0912676304578781 (0.0841307137902845)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.94)
epoch: 42, Avg_Loss 0.08417796120598105
Test: [ 0/51]	Time 21.459 (21.459)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.169 ( 2.460)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 81.68)	Acc@5  93.75 ( 88.78)
Test: [20/51]	Time  0.192 ( 2.325)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 80.88)	Acc@5  95.31 ( 88.99)
Test: [30/51]	Time  0.143 ( 1.620)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 80.95)	Acc@5  85.94 ( 88.61)
Test: [40/51]	Time  2.627 ( 1.832)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 81.14)	Acc@5  81.25 ( 88.30)
Test: [50/51]	Time  0.130 ( 1.829)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.45 ( 81.17)	Acc@5  96.36 ( 88.20)
 * Acc@1 81.167 Acc@5 88.203
Epoch: [43][  0/203]	Time 40.089 (40.089)	Data 39.411 (39.411)	Loss 0.0741934701800346 (0.0741934701800346)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [43][ 10/203]	Time  0.513 ( 4.293)	Data  0.001 ( 3.583)	Loss 0.1007234230637550 (0.0616588037122380)	Acc@1  95.31 ( 98.01)	Acc@5 100.00 (100.00)
Epoch: [43][ 20/203]	Time  0.544 ( 3.474)	Data  0.000 ( 2.829)	Loss 0.1429777592420578 (0.0713149720714206)	Acc@1  98.44 ( 97.84)	Acc@5 100.00 ( 99.85)
Epoch: [43][ 30/203]	Time  0.565 ( 2.529)	Data  0.000 ( 1.916)	Loss 0.0695605054497719 (0.0664744784214324)	Acc@1  98.44 ( 98.03)	Acc@5 100.00 ( 99.90)
Epoch: [43][ 40/203]	Time  0.569 ( 2.682)	Data  0.000 ( 2.082)	Loss 0.1559816002845764 (0.0700177082155899)	Acc@1  96.88 ( 97.98)	Acc@5  98.44 ( 99.85)
Epoch: [43][ 50/203]	Time  0.632 ( 2.621)	Data  0.000 ( 2.023)	Loss 0.1272893995046616 (0.0714854700856057)	Acc@1  95.31 ( 97.82)	Acc@5 100.00 ( 99.88)
Epoch: [43][ 60/203]	Time  0.569 ( 2.320)	Data  0.000 ( 1.726)	Loss 0.1064195707440376 (0.0693019003927952)	Acc@1  95.31 ( 97.85)	Acc@5 100.00 ( 99.90)
Epoch: [43][ 70/203]	Time  0.527 ( 2.346)	Data  0.000 ( 1.752)	Loss 0.1066172346472740 (0.0739183822174517)	Acc@1  96.88 ( 97.71)	Acc@5 100.00 ( 99.87)
Epoch: [43][ 80/203]	Time 22.434 ( 2.395)	Data 21.752 ( 1.804)	Loss 0.0423539802432060 (0.0724117399572774)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 ( 99.88)
Epoch: [43][ 90/203]	Time  0.562 ( 2.218)	Data  0.000 ( 1.630)	Loss 0.0316741168498993 (0.0707930874202278)	Acc@1 100.00 ( 97.80)	Acc@5 100.00 ( 99.90)
Epoch: [43][100/203]	Time  1.073 ( 2.271)	Data  0.385 ( 1.683)	Loss 0.1240421906113625 (0.0700837732431027)	Acc@1  95.31 ( 97.77)	Acc@5 100.00 ( 99.91)
Epoch: [43][110/203]	Time  0.619 ( 2.120)	Data  0.000 ( 1.531)	Loss 0.0516169220209122 (0.0703922702033106)	Acc@1  98.44 ( 97.75)	Acc@5 100.00 ( 99.90)
Epoch: [43][120/203]	Time  0.608 ( 2.177)	Data  0.000 ( 1.588)	Loss 0.0587806440889835 (0.0712160638433473)	Acc@1  96.88 ( 97.69)	Acc@5 100.00 ( 99.91)
Epoch: [43][130/203]	Time  1.995 ( 2.251)	Data  1.390 ( 1.660)	Loss 0.0895384848117828 (0.0716338259957105)	Acc@1  96.88 ( 97.70)	Acc@5  98.44 ( 99.90)
Epoch: [43][140/203]	Time  0.568 ( 2.136)	Data  0.000 ( 1.542)	Loss 0.0659556388854980 (0.0708198924185642)	Acc@1  98.44 ( 97.72)	Acc@5 100.00 ( 99.91)
Epoch: [43][150/203]	Time  0.705 ( 2.181)	Data  0.000 ( 1.585)	Loss 0.0702736079692841 (0.0701129295931056)	Acc@1  98.44 ( 97.74)	Acc@5  98.44 ( 99.91)
Epoch: [43][160/203]	Time 20.986 ( 2.207)	Data 20.441 ( 1.614)	Loss 0.0632979348301888 (0.0711348082766122)	Acc@1  96.88 ( 97.71)	Acc@5 100.00 ( 99.91)
Epoch: [43][170/203]	Time  0.511 ( 2.163)	Data  0.001 ( 1.569)	Loss 0.0200250875204802 (0.0701679483829447)	Acc@1 100.00 ( 97.74)	Acc@5 100.00 ( 99.92)
Epoch: [43][180/203]	Time  0.515 ( 2.209)	Data  0.000 ( 1.618)	Loss 0.0776724591851234 (0.0698172172984283)	Acc@1  96.88 ( 97.76)	Acc@5 100.00 ( 99.92)
Epoch: [43][190/203]	Time  0.518 ( 2.123)	Data  0.000 ( 1.533)	Loss 0.0143554117530584 (0.0706032379310949)	Acc@1 100.00 ( 97.75)	Acc@5 100.00 ( 99.92)
Epoch: [43][200/203]	Time  0.555 ( 2.167)	Data  0.000 ( 1.578)	Loss 0.0582727119326591 (0.0708427837127773)	Acc@1  98.44 ( 97.75)	Acc@5 100.00 ( 99.91)
epoch: 43, Avg_Loss 0.07085066995230214
Test: [ 0/51]	Time 25.411 (25.411)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  2.381 ( 2.666)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 80.82)	Acc@5  87.50 ( 88.64)
Test: [20/51]	Time  0.119 ( 2.374)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 80.73)	Acc@5  87.50 ( 87.87)
Test: [30/51]	Time  0.131 ( 1.663)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  92.19 ( 81.20)	Acc@5  95.31 ( 88.56)
Test: [40/51]	Time  0.136 ( 1.778)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 81.52)	Acc@5  92.19 ( 88.99)
Test: [50/51]	Time  0.131 ( 1.806)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  83.64 ( 81.69)	Acc@5  85.45 ( 88.76)
 * Acc@1 81.690 Acc@5 88.756
Epoch: [44][  0/203]	Time 36.759 (36.759)	Data 36.190 (36.190)	Loss 0.0080529823899269 (0.0080529823899269)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [44][ 10/203]	Time  0.537 ( 3.863)	Data  0.001 ( 3.290)	Loss 0.1429570615291595 (0.0805875911292705)	Acc@1  96.88 ( 97.16)	Acc@5 100.00 ( 99.86)
Epoch: [44][ 20/203]	Time  0.571 ( 3.441)	Data  0.000 ( 2.863)	Loss 0.0482981055974960 (0.0697159757394166)	Acc@1  98.44 ( 97.47)	Acc@5 100.00 ( 99.93)
Epoch: [44][ 30/203]	Time  0.524 ( 2.538)	Data  0.000 ( 1.975)	Loss 0.0963039919734001 (0.0674593325463995)	Acc@1  98.44 ( 97.88)	Acc@5 100.00 ( 99.90)
Epoch: [44][ 40/203]	Time  0.572 ( 2.625)	Data  0.000 ( 2.059)	Loss 0.0252014268189669 (0.0659738078985999)	Acc@1 100.00 ( 98.02)	Acc@5 100.00 ( 99.85)
Epoch: [44][ 50/203]	Time  8.071 ( 2.803)	Data  7.142 ( 2.234)	Loss 0.0255641601979733 (0.0645201471542903)	Acc@1 100.00 ( 98.07)	Acc@5 100.00 ( 99.88)
Epoch: [44][ 60/203]	Time  0.635 ( 2.442)	Data  0.000 ( 1.867)	Loss 0.1699699610471725 (0.0636745479385384)	Acc@1  95.31 ( 98.13)	Acc@5  98.44 ( 99.87)
Epoch: [44][ 70/203]	Time  0.566 ( 2.493)	Data  0.000 ( 1.915)	Loss 0.1119537949562073 (0.0648354198521292)	Acc@1  95.31 ( 98.11)	Acc@5 100.00 ( 99.85)
Epoch: [44][ 80/203]	Time 13.132 ( 2.410)	Data 12.601 ( 1.834)	Loss 0.0394294075667858 (0.0646912352193469)	Acc@1  98.44 ( 98.09)	Acc@5 100.00 ( 99.85)
Epoch: [44][ 90/203]	Time  0.536 ( 2.310)	Data  0.000 ( 1.737)	Loss 0.0648208186030388 (0.0671865537373738)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 ( 99.86)
Epoch: [44][100/203]	Time  0.573 ( 2.413)	Data  0.000 ( 1.842)	Loss 0.0960621684789658 (0.0666595134828793)	Acc@1  96.88 ( 98.04)	Acc@5 100.00 ( 99.86)
Epoch: [44][110/203]	Time  0.665 ( 2.258)	Data  0.000 ( 1.680)	Loss 0.0475613325834274 (0.0660061600643235)	Acc@1  98.44 ( 98.06)	Acc@5 100.00 ( 99.85)
Epoch: [44][120/203]	Time  0.556 ( 2.318)	Data  0.000 ( 1.737)	Loss 0.0569203644990921 (0.0681585327622073)	Acc@1  98.44 ( 97.93)	Acc@5 100.00 ( 99.85)
Epoch: [44][130/203]	Time  8.355 ( 2.385)	Data  7.840 ( 1.803)	Loss 0.0592051222920418 (0.0688489063123938)	Acc@1  98.44 ( 97.90)	Acc@5 100.00 ( 99.86)
Epoch: [44][140/203]	Time  0.547 ( 2.255)	Data  0.000 ( 1.675)	Loss 0.1148133203387260 (0.0694229303073164)	Acc@1  98.44 ( 97.89)	Acc@5 100.00 ( 99.84)
Epoch: [44][150/203]	Time  0.689 ( 2.310)	Data  0.000 ( 1.726)	Loss 0.0228820722550154 (0.0680481443267982)	Acc@1 100.00 ( 97.95)	Acc@5 100.00 ( 99.86)
Epoch: [44][160/203]	Time 16.788 ( 2.310)	Data 16.238 ( 1.725)	Loss 0.1107451692223549 (0.0684568780873503)	Acc@1  96.88 ( 97.95)	Acc@5 100.00 ( 99.86)
Epoch: [44][170/203]	Time  0.680 ( 2.268)	Data  0.002 ( 1.674)	Loss 0.0195628628134727 (0.0689014524809624)	Acc@1 100.00 ( 97.93)	Acc@5 100.00 ( 99.87)
Epoch: [44][180/203]	Time  0.606 ( 2.315)	Data  0.000 ( 1.720)	Loss 0.0801371932029724 (0.0683931973737083)	Acc@1  96.88 ( 97.95)	Acc@5 100.00 ( 99.88)
Epoch: [44][190/203]	Time  0.584 ( 2.225)	Data  0.000 ( 1.630)	Loss 0.0260863043367863 (0.0687933798430790)	Acc@1 100.00 ( 97.91)	Acc@5 100.00 ( 99.89)
Epoch: [44][200/203]	Time  0.637 ( 2.277)	Data  0.000 ( 1.680)	Loss 0.0454792939126492 (0.0675219000914871)	Acc@1 100.00 ( 97.94)	Acc@5 100.00 ( 99.89)
epoch: 44, Avg_Loss 0.06765900325176898
Test: [ 0/51]	Time 28.547 (28.547)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.38)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.165 ( 2.776)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 82.81)	Acc@5  85.94 ( 87.22)
Test: [20/51]	Time  0.208 ( 2.649)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 82.74)	Acc@5  93.75 ( 88.10)
Test: [30/51]	Time  0.143 ( 1.847)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 82.46)	Acc@5  89.06 ( 88.31)
Test: [40/51]	Time  0.148 ( 2.050)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 82.77)	Acc@5  92.19 ( 88.53)
Test: [50/51]	Time  0.122 ( 2.068)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.36 ( 82.40)	Acc@5  81.82 ( 88.20)
 * Acc@1 82.396 Acc@5 88.203
Epoch: [45][  0/203]	Time 37.237 (37.237)	Data 36.710 (36.710)	Loss 0.0344033949077129 (0.0344033949077129)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [45][ 10/203]	Time  0.751 ( 4.041)	Data  0.001 ( 3.434)	Loss 0.0343271978199482 (0.0576602841981433)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [45][ 20/203]	Time  0.596 ( 3.982)	Data  0.001 ( 3.328)	Loss 0.0486412048339844 (0.0537452945219619)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 (100.00)
Epoch: [45][ 30/203]	Time  0.550 ( 2.874)	Data  0.000 ( 2.254)	Loss 0.0391288436949253 (0.0553974074221426)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 (100.00)
Epoch: [45][ 40/203]	Time  0.550 ( 2.883)	Data  0.000 ( 2.265)	Loss 0.0468195043504238 (0.0578141938440683)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [45][ 50/203]	Time  0.533 ( 3.259)	Data  0.000 ( 2.651)	Loss 0.1578918099403381 (0.0603864538465060)	Acc@1  93.75 ( 98.13)	Acc@5 100.00 (100.00)
Epoch: [45][ 60/203]	Time  0.575 ( 2.817)	Data  0.000 ( 2.217)	Loss 0.0453195571899414 (0.0596976928473985)	Acc@1 100.00 ( 98.16)	Acc@5 100.00 (100.00)
Epoch: [45][ 70/203]	Time  0.577 ( 2.833)	Data  0.000 ( 2.235)	Loss 0.0724123790860176 (0.0606437768314926)	Acc@1  96.88 ( 98.13)	Acc@5 100.00 ( 99.98)
Epoch: [45][ 80/203]	Time 21.026 ( 2.808)	Data 20.363 ( 2.210)	Loss 0.0087137417867780 (0.0612400252441013)	Acc@1 100.00 ( 98.13)	Acc@5 100.00 ( 99.96)
Epoch: [45][ 90/203]	Time  0.530 ( 2.573)	Data  0.000 ( 1.979)	Loss 0.1161987185478210 (0.0613375667707769)	Acc@1  93.75 ( 98.11)	Acc@5 100.00 ( 99.97)
Epoch: [45][100/203]	Time  0.571 ( 2.648)	Data  0.000 ( 2.056)	Loss 0.0732474774122238 (0.0629692728179369)	Acc@1  95.31 ( 97.97)	Acc@5 100.00 ( 99.95)
Epoch: [45][110/203]	Time  0.618 ( 2.459)	Data  0.000 ( 1.871)	Loss 0.0545790977776051 (0.0637068434593243)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 ( 99.94)
Epoch: [45][120/203]	Time  0.569 ( 2.515)	Data  0.000 ( 1.926)	Loss 0.1872076541185379 (0.0647180002752291)	Acc@1  92.19 ( 97.91)	Acc@5 100.00 ( 99.95)
Epoch: [45][130/203]	Time  0.516 ( 2.609)	Data  0.000 ( 2.025)	Loss 0.0354663208127022 (0.0626721767609129)	Acc@1  98.44 ( 97.97)	Acc@5 100.00 ( 99.95)
Epoch: [45][140/203]	Time  0.540 ( 2.466)	Data  0.000 ( 1.881)	Loss 0.0714950636029243 (0.0643924956196747)	Acc@1  96.88 ( 97.91)	Acc@5 100.00 ( 99.96)
Epoch: [45][150/203]	Time  0.530 ( 2.485)	Data  0.000 ( 1.902)	Loss 0.0349403582513332 (0.0628539449874534)	Acc@1 100.00 ( 97.95)	Acc@5 100.00 ( 99.96)
Epoch: [45][160/203]	Time 20.236 ( 2.503)	Data 19.699 ( 1.923)	Loss 0.0235245041549206 (0.0625672483504374)	Acc@1 100.00 ( 97.98)	Acc@5 100.00 ( 99.95)
Epoch: [45][170/203]	Time  0.725 ( 2.421)	Data  0.001 ( 1.839)	Loss 0.1339658051729202 (0.0622449191232697)	Acc@1  98.44 ( 97.99)	Acc@5  98.44 ( 99.95)
Epoch: [45][180/203]	Time  0.538 ( 2.439)	Data  0.000 ( 1.856)	Loss 0.0120049444958568 (0.0610961466667484)	Acc@1 100.00 ( 98.03)	Acc@5 100.00 ( 99.95)
Epoch: [45][190/203]	Time  2.938 ( 2.355)	Data  2.360 ( 1.771)	Loss 0.0257793255150318 (0.0615418158832411)	Acc@1 100.00 ( 98.03)	Acc@5 100.00 ( 99.95)
Epoch: [45][200/203]	Time  0.493 ( 2.369)	Data  0.000 ( 1.785)	Loss 0.0815807059407234 (0.0632232652921508)	Acc@1  98.44 ( 97.96)	Acc@5 100.00 ( 99.95)
epoch: 45, Avg_Loss 0.06318810554175394
Test: [ 0/51]	Time 26.861 (26.861)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.123 ( 2.579)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 81.53)	Acc@5  82.81 ( 89.20)
Test: [20/51]	Time  0.133 ( 2.537)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 80.06)	Acc@5  81.25 ( 88.32)
Test: [30/51]	Time  0.117 ( 1.857)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 80.49)	Acc@5  89.06 ( 88.51)
Test: [40/51]	Time  0.136 ( 1.974)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 81.10)	Acc@5  89.06 ( 88.34)
Test: [50/51]	Time  0.121 ( 1.986)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  74.55 ( 80.80)	Acc@5  83.64 ( 88.11)
 * Acc@1 80.799 Acc@5 88.111
Epoch: [46][  0/203]	Time 35.211 (35.211)	Data 34.663 (34.663)	Loss 0.0599287599325180 (0.0599287599325180)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [46][ 10/203]	Time  0.511 ( 3.746)	Data  0.001 ( 3.152)	Loss 0.0836291462182999 (0.0856224168938669)	Acc@1  96.88 ( 97.16)	Acc@5  98.44 ( 99.86)
Epoch: [46][ 20/203]	Time  0.565 ( 3.230)	Data  0.000 ( 2.665)	Loss 0.0371570847928524 (0.0687733783519694)	Acc@1 100.00 ( 97.84)	Acc@5 100.00 ( 99.93)
Epoch: [46][ 30/203]	Time  0.581 ( 2.368)	Data  0.000 ( 1.805)	Loss 0.0234688539057970 (0.0605514453603856)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.95)
Epoch: [46][ 40/203]	Time  0.529 ( 2.473)	Data  0.000 ( 1.916)	Loss 0.0353371277451515 (0.0589846223365606)	Acc@1 100.00 ( 98.25)	Acc@5 100.00 ( 99.96)
Epoch: [46][ 50/203]	Time  0.653 ( 2.530)	Data  0.001 ( 1.965)	Loss 0.0182430930435658 (0.0557379596044912)	Acc@1 100.00 ( 98.50)	Acc@5 100.00 ( 99.97)
Epoch: [46][ 60/203]	Time  0.641 ( 2.210)	Data  0.000 ( 1.643)	Loss 0.0735209956765175 (0.0579611561184780)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 ( 99.97)
Epoch: [46][ 70/203]	Time  0.492 ( 2.294)	Data  0.000 ( 1.728)	Loss 0.0172288306057453 (0.0565951794490848)	Acc@1 100.00 ( 98.42)	Acc@5 100.00 ( 99.96)
Epoch: [46][ 80/203]	Time 28.861 ( 2.423)	Data 28.226 ( 1.863)	Loss 0.0446496009826660 (0.0586447059694264)	Acc@1  98.44 ( 98.28)	Acc@5 100.00 ( 99.94)
Epoch: [46][ 90/203]	Time  0.492 ( 2.216)	Data  0.000 ( 1.658)	Loss 0.1396056115627289 (0.0576686980100451)	Acc@1  95.31 ( 98.33)	Acc@5 100.00 ( 99.93)
Epoch: [46][100/203]	Time  0.810 ( 2.284)	Data  0.003 ( 1.720)	Loss 0.0124423187226057 (0.0601322183219513)	Acc@1 100.00 ( 98.22)	Acc@5 100.00 ( 99.94)
Epoch: [46][110/203]	Time  0.783 ( 2.152)	Data  0.000 ( 1.565)	Loss 0.0039047026075423 (0.0587153569040065)	Acc@1 100.00 ( 98.27)	Acc@5 100.00 ( 99.94)
Epoch: [46][120/203]	Time  0.870 ( 2.180)	Data  0.000 ( 1.592)	Loss 0.0436824560165405 (0.0574163426722069)	Acc@1  98.44 ( 98.26)	Acc@5 100.00 ( 99.95)
Epoch: [46][130/203]	Time  0.502 ( 2.221)	Data  0.000 ( 1.625)	Loss 0.1416095197200775 (0.0582367678258198)	Acc@1  95.31 ( 98.23)	Acc@5 100.00 ( 99.94)
Epoch: [46][140/203]	Time  0.625 ( 2.120)	Data  0.000 ( 1.525)	Loss 0.0580950379371643 (0.0586032638464995)	Acc@1  96.88 ( 98.22)	Acc@5 100.00 ( 99.94)
Epoch: [46][150/203]	Time  0.538 ( 2.175)	Data  0.000 ( 1.582)	Loss 0.0728959590196609 (0.0587553492167483)	Acc@1  98.44 ( 98.17)	Acc@5 100.00 ( 99.95)
Epoch: [46][160/203]	Time 18.671 ( 2.188)	Data 18.039 ( 1.596)	Loss 0.0597982890903950 (0.0579581451457665)	Acc@1  96.88 ( 98.19)	Acc@5 100.00 ( 99.95)
Epoch: [46][170/203]	Time  0.632 ( 2.105)	Data  0.001 ( 1.513)	Loss 0.0422517880797386 (0.0579723598577126)	Acc@1 100.00 ( 98.18)	Acc@5 100.00 ( 99.95)
Epoch: [46][180/203]	Time  0.583 ( 2.132)	Data  0.000 ( 1.542)	Loss 0.0769143626093864 (0.0587294959560942)	Acc@1  96.88 ( 98.12)	Acc@5 100.00 ( 99.96)
Epoch: [46][190/203]	Time  0.669 ( 2.053)	Data  0.000 ( 1.461)	Loss 0.1012363955378532 (0.0602266267283347)	Acc@1  98.44 ( 98.11)	Acc@5 100.00 ( 99.93)
Epoch: [46][200/203]	Time  0.687 ( 2.090)	Data  0.000 ( 1.494)	Loss 0.1829513162374496 (0.0603922850206791)	Acc@1  95.31 ( 98.10)	Acc@5 100.00 ( 99.93)
epoch: 46, Avg_Loss 0.06069655045224675
Test: [ 0/51]	Time 26.669 (26.669)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 78.12)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.130 ( 2.629)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 81.82)	Acc@5  87.50 ( 88.78)
Test: [20/51]	Time  0.139 ( 2.421)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 82.29)	Acc@5  85.94 ( 88.32)
Test: [30/51]	Time  0.146 ( 1.686)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 82.31)	Acc@5  85.94 ( 88.21)
Test: [40/51]	Time  0.127 ( 1.867)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 82.85)	Acc@5  92.19 ( 88.41)
Test: [50/51]	Time  0.136 ( 1.890)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  74.55 ( 82.80)	Acc@5  87.27 ( 88.57)
 * Acc@1 82.796 Acc@5 88.571
Epoch: [47][  0/203]	Time 33.251 (33.251)	Data 32.438 (32.438)	Loss 0.0243414267897606 (0.0243414267897606)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [47][ 10/203]	Time  0.505 ( 3.549)	Data  0.001 ( 2.949)	Loss 0.0799238532781601 (0.0679894043979320)	Acc@1  96.88 ( 97.73)	Acc@5  98.44 ( 99.86)
Epoch: [47][ 20/203]	Time  0.696 ( 3.384)	Data  0.000 ( 2.805)	Loss 0.0131804775446653 (0.0566411023693425)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.93)
Epoch: [47][ 30/203]	Time  0.557 ( 2.472)	Data  0.000 ( 1.900)	Loss 0.0589812397956848 (0.0563100594726782)	Acc@1  96.88 ( 98.03)	Acc@5 100.00 ( 99.95)
Epoch: [47][ 40/203]	Time  1.148 ( 2.594)	Data  0.001 ( 1.980)	Loss 0.0285161715000868 (0.0568376987854519)	Acc@1 100.00 ( 98.06)	Acc@5 100.00 ( 99.96)
Epoch: [47][ 50/203]	Time  1.130 ( 2.571)	Data  0.621 ( 1.944)	Loss 0.0104343593120575 (0.0573902166101570)	Acc@1 100.00 ( 98.04)	Acc@5 100.00 ( 99.97)
Epoch: [47][ 60/203]	Time  0.582 ( 2.244)	Data  0.001 ( 1.625)	Loss 0.0607089288532734 (0.0568969181021217)	Acc@1  96.88 ( 98.05)	Acc@5 100.00 ( 99.97)
Epoch: [47][ 70/203]	Time  0.706 ( 2.341)	Data  0.001 ( 1.716)	Loss 0.0835012495517731 (0.0580730165525431)	Acc@1  96.88 ( 98.04)	Acc@5 100.00 ( 99.98)
Epoch: [47][ 80/203]	Time 18.535 ( 2.359)	Data 17.832 ( 1.724)	Loss 0.0804607942700386 (0.0591742593829555)	Acc@1  95.31 ( 97.99)	Acc@5 100.00 ( 99.98)
Epoch: [47][ 90/203]	Time  0.545 ( 2.165)	Data  0.000 ( 1.535)	Loss 0.0532320290803909 (0.0590432408818422)	Acc@1  98.44 ( 98.01)	Acc@5 100.00 ( 99.98)
Epoch: [47][100/203]	Time  0.584 ( 2.257)	Data  0.000 ( 1.634)	Loss 0.0174982026219368 (0.0562815422717814)	Acc@1 100.00 ( 98.13)	Acc@5 100.00 ( 99.98)
Epoch: [47][110/203]	Time  0.525 ( 2.099)	Data  0.000 ( 1.487)	Loss 0.0301954988390207 (0.0566749117119020)	Acc@1 100.00 ( 98.14)	Acc@5 100.00 ( 99.97)
Epoch: [47][120/203]	Time  0.547 ( 2.198)	Data  0.000 ( 1.586)	Loss 0.0215942226350307 (0.0568007021057150)	Acc@1 100.00 ( 98.15)	Acc@5 100.00 ( 99.97)
Epoch: [47][130/203]	Time  7.176 ( 2.284)	Data  6.612 ( 1.675)	Loss 0.0178601089864969 (0.0560426021826574)	Acc@1 100.00 ( 98.20)	Acc@5 100.00 ( 99.98)
Epoch: [47][140/203]	Time  0.514 ( 2.184)	Data  0.000 ( 1.579)	Loss 0.0171563941985369 (0.0555273212842538)	Acc@1 100.00 ( 98.20)	Acc@5 100.00 ( 99.98)
Epoch: [47][150/203]	Time  0.522 ( 2.267)	Data  0.000 ( 1.661)	Loss 0.0551861375570297 (0.0555592243411634)	Acc@1  96.88 ( 98.19)	Acc@5 100.00 ( 99.98)
Epoch: [47][160/203]	Time 18.688 ( 2.274)	Data 18.099 ( 1.670)	Loss 0.0217997655272484 (0.0543003841303289)	Acc@1 100.00 ( 98.23)	Acc@5 100.00 ( 99.98)
Epoch: [47][170/203]	Time  0.538 ( 2.264)	Data  0.001 ( 1.663)	Loss 0.1243961602449417 (0.0543083193635688)	Acc@1  95.31 ( 98.25)	Acc@5 100.00 ( 99.98)
Epoch: [47][180/203]	Time  0.621 ( 2.384)	Data  0.000 ( 1.785)	Loss 0.0083100637421012 (0.0532337277638855)	Acc@1 100.00 ( 98.30)	Acc@5 100.00 ( 99.98)
Epoch: [47][190/203]	Time  0.558 ( 2.294)	Data  0.000 ( 1.698)	Loss 0.0495564416050911 (0.0535260725678652)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.98)
Epoch: [47][200/203]	Time  0.538 ( 2.350)	Data  0.000 ( 1.756)	Loss 0.0356526523828506 (0.0535700399734413)	Acc@1  98.44 ( 98.29)	Acc@5 100.00 ( 99.98)
epoch: 47, Avg_Loss 0.05355979103521614
Test: [ 0/51]	Time 27.820 (27.820)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 76.56)	Acc@5  92.19 ( 92.19)
Test: [10/51]	Time  0.149 ( 2.879)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 81.68)	Acc@5  85.94 ( 88.49)
Test: [20/51]	Time  0.148 ( 2.860)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 82.66)	Acc@5  84.38 ( 89.43)
Test: [30/51]	Time  0.139 ( 1.988)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 82.41)	Acc@5  85.94 ( 89.31)
Test: [40/51]	Time  0.126 ( 2.173)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 82.89)	Acc@5  87.50 ( 89.37)
Test: [50/51]	Time  0.143 ( 2.117)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  83.64 ( 82.37)	Acc@5  85.45 ( 88.51)
 * Acc@1 82.366 Acc@5 88.510
Epoch: [48][  0/203]	Time 37.386 (37.386)	Data 36.649 (36.649)	Loss 0.0495433360338211 (0.0495433360338211)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [48][ 10/203]	Time  0.610 ( 3.958)	Data  0.001 ( 3.375)	Loss 0.0200735051184893 (0.0481958245350556)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.72)
Epoch: [48][ 20/203]	Time  0.535 ( 3.589)	Data  0.000 ( 3.022)	Loss 0.0358334518969059 (0.0540184435168547)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.78)
Epoch: [48][ 30/203]	Time  0.517 ( 2.600)	Data  0.000 ( 2.047)	Loss 0.0353908240795135 (0.0457870253782359)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 ( 99.85)
Epoch: [48][ 40/203]	Time  0.574 ( 2.646)	Data  0.000 ( 2.091)	Loss 0.0578376874327660 (0.0454082390089042)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 ( 99.89)
Epoch: [48][ 50/203]	Time  0.594 ( 2.931)	Data  0.000 ( 2.374)	Loss 0.0420389957726002 (0.0505364501355764)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 ( 99.91)
Epoch: [48][ 60/203]	Time  0.525 ( 2.542)	Data  0.000 ( 1.984)	Loss 0.0157985873520374 (0.0490331183202931)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.90)
Epoch: [48][ 70/203]	Time  0.661 ( 2.604)	Data  0.000 ( 2.040)	Loss 0.0752365514636040 (0.0498826311979915)	Acc@1  98.44 ( 98.68)	Acc@5 100.00 ( 99.91)
Epoch: [48][ 80/203]	Time 25.928 ( 2.663)	Data 25.154 ( 2.099)	Loss 0.0721354410052299 (0.0502738725440002)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 ( 99.92)
Epoch: [48][ 90/203]	Time  0.544 ( 2.442)	Data  0.000 ( 1.870)	Loss 0.1044470965862274 (0.0525050871432401)	Acc@1  95.31 ( 98.51)	Acc@5 100.00 ( 99.91)
Epoch: [48][100/203]	Time  0.631 ( 2.520)	Data  0.000 ( 1.946)	Loss 0.0290764775127172 (0.0514866146489535)	Acc@1 100.00 ( 98.59)	Acc@5 100.00 ( 99.92)
Epoch: [48][110/203]	Time  0.505 ( 2.347)	Data  0.000 ( 1.771)	Loss 0.0410588718950748 (0.0512071529587915)	Acc@1  98.44 ( 98.61)	Acc@5 100.00 ( 99.93)
Epoch: [48][120/203]	Time  0.653 ( 2.407)	Data  0.000 ( 1.824)	Loss 0.0227331519126892 (0.0505553811696196)	Acc@1 100.00 ( 98.58)	Acc@5 100.00 ( 99.94)
Epoch: [48][130/203]	Time  0.694 ( 2.440)	Data  0.000 ( 1.858)	Loss 0.0144277047365904 (0.0507053658366203)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.93)
Epoch: [48][140/203]	Time  0.562 ( 2.338)	Data  0.000 ( 1.755)	Loss 0.0220655910670757 (0.0513140942161599)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.93)
Epoch: [48][150/203]	Time  0.766 ( 2.366)	Data  0.000 ( 1.780)	Loss 0.0290556997060776 (0.0512875343321372)	Acc@1 100.00 ( 98.52)	Acc@5 100.00 ( 99.94)
Epoch: [48][160/203]	Time 22.050 ( 2.397)	Data 21.396 ( 1.802)	Loss 0.0582361407577991 (0.0517660203904654)	Acc@1  98.44 ( 98.50)	Acc@5 100.00 ( 99.94)
Epoch: [48][170/203]	Time  0.538 ( 2.295)	Data  0.001 ( 1.701)	Loss 0.0767966657876968 (0.0527859235629004)	Acc@1  96.88 ( 98.46)	Acc@5 100.00 ( 99.95)
Epoch: [48][180/203]	Time  0.603 ( 2.355)	Data  0.000 ( 1.757)	Loss 0.1104403883218765 (0.0522906093894200)	Acc@1  95.31 ( 98.44)	Acc@5 100.00 ( 99.95)
Epoch: [48][190/203]	Time  0.646 ( 2.263)	Data  0.000 ( 1.665)	Loss 0.0252677388489246 (0.0521362392348847)	Acc@1  98.44 ( 98.45)	Acc@5 100.00 ( 99.95)
Epoch: [48][200/203]	Time  0.606 ( 2.282)	Data  0.000 ( 1.684)	Loss 0.0278845876455307 (0.0527218372111593)	Acc@1  98.44 ( 98.40)	Acc@5 100.00 ( 99.94)
epoch: 48, Avg_Loss 0.05286401034025429
Test: [ 0/51]	Time 26.646 (26.646)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 81.25)	Acc@5  82.81 ( 82.81)
Test: [10/51]	Time  0.139 ( 2.736)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 83.95)	Acc@5  92.19 ( 88.92)
Test: [20/51]	Time  0.184 ( 2.864)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 83.71)	Acc@5  92.19 ( 89.06)
Test: [30/51]	Time  0.127 ( 1.985)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 83.27)	Acc@5  85.94 ( 88.96)
Test: [40/51]	Time  0.129 ( 2.114)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 83.08)	Acc@5  84.38 ( 88.76)
Test: [50/51]	Time  0.145 ( 2.144)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  83.64 ( 83.01)	Acc@5  90.91 ( 88.97)
 * Acc@1 83.011 Acc@5 88.971
Epoch: [49][  0/203]	Time 30.769 (30.769)	Data 30.206 (30.206)	Loss 0.0261128582060337 (0.0261128582060337)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [49][ 10/203]	Time  0.688 ( 3.560)	Data  0.001 ( 2.990)	Loss 0.0386762842535973 (0.0464726483280008)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 ( 99.86)
Epoch: [49][ 20/203]	Time  1.106 ( 3.112)	Data  0.312 ( 2.504)	Loss 0.0689181387424469 (0.0472059115501387)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.85)
Epoch: [49][ 30/203]	Time  0.597 ( 2.389)	Data  0.000 ( 1.732)	Loss 0.0755115970969200 (0.0492316468528682)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.90)
Epoch: [49][ 40/203]	Time  0.618 ( 2.424)	Data  0.000 ( 1.777)	Loss 0.0863279253244400 (0.0485313539733974)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 ( 99.92)
Epoch: [49][ 50/203]	Time  0.629 ( 2.488)	Data  0.000 ( 1.844)	Loss 0.0573347993195057 (0.0500102191067794)	Acc@1  98.44 ( 98.35)	Acc@5 100.00 ( 99.94)
Epoch: [49][ 60/203]	Time  0.669 ( 2.202)	Data  0.000 ( 1.566)	Loss 0.1857079416513443 (0.0501755020413242)	Acc@1  95.31 ( 98.44)	Acc@5  98.44 ( 99.92)
Epoch: [49][ 70/203]	Time  0.512 ( 2.254)	Data  0.000 ( 1.625)	Loss 0.0228148773312569 (0.0496389701254141)	Acc@1 100.00 ( 98.50)	Acc@5 100.00 ( 99.91)
Epoch: [49][ 80/203]	Time 13.836 ( 2.206)	Data 13.220 ( 1.587)	Loss 0.0341028608381748 (0.0484815422146593)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.92)
Epoch: [49][ 90/203]	Time  0.775 ( 2.141)	Data  0.000 ( 1.519)	Loss 0.0197295416146517 (0.0486494079385731)	Acc@1 100.00 ( 98.56)	Acc@5 100.00 ( 99.93)
Epoch: [49][100/203]	Time  2.302 ( 2.206)	Data  1.557 ( 1.577)	Loss 0.0870700031518936 (0.0508812887013180)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.94)
Epoch: [49][110/203]	Time  0.757 ( 2.064)	Data  0.000 ( 1.435)	Loss 0.0567213036119938 (0.0503954055031074)	Acc@1  96.88 ( 98.52)	Acc@5 100.00 ( 99.94)
Epoch: [49][120/203]	Time  0.662 ( 2.120)	Data  0.000 ( 1.492)	Loss 0.0278376229107380 (0.0499217164902832)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 ( 99.95)
Epoch: [49][130/203]	Time  0.535 ( 2.124)	Data  0.000 ( 1.499)	Loss 0.0317820385098457 (0.0498241806537880)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.94)
Epoch: [49][140/203]	Time  0.563 ( 2.056)	Data  0.000 ( 1.434)	Loss 0.0129158608615398 (0.0504422746895951)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.94)
Epoch: [49][150/203]	Time  0.589 ( 2.101)	Data  0.001 ( 1.478)	Loss 0.0705469474196434 (0.0500361532102407)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.95)
Epoch: [49][160/203]	Time 10.083 ( 2.067)	Data  9.522 ( 1.446)	Loss 0.0151736084371805 (0.0503337223007581)	Acc@1 100.00 ( 98.43)	Acc@5 100.00 ( 99.95)
Epoch: [49][170/203]	Time  0.784 ( 2.052)	Data  0.251 ( 1.425)	Loss 0.0341325700283051 (0.0493612294684420)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.95)
Epoch: [49][180/203]	Time  0.555 ( 2.094)	Data  0.000 ( 1.471)	Loss 0.1664139926433563 (0.0497332230668247)	Acc@1  93.75 ( 98.40)	Acc@5 100.00 ( 99.96)
Epoch: [49][190/203]	Time  0.617 ( 2.018)	Data  0.000 ( 1.394)	Loss 0.0251848455518484 (0.0491268583427120)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 ( 99.96)
Epoch: [49][200/203]	Time  0.536 ( 2.045)	Data  0.000 ( 1.419)	Loss 0.0497998706996441 (0.0487493800268096)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.96)
epoch: 49, Avg_Loss 0.048707236402801106
Test: [ 0/51]	Time 27.348 (27.348)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 89.06)	Acc@5  95.31 ( 95.31)
Test: [10/51]	Time  0.191 ( 2.603)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 84.09)	Acc@5  93.75 ( 88.64)
Test: [20/51]	Time  0.180 ( 2.553)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 83.63)	Acc@5  92.19 ( 88.54)
Test: [30/51]	Time  0.151 ( 1.773)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 83.62)	Acc@5  84.38 ( 88.71)
Test: [40/51]	Time  0.130 ( 1.981)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 83.42)	Acc@5  81.25 ( 88.64)
Test: [50/51]	Time  0.120 ( 2.047)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.27 ( 83.07)	Acc@5  94.55 ( 88.54)
 * Acc@1 83.072 Acc@5 88.541
Epoch: [50][  0/203]	Time 34.669 (34.669)	Data 34.103 (34.103)	Loss 0.0823574662208557 (0.0823574662208557)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [50][ 10/203]	Time  0.666 ( 3.756)	Data  0.001 ( 3.155)	Loss 0.0609313361346722 (0.0401750728487968)	Acc@1  96.88 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [50][ 20/203]	Time  0.634 ( 3.235)	Data  0.000 ( 2.620)	Loss 0.0518061108887196 (0.0380272353511481)	Acc@1  96.88 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [50][ 30/203]	Time  0.543 ( 2.374)	Data  0.000 ( 1.775)	Loss 0.1126252114772797 (0.0439040090648397)	Acc@1  95.31 ( 98.39)	Acc@5 100.00 (100.00)
Epoch: [50][ 40/203]	Time  0.559 ( 2.428)	Data  0.000 ( 1.837)	Loss 0.0392208807170391 (0.0437780696353534)	Acc@1  98.44 ( 98.48)	Acc@5 100.00 (100.00)
Epoch: [50][ 50/203]	Time  5.543 ( 2.475)	Data  4.813 ( 1.877)	Loss 0.0504925288259983 (0.0479431639142407)	Acc@1  96.88 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [50][ 60/203]	Time  0.492 ( 2.157)	Data  0.000 ( 1.569)	Loss 0.0266771968454123 (0.0489342870060965)	Acc@1 100.00 ( 98.41)	Acc@5 100.00 ( 99.97)
Epoch: [50][ 70/203]	Time  0.529 ( 2.228)	Data  0.000 ( 1.646)	Loss 0.0190876331180334 (0.0456305446372118)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.98)
Epoch: [50][ 80/203]	Time  7.760 ( 2.109)	Data  7.243 ( 1.532)	Loss 0.0177928134799004 (0.0453608822290222)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.98)
Epoch: [50][ 90/203]	Time  0.528 ( 2.077)	Data  0.000 ( 1.502)	Loss 0.0736086592078209 (0.0449248602905485)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.98)
Epoch: [50][100/203]	Time  0.544 ( 2.184)	Data  0.000 ( 1.611)	Loss 0.0834251567721367 (0.0446688978504021)	Acc@1  96.88 ( 98.55)	Acc@5 100.00 ( 99.98)
Epoch: [50][110/203]	Time  0.538 ( 2.037)	Data  0.000 ( 1.466)	Loss 0.0374446436762810 (0.0454178913643265)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.99)
Epoch: [50][120/203]	Time  0.577 ( 2.080)	Data  0.000 ( 1.509)	Loss 0.0137081677094102 (0.0443460990055195)	Acc@1 100.00 ( 98.57)	Acc@5 100.00 ( 99.99)
Epoch: [50][130/203]	Time  7.558 ( 2.108)	Data  6.886 ( 1.540)	Loss 0.0426829755306244 (0.0468987495094566)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.98)
Epoch: [50][140/203]	Time  0.553 ( 1.996)	Data  0.000 ( 1.431)	Loss 0.0407762676477432 (0.0466306530523728)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 ( 99.97)
Epoch: [50][150/203]	Time  0.503 ( 2.054)	Data  0.000 ( 1.483)	Loss 0.0569190755486488 (0.0470665458494193)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.96)
Epoch: [50][160/203]	Time  9.076 ( 2.016)	Data  8.518 ( 1.443)	Loss 0.0102693876251578 (0.0465424066794145)	Acc@1 100.00 ( 98.52)	Acc@5 100.00 ( 99.96)
Epoch: [50][170/203]	Time  0.534 ( 2.001)	Data  0.001 ( 1.431)	Loss 0.0357744321227074 (0.0456120309498902)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.96)
Epoch: [50][180/203]	Time  0.619 ( 2.040)	Data  0.000 ( 1.471)	Loss 0.0602313093841076 (0.0453043155158607)	Acc@1  98.44 ( 98.57)	Acc@5 100.00 ( 99.97)
Epoch: [50][190/203]	Time  0.500 ( 1.962)	Data  0.000 ( 1.394)	Loss 0.0219050180166960 (0.0455768424664083)	Acc@1 100.00 ( 98.54)	Acc@5 100.00 ( 99.97)
Epoch: [50][200/203]	Time  0.514 ( 1.992)	Data  0.000 ( 1.422)	Loss 0.0474786125123501 (0.0458789122469297)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.96)
epoch: 50, Avg_Loss 0.04625046553590285
Test: [ 0/51]	Time 24.605 (24.605)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  92.19 ( 92.19)	Acc@5  93.75 ( 93.75)
Test: [10/51]	Time  0.132 ( 2.412)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 84.52)	Acc@5  87.50 ( 89.06)
Test: [20/51]	Time  0.121 ( 2.376)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 84.15)	Acc@5  84.38 ( 89.14)
Test: [30/51]	Time  0.133 ( 1.705)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.07)	Acc@5  89.06 ( 88.96)
Test: [40/51]	Time  0.131 ( 1.871)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 83.57)	Acc@5  87.50 ( 88.87)
Test: [50/51]	Time  0.118 ( 1.913)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 83.47)	Acc@5  90.91 ( 88.79)
 * Acc@1 83.472 Acc@5 88.786
Epoch: [51][  0/203]	Time 33.136 (33.136)	Data 32.570 (32.570)	Loss 0.0577100813388824 (0.0577100813388824)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [51][ 10/203]	Time  0.522 ( 3.713)	Data  0.001 ( 3.155)	Loss 0.0696981325745583 (0.0489293416030705)	Acc@1  96.88 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [51][ 20/203]	Time  0.498 ( 3.322)	Data  0.000 ( 2.750)	Loss 0.0099459942430258 (0.0421605295324255)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [51][ 30/203]	Time  0.705 ( 2.425)	Data  0.000 ( 1.863)	Loss 0.0388941615819931 (0.0410192222634871)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [51][ 40/203]	Time  0.729 ( 2.494)	Data  0.000 ( 1.932)	Loss 0.0091210519894958 (0.0439654518282268)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.96)
Epoch: [51][ 50/203]	Time  0.536 ( 2.526)	Data  0.000 ( 1.964)	Loss 0.0149837862700224 (0.0460941904023582)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.97)
Epoch: [51][ 60/203]	Time  0.566 ( 2.199)	Data  0.000 ( 1.642)	Loss 0.0448937900364399 (0.0475335282075112)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 ( 99.95)
Epoch: [51][ 70/203]	Time  0.513 ( 2.282)	Data  0.000 ( 1.729)	Loss 0.0634390711784363 (0.0462325736683544)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 ( 99.96)
Epoch: [51][ 80/203]	Time 17.608 ( 2.276)	Data 16.308 ( 1.717)	Loss 0.0272848978638649 (0.0476286206681879)	Acc@1 100.00 ( 98.65)	Acc@5 100.00 ( 99.96)
Epoch: [51][ 90/203]	Time  0.501 ( 2.150)	Data  0.000 ( 1.597)	Loss 0.0604829415678978 (0.0470341950562875)	Acc@1  98.44 ( 98.64)	Acc@5 100.00 ( 99.97)
Epoch: [51][100/203]	Time  0.498 ( 2.222)	Data  0.000 ( 1.666)	Loss 0.0080488221719861 (0.0458774294492115)	Acc@1 100.00 ( 98.65)	Acc@5 100.00 ( 99.97)
Epoch: [51][110/203]	Time  0.483 ( 2.069)	Data  0.000 ( 1.516)	Loss 0.0283930338919163 (0.0446995420775771)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.97)
Epoch: [51][120/203]	Time  0.495 ( 2.129)	Data  0.000 ( 1.572)	Loss 0.0995736792683601 (0.0442107182788886)	Acc@1  96.88 ( 98.72)	Acc@5 100.00 ( 99.96)
Epoch: [51][130/203]	Time  0.496 ( 2.156)	Data  0.000 ( 1.599)	Loss 0.0584663525223732 (0.0438229523648913)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 ( 99.96)
Epoch: [51][140/203]	Time  0.522 ( 2.042)	Data  0.000 ( 1.486)	Loss 0.0811469480395317 (0.0447437318458044)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.97)
Epoch: [51][150/203]	Time  0.517 ( 2.076)	Data  0.000 ( 1.521)	Loss 0.0990208163857460 (0.0445077655719754)	Acc@1  96.88 ( 98.69)	Acc@5 100.00 ( 99.97)
Epoch: [51][160/203]	Time 13.098 ( 2.059)	Data 12.569 ( 1.504)	Loss 0.0289440043270588 (0.0440232178560742)	Acc@1 100.00 ( 98.71)	Acc@5 100.00 ( 99.97)
Epoch: [51][170/203]	Time  0.651 ( 2.021)	Data  0.002 ( 1.465)	Loss 0.0343618839979172 (0.0448102019482145)	Acc@1  98.44 ( 98.68)	Acc@5 100.00 ( 99.96)
Epoch: [51][180/203]	Time  0.550 ( 2.077)	Data  0.000 ( 1.521)	Loss 0.0159644652158022 (0.0448335341733587)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.96)
Epoch: [51][190/203]	Time  0.488 ( 1.997)	Data  0.000 ( 1.441)	Loss 0.0079699344933033 (0.0442543767992388)	Acc@1 100.00 ( 98.67)	Acc@5 100.00 ( 99.96)
Epoch: [51][200/203]	Time  0.610 ( 2.041)	Data  0.000 ( 1.485)	Loss 0.1024460420012474 (0.0452521325098304)	Acc@1  96.88 ( 98.65)	Acc@5 100.00 ( 99.95)
epoch: 51, Avg_Loss 0.04554634107955791
Test: [ 0/51]	Time 24.694 (24.694)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 85.94)	Acc@5  92.19 ( 92.19)
Test: [10/51]	Time  0.970 ( 2.547)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 84.66)	Acc@5  89.06 ( 90.06)
Test: [20/51]	Time  0.140 ( 2.568)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 83.56)	Acc@5  87.50 ( 89.21)
Test: [30/51]	Time  0.130 ( 1.783)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 82.91)	Acc@5  90.62 ( 89.06)
Test: [40/51]	Time  0.123 ( 1.935)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 82.32)	Acc@5  89.06 ( 88.57)
Test: [50/51]	Time  0.119 ( 2.011)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.18 ( 82.55)	Acc@5  83.64 ( 88.60)
 * Acc@1 82.550 Acc@5 88.602
Epoch: [52][  0/203]	Time 36.495 (36.495)	Data 35.853 (35.853)	Loss 0.1056888103485107 (0.1056888103485107)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [52][ 10/203]	Time  0.560 ( 3.819)	Data  0.001 ( 3.260)	Loss 0.0606984868645668 (0.0556341051970693)	Acc@1  96.88 ( 97.73)	Acc@5 100.00 (100.00)
Epoch: [52][ 20/203]	Time  0.752 ( 3.396)	Data  0.000 ( 2.817)	Loss 0.0683888420462608 (0.0503441595383698)	Acc@1  98.44 ( 98.21)	Acc@5 100.00 (100.00)
Epoch: [52][ 30/203]	Time  0.534 ( 2.483)	Data  0.000 ( 1.908)	Loss 0.0654198676347733 (0.0531794250972809)	Acc@1  98.44 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [52][ 40/203]	Time  0.474 ( 2.522)	Data  0.000 ( 1.951)	Loss 0.2399665117263794 (0.0523224527516016)	Acc@1  95.31 ( 98.21)	Acc@5  98.44 ( 99.96)
Epoch: [52][ 50/203]	Time  0.543 ( 2.594)	Data  0.000 ( 2.027)	Loss 0.0675164088606834 (0.0518233378089088)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 ( 99.97)
Epoch: [52][ 60/203]	Time  0.499 ( 2.259)	Data  0.000 ( 1.695)	Loss 0.0340406447649002 (0.0505302987427863)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 ( 99.97)
Epoch: [52][ 70/203]	Time  0.507 ( 2.351)	Data  0.000 ( 1.793)	Loss 0.0548992939293385 (0.0519256986297247)	Acc@1  98.44 ( 98.20)	Acc@5 100.00 ( 99.96)
Epoch: [52][ 80/203]	Time 25.062 ( 2.431)	Data 24.247 ( 1.871)	Loss 0.0137036154046655 (0.0491588178757624)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 ( 99.96)
Epoch: [52][ 90/203]	Time  0.558 ( 2.234)	Data  0.000 ( 1.665)	Loss 0.0430091544985771 (0.0503607692432354)	Acc@1 100.00 ( 98.37)	Acc@5 100.00 ( 99.95)
Epoch: [52][100/203]	Time  0.597 ( 2.322)	Data  0.000 ( 1.756)	Loss 0.0049797836691141 (0.0490760329031929)	Acc@1 100.00 ( 98.41)	Acc@5 100.00 ( 99.94)
Epoch: [52][110/203]	Time  0.668 ( 2.170)	Data  0.000 ( 1.598)	Loss 0.0228460300713778 (0.0469980051212415)	Acc@1 100.00 ( 98.49)	Acc@5 100.00 ( 99.94)
Epoch: [52][120/203]	Time  0.527 ( 2.231)	Data  0.000 ( 1.658)	Loss 0.0880108252167702 (0.0470349166180538)	Acc@1  98.44 ( 98.50)	Acc@5 100.00 ( 99.95)
Epoch: [52][130/203]	Time  0.483 ( 2.313)	Data  0.000 ( 1.740)	Loss 0.0098510142415762 (0.0478319629550492)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.95)
Epoch: [52][140/203]	Time  0.723 ( 2.191)	Data  0.000 ( 1.617)	Loss 0.1111494600772858 (0.0484665977200559)	Acc@1  96.88 ( 98.49)	Acc@5 100.00 ( 99.94)
Epoch: [52][150/203]	Time  0.501 ( 2.234)	Data  0.000 ( 1.660)	Loss 0.0774815082550049 (0.0478018760089053)	Acc@1  96.88 ( 98.50)	Acc@5 100.00 ( 99.94)
Epoch: [52][160/203]	Time 26.585 ( 2.291)	Data 25.954 ( 1.718)	Loss 0.0394027754664421 (0.0471405905515233)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 ( 99.94)
Epoch: [52][170/203]	Time  0.502 ( 2.186)	Data  0.001 ( 1.617)	Loss 0.0443993732333183 (0.0468474859861951)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.95)
Epoch: [52][180/203]	Time  0.498 ( 2.258)	Data  0.000 ( 1.691)	Loss 0.0766497999429703 (0.0461245826779973)	Acc@1  96.88 ( 98.56)	Acc@5 100.00 ( 99.95)
Epoch: [52][190/203]	Time  0.503 ( 2.169)	Data  0.000 ( 1.603)	Loss 0.0467485673725605 (0.0455381582827546)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 ( 99.94)
Epoch: [52][200/203]	Time  0.545 ( 2.267)	Data  0.000 ( 1.702)	Loss 0.0075273830443621 (0.0453001213542635)	Acc@1 100.00 ( 98.56)	Acc@5 100.00 ( 99.93)
epoch: 52, Avg_Loss 0.04564589475341178
Test: [ 0/51]	Time 35.646 (35.646)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.127 ( 3.654)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 83.66)	Acc@5  92.19 ( 90.20)
Test: [20/51]	Time  0.163 ( 3.143)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 82.07)	Acc@5  87.50 ( 88.47)
Test: [30/51]	Time  0.130 ( 2.178)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 83.47)	Acc@5  82.81 ( 88.81)
Test: [40/51]	Time  0.134 ( 2.169)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  71.88 ( 83.00)	Acc@5  81.25 ( 88.41)
Test: [50/51]	Time  0.121 ( 2.242)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.45 ( 83.04)	Acc@5  89.09 ( 88.36)
 * Acc@1 83.041 Acc@5 88.356
Epoch: [53][  0/203]	Time 31.628 (31.628)	Data 30.968 (30.968)	Loss 0.0184070467948914 (0.0184070467948914)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [53][ 10/203]	Time  0.583 ( 3.642)	Data  0.001 ( 3.074)	Loss 0.0236536934971809 (0.0271775885061784)	Acc@1 100.00 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [53][ 20/203]	Time  0.670 ( 3.214)	Data  0.000 ( 2.627)	Loss 0.0072513041086495 (0.0310452974933599)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [53][ 30/203]	Time  0.670 ( 2.364)	Data  0.000 ( 1.780)	Loss 0.0323922522366047 (0.0294431274035765)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [53][ 40/203]	Time  0.534 ( 2.399)	Data  0.000 ( 1.813)	Loss 0.0274587124586105 (0.0378461076151125)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [53][ 50/203]	Time  3.651 ( 2.510)	Data  3.053 ( 1.930)	Loss 0.1342585086822510 (0.0406888076560754)	Acc@1  95.31 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [53][ 60/203]	Time  0.505 ( 2.184)	Data  0.000 ( 1.614)	Loss 0.0042417249642313 (0.0389326517737364)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [53][ 70/203]	Time  0.502 ( 2.276)	Data  0.000 ( 1.706)	Loss 0.0135201578959823 (0.0365615150281294)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [53][ 80/203]	Time 17.997 ( 2.278)	Data 17.399 ( 1.711)	Loss 0.0162040330469608 (0.0377774774183140)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [53][ 90/203]	Time  0.513 ( 2.142)	Data  0.000 ( 1.578)	Loss 0.0259321443736553 (0.0383197672455316)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [53][100/203]	Time  0.529 ( 2.199)	Data  0.000 ( 1.629)	Loss 0.0410069637000561 (0.0395303066280477)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [53][110/203]	Time  0.534 ( 2.053)	Data  0.000 ( 1.482)	Loss 0.0226420648396015 (0.0389829675755086)	Acc@1 100.00 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [53][120/203]	Time  0.548 ( 2.110)	Data  0.000 ( 1.543)	Loss 0.0850862190127373 (0.0391473425302100)	Acc@1  95.31 ( 98.80)	Acc@5 100.00 (100.00)
Epoch: [53][130/203]	Time  8.762 ( 2.167)	Data  8.188 ( 1.601)	Loss 0.0520700924098492 (0.0389931237819171)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [53][140/203]	Time  0.552 ( 2.052)	Data  0.000 ( 1.488)	Loss 0.0158479139208794 (0.0379832006829084)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [53][150/203]	Time  0.530 ( 2.111)	Data  0.000 ( 1.547)	Loss 0.0609213300049305 (0.0389895158317187)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [53][160/203]	Time 17.560 ( 2.120)	Data 17.059 ( 1.556)	Loss 0.0393518581986427 (0.0388892578577148)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [53][170/203]	Time  0.610 ( 2.072)	Data  0.001 ( 1.510)	Loss 0.1158945634961128 (0.0389372802282308)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [53][180/203]	Time  0.496 ( 2.106)	Data  0.000 ( 1.544)	Loss 0.0238595027476549 (0.0396736188861156)	Acc@1  98.44 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [53][190/203]	Time  0.494 ( 2.024)	Data  0.000 ( 1.463)	Loss 0.0379135049879551 (0.0407159865275513)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [53][200/203]	Time  0.562 ( 2.060)	Data  0.000 ( 1.499)	Loss 0.0166935771703720 (0.0404232544141048)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 (100.00)
epoch: 53, Avg_Loss 0.040183363355044736
Test: [ 0/51]	Time 27.953 (27.953)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 73.44)	Acc@5  81.25 ( 81.25)
Test: [10/51]	Time  0.173 ( 2.769)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 82.95)	Acc@5  90.62 ( 88.92)
Test: [20/51]	Time  0.119 ( 2.653)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.56 ( 81.62)	Acc@5  84.38 ( 88.10)
Test: [30/51]	Time  0.124 ( 1.893)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.12 ( 82.81)	Acc@5  87.50 ( 88.61)
Test: [40/51]	Time  0.123 ( 2.012)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 83.08)	Acc@5  89.06 ( 88.38)
Test: [50/51]	Time  0.116 ( 2.057)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  70.91 ( 82.67)	Acc@5  76.36 ( 88.05)
 * Acc@1 82.673 Acc@5 88.049
Epoch: [54][  0/203]	Time 33.876 (33.876)	Data 33.339 (33.339)	Loss 0.0080911498516798 (0.0080911498516798)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [54][ 10/203]	Time  0.670 ( 3.602)	Data  0.002 ( 3.031)	Loss 0.0312074217945337 (0.0306789444082163)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [54][ 20/203]	Time  0.616 ( 3.289)	Data  0.000 ( 2.706)	Loss 0.0286847185343504 (0.0388201618389714)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 ( 99.93)
Epoch: [54][ 30/203]	Time  0.503 ( 2.413)	Data  0.000 ( 1.833)	Loss 0.1137060746550560 (0.0454418021404455)	Acc@1  96.88 ( 98.54)	Acc@5  98.44 ( 99.90)
Epoch: [54][ 40/203]	Time  0.601 ( 2.473)	Data  0.000 ( 1.910)	Loss 0.1314622908830643 (0.0446519765253292)	Acc@1  96.88 ( 98.67)	Acc@5 100.00 ( 99.89)
Epoch: [54][ 50/203]	Time  0.661 ( 2.469)	Data  0.000 ( 1.903)	Loss 0.0300959739834070 (0.0434509761467138)	Acc@1  98.44 ( 98.62)	Acc@5 100.00 ( 99.88)
Epoch: [54][ 60/203]	Time  0.529 ( 2.182)	Data  0.000 ( 1.591)	Loss 0.0209921021014452 (0.0428161840870610)	Acc@1 100.00 ( 98.62)	Acc@5 100.00 ( 99.90)
Epoch: [54][ 70/203]	Time  0.543 ( 2.271)	Data  0.000 ( 1.680)	Loss 0.0366826988756657 (0.0409982140753156)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 ( 99.91)
Epoch: [54][ 80/203]	Time 20.853 ( 2.306)	Data 20.274 ( 1.723)	Loss 0.0162250157445669 (0.0405808875371736)	Acc@1 100.00 ( 98.75)	Acc@5 100.00 ( 99.90)
Epoch: [54][ 90/203]	Time  0.506 ( 2.110)	Data  0.000 ( 1.533)	Loss 0.0312656164169312 (0.0391737047664739)	Acc@1  98.44 ( 98.80)	Acc@5 100.00 ( 99.91)
Epoch: [54][100/203]	Time  0.572 ( 2.169)	Data  0.000 ( 1.594)	Loss 0.0459287911653519 (0.0385826117829374)	Acc@1  98.44 ( 98.81)	Acc@5 100.00 ( 99.92)
Epoch: [54][110/203]	Time  0.507 ( 2.027)	Data  0.000 ( 1.453)	Loss 0.0744157955050468 (0.0393103506659401)	Acc@1  96.88 ( 98.79)	Acc@5 100.00 ( 99.93)
Epoch: [54][120/203]	Time  0.522 ( 2.069)	Data  0.000 ( 1.494)	Loss 0.0362614803016186 (0.0389091194807436)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.94)
Epoch: [54][130/203]	Time  0.498 ( 2.115)	Data  0.000 ( 1.545)	Loss 0.0231605302542448 (0.0383159646494243)	Acc@1 100.00 ( 98.80)	Acc@5 100.00 ( 99.94)
Epoch: [54][140/203]	Time  0.681 ( 2.023)	Data  0.000 ( 1.451)	Loss 0.0142841301858425 (0.0391146441630966)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 ( 99.94)
Epoch: [54][150/203]	Time  0.580 ( 2.048)	Data  0.000 ( 1.476)	Loss 0.0093271695077419 (0.0386877251690291)	Acc@1 100.00 ( 98.80)	Acc@5 100.00 ( 99.95)
Epoch: [54][160/203]	Time 17.619 ( 2.090)	Data 17.021 ( 1.519)	Loss 0.0732726454734802 (0.0381745379707365)	Acc@1  98.44 ( 98.85)	Acc@5 100.00 ( 99.95)
Epoch: [54][170/203]	Time  0.553 ( 2.025)	Data  0.001 ( 1.456)	Loss 0.0056018354371190 (0.0390709992116916)	Acc@1 100.00 ( 98.84)	Acc@5 100.00 ( 99.95)
Epoch: [54][180/203]	Time  0.519 ( 2.069)	Data  0.000 ( 1.500)	Loss 0.0370513498783112 (0.0400440558348654)	Acc@1  98.44 ( 98.83)	Acc@5 100.00 ( 99.95)
Epoch: [54][190/203]	Time  0.501 ( 1.994)	Data  0.000 ( 1.426)	Loss 0.0851195678114891 (0.0409978769904890)	Acc@1  95.31 ( 98.77)	Acc@5 100.00 ( 99.95)
Epoch: [54][200/203]	Time  0.506 ( 2.027)	Data  0.000 ( 1.461)	Loss 0.0296214353293180 (0.0409563916494412)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 ( 99.95)
epoch: 54, Avg_Loss 0.04068581635370997
Test: [ 0/51]	Time 28.238 (28.238)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 89.06)	Acc@5  92.19 ( 92.19)
Test: [10/51]	Time  0.145 ( 2.726)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 83.95)	Acc@5  89.06 ( 88.07)
Test: [20/51]	Time  0.131 ( 2.653)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 83.26)	Acc@5  90.62 ( 87.65)
Test: [30/51]	Time  0.138 ( 1.842)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 82.86)	Acc@5  87.50 ( 87.50)
Test: [40/51]	Time  1.842 ( 1.983)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 83.31)	Acc@5  82.81 ( 87.84)
Test: [50/51]	Time  0.113 ( 1.979)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 83.10)	Acc@5  89.09 ( 88.02)
 * Acc@1 83.103 Acc@5 88.018
Epoch: [55][  0/203]	Time 32.965 (32.965)	Data 32.350 (32.350)	Loss 0.0053365458734334 (0.0053365458734334)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [55][ 10/203]	Time  0.532 ( 3.547)	Data  0.001 ( 3.013)	Loss 0.0552874393761158 (0.0310106758790260)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [55][ 20/203]	Time  0.533 ( 3.172)	Data  0.001 ( 2.610)	Loss 0.0137252379208803 (0.0308803504865084)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [55][ 30/203]	Time  0.522 ( 2.328)	Data  0.000 ( 1.768)	Loss 0.0365952104330063 (0.0332389706745744)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 ( 99.95)
Epoch: [55][ 40/203]	Time  0.546 ( 2.444)	Data  0.000 ( 1.869)	Loss 0.0199648607522249 (0.0313018518840758)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 ( 99.96)
Epoch: [55][ 50/203]	Time  0.533 ( 2.452)	Data  0.000 ( 1.882)	Loss 0.0097552891820669 (0.0311810465041073)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 ( 99.97)
Epoch: [55][ 60/203]	Time  0.581 ( 2.140)	Data  0.000 ( 1.573)	Loss 0.0058397143147886 (0.0336873852208898)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 ( 99.95)
Epoch: [55][ 70/203]	Time  0.533 ( 2.194)	Data  0.000 ( 1.631)	Loss 0.0084420200437307 (0.0334240822203484)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 ( 99.96)
Epoch: [55][ 80/203]	Time 23.733 ( 2.277)	Data 23.168 ( 1.716)	Loss 0.0545924678444862 (0.0348124433334710)	Acc@1  96.88 ( 98.84)	Acc@5 100.00 ( 99.96)
Epoch: [55][ 90/203]	Time  0.635 ( 2.091)	Data  0.001 ( 1.528)	Loss 0.0306059084832668 (0.0352570664682579)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 ( 99.95)
Epoch: [55][100/203]	Time  0.543 ( 2.155)	Data  0.001 ( 1.592)	Loss 0.0290259942412376 (0.0357612682665505)	Acc@1 100.00 ( 98.84)	Acc@5 100.00 ( 99.95)
Epoch: [55][110/203]	Time  0.509 ( 2.006)	Data  0.000 ( 1.449)	Loss 0.0514936149120331 (0.0361689163323676)	Acc@1  96.88 ( 98.83)	Acc@5 100.00 ( 99.96)
Epoch: [55][120/203]	Time  0.678 ( 2.071)	Data  0.000 ( 1.514)	Loss 0.0730107873678207 (0.0350938890377552)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 ( 99.96)
Epoch: [55][130/203]	Time  0.523 ( 2.116)	Data  0.000 ( 1.557)	Loss 0.0251267347484827 (0.0344049321569303)	Acc@1 100.00 ( 98.91)	Acc@5 100.00 ( 99.96)
Epoch: [55][140/203]	Time  0.529 ( 2.004)	Data  0.000 ( 1.446)	Loss 0.0135621707886457 (0.0339783120665911)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.97)
Epoch: [55][150/203]	Time  0.512 ( 2.049)	Data  0.000 ( 1.493)	Loss 0.0065382705070078 (0.0350351988674074)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 ( 99.96)
Epoch: [55][160/203]	Time 23.648 ( 2.098)	Data 23.070 ( 1.544)	Loss 0.0035091612953693 (0.0342489667959881)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.96)
Epoch: [55][170/203]	Time  0.520 ( 2.006)	Data  0.001 ( 1.453)	Loss 0.0404849424958229 (0.0348618486378756)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.96)
Epoch: [55][180/203]	Time  0.498 ( 2.062)	Data  0.000 ( 1.509)	Loss 0.0109920455142856 (0.0343950556987351)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.97)
Epoch: [55][190/203]	Time  0.534 ( 1.981)	Data  0.000 ( 1.430)	Loss 0.0045225857757032 (0.0340210981081918)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 ( 99.97)
Epoch: [55][200/203]	Time  0.557 ( 2.021)	Data  0.000 ( 1.471)	Loss 0.0558216050267220 (0.0341549610895156)	Acc@1  96.88 ( 98.88)	Acc@5 100.00 ( 99.97)
epoch: 55, Avg_Loss 0.034252568767428986
Test: [ 0/51]	Time 27.113 (27.113)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  82.81 ( 82.81)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.163 ( 2.753)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 83.66)	Acc@5  93.75 ( 88.78)
Test: [20/51]	Time  0.126 ( 2.596)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 83.85)	Acc@5  90.62 ( 89.43)
Test: [30/51]	Time  0.124 ( 1.800)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 83.47)	Acc@5  93.75 ( 88.96)
Test: [40/51]	Time  0.126 ( 1.904)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 82.74)	Acc@5  81.25 ( 88.34)
Test: [50/51]	Time  0.122 ( 1.940)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  78.18 ( 82.64)	Acc@5  80.00 ( 87.96)
 * Acc@1 82.642 Acc@5 87.957
Epoch: [56][  0/203]	Time 30.845 (30.845)	Data 30.251 (30.251)	Loss 0.0326619893312454 (0.0326619893312454)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [56][ 10/203]	Time  0.484 ( 3.371)	Data  0.001 ( 2.824)	Loss 0.0714734122157097 (0.0262173670767383)	Acc@1  96.88 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [56][ 20/203]	Time  0.565 ( 3.379)	Data  0.000 ( 2.841)	Loss 0.0273882318288088 (0.0278166510009517)	Acc@1 100.00 ( 99.33)	Acc@5 100.00 (100.00)
Epoch: [56][ 30/203]	Time  0.477 ( 2.454)	Data  0.000 ( 1.925)	Loss 0.0535651110112667 (0.0317051854367638)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [56][ 40/203]	Time  0.617 ( 2.576)	Data  0.000 ( 2.041)	Loss 0.0596461780369282 (0.0320362799159228)	Acc@1  96.88 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [56][ 50/203]	Time  0.683 ( 2.843)	Data  0.000 ( 2.289)	Loss 0.0557486079633236 (0.0314038742091689)	Acc@1  98.44 ( 99.08)	Acc@5  98.44 ( 99.97)
Epoch: [56][ 60/203]	Time  0.657 ( 2.474)	Data  0.000 ( 1.914)	Loss 0.0388313755393028 (0.0316236509357533)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 ( 99.97)
Epoch: [56][ 70/203]	Time  0.513 ( 2.625)	Data  0.000 ( 2.063)	Loss 0.0310610421001911 (0.0327697830048429)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 ( 99.98)
Epoch: [56][ 80/203]	Time 20.402 ( 2.609)	Data 19.729 ( 2.052)	Loss 0.0477015599608421 (0.0332313916217651)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 ( 99.96)
Epoch: [56][ 90/203]	Time  0.705 ( 2.384)	Data  0.000 ( 1.826)	Loss 0.0089033944532275 (0.0327232115387732)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 ( 99.97)
Epoch: [56][100/203]	Time  0.480 ( 2.465)	Data  0.000 ( 1.906)	Loss 0.0115269292145967 (0.0320190229478504)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 ( 99.97)
Epoch: [56][110/203]	Time  0.607 ( 2.288)	Data  0.000 ( 1.734)	Loss 0.0279310643672943 (0.0309029606932371)	Acc@1  98.44 ( 99.16)	Acc@5 100.00 ( 99.97)
Epoch: [56][120/203]	Time  0.501 ( 2.370)	Data  0.000 ( 1.817)	Loss 0.0279599130153656 (0.0320733029708990)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 ( 99.96)
Epoch: [56][130/203]	Time  0.689 ( 2.408)	Data  0.000 ( 1.854)	Loss 0.0320176742970943 (0.0321363301313205)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 ( 99.96)
Epoch: [56][140/203]	Time  0.511 ( 2.277)	Data  0.000 ( 1.722)	Loss 0.0792076215147972 (0.0328914799144597)	Acc@1  96.88 ( 99.10)	Acc@5 100.00 ( 99.97)
Epoch: [56][150/203]	Time  0.505 ( 2.351)	Data  0.000 ( 1.796)	Loss 0.0369832552969456 (0.0330426023913769)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 ( 99.97)
Epoch: [56][160/203]	Time 22.184 ( 2.370)	Data 21.545 ( 1.818)	Loss 0.0060457033105195 (0.0333766466410113)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.97)
Epoch: [56][170/203]	Time  0.522 ( 2.291)	Data  0.001 ( 1.737)	Loss 0.0113288313150406 (0.0329743740087571)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 ( 99.97)
Epoch: [56][180/203]	Time  0.505 ( 2.331)	Data  0.000 ( 1.777)	Loss 0.0173142366111279 (0.0332706388573610)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 ( 99.97)
Epoch: [56][190/203]	Time  0.509 ( 2.238)	Data  0.000 ( 1.684)	Loss 0.0117072807624936 (0.0331302775181001)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 ( 99.98)
Epoch: [56][200/203]	Time  0.466 ( 2.287)	Data  0.000 ( 1.734)	Loss 0.0242138393223286 (0.0334583700892854)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 ( 99.97)
epoch: 56, Avg_Loss 0.03388371941085281
Test: [ 0/51]	Time 26.340 (26.340)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 79.69)	Acc@5  87.50 ( 87.50)
Test: [10/51]	Time  0.204 ( 2.679)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 85.23)	Acc@5  92.19 ( 89.63)
Test: [20/51]	Time  0.130 ( 2.437)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  90.62 ( 83.33)	Acc@5  92.19 ( 88.24)
Test: [30/51]	Time  0.130 ( 1.694)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 83.11)	Acc@5  89.06 ( 88.21)
Test: [40/51]	Time  0.126 ( 1.860)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  75.00 ( 82.66)	Acc@5  82.81 ( 88.07)
Test: [50/51]	Time  0.110 ( 1.984)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.27 ( 82.76)	Acc@5  87.27 ( 88.11)
 * Acc@1 82.765 Acc@5 88.111
Epoch: [57][  0/203]	Time 32.631 (32.631)	Data 31.978 (31.978)	Loss 0.0045612086541951 (0.0045612086541951)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [57][ 10/203]	Time  0.659 ( 3.861)	Data  0.004 ( 3.271)	Loss 0.0077249235473573 (0.0289227598431436)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.86)
Epoch: [57][ 20/203]	Time  0.679 ( 3.341)	Data  0.001 ( 2.754)	Loss 0.0128941768780351 (0.0327433901617215)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 ( 99.93)
Epoch: [57][ 30/203]	Time  0.592 ( 2.461)	Data  0.000 ( 1.866)	Loss 0.0119732310995460 (0.0285964392636332)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 ( 99.95)
Epoch: [57][ 40/203]	Time  0.524 ( 2.610)	Data  0.000 ( 2.029)	Loss 0.0468504801392555 (0.0308632488226200)	Acc@1  98.44 ( 99.24)	Acc@5 100.00 ( 99.92)
Epoch: [57][ 50/203]	Time  3.356 ( 2.629)	Data  2.836 ( 2.047)	Loss 0.0098561346530914 (0.0345968564552273)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 ( 99.94)
Epoch: [57][ 60/203]	Time  0.494 ( 2.292)	Data  0.000 ( 1.711)	Loss 0.0314693599939346 (0.0338512894957036)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 ( 99.95)
Epoch: [57][ 70/203]	Time  0.551 ( 2.332)	Data  0.000 ( 1.752)	Loss 0.0541427992284298 (0.0335181222861292)	Acc@1  96.88 ( 99.10)	Acc@5 100.00 ( 99.96)
Epoch: [57][ 80/203]	Time 15.315 ( 2.304)	Data 14.693 ( 1.717)	Loss 0.0064557115547359 (0.0343906169205352)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 ( 99.96)
Epoch: [57][ 90/203]	Time  0.510 ( 2.183)	Data  0.000 ( 1.601)	Loss 0.0525111258029938 (0.0333777579714309)	Acc@1  98.44 ( 99.12)	Acc@5 100.00 ( 99.97)
Epoch: [57][100/203]	Time  0.581 ( 2.343)	Data  0.000 ( 1.757)	Loss 0.0322026573121548 (0.0331671512455191)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 ( 99.97)
Epoch: [57][110/203]	Time  0.498 ( 2.185)	Data  0.000 ( 1.599)	Loss 0.0365277901291847 (0.0332943744923886)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 ( 99.97)
Epoch: [57][120/203]	Time  0.590 ( 2.261)	Data  0.000 ( 1.673)	Loss 0.0196209419518709 (0.0340064060220048)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 ( 99.97)
Epoch: [57][130/203]	Time  8.201 ( 2.274)	Data  7.627 ( 1.686)	Loss 0.0142050990834832 (0.0345455422119472)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 ( 99.98)
Epoch: [57][140/203]	Time  0.526 ( 2.154)	Data  0.000 ( 1.566)	Loss 0.0076890741474926 (0.0339763215165057)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.98)
Epoch: [57][150/203]	Time  0.546 ( 2.171)	Data  0.000 ( 1.586)	Loss 0.0671087354421616 (0.0340605968600201)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 ( 99.98)
Epoch: [57][160/203]	Time 15.736 ( 2.170)	Data 15.162 ( 1.582)	Loss 0.0470590740442276 (0.0342699291650206)	Acc@1  96.88 ( 98.96)	Acc@5 100.00 ( 99.98)
Epoch: [57][170/203]	Time  0.528 ( 2.117)	Data  0.001 ( 1.529)	Loss 0.0399621538817883 (0.0349616622075722)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 ( 99.97)
Epoch: [57][180/203]	Time  0.520 ( 2.147)	Data  0.000 ( 1.557)	Loss 0.0615711882710457 (0.0353736017035701)	Acc@1  96.88 ( 98.93)	Acc@5 100.00 ( 99.97)
Epoch: [57][190/203]	Time  0.523 ( 2.063)	Data  0.000 ( 1.475)	Loss 0.0058781285770237 (0.0350208360840766)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 ( 99.98)
Epoch: [57][200/203]	Time  1.711 ( 2.089)	Data  1.234 ( 1.503)	Loss 0.0481066554784775 (0.0347189822370900)	Acc@1  96.88 ( 98.94)	Acc@5 100.00 ( 99.98)
epoch: 57, Avg_Loss 0.03453996186282284
Test: [ 0/51]	Time 21.107 (21.107)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  90.62 ( 90.62)	Acc@5  93.75 ( 93.75)
Test: [10/51]	Time  0.135 ( 2.264)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.94)	Acc@5  90.62 ( 89.06)
Test: [20/51]	Time  0.267 ( 1.895)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 84.67)	Acc@5  89.06 ( 88.62)
Test: [30/51]	Time  0.151 ( 1.333)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 83.11)	Acc@5  85.94 ( 87.65)
Test: [40/51]	Time  0.124 ( 1.523)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 83.19)	Acc@5  89.06 ( 88.03)
Test: [50/51]	Time  4.119 ( 1.539)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.82 ( 82.98)	Acc@5  81.82 ( 87.90)
 * Acc@1 82.980 Acc@5 87.896
Epoch: [58][  0/203]	Time 36.406 (36.406)	Data 35.883 (35.883)	Loss 0.0212561208754778 (0.0212561208754778)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [58][ 10/203]	Time  0.533 ( 3.810)	Data  0.001 ( 3.262)	Loss 0.0057492814958096 (0.0349840427833525)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 ( 99.86)
Epoch: [58][ 20/203]	Time  0.536 ( 3.347)	Data  0.000 ( 2.813)	Loss 0.1211172565817833 (0.0420967830522429)	Acc@1  93.75 ( 98.66)	Acc@5 100.00 ( 99.85)
Epoch: [58][ 30/203]	Time  0.601 ( 2.482)	Data  0.000 ( 1.906)	Loss 0.0363446772098541 (0.0428393527662622)	Acc@1  98.44 ( 98.54)	Acc@5 100.00 ( 99.90)
Epoch: [58][ 40/203]	Time  0.606 ( 2.465)	Data  0.000 ( 1.878)	Loss 0.0239979512989521 (0.0424859819326141)	Acc@1 100.00 ( 98.55)	Acc@5 100.00 ( 99.92)
Epoch: [58][ 50/203]	Time  0.872 ( 2.524)	Data  0.003 ( 1.928)	Loss 0.0279735866934061 (0.0419287629557920)	Acc@1  98.44 ( 98.56)	Acc@5 100.00 ( 99.94)
Epoch: [58][ 60/203]	Time  0.579 ( 2.204)	Data  0.000 ( 1.612)	Loss 0.0062274122610688 (0.0377651153296446)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 ( 99.95)
Epoch: [58][ 70/203]	Time  0.551 ( 2.244)	Data  0.000 ( 1.651)	Loss 0.0200482085347176 (0.0362907599011751)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 ( 99.96)
Epoch: [58][ 80/203]	Time 17.610 ( 2.268)	Data 16.921 ( 1.676)	Loss 0.0306438468396664 (0.0357959103514728)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 ( 99.96)
Epoch: [58][ 90/203]	Time  0.584 ( 2.127)	Data  0.000 ( 1.534)	Loss 0.0243488159030676 (0.0345872486724037)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 ( 99.95)
Epoch: [58][100/203]	Time  0.527 ( 2.131)	Data  0.000 ( 1.537)	Loss 0.1722923517227173 (0.0364772318159276)	Acc@1  96.88 ( 98.89)	Acc@5  98.44 ( 99.92)
Epoch: [58][110/203]	Time  0.689 ( 2.026)	Data  0.000 ( 1.425)	Loss 0.0075944229029119 (0.0357896853521517)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 ( 99.93)
Epoch: [58][120/203]	Time  0.497 ( 2.060)	Data  0.000 ( 1.460)	Loss 0.0153235401958227 (0.0346781620977077)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 ( 99.94)
Epoch: [58][130/203]	Time  0.541 ( 2.093)	Data  0.000 ( 1.496)	Loss 0.0106606809422374 (0.0352010556864588)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 ( 99.94)
Epoch: [58][140/203]	Time  0.748 ( 2.012)	Data  0.001 ( 1.404)	Loss 0.0451669655740261 (0.0350435450161206)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 ( 99.94)
Epoch: [58][150/203]	Time  0.657 ( 2.047)	Data  0.000 ( 1.431)	Loss 0.0351398065686226 (0.0352447439765323)	Acc@1  98.44 ( 98.91)	Acc@5 100.00 ( 99.95)
Epoch: [58][160/203]	Time 20.621 ( 2.085)	Data 19.883 ( 1.465)	Loss 0.0124550918117166 (0.0365574844369538)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 ( 99.95)
Epoch: [58][170/203]	Time  0.629 ( 1.997)	Data  0.001 ( 1.380)	Loss 0.0265213511884212 (0.0358993451843550)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.95)
Epoch: [58][180/203]	Time  0.657 ( 2.033)	Data  0.000 ( 1.415)	Loss 0.0164874959737062 (0.0358815789261308)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 ( 99.96)
Epoch: [58][190/203]	Time  0.506 ( 1.959)	Data  0.000 ( 1.344)	Loss 0.0601001046597958 (0.0362559417835607)	Acc@1  96.88 ( 98.93)	Acc@5 100.00 ( 99.96)
Epoch: [58][200/203]	Time  0.659 ( 1.999)	Data  0.000 ( 1.385)	Loss 0.0366545878350735 (0.0357702689150358)	Acc@1  98.44 ( 98.95)	Acc@5 100.00 ( 99.96)
epoch: 58, Avg_Loss 0.035589010072780286
Test: [ 0/51]	Time 24.768 (24.768)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  85.94 ( 85.94)	Acc@5  85.94 ( 85.94)
Test: [10/51]	Time  0.160 ( 2.415)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 83.52)	Acc@5  85.94 ( 88.35)
Test: [20/51]	Time  0.133 ( 2.316)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.50 ( 83.33)	Acc@5  93.75 ( 88.24)
Test: [30/51]	Time  0.122 ( 1.613)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  73.44 ( 83.27)	Acc@5  79.69 ( 88.31)
Test: [40/51]	Time  0.138 ( 1.793)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  81.25 ( 82.81)	Acc@5  90.62 ( 88.34)
Test: [50/51]	Time  0.113 ( 1.842)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  87.27 ( 82.80)	Acc@5  92.73 ( 88.36)
 * Acc@1 82.796 Acc@5 88.356
Epoch: [59][  0/203]	Time 33.118 (33.118)	Data 32.485 (32.485)	Loss 0.0331991910934448 (0.0331991910934448)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [59][ 10/203]	Time  0.745 ( 3.692)	Data  0.001 ( 3.055)	Loss 0.1063104569911957 (0.0409969285299832)	Acc@1  96.88 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [59][ 20/203]	Time  0.545 ( 3.381)	Data  0.000 ( 2.757)	Loss 0.0322156585752964 (0.0467125691163043)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 ( 99.93)
Epoch: [59][ 30/203]	Time  0.538 ( 2.479)	Data  0.000 ( 1.868)	Loss 0.1047378107905388 (0.0429855285723123)	Acc@1  95.31 ( 98.49)	Acc@5 100.00 ( 99.95)
Epoch: [59][ 40/203]	Time  0.520 ( 2.523)	Data  0.000 ( 1.911)	Loss 0.1062900424003601 (0.0430248000590903)	Acc@1  95.31 ( 98.59)	Acc@5 100.00 ( 99.92)
Epoch: [59][ 50/203]	Time 10.174 ( 2.580)	Data  9.627 ( 1.981)	Loss 0.0203104447573423 (0.0385300946472140)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 ( 99.94)
Epoch: [59][ 60/203]	Time  0.641 ( 2.273)	Data  0.000 ( 1.656)	Loss 0.0252374541014433 (0.0393887526092318)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 ( 99.95)
Epoch: [59][ 70/203]	Time  0.512 ( 2.286)	Data  0.000 ( 1.671)	Loss 0.0101620070636272 (0.0401625035537249)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 ( 99.96)
Epoch: [59][ 80/203]	Time 13.121 ( 2.229)	Data 12.510 ( 1.619)	Loss 0.0207502879202366 (0.0405686160615634)	Acc@1 100.00 ( 98.69)	Acc@5 100.00 ( 99.96)
Epoch: [59][ 90/203]	Time  0.533 ( 2.135)	Data  0.000 ( 1.525)	Loss 0.0578629225492477 (0.0397804124667156)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 ( 99.97)
Epoch: [59][100/203]	Time  0.685 ( 2.213)	Data  0.000 ( 1.605)	Loss 0.0153760490939021 (0.0384554630641060)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.97)
Epoch: [59][110/203]	Time  0.589 ( 2.066)	Data  0.000 ( 1.461)	Loss 0.0298257190734148 (0.0377596127286738)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 ( 99.96)
Epoch: [59][120/203]	Time  0.589 ( 2.108)	Data  0.000 ( 1.506)	Loss 0.0035447927657515 (0.0365329261586332)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 ( 99.96)
Epoch: [59][130/203]	Time 11.243 ( 2.162)	Data 10.720 ( 1.562)	Loss 0.0062173753976822 (0.0374822936363817)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.96)
Epoch: [59][140/203]	Time  0.685 ( 2.049)	Data  0.000 ( 1.451)	Loss 0.0096811354160309 (0.0372970773787271)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 ( 99.97)
Epoch: [59][150/203]	Time  0.699 ( 2.081)	Data  0.000 ( 1.480)	Loss 0.0160744823515415 (0.0379586000718633)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 ( 99.96)
Epoch: [59][160/203]	Time  7.912 ( 2.033)	Data  7.270 ( 1.433)	Loss 0.0192402340471745 (0.0390478616923105)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.96)
Epoch: [59][170/203]	Time  0.641 ( 2.032)	Data  0.001 ( 1.433)	Loss 0.0272825863212347 (0.0389517511286070)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.95)
Epoch: [59][180/203]	Time  2.645 ( 2.076)	Data  2.114 ( 1.477)	Loss 0.0210373643785715 (0.0386609681142309)	Acc@1 100.00 ( 98.75)	Acc@5 100.00 ( 99.96)
Epoch: [59][190/203]	Time  0.586 ( 1.996)	Data  0.000 ( 1.400)	Loss 0.0138509953394532 (0.0387850540686467)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 ( 99.95)
Epoch: [59][200/203]	Time  0.591 ( 2.030)	Data  0.024 ( 1.433)	Loss 0.0139005761593580 (0.0384150651863901)	Acc@1 100.00 ( 98.80)	Acc@5 100.00 ( 99.95)
epoch: 59, Avg_Loss 0.03847765500755898
Test: [ 0/51]	Time 24.609 (24.609)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 84.38)	Acc@5  90.62 ( 90.62)
Test: [10/51]	Time  0.132 ( 2.604)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  84.38 ( 81.96)	Acc@5  89.06 ( 86.65)
Test: [20/51]	Time  2.027 ( 2.447)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  79.69 ( 82.07)	Acc@5  82.81 ( 86.83)
Test: [30/51]	Time  0.128 ( 1.831)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 82.71)	Acc@5  89.06 ( 87.50)
Test: [40/51]	Time  0.150 ( 1.947)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  89.06 ( 83.04)	Acc@5  89.06 ( 88.19)
Test: [50/51]	Time  0.126 ( 1.867)	Loss 0.0000e+00 (0.0000e+00)	Acc@1  76.36 ( 82.92)	Acc@5  87.27 ( 88.02)
 * Acc@1 82.919 Acc@5 88.018
best_acc1: tensor(83.4716, device='cuda:4')
